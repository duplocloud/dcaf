{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"DCAF - DuploCloud Agent Framework","text":"<p>DCAF (DuploCloud Agent Framework) is a Python framework for building LLM-powered AI agents with tool calling and human-in-the-loop approval.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from dcaf.core import Agent, serve\nfrom dcaf.tools import tool\n\n# 1. Define tools\n@tool(description=\"List Kubernetes pods\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n\n@tool(requires_approval=True, description=\"Delete a pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n\n# 2. Create an agent\nagent = Agent(tools=[list_pods, delete_pod])\n\n# 3. Serve it\nserve(agent)  # Running at http://0.0.0.0:8000\n</code></pre> <p>Test it:</p> <pre><code>curl -X POST http://localhost:8000/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"messages\": [{\"role\": \"user\", \"content\": \"What pods are running?\"}]}'\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"Feature Description \ud83d\udee0\ufe0f Tool Calling Easy decorator-based tool definitions with auto-generated, dict, or Pydantic schemas \u2705 Human-in-the-Loop Built-in approval flow for dangerous operations \ud83d\udd0c Interceptors Hook into request/response for validation, context, security \ud83d\udd04 Framework Adapters Swap LLM frameworks (Agno, Strands, LangChain) with one parameter \ud83d\udd17 HelpDesk Protocol Full compatibility with DuploCloud HelpDesk messaging \ud83c\udf10 REST API One-line server with <code>serve(agent)</code> \ud83d\udce1 Streaming Real-time token-by-token responses \ud83d\udd00 Custom Logic Build agents with any structure you need \ud83d\udd27 MCP Integration Connect to external MCP servers and use their tools"},{"location":"#architecture","title":"Architecture","text":""},{"location":"#how-it-works","title":"How It Works","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Your Code                                \u2502\n\u2502                                                                  \u2502\n\u2502   agent = Agent(tools=[...])    OR    def my_agent(messages, ctx)\u2502\n\u2502   serve(agent)                        serve(my_agent)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        DCAF Core                                 \u2502\n\u2502                                                                  \u2502\n\u2502   1. Receives HTTP request from HelpDesk                        \u2502\n\u2502   2. Converts to simple message format                          \u2502\n\u2502   3. Runs your agent logic                                      \u2502\n\u2502   4. Handles tool approvals automatically                       \u2502\n\u2502   5. Returns response in HelpDesk protocol                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    LLM (AWS Bedrock)                             \u2502\n\u2502                                                                  \u2502\n\u2502   Claude 3.5 Sonnet / Claude 4 / etc.                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#requestresponse-flow","title":"Request/Response Flow","text":"<pre><code>  DuploCloud HelpDesk                      Your Agent\n         \u2502                                      \u2502\n         \u2502  POST /api/chat                      \u2502\n         \u2502  {\"messages\": [...]}                 \u2502\n         \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502\n         \u2502                                      \u2502\n         \u2502                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                              \u2502 Agent.run()   \u2502\n         \u2502                              \u2502 calls LLM     \u2502\n         \u2502                              \u2502 with tools    \u2502\n         \u2502                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                                      \u2502\n         \u2502  Tool needs approval?                \u2502\n         \u2502  \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n         \u2502  {\"tool_calls\": [...]}               \u2502\n         \u2502                                      \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510                                 \u2502\n    \u2502  User   \u2502                                 \u2502\n    \u2502 Approves\u2502                                 \u2502\n    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                                 \u2502\n         \u2502                                      \u2502\n         \u2502  POST /api/chat                      \u2502\n         \u2502  {tool_calls: [execute: true]}       \u2502\n         \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502\n         \u2502                                      \u2502\n         \u2502                              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                              \u2502 Execute tool  \u2502\n         \u2502                              \u2502 Return result \u2502\n         \u2502                              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                                      \u2502\n         \u2502  {\"content\": \"Done!\", ...}           \u2502\n         \u2502  \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502\n</code></pre>"},{"location":"#component-overview","title":"Component Overview","text":"Component What It Does Agent Your LLM-powered assistant with tools Tools Functions the agent can call (with optional approval) serve() Runs your agent as a REST API HelpDesk Protocol Message format for DuploCloud integration <p>For internal architecture details, see Engineering Handoff.</p>"},{"location":"#two-ways-to-build-agents","title":"Two Ways to Build Agents","text":""},{"location":"#option-1-simple-agent-class","title":"Option 1: Simple (Agent Class)","text":"<p>For most use cases:</p> <pre><code>from dcaf.core import Agent, serve\n\nagent = Agent(\n    tools=[list_pods, delete_pod],\n    system=\"You are a Kubernetes assistant.\",\n)\nserve(agent)\n</code></pre>"},{"location":"#option-2-custom-function","title":"Option 2: Custom Function","text":"<p>For complex logic (multiple LLM calls, branching, etc.):</p> <pre><code>from dcaf.core import Agent, AgentResult, serve\n\ndef my_agent(messages: list, context: dict) -&gt; AgentResult:\n    # Classify intent\n    classifier = Agent(system=\"Classify as: query or action\")\n    intent = classifier.run(messages)\n\n    if \"action\" in intent.text:\n        # Use tools for actions\n        executor = Agent(tools=[...])\n        result = executor.run(messages)\n        return AgentResult(text=result.text, ...)\n\n    return AgentResult(text=intent.text)\n\nserve(my_agent)\n</code></pre> <p>See Custom Agents Guide for patterns.</p>"},{"location":"#endpoints","title":"Endpoints","text":"Endpoint Method Description <code>/health</code> GET Health check <code>/api/chat</code> POST Synchronous chat <code>/api/chat-stream</code> POST Streaming (NDJSON)"},{"location":"#tool-approval","title":"Tool Approval","text":"<p>Tools that modify state should require approval:</p> <pre><code>@tool(requires_approval=True, description=\"Delete a pod\")\ndef delete_pod(name: str) -&gt; str:\n    return kubectl(f\"delete pod {name}\")\n</code></pre> <p>The agent will pause and ask for approval before executing.</p>"},{"location":"#documentation","title":"Documentation","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation &amp; Quick Start</li> </ul>"},{"location":"#core-framework","title":"Core Framework","text":"<ul> <li>Core Overview - The Agent class and API</li> <li>Server - Running agents as REST APIs</li> <li>HelpDesk Protocol - Full DuploCloud HelpDesk compatibility</li> <li>Framework Adapters - Swap between Agno, Strands, LangChain</li> <li>Interceptors Guide - Hook into request/response pipeline</li> <li>Custom Agents Guide - Building complex agents</li> </ul>"},{"location":"#reference","title":"Reference","text":"<ul> <li>Tools - Creating tools with <code>@tool</code></li> <li>MCP Tools - Connect to external MCP servers</li> <li>Schemas - Message format reference</li> <li>Streaming - Streaming responses</li> </ul>"},{"location":"#architecture_1","title":"Architecture","text":"<ul> <li>Architecture Guide - How DCAF works internally</li> <li>Engineering Handoff - Team handoff documentation</li> <li>Architecture Decision Records - Design decisions</li> </ul>"},{"location":"#legacy-v1","title":"Legacy (v1)","text":"<p>The original API is still available for existing integrations:</p> <ul> <li>BedrockLLM - Direct Bedrock access</li> <li>Agents (v1) - Legacy agent classes</li> <li>Agent Server - Legacy server setup</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code># From GitHub\npip install git+https://github.com/duplocloud/service-desk-agents.git\n\n# For development\ngit clone https://github.com/duplocloud/service-desk-agents.git\ncd service-desk-agents\npip install -r requirements.txt\n</code></pre>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.12+</li> <li>AWS credentials with Bedrock access</li> <li>Dependencies: <code>fastapi</code>, <code>pydantic</code>, <code>uvicorn</code>, <code>boto3</code></li> </ul>"},{"location":"#license","title":"License","text":"<p>MIT License - See LICENSE for details.</p>"},{"location":"#support","title":"Support","text":"<ul> <li>GitHub Issues: service-desk-agents</li> <li>DuploCloud Support: support@duplocloud.com</li> </ul>"},{"location":"agno-bug-report/","title":"Agno Bug Report: Empty List Content Returns \"[]\" String","text":""},{"location":"agno-bug-report/#issue-title","title":"Issue Title","text":"<p><code>[fix] get_content_string() returns \"[]\" for empty content list, causing concatenation issues</code></p>"},{"location":"agno-bug-report/#description","title":"Description","text":"<p>When a model response contains an empty content list <code>[]</code> (common after tool execution when the model has nothing more to say), the <code>Message.get_content_string()</code> method returns the literal string <code>\"[]\"</code> via <code>json.dumps([])</code> instead of returning an empty string.</p> <p>This string then gets concatenated to existing content in <code>base.py</code>, resulting in malformed responses like:</p> <pre><code>\"I'll help you execute the command.[]\"\n</code></pre>"},{"location":"agno-bug-report/#environment","title":"Environment","text":"<ul> <li>Agno Version: Confirmed in 2.3.21 and 2.3.26</li> <li>Model Provider: AWS Bedrock (Claude 3.5 Sonnet)</li> <li>Python Version: 3.13</li> <li>OS: macOS / Linux</li> </ul>"},{"location":"agno-bug-report/#steps-to-reproduce","title":"Steps to Reproduce","text":"<pre><code>from agno.agent import Agent\nfrom agno.models.aws import AwsBedrock\nfrom agno.tools import tool\nimport aioboto3\nimport asyncio\n\n@tool(name=\"run_cmd\", description=\"Run a terminal command\")\ndef run_cmd(command: str) -&gt; str:\n    return f\"Executed: {command}\"\n\nasync def main():\n    async_session = aioboto3.Session(region_name=\"us-west-2\")\n    model = AwsBedrock(\n        id=\"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n        aws_region=\"us-west-2\",\n        async_session=async_session,\n    )\n\n    agent = Agent(\n        model=model,\n        tools=[run_cmd],\n        instructions=\"Use the run_cmd tool when asked to execute commands.\",\n    )\n\n    run_output = await agent.arun(\"Execute: echo hello\")\n\n    print(f\"Content: {repr(run_output.content)}\")\n    print(f\"Content ends with '[]': {run_output.content.endswith('[]')}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"agno-bug-report/#expected-output","title":"Expected Output","text":"<pre><code>Content: \"I'll help you execute the echo command.\"\nContent ends with '[]': False\n</code></pre>"},{"location":"agno-bug-report/#actual-output","title":"Actual Output","text":"<pre><code>Content: \"I'll help you execute the echo command.[]\"\nContent ends with '[]': True\n</code></pre>"},{"location":"agno-bug-report/#root-cause-analysis","title":"Root Cause Analysis","text":""},{"location":"agno-bug-report/#location-1-libsagnoagnomodelsmessagepy-lines-127-131","title":"Location 1: <code>libs/agno/agno/models/message.py</code> (lines 127-131)","text":"<pre><code>def get_content_string(self) -&gt; str:\n    \"\"\"Returns the content as a string.\"\"\"\n    if isinstance(self.content, str):\n        return self.content\n    if isinstance(self.content, list):\n        if len(self.content) &gt; 0 and isinstance(self.content[0], dict) and \"text\" in self.content[0]:\n            return self.content[0].get(\"text\", \"\")\n        else:\n            return json.dumps(self.content)  # BUG: Returns \"[]\" for empty list!\n    return \"\"\n</code></pre> <p>When <code>self.content = []</code> (empty list): 1. <code>isinstance(self.content, list)</code> evaluates to <code>True</code> 2. <code>len(self.content) &gt; 0</code> evaluates to <code>False</code> (empty list) 3. Falls through to <code>else: return json.dumps(self.content)</code> which returns <code>\"[]\"</code></p>"},{"location":"agno-bug-report/#location-2-libsagnoagnomodelsbasepy-line-1117","title":"Location 2: <code>libs/agno/agno/models/base.py</code> (line 1117)","text":"<pre><code>if assistant_message.content is not None:\n    if model_response.content is None:\n        model_response.content = assistant_message.get_content_string()\n    else:\n        model_response.content += assistant_message.get_content_string()  # Concatenates \"[]\"\n</code></pre>"},{"location":"agno-bug-report/#why-empty-list-occurs","title":"Why Empty List Occurs","text":"<p>After tool execution, if the model has nothing additional to say, AWS Bedrock returns:</p> <pre><code>{\n  \"output\": {\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": []\n    }\n  }\n}\n</code></pre> <p>The Bedrock parser in <code>libs/agno/agno/models/aws/bedrock.py</code> (lines 698-702) preserves this empty list:</p> <pre><code># Extract text content if it's a list of dictionaries\nif isinstance(content, list) and content and isinstance(content[0], dict):\n    # This condition is False for empty list (content is falsy)\n    content = [item.get(\"text\", \"\") for item in content if \"text\" in item]\n    content = \"\\n\".join(content)\n\nmodel_response.content = content  # Sets content to [] when list is empty\n</code></pre>"},{"location":"agno-bug-report/#suggested-fix","title":"Suggested Fix","text":""},{"location":"agno-bug-report/#option-a-fix-in-get_content_string-recommended","title":"Option A: Fix in <code>get_content_string()</code> (Recommended)","text":"<p>This fix handles all model providers, not just Bedrock:</p> <pre><code>def get_content_string(self) -&gt; str:\n    \"\"\"Returns the content as a string.\"\"\"\n    if isinstance(self.content, str):\n        return self.content\n    if isinstance(self.content, list):\n        if len(self.content) == 0:\n            return \"\"  # FIX: Return empty string for empty list\n        if isinstance(self.content[0], dict) and \"text\" in self.content[0]:\n            return self.content[0].get(\"text\", \"\")\n        else:\n            return json.dumps(self.content)\n    return \"\"\n</code></pre>"},{"location":"agno-bug-report/#option-b-fix-in-bedrock-parser","title":"Option B: Fix in Bedrock parser","text":"<pre><code>model_response.content = content if content else None\n</code></pre>"},{"location":"agno-bug-report/#impact","title":"Impact","text":"<p>This bug affects any workflow where: 1. Tools are used 2. The model returns an empty content list after tool execution</p> <p>The <code>[]</code> appears at the end of every such response, which: - Looks unprofessional in user-facing applications - May break downstream parsing that expects clean text - Affects logging and analytics</p>"},{"location":"agno-bug-report/#workaround","title":"Workaround","text":"<p>Until fixed upstream, consumers can strip trailing <code>[]</code>:</p> <pre><code>if text and text.endswith('[]'):\n    text = text[:-2]\n</code></pre>"},{"location":"agno-bug-report/#related","title":"Related","text":"<ul> <li>Model provider: AWS Bedrock</li> <li>Affected components: <code>Message.get_content_string()</code>, content concatenation in <code>base.py</code></li> </ul>"},{"location":"agno-bug-report/#pr-information","title":"PR Information","text":"<p>If submitting as a PR, use title format per CONTRIBUTING.md:</p> <p>Title: <code>[fix] Return empty string for empty content list in get_content_string()</code></p> <p>Description:  <pre><code>This PR fixes an issue where `Message.get_content_string()` returns `\"[]\"` for empty content lists, \ncausing malformed responses like `\"I'll help you.[]\"` after tool execution.\n\nFixes #&lt;issue_number&gt;\n\n## Changes\n- Modified `get_content_string()` in `libs/agno/agno/models/message.py` to return `\"\"` for empty lists\n- Added test case to verify empty list handling\n\n## Testing\n- Verified with AWS Bedrock + Claude 3.5 Sonnet\n- Confirmed `[]` no longer appears in responses after tool execution\n</code></pre></p>"},{"location":"architecture/","title":"Architecture Guide","text":"<p>This guide explains how DCAF works internally, so you can understand, extend, and troubleshoot it effectively.</p>"},{"location":"architecture/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>High-Level Flow</li> <li>Core Components</li> <li>Request Lifecycle</li> <li>Tool Execution &amp; Approval</li> <li>Streaming</li> <li>Extending DCAF</li> <li>Key Design Decisions</li> </ol>"},{"location":"architecture/#overview","title":"Overview","text":"<p>DCAF is structured in layers that separate concerns:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         YOUR CODE                                \u2502\n\u2502                                                                  \u2502\n\u2502   from dcaf.core import Agent, serve                            \u2502\n\u2502   agent = Agent(tools=[...])                                    \u2502\n\u2502   serve(agent)                                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502                     \u2502     Agent       \u2502  \u25c4\u2500\u2500 Facade (simple API)\u2502\n\u2502                     \u2502   (agent.py)    \u2502                         \u2502\n\u2502                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502                              \u2502                                   \u2502\n\u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502              \u25bc               \u25bc               \u25bc                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502\n\u2502   \u2502 Conversation \u2502  \u2502 AgentService \u2502  \u2502  LLM Adapter \u2502         \u2502\n\u2502   \u2502   (Domain)   \u2502  \u2502 (Application)\u2502  \u2502  (Outbound)  \u2502         \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502\n\u2502                                                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                       SERVER LAYER                               \u2502\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  FastAPI  \u2192  ServerAdapter  \u2192  Agent  \u2192  Response       \u2502   \u2502\n\u2502   \u2502  /api/chat                                              \u2502   \u2502\n\u2502   \u2502  /api/chat-stream                                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Key insight: The <code>Agent</code> class is a facade that hides internal complexity. Most users only interact with <code>Agent</code> and <code>@tool</code>.</p>"},{"location":"architecture/#high-level-flow","title":"High-Level Flow","text":"<p>Here's what happens when a request comes in:</p> <pre><code>  HelpDesk UI                           DCAF                              AWS Bedrock\n      \u2502                                   \u2502                                    \u2502\n      \u2502  POST /api/chat                   \u2502                                    \u2502\n      \u2502  {\"messages\": [...]}              \u2502                                    \u2502\n      \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502                                    \u2502\n      \u2502                                   \u2502                                    \u2502\n      \u2502                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n      \u2502                           \u2502 1. Parse      \u2502                           \u2502\n      \u2502                           \u2502    request    \u2502                           \u2502\n      \u2502                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502\n      \u2502                                   \u2502                                    \u2502\n      \u2502                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n      \u2502                           \u2502 2. Extract    \u2502                           \u2502\n      \u2502                           \u2502    context    \u2502                           \u2502\n      \u2502                           \u2502    &amp; history  \u2502                           \u2502\n      \u2502                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502\n      \u2502                                   \u2502                                    \u2502\n      \u2502                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   invoke_model()          \u2502\n      \u2502                           \u2502 3. Call LLM   \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\n      \u2502                           \u2502    with tools \u2502                           \u2502\n      \u2502                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502\n      \u2502                                   \u2502                  tool_use          \u2502\n      \u2502                                   \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n      \u2502                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u2502\n      \u2502                           \u2502 4. Process    \u2502                           \u2502\n      \u2502                           \u2502    tool calls \u2502                           \u2502\n      \u2502                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2502\n      \u2502                                   \u2502                                    \u2502\n      \u2502                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n      \u2502                       \u2502                       \u2502                       \u2502\n      \u2502               needs_approval?            auto_execute                 \u2502\n      \u2502                       \u2502                       \u2502                       \u2502\n      \u2502                       \u25bc                       \u25bc                       \u2502\n      \u2502               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510               \u2502\n      \u2502               \u2502 Return with   \u2502      \u2502 Execute tool  \u2502               \u2502\n      \u2502               \u2502 pending tools \u2502      \u2502 Return result \u2502               \u2502\n      \u2502               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\n      \u2502                       \u2502                       \u2502                       \u2502\n      \u2502                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n      \u2502                                   \u2502                                    \u2502\n      \u2502  {\"content\": \"...\",              \u2502                                    \u2502\n      \u2502   \"tool_calls\": [...]}           \u2502                                    \u2502\n      \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502                                    \u2502\n      \u2502                                   \u2502                                    \u2502\n</code></pre>"},{"location":"architecture/#core-components","title":"Core Components","text":""},{"location":"architecture/#1-agent-facade","title":"1. Agent (Facade)","text":"<p>File: <code>dcaf/core/agent.py</code></p> <p>The main entry point. Hides all internal complexity.</p> <pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    tools=[list_pods, delete_pod],  # Tools available to the LLM\n    system=\"You are a K8s assistant\", # System prompt\n    model=\"anthropic.claude-3-sonnet\", # LLM model\n)\n\nresponse = agent.run(messages=[...])\n</code></pre> <p>What it does internally:</p> <ol> <li>Creates a <code>Conversation</code> entity to track messages</li> <li>Creates an <code>AgentService</code> to orchestrate the request</li> <li>Creates an <code>LLM Adapter</code> to call AWS Bedrock</li> <li>Wires everything together</li> </ol>"},{"location":"architecture/#2-conversation-domain-entity","title":"2. Conversation (Domain Entity)","text":"<p>File: <code>dcaf/core/domain/entities/conversation.py</code></p> <p>Tracks the state of a conversation:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Conversation                              \u2502\n\u2502                                                                   \u2502\n\u2502   messages: [Message, Message, ...]     \u25c4\u2500\u2500 Chat history         \u2502\n\u2502   tool_calls: [ToolCall, ToolCall, ...] \u25c4\u2500\u2500 Pending &amp; executed   \u2502\n\u2502   platform_context: {...}               \u25c4\u2500\u2500 Runtime info         \u2502\n\u2502                                                                   \u2502\n\u2502   Methods:                                                        \u2502\n\u2502   \u2022 add_user_message(content)                                    \u2502\n\u2502   \u2022 add_assistant_message(content)                               \u2502\n\u2502   \u2022 add_tool_call(name, input)                                   \u2502\n\u2502   \u2022 approve_tool_call(id)                                        \u2502\n\u2502   \u2022 execute_tool_call(id, result)                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#3-toolcall-domain-entity","title":"3. ToolCall (Domain Entity)","text":"<p>File: <code>dcaf/core/domain/entities/tool_call.py</code></p> <p>Represents a single tool invocation with a lifecycle:</p> <pre><code>                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                      \u2502 PENDING  \u2502\n                      \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n                           \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502            \u2502            \u2502\n              \u25bc            \u2502            \u25bc\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502 APPROVED \u2502        \u2502     \u2502 REJECTED \u2502\n       \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518        \u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502              \u2502\n            \u25bc              \u2502\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n       \u2502 EXECUTED \u2502        \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518        \u2502\n                           \u2502\n                           \u25bc\n                    (auto-execute if\n                     requires_approval=False)\n</code></pre> <p>Properties:</p> Property Description <code>id</code> Unique identifier (UUID) <code>name</code> Tool name (e.g., \"delete_pod\") <code>input</code> Arguments passed to the tool <code>status</code> PENDING, APPROVED, REJECTED, EXECUTED <code>result</code> Output after execution"},{"location":"architecture/#4-agentservice-application-layer","title":"4. AgentService (Application Layer)","text":"<p>File: <code>dcaf/core/application/services/agent_service.py</code></p> <p>Orchestrates the agent logic:</p> <pre><code>class AgentService:\n    def execute(self, request: AgentRequest) -&gt; AgentResponse:\n        # 1. Get or create conversation\n        conversation = self._get_conversation(request)\n\n        # 2. Add user message\n        conversation.add_user_message(request.message)\n\n        # 3. Call LLM via adapter\n        llm_response = self._runtime.invoke(\n            messages=conversation.messages,\n            tools=request.tools,\n        )\n\n        # 4. Process tool calls\n        for tool_call in llm_response.tool_calls:\n            if self._requires_approval(tool_call):\n                # Mark as pending - user must approve\n                conversation.add_pending_tool_call(tool_call)\n            else:\n                # Auto-execute\n                result = self._execute_tool(tool_call)\n                conversation.add_executed_tool_call(tool_call, result)\n\n        # 5. Build response\n        return AgentResponse(\n            text=llm_response.text,\n            pending_tools=conversation.pending_tool_calls,\n            executed_tools=conversation.executed_tool_calls,\n        )\n</code></pre>"},{"location":"architecture/#5-llm-adapter-outbound","title":"5. LLM Adapter (Outbound)","text":"<p>File: <code>dcaf/core/adapters/outbound/agno/adapter.py</code></p> <p>Translates between DCAF and the LLM provider:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        LLM Adapter                               \u2502\n\u2502                                                                  \u2502\n\u2502   DCAF Format                         Provider Format            \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                         \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500            \u2502\n\u2502                                                                  \u2502\n\u2502   Message(role, content)      \u2500\u2500\u2500\u2500\u2500\u25ba  {\"role\": \"user\", ...}     \u2502\n\u2502   Tool(name, schema)          \u2500\u2500\u2500\u2500\u2500\u25ba  {\"name\": \"...\", ...}      \u2502\n\u2502                                                                  \u2502\n\u2502   LLMResponse                 \u25c4\u2500\u2500\u2500\u2500\u2500  Bedrock API Response      \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Why adapters matter: You can swap LLM providers (Bedrock, OpenAI, local) without changing your agent code.</p>"},{"location":"architecture/#6-serveradapter-inbound","title":"6. ServerAdapter (Inbound)","text":"<p>File: <code>dcaf/core/adapters/inbound/server_adapter.py</code></p> <p>Bridges FastAPI and your Agent:</p> <pre><code>HTTP Request                    ServerAdapter                    Agent\n    \u2502                               \u2502                              \u2502\n    \u2502  POST /api/chat               \u2502                              \u2502\n    \u2502  {\"messages\": [...]}          \u2502                              \u2502\n    \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502                              \u2502\n    \u2502                               \u2502                              \u2502\n    \u2502                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n    \u2502                        \u2502 Convert to  \u2502                       \u2502\n    \u2502                        \u2502 DCAF format \u2502                       \u2502\n    \u2502                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n    \u2502                               \u2502                              \u2502\n    \u2502                               \u2502  agent.run(messages)         \u2502\n    \u2502                               \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\n    \u2502                               \u2502                              \u2502\n    \u2502                               \u2502  AgentResponse               \u2502\n    \u2502                               \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n    \u2502                               \u2502                              \u2502\n    \u2502                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510                       \u2502\n    \u2502                        \u2502 Convert to  \u2502                       \u2502\n    \u2502                        \u2502 HelpDesk    \u2502                       \u2502\n    \u2502                        \u2502 protocol    \u2502                       \u2502\n    \u2502                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2502\n    \u2502                               \u2502                              \u2502\n    \u2502  AgentMessage (JSON)          \u2502                              \u2502\n    \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502                              \u2502\n</code></pre>"},{"location":"architecture/#request-lifecycle","title":"Request Lifecycle","text":""},{"location":"architecture/#step-by-step","title":"Step-by-Step","text":"<ol> <li>HTTP Request arrives at <code>/api/chat</code></li> <li>ServerAdapter extracts messages and platform_context</li> <li>Agent.run() is called with the messages</li> <li>AgentService creates/loads a Conversation</li> <li>LLM Adapter sends request to AWS Bedrock</li> <li>Bedrock returns text and/or tool_use blocks</li> <li>AgentService checks each tool call:</li> <li><code>requires_approval=True</code> \u2192 add to pending</li> <li><code>requires_approval=False</code> \u2192 execute immediately</li> <li>AgentResponse is built with text + pending/executed tools</li> <li>ServerAdapter converts to HelpDesk protocol format</li> <li>HTTP Response sent back</li> </ol>"},{"location":"architecture/#approval-loop","title":"Approval Loop","text":"<p>When tools require approval, the flow pauses:</p> <pre><code>Request 1: \"Delete the broken pods\"\n    \u2502\n    \u25bc\nResponse: { tool_calls: [{name: \"delete_pod\", execute: false}] }\n    \u2502\n    \u2502  User sees approval UI in HelpDesk\n    \u2502  User clicks \"Approve\"\n    \u2502\n    \u25bc\nRequest 2: { tool_calls: [{name: \"delete_pod\", execute: true}] }\n    \u2502\n    \u25bc\nResponse: { executed_tool_calls: [{output: \"pod deleted\"}] }\n</code></pre>"},{"location":"architecture/#tool-execution-approval","title":"Tool Execution &amp; Approval","text":""},{"location":"architecture/#how-approval-is-determined","title":"How Approval is Determined","text":"<pre><code>def requires_approval(tool, tool_call, context):\n    # Check tool configuration\n    if tool.requires_approval:\n        return True\n\n    return False\n</code></pre>"},{"location":"architecture/#tool-execution-flow","title":"Tool Execution Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       Tool Execution                             \u2502\n\u2502                                                                  \u2502\n\u2502   1. Find tool by name                                          \u2502\n\u2502      \u2514\u2500\u2500 tools = {name: tool for tool in agent.tools}           \u2502\n\u2502                                                                  \u2502\n\u2502   2. Extract input parameters                                   \u2502\n\u2502      \u2514\u2500\u2500 input = {\"pod_name\": \"nginx\", \"namespace\": \"prod\"}     \u2502\n\u2502                                                                  \u2502\n\u2502   3. Call tool function                                         \u2502\n\u2502      \u2514\u2500\u2500 result = tool.execute(input, platform_context)         \u2502\n\u2502                                                                  \u2502\n\u2502   4. Capture result                                             \u2502\n\u2502      \u2514\u2500\u2500 \"pod nginx deleted\"                                    \u2502\n\u2502                                                                  \u2502\n\u2502   5. Add to conversation                                        \u2502\n\u2502      \u2514\u2500\u2500 conversation.add_executed_tool_call(tool_call, result) \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#streaming","title":"Streaming","text":"<p>For real-time responses, DCAF uses NDJSON (newline-delimited JSON):</p> <pre><code>POST /api/chat-stream\n\nResponse (line by line):\n{\"type\": \"text_delta\", \"text\": \"I'll \"}\n{\"type\": \"text_delta\", \"text\": \"help \"}\n{\"type\": \"text_delta\", \"text\": \"you \"}\n{\"type\": \"text_delta\", \"text\": \"delete \"}\n{\"type\": \"text_delta\", \"text\": \"that pod.\"}\n{\"type\": \"tool_calls\", \"tool_calls\": [...]}\n{\"type\": \"done\"}\n</code></pre>"},{"location":"architecture/#stream-events","title":"Stream Events","text":"Event Type Description <code>text_delta</code> Incremental text token <code>tool_calls</code> Tools needing approval <code>executed_tool_calls</code> Tools that were executed <code>done</code> Stream complete <code>error</code> Error occurred"},{"location":"architecture/#implementation","title":"Implementation","text":"<pre><code>for event in agent.run_stream(messages=[...]):\n    if isinstance(event, TextDeltaEvent):\n        print(event.text, end=\"\", flush=True)\n    elif isinstance(event, ToolCallsEvent):\n        # Handle approval UI\n        pass\n    elif isinstance(event, DoneEvent):\n        break\n</code></pre>"},{"location":"architecture/#extending-dcaf","title":"Extending DCAF","text":""},{"location":"architecture/#adding-a-new-llm-provider","title":"Adding a New LLM Provider","text":"<ol> <li>Create an adapter that implements <code>AgentRuntime</code>:</li> </ol> <pre><code># dcaf/core/adapters/outbound/openai/adapter.py\n\nfrom dcaf.core.application.ports import AgentRuntime\n\nclass OpenAIAdapter(AgentRuntime):\n    def __init__(self, model: str = \"gpt-4\"):\n        self.client = OpenAI()\n        self.model = model\n\n    def invoke(self, messages, tools) -&gt; AgentResponse:\n        # Convert messages to OpenAI format\n        openai_messages = self._convert_messages(messages)\n        openai_tools = self._convert_tools(tools)\n\n        # Call OpenAI\n        response = self.client.chat.completions.create(\n            model=self.model,\n            messages=openai_messages,\n            tools=openai_tools,\n        )\n\n        # Convert back to DCAF format\n        return self._convert_response(response)\n</code></pre> <ol> <li>Use it:</li> </ol> <pre><code>from dcaf.core import Agent\nfrom dcaf.core.adapters.outbound.openai import OpenAIAdapter\n\nagent = Agent(\n    tools=[...],\n    runtime=OpenAIAdapter(\"gpt-4\"),\n)\n</code></pre>"},{"location":"architecture/#adding-custom-approval-logic","title":"Adding Custom Approval Logic","text":"<pre><code>from dcaf.core.domain.services import ApprovalPolicy\n\nclass StrictProductionPolicy(ApprovalPolicy):\n    def requires_approval(self, tool_call, context):\n        # Always require approval in production\n        if context.get(\"tenant_name\") == \"production\":\n            return True\n\n        # Require approval for destructive actions\n        if any(word in tool_call.name for word in [\"delete\", \"remove\", \"drop\"]):\n            return True\n\n        return False\n\n# Use custom policy\nagent = Agent(\n    tools=[...],\n    approval_policy=StrictProductionPolicy(),\n)\n</code></pre>"},{"location":"architecture/#adding-custom-event-handlers","title":"Adding Custom Event Handlers","text":"<pre><code>def audit_logger(event):\n    \"\"\"Log all events to audit system.\"\"\"\n    log_to_audit_db({\n        \"event_type\": event.event_type,\n        \"timestamp\": event.timestamp,\n        \"data\": event.data,\n    })\n\ndef slack_notifier(event):\n    \"\"\"Notify Slack on approvals.\"\"\"\n    if event.event_type == \"ApprovalRequested\":\n        post_to_slack(f\"Approval needed: {event.tool_name}\")\n\nagent = Agent(\n    tools=[...],\n    on_event=[audit_logger, slack_notifier],\n)\n</code></pre>"},{"location":"architecture/#key-design-decisions","title":"Key Design Decisions","text":""},{"location":"architecture/#why-clean-architecture","title":"Why Clean Architecture?","text":"Benefit How It Helps Testability Test business logic without LLM calls Flexibility Swap LLM providers without code changes Maintainability Changes isolated to specific layers"},{"location":"architecture/#why-facade-pattern","title":"Why Facade Pattern?","text":"<p>Most users don't need to understand the internals. The <code>Agent</code> class provides a simple API:</p> <pre><code># User sees this (simple):\nagent = Agent(tools=[...])\nresponse = agent.run(messages)\n\n# Internally it's this (complex):\nconversation = Conversation()\nservice = AgentService(\n    runtime=AgnoAdapter(),\n    repository=InMemoryConversationRepository(),\n    approval_policy=DefaultApprovalPolicy(),\n)\nresponse = service.execute(AgentRequest(...))\n</code></pre>"},{"location":"architecture/#why-protocol-first","title":"Why Protocol-First?","text":"<p>DCAF is designed to work with the DuploCloud HelpDesk. The message format (<code>tool_calls</code>, <code>executed_tool_calls</code>, etc.) is defined by the HelpDesk protocol, and DCAF adapts to it.</p>"},{"location":"architecture/#see-also","title":"See Also","text":"<ul> <li>Message Protocol Guide - Complete protocol reference</li> <li>Core API - Agent class documentation</li> <li>Server Documentation - Running as REST API</li> <li>Custom Agents Guide - Building complex agents</li> </ul>"},{"location":"engineering-handoff/","title":"DCAF Engineering Handoff Guide","text":""},{"location":"engineering-handoff/#project-overview","title":"Project Overview","text":"<p>DCAF (DuploCloud Agent Framework) is an agent framework designed to orchestrate AI-powered conversations that can execute tools requiring human approval. It's particularly focused on infrastructure operations (Kubernetes, AWS) where autonomous execution without oversight could be dangerous.</p>"},{"location":"engineering-handoff/#what-problem-does-it-solve","title":"What Problem Does It Solve?","text":"<ol> <li>Safe Tool Execution: Agents can propose actions, but dangerous operations require human approval before execution</li> <li>Framework Flexibility: Swap between LLM frameworks (Agno, LangChain, Bedrock) without changing business logic</li> <li>Consistent Behavior: Approval flows, streaming, and error handling work the same regardless of the underlying framework</li> </ol>"},{"location":"engineering-handoff/#user-facing-api","title":"User-Facing API","text":"<p>Most users interact with DCAF through a simple API:</p> <pre><code>from dcaf.core import Agent, serve\n\nagent = Agent(tools=[list_pods, delete_pod])\nserve(agent)\n</code></pre> <p>For custom logic, users write a function:</p> <pre><code>from dcaf.core import Agent, AgentResult, serve\n\ndef my_agent(messages: list, context: dict) -&gt; AgentResult:\n    classifier = Agent(system=\"Classify intent\")\n    intent = classifier.run(messages)\n    # ... custom logic\n    return AgentResult(text=response.text)\n\nserve(my_agent)\n</code></pre> <p>The complexity below is hidden from users. The <code>Agent</code> class is a facade over the Clean Architecture internals.</p>"},{"location":"engineering-handoff/#architecture-overview-internal","title":"Architecture Overview (Internal)","text":"<p>DCAF Core follows Clean Architecture with Domain-Driven Design tactical patterns. This section explains how all the pieces fit together.</p>"},{"location":"engineering-handoff/#the-big-picture","title":"The Big Picture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        External World                            \u2502\n\u2502          (HTTP, CLI, Agno SDK, LangChain, Databases)            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                          ADAPTERS                                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  Inbound    \u2502  \u2502  Outbound   \u2502  \u2502    Persistence       \u2502   \u2502\n\u2502   \u2502  (FastAPI)  \u2502  \u2502  (Agno)     \u2502  \u2502  (Repositories)      \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                        APPLICATION                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502    Services    \u2502  \u2502              Ports                  \u2502  \u2502\n\u2502   \u2502  (ExecuteAgent) \u2502  \u2502  (AgentRuntime, ConversationRepo)   \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                          DOMAIN                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502 Entities \u2502  \u2502Value Objects \u2502  \u2502   Domain Services      \u2502   \u2502\n\u2502   \u2502(ToolCall)\u2502  \u2502 (ToolCallId) \u2502  \u2502  (ApprovalPolicy)      \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>The Dependency Rule: Dependencies always point inward. Domain knows nothing about HTTP, Agno, or databases.</p>"},{"location":"engineering-handoff/#layer-by-layer-breakdown","title":"Layer-by-Layer Breakdown","text":""},{"location":"engineering-handoff/#1-domain-layer-core-business-logic","title":"1. Domain Layer (Core Business Logic)","text":"<p>The innermost layer contains pure business logic with zero external dependencies.</p> Component Purpose Example Entities Objects with identity and lifecycle <code>Conversation</code>, <code>ToolCall</code>, <code>Message</code> Value Objects Immutable data holders <code>ToolCallId</code>, <code>ToolInput</code>, <code>MessageContent</code> Domain Services Logic that doesn't belong to a single entity <code>ApprovalPolicy</code> Domain Events Notifications about what happened <code>ToolCallApproved</code>, <code>MessageAdded</code> <p>Key Domain Entities:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Conversation (Aggregate Root)               \u2502\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  Messages[]           - User and assistant messages      \u2502   \u2502\n\u2502   \u2502  ToolCalls[]          - Pending and executed tool calls  \u2502   \u2502\n\u2502   \u2502  PlatformContext      - Runtime environment (tenant, etc)\u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                  \u2502\n\u2502   Methods:                                                       \u2502\n\u2502   \u2022 add_user_message(content)                                   \u2502\n\u2502   \u2022 add_assistant_message(content)                              \u2502\n\u2502   \u2022 add_tool_call(name, input)                                  \u2502\n\u2502   \u2022 approve_tool_call(id)                                       \u2502\n\u2502   \u2022 reject_tool_call(id, reason)                                \u2502\n\u2502   \u2022 execute_tool_call(id, result)                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         ToolCall (Entity)                        \u2502\n\u2502                                                                  \u2502\n\u2502   State Machine:                                                 \u2502\n\u2502                                                                  \u2502\n\u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  approve()   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  execute()  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502      \u2502 PENDING  \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502 APPROVED \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba \u2502 DONE \u2502\u2502\n\u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502           \u2502                                                      \u2502\n\u2502           \u2502 reject()                                            \u2502\n\u2502           \u25bc                                                      \u2502\n\u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                               \u2502\n\u2502      \u2502 REJECTED \u2502                                               \u2502\n\u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                               \u2502\n\u2502                                                                  \u2502\n\u2502   Properties:                                                    \u2502\n\u2502   \u2022 id: ToolCallId (UUID)                                       \u2502\n\u2502   \u2022 name: str (\"delete_pod\", \"list_services\")                   \u2502\n\u2502   \u2022 input: dict ({\"name\": \"my-pod\", \"namespace\": \"prod\"})       \u2502\n\u2502   \u2022 status: ToolCallStatus                                      \u2502\n\u2502   \u2022 result: Optional[str]                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"engineering-handoff/#2-application-layer-use-case-orchestration","title":"2. Application Layer (Use Case Orchestration)","text":"<p>This layer coordinates the domain to achieve use cases. It knows what to do but not how (that's for adapters).</p> Component Purpose Example Services Orchestrate domain objects <code>AgentService.execute()</code> Ports Interfaces for external dependencies <code>AgentRuntime</code>, <code>ConversationRepository</code> DTOs Data transfer objects <code>AgentRequest</code>, <code>AgentResponse</code> <p>Key Application Service:</p> <pre><code># Simplified view of AgentService\nclass AgentService:\n    def __init__(self, runtime: AgentRuntime, repo: ConversationRepository):\n        self.runtime = runtime  # Port - implemented by adapters\n        self.repo = repo        # Port - implemented by adapters\n\n    def execute(self, request: AgentRequest) -&gt; AgentResponse:\n        # 1. Load or create conversation\n        conversation = self.repo.get(request.conversation_id)\n\n        # 2. Add user message to conversation\n        conversation.add_user_message(request.message)\n\n        # 3. Call the LLM via the runtime port\n        llm_response = self.runtime.invoke(\n            messages=conversation.messages,\n            tools=request.tools,\n        )\n\n        # 4. Process tool calls with approval policy\n        for tool_call in llm_response.tool_calls:\n            if self.approval_policy.requires_approval(tool_call):\n                conversation.add_pending_tool_call(tool_call)\n            else:\n                result = self._execute_tool(tool_call)\n                conversation.add_executed_tool_call(tool_call, result)\n\n        # 5. Return response\n        return AgentResponse(\n            text=llm_response.text,\n            pending_tools=conversation.pending_tool_calls,\n        )\n</code></pre> <p>Ports (Interfaces):</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          PORTS                                   \u2502\n\u2502           (Interfaces defined in Application layer)              \u2502\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  AgentRuntime (Port)                                     \u2502   \u2502\n\u2502   \u2502  \u2022 invoke(messages, tools) \u2192 LLMResponse                 \u2502   \u2502\n\u2502   \u2502  \u2022 invoke_stream(messages, tools) \u2192 Iterator[Event]      \u2502   \u2502\n\u2502   \u2502                                                          \u2502   \u2502\n\u2502   \u2502  Implemented by:                                         \u2502   \u2502\n\u2502   \u2502  \u2022 AgnoAdapter (uses Agno SDK)                          \u2502   \u2502\n\u2502   \u2502  \u2022 BedrockAdapter (direct AWS Bedrock)                  \u2502   \u2502\n\u2502   \u2502  \u2022 LangChainAdapter (uses LangChain)                    \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  ConversationRepository (Port)                           \u2502   \u2502\n\u2502   \u2502  \u2022 get(id) \u2192 Conversation                                \u2502   \u2502\n\u2502   \u2502  \u2022 save(conversation)                                    \u2502   \u2502\n\u2502   \u2502                                                          \u2502   \u2502\n\u2502   \u2502  Implemented by:                                         \u2502   \u2502\n\u2502   \u2502  \u2022 InMemoryConversationRepository                       \u2502   \u2502\n\u2502   \u2502  \u2022 RedisConversationRepository                          \u2502   \u2502\n\u2502   \u2502  \u2022 DynamoDBConversationRepository                       \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"engineering-handoff/#3-adapters-layer-external-world-translation","title":"3. Adapters Layer (External World Translation)","text":"<p>Adapters translate between our domain and external systems. There are two types:</p> <p>Inbound Adapters - Receive requests from the outside world:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      INBOUND ADAPTERS                            \u2502\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  ServerAdapter (FastAPI)                                 \u2502   \u2502\n\u2502   \u2502                                                          \u2502   \u2502\n\u2502   \u2502  HTTP Request                                            \u2502   \u2502\n\u2502   \u2502      \u2502                                                   \u2502   \u2502\n\u2502   \u2502      \u25bc                                                   \u2502   \u2502\n\u2502   \u2502  POST /api/chat                                          \u2502   \u2502\n\u2502   \u2502  {\"messages\": [{\"role\": \"user\", \"content\": \"...\"}]}      \u2502   \u2502\n\u2502   \u2502      \u2502                                                   \u2502   \u2502\n\u2502   \u2502      \u25bc                                                   \u2502   \u2502\n\u2502   \u2502  Convert to AgentRequest                                 \u2502   \u2502\n\u2502   \u2502      \u2502                                                   \u2502   \u2502\n\u2502   \u2502      \u25bc                                                   \u2502   \u2502\n\u2502   \u2502  AgentService.execute(request)                           \u2502   \u2502\n\u2502   \u2502      \u2502                                                   \u2502   \u2502\n\u2502   \u2502      \u25bc                                                   \u2502   \u2502\n\u2502   \u2502  Convert AgentResponse to HTTP Response                  \u2502   \u2502\n\u2502   \u2502      \u2502                                                   \u2502   \u2502\n\u2502   \u2502      \u25bc                                                   \u2502   \u2502\n\u2502   \u2502  HTTP 200 {\"content\": \"...\", \"tool_calls\": [...]}        \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Outbound Adapters - Call external systems:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      OUTBOUND ADAPTERS                           \u2502\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  AgnoAdapter (implements AgentRuntime)                   \u2502   \u2502\n\u2502   \u2502                                                          \u2502   \u2502\n\u2502   \u2502  Our Domain Format          Agno SDK Format              \u2502   \u2502\n\u2502   \u2502  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500          \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500              \u2502   \u2502\n\u2502   \u2502  Message                    agno.Message                 \u2502   \u2502\n\u2502   \u2502  Tool                   \u2192   agno.Tool                    \u2502   \u2502\n\u2502   \u2502  ToolCall                   agno.ToolCall                \u2502   \u2502\n\u2502   \u2502                                                          \u2502   \u2502\n\u2502   \u2502  AgnoAdapter.invoke():                                   \u2502   \u2502\n\u2502   \u2502  1. Convert our Messages \u2192 Agno Messages                 \u2502   \u2502\n\u2502   \u2502  2. Convert our Tools \u2192 Agno Tools                       \u2502   \u2502\n\u2502   \u2502  3. Call Agno SDK: agno_agent.run(messages, tools)       \u2502   \u2502\n\u2502   \u2502  4. Convert Agno Response \u2192 our AgentResponse            \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  BedrockAdapter (implements AgentRuntime)                \u2502   \u2502\n\u2502   \u2502                                                          \u2502   \u2502\n\u2502   \u2502  1. Convert Messages \u2192 Bedrock API format                \u2502   \u2502\n\u2502   \u2502  2. Convert Tools \u2192 Bedrock tool_config                  \u2502   \u2502\n\u2502   \u2502  3. Call boto3: bedrock.invoke_model(...)                \u2502   \u2502\n\u2502   \u2502  4. Parse Bedrock response \u2192 our AgentResponse           \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"engineering-handoff/#how-components-connect","title":"How Components Connect","text":"<p>Here's how a complete request flows through all layers:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           COMPLETE REQUEST FLOW                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n  User (HelpDesk UI)\n       \u2502\n       \u2502  POST /api/chat {\"messages\": [...]}\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  FastAPI Server  \u2502  \u25c4\u2500\u2500 Infrastructure (routes, middleware)\n\u2502  (agent_server)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  ServerAdapter   \u2502  \u25c4\u2500\u2500 Inbound Adapter\n\u2502  (or Callable-   \u2502      Converts HTTP \u2192 Domain format\n\u2502   Adapter)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502  AgentRequest(messages=[...], tools=[...])\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  AgentService    \u2502  \u25c4\u2500\u2500 Application Service\n\u2502  (orchestrates)  \u2502      Coordinates domain objects\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502  Calls port interface\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  AgentRuntime    \u2502  \u25c4\u2500\u2500 Application Port (interface)\n\u2502  (port/interface)\u2502      Defines what we need, not how\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502  Implemented by...\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  AgnoAdapter     \u2502  \u25c4\u2500\u2500 Outbound Adapter\n\u2502  (or Bedrock-    \u2502      Implements the port\n\u2502   Adapter)       \u2502      Knows how to call the LLM\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u2502  Agno SDK / boto3 calls\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  AWS Bedrock     \u2502  \u25c4\u2500\u2500 External System\n\u2502  (Claude, etc.)  \u2502      The actual LLM\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"engineering-handoff/#the-agent-facade","title":"The Agent Facade","text":"<p>The <code>Agent</code> class is a facade that hides all this complexity:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                             USER CODE                                     \u2502\n\u2502                                                                          \u2502\n\u2502   agent = Agent(tools=[list_pods], system=\"You are helpful\")             \u2502\n\u2502   result = agent.run(messages)                                           \u2502\n\u2502                                                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                    \u2502\n                                    \u2502  Internally creates and coordinates:\n                                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          AGENT FACADE (agent.py)                          \u2502\n\u2502                                                                          \u2502\n\u2502   class Agent:                                                           \u2502\n\u2502       def __init__(self, tools, system):                                 \u2502\n\u2502           # Create internal components                                   \u2502\n\u2502           self._conversation = Conversation()        \u25c4\u2500\u2500 Domain Entity  \u2502\n\u2502           self._runtime = AgnoAdapter(model, tools)  \u25c4\u2500\u2500 Outbound Adapter\u2502\n\u2502           self._service = AgentService(runtime)      \u25c4\u2500\u2500 App Service    \u2502\n\u2502                                                                          \u2502\n\u2502       def run(self, messages) -&gt; AgentResponse:                          \u2502\n\u2502           # Delegate to internal service                                 \u2502\n\u2502           return self._service.execute(AgentRequest(messages))           \u2502\n\u2502                                                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"engineering-handoff/#why-this-architecture","title":"Why This Architecture?","text":"Benefit How It's Achieved Testability Domain has no dependencies \u2192 easy unit tests Flexibility Swap LLM providers by changing adapters Maintainability Changes isolated to specific layers Framework Independence Agno/LangChain details don't leak into business logic <p>Example: Swapping LLM Providers</p> <pre><code># Before: Using Agno\nagent = Agent(tools=[...], runtime=AgnoAdapter())\n\n# After: Using LangChain (no business logic changes!)\nagent = Agent(tools=[...], runtime=LangChainAdapter())\n</code></pre> <p>Only the adapter changes. Domain logic, approval flows, and conversation management stay the same.</p>"},{"location":"engineering-handoff/#helpdesk-protocol-integration","title":"HelpDesk Protocol Integration","text":"<p>DCAF agents communicate with the DuploCloud HelpDesk using a specific message protocol. Understanding this protocol is essential for server integration.</p>"},{"location":"engineering-handoff/#message-format","title":"Message Format","text":"<p>Incoming Request (from HelpDesk):</p> <pre><code>{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Delete the pod my-pod in production\",\n      \"data\": {\n        \"cmds\": [],\n        \"executed_cmds\": [],\n        \"tool_calls\": [],\n        \"executed_tool_calls\": []\n      },\n      \"platform_context\": {\n        \"tenant_name\": \"production\",\n        \"k8s_namespace\": \"default\",\n        \"duplo_token\": \"...\",\n        \"aws_credentials\": {...}\n      }\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"I'll delete that pod. This requires your approval.\",\n      \"data\": {\n        \"tool_calls\": [\n          {\n            \"id\": \"tc_123\",\n            \"name\": \"delete_pod\",\n            \"input\": {\"name\": \"my-pod\", \"namespace\": \"default\"},\n            \"execute\": false,\n            \"tool_description\": \"Delete a Kubernetes pod\"\n          }\n        ]\n      }\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"\",\n      \"data\": {\n        \"tool_calls\": [\n          {\n            \"id\": \"tc_123\",\n            \"name\": \"delete_pod\",\n            \"input\": {\"name\": \"my-pod\", \"namespace\": \"default\"},\n            \"execute\": true  // \u25c4\u2500\u2500 User approved!\n          }\n        ]\n      }\n    }\n  ]\n}\n</code></pre> <p>Outgoing Response (to HelpDesk):</p> <pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"The pod my-pod has been deleted.\",\n  \"data\": {\n    \"tool_calls\": [],\n    \"executed_tool_calls\": [\n      {\n        \"id\": \"tc_123\",\n        \"name\": \"delete_pod\",\n        \"input\": {\"name\": \"my-pod\", \"namespace\": \"default\"},\n        \"output\": \"pod \\\"my-pod\\\" deleted\"\n      }\n    ],\n    \"cmds\": [],\n    \"executed_cmds\": []\n  }\n}\n</code></pre>"},{"location":"engineering-handoff/#protocol-fields-explained","title":"Protocol Fields Explained","text":"Field Purpose <code>tool_calls</code> Tools that need approval (<code>execute: false</code>) or were approved (<code>execute: true</code>) <code>executed_tool_calls</code> Tools that were executed this turn, with their output <code>cmds</code> Terminal commands that need approval <code>executed_cmds</code> Terminal commands that were executed, with output <code>platform_context</code> Runtime environment (credentials, namespace, tenant)"},{"location":"engineering-handoff/#core-dtos-recommended","title":"Core DTOs (Recommended)","text":"<p>DCAF Core provides Python dataclasses that match this protocol exactly:</p> <pre><code>from dcaf.core import (\n    PlatformContext,    # platform_context\n    DataDTO,            # data container\n    CommandDTO,         # cmds entries\n    ExecutedCommandDTO, # executed_cmds entries\n    ToolCallDTO,        # tool_calls entries\n    ExecutedToolCallDTO,# executed_tool_calls entries\n    StreamEvent,        # streaming events\n)\n\n# Example: Create a response with pending tool call\nfrom dcaf.core import AgentResponse, DataDTO, ToolCallDTO\n\nresponse = AgentResponse(\n    conversation_id=\"123\",\n    text=\"I need approval to delete the pod.\",\n    data=DataDTO(\n        tool_calls=[\n            ToolCallDTO(\n                id=\"tc_123\",\n                name=\"delete_pod\",\n                input={\"name\": \"my-pod\"},\n                execute=False,\n                tool_description=\"Delete a Kubernetes pod\",\n            )\n        ]\n    ),\n    has_pending_approvals=True,\n)\n\n# Convert to HelpDesk message format\nhelpdesk_msg = response.to_helpdesk_message()\n</code></pre> <p>See HelpDesk Protocol Guide for full documentation.</p>"},{"location":"engineering-handoff/#approval-flow-sequence","title":"Approval Flow Sequence","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                          TOOL APPROVAL SEQUENCE                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n  HelpDesk                         DCAF Agent                        LLM\n     \u2502                                 \u2502                              \u2502\n     \u2502  1. User: \"delete pod x\"        \u2502                              \u2502\n     \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba  \u2502                              \u2502\n     \u2502                                 \u2502  2. Call LLM                 \u2502\n     \u2502                                 \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\n     \u2502                                 \u2502                              \u2502\n     \u2502                                 \u2502  3. LLM: tool_use delete_pod \u2502\n     \u2502                                 \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n     \u2502                                 \u2502                              \u2502\n     \u2502  4. Response with tool_calls    \u2502                              \u2502\n     \u2502     [execute: false]            \u2502                              \u2502\n     \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502                              \u2502\n     \u2502                                 \u2502                              \u2502\n     \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502                              \u2502\n     \u2502  \u2502  User sees approval UI  \u2502    \u2502                              \u2502\n     \u2502  \u2502  [Approve] [Reject]     \u2502    \u2502                              \u2502\n     \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502                              \u2502\n     \u2502                                 \u2502                              \u2502\n     \u2502  5. User clicks Approve         \u2502                              \u2502\n     \u2502     tool_calls[execute: true]   \u2502                              \u2502\n     \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba  \u2502                              \u2502\n     \u2502                                 \u2502  6. Execute tool             \u2502\n     \u2502                                 \u2502     kubectl delete pod x     \u2502\n     \u2502                                 \u2502                              \u2502\n     \u2502                                 \u2502  7. Call LLM with result     \u2502\n     \u2502                                 \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\n     \u2502                                 \u2502                              \u2502\n     \u2502                                 \u2502  8. LLM: final response      \u2502\n     \u2502                                 \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n     \u2502                                 \u2502                              \u2502\n     \u2502  9. Response with:              \u2502                              \u2502\n     \u2502     executed_tool_calls         \u2502                              \u2502\n     \u2502     content: \"Pod deleted\"      \u2502                              \u2502\n     \u2502 \u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500  \u2502                              \u2502\n     \u2502                                 \u2502                              \u2502\n</code></pre>"},{"location":"engineering-handoff/#streaming-protocol","title":"Streaming Protocol","text":"<p>For <code>/api/chat-stream</code>, responses are NDJSON (newline-delimited JSON):</p> <pre><code>{\"type\": \"text_delta\", \"text\": \"I'll \"}\n{\"type\": \"text_delta\", \"text\": \"delete \"}\n{\"type\": \"text_delta\", \"text\": \"that pod.\"}\n{\"type\": \"tool_calls\", \"tool_calls\": [...]}\n{\"type\": \"done\"}\n</code></pre> Event Type Purpose <code>text_delta</code> Incremental text tokens <code>tool_calls</code> Tools that need approval <code>executed_tool_calls</code> Tools that were just executed <code>commands</code> Terminal commands that need approval <code>executed_commands</code> Terminal commands that were executed <code>done</code> Stream complete <code>error</code> Error occurred"},{"location":"engineering-handoff/#key-concepts-ubiquitous-language","title":"Key Concepts &amp; Ubiquitous Language","text":"Term Definition Conversation A sequence of messages between user and agent; the aggregate root Turn One user message followed by one agent response Message A single communication unit with role (user/assistant) and content Tool A capability the agent can invoke (e.g., kubectl, AWS CLI) Tool Call A request to execute a tool with specific inputs; has lifecycle (pending\u2192approved\u2192executed) Approval Gate A checkpoint requiring human authorization before tool execution Platform Context Runtime environment data (tenant, namespace, credentials) Session Key-value store for persisting state across conversation turns Agent Runtime The port/interface that framework adapters implement Adapter Translates between our domain and a specific framework"},{"location":"engineering-handoff/#how-a-request-flows","title":"How a Request Flows","text":""},{"location":"engineering-handoff/#simple-flow-no-approval-needed","title":"Simple Flow (No Approval Needed)","text":"<pre><code>1. HTTP POST /chat\n      \u2502\n      \u25bc\n2. FastAPI Controller\n      \u2502 Converts HTTP \u2192 AgentRequest\n      \u25bc\n3. AgentService.execute()\n      \u2502 Loads conversation, adds message\n      \u25bc\n4. AgentRuntime.invoke() [via adapter]\n      \u2502 Calls LLM, gets tool calls\n      \u25bc\n5. Tool has requires_approval=False\n      \u2502 Execute immediately\n      \u25bc\n6. Return AgentResponse\n      \u2502\n      \u25bc\n7. HTTP 200 with response\n</code></pre>"},{"location":"engineering-handoff/#flow-with-approval-required","title":"Flow with Approval Required","text":"<pre><code>1. HTTP POST /chat\n      \u2502\n      \u25bc\n2-4. Same as above...\n      \u2502\n      \u25bc\n5. Tool has requires_approval=True\n      \u2502\n      \u25bc\n6. Return response with pending ToolCalls\n      \u2502 status=PENDING\n      \u25bc\n7. HTTP 200 with tool_calls requiring approval\n      \u2502\n      \u25bc\n8. User reviews in UI, clicks Approve\n      \u2502\n      \u25bc\n9. HTTP POST /chat with execute=true on ToolCall\n      \u2502\n      \u25bc\n10. Use case sees approved tool, executes it\n      \u2502\n      \u25bc\n11. Continue with execution result\n</code></pre>"},{"location":"engineering-handoff/#human-in-the-loop-explained","title":"Human-in-the-Loop Explained","text":""},{"location":"engineering-handoff/#why-approvals-exist","title":"Why Approvals Exist","text":"<p>Autonomous agents executing infrastructure operations is risky:</p> <ul> <li>Destructive actions: <code>kubectl delete pod</code> or <code>aws ec2 terminate-instances</code></li> <li>Irreversible changes: Data deletion, resource destruction</li> <li>Compliance: Some environments require human sign-off</li> <li>Cost: Expensive operations should be reviewed</li> </ul>"},{"location":"engineering-handoff/#how-approvals-work","title":"How Approvals Work","text":"<ol> <li> <p>Tool Configuration: Each <code>Tool</code> has <code>requires_approval: bool</code></p> </li> <li> <p>Approval Policy: Domain service that determines if a specific call needs approval based on tool config and context</p> </li> <li> <p>ToolCall Lifecycle:    <pre><code>PENDING \u2500\u2500approve()\u2500\u2500\u25ba APPROVED \u2500\u2500execute()\u2500\u2500\u25ba COMPLETED\n   \u2502                                               \n   \u2514\u2500\u2500reject(reason)\u2500\u2500\u25ba REJECTED\n</code></pre></p> </li> <li> <p>Conversation Blocking: The <code>Conversation</code> aggregate won't accept new messages while tool calls are pending</p> </li> </ol>"},{"location":"engineering-handoff/#implementation-points","title":"Implementation Points","text":"<ul> <li><code>ToolCall</code> entity in <code>domain/entities/tool_call.py</code></li> <li><code>ApprovalPolicy</code> service in <code>domain/services/approval_policy.py</code></li> <li><code>ApprovalCallback</code> port in <code>application/ports/approval_callback.py</code></li> </ul>"},{"location":"engineering-handoff/#session-management","title":"Session Management","text":"<p>Sessions provide a mechanism for persisting state across conversation turns. This is essential for multi-step workflows where tools need to share data.</p>"},{"location":"engineering-handoff/#session-class","title":"Session Class","text":"<p>The <code>Session</code> class (<code>dcaf/core/session.py</code>) is a key-value store with typed serialization support:</p> <pre><code>from dcaf.core import Session\n\nsession = Session()\n\n# Basic operations\nsession.set(\"user_id\", \"12345\")\nuser_id = session.get(\"user_id\")\nsession.delete(\"user_id\")\n\n# With defaults\ncount = session.get(\"count\", 0)\n\n# Dict-like access\nsession[\"key\"] = \"value\"\nvalue = session[\"key\"]\n\n# Bulk operations\nsession.update({\"a\": 1, \"b\": 2})\nsession.clear()\n</code></pre>"},{"location":"engineering-handoff/#typed-storage","title":"Typed Storage","text":"<p>Session supports automatic serialization/deserialization of Pydantic models and dataclasses:</p> <pre><code>from pydantic import BaseModel\nfrom dcaf.core import Session\n\nclass UserPrefs(BaseModel):\n    theme: str = \"light\"\n    language: str = \"en\"\n\nsession = Session()\n\n# Store Pydantic model (auto-serializes via model_dump())\nsession.set(\"prefs\", UserPrefs(theme=\"dark\"))\n\n# Retrieve as typed model (auto-deserializes via model_validate())\nprefs = session.get(\"prefs\", as_type=UserPrefs)\nprint(prefs.theme)  # \"dark\"\n\n# Without type - returns raw dict\nraw = session.get(\"prefs\")  # {\"theme\": \"dark\", \"language\": \"en\"}\n</code></pre> <p>Serialization/Deserialization:</p> Type Serialization Deserialization Pydantic model <code>model_dump()</code> <code>model_validate()</code> Dataclass <code>asdict()</code> Constructor <code>cls(**data)</code> Primitives/dicts Stored as-is Returned as-is"},{"location":"engineering-handoff/#using-session-in-tools","title":"Using Session in Tools","text":"<p>Tools can declare a <code>Session</code> parameter that DCAF automatically injects:</p> <pre><code>from pydantic import BaseModel, Field\nfrom dcaf.core import Session\nfrom dcaf.tools import tool\n\nclass ShoppingCart(BaseModel):\n    items: list[dict] = Field(default_factory=list)\n\n@tool(description=\"Add item to cart\")\ndef add_to_cart(item: str, quantity: int, session: Session) -&gt; str:\n    # Get as typed model\n    cart = session.get(\"cart\", as_type=ShoppingCart) or ShoppingCart()\n    cart.items.append({\"item\": item, \"quantity\": quantity})\n    session.set(\"cart\", cart)\n    return f\"Added {quantity}x {item}\"\n</code></pre>"},{"location":"engineering-handoff/#protocol-integration","title":"Protocol Integration","text":"<p>Session data travels with the HelpDesk protocol in the <code>data.session</code> field:</p> <p>Response (agent \u2192 HelpDesk):</p> <pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"Added item to cart.\",\n  \"data\": {\n    \"session\": {\n      \"cart\": [{\"item\": \"Widget\", \"quantity\": 2}]\n    }\n  }\n}\n</code></pre> <p>Subsequent Request (HelpDesk \u2192 agent):</p> <pre><code>{\n  \"messages\": [{\n    \"role\": \"user\",\n    \"content\": \"What's in my cart?\",\n    \"data\": {\n      \"session\": {\n        \"cart\": [{\"item\": \"Widget\", \"quantity\": 2}]\n      }\n    }\n  }]\n}\n</code></pre>"},{"location":"engineering-handoff/#implementation-points_1","title":"Implementation Points","text":"<ul> <li><code>Session</code> class in <code>dcaf/core/session.py</code></li> <li>Session injection in tool execution pipeline</li> <li>Serialization in <code>AgentResponse.to_helpdesk_message()</code></li> </ul>"},{"location":"engineering-handoff/#tool-schema-options","title":"Tool Schema Options","text":"<p>DCAF supports three ways to define tool schemas, providing flexibility from simple auto-generation to full type-safe Pydantic models:</p>"},{"location":"engineering-handoff/#option-1-auto-generate-from-function-signature","title":"Option 1: Auto-Generate from Function Signature","text":"<pre><code>@tool(description=\"List pods\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n</code></pre> <p>Schema is automatically generated from type hints.</p>"},{"location":"engineering-handoff/#option-2-explicit-dict-schema","title":"Option 2: Explicit Dict Schema","text":"<pre><code>@tool(\n    description=\"Delete a pod\",\n    schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\"type\": \"string\", \"description\": \"Pod name\"},\n            \"namespace\": {\"type\": \"string\", \"default\": \"default\"}\n        },\n        \"required\": [\"name\"]\n    }\n)\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n</code></pre>"},{"location":"engineering-handoff/#option-3-pydantic-model","title":"Option 3: Pydantic Model","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass DeletePodInput(BaseModel):\n    name: str = Field(..., description=\"Pod name\")\n    namespace: str = Field(default=\"default\")\n\n@tool(description=\"Delete a pod\", schema=DeletePodInput)\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n</code></pre> <p>DCAF automatically converts Pydantic models to JSON schema via <code>model_json_schema()</code>.</p>"},{"location":"engineering-handoff/#accessing-tool-schema","title":"Accessing Tool Schema","text":"<p>The <code>Tool</code> class provides access to the schema:</p> <pre><code>tool = create_tool(delete_pod)\nprint(tool.name)         # \"delete_pod\"\nprint(tool.description)  # \"Delete a pod\"\nprint(tool.schema)       # Full schema dict including input_schema\n</code></pre>"},{"location":"engineering-handoff/#adding-a-new-framework-adapter","title":"Adding a New Framework Adapter","text":"<p>Example: Adding a LangChain adapter</p>"},{"location":"engineering-handoff/#step-1-create-the-adapter-folder","title":"Step 1: Create the Adapter Folder","text":"<pre><code>dcaf/core/adapters/outbound/langchain/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 adapter.py\n\u251c\u2500\u2500 tool_converter.py\n\u251c\u2500\u2500 message_converter.py\n\u2514\u2500\u2500 types.py\n</code></pre>"},{"location":"engineering-handoff/#step-2-implement-the-tool-converter","title":"Step 2: Implement the Tool Converter","text":"<pre><code># tool_converter.py\nfrom dcaf.tools import Tool\n\nclass LangChainToolConverter:\n    def to_langchain(self, tool: Tool) -&gt; dict:\n        \"\"\"Convert dcaf Tool to LangChain tool format.\"\"\"\n        return {\n            \"name\": tool.name,\n            \"description\": tool.description,\n            \"parameters\": tool.schema[\"input_schema\"],\n        }\n</code></pre>"},{"location":"engineering-handoff/#step-3-implement-the-message-converter","title":"Step 3: Implement the Message Converter","text":"<pre><code># message_converter.py\nfrom dcaf.core.domain.entities import Message\nfrom dcaf.core.application.dto import AgentResponse\n\nclass LangChainMessageConverter:\n    def to_langchain(self, messages: List[Message]) -&gt; List[dict]:\n        \"\"\"Convert dcaf Messages to LangChain format.\"\"\"\n        ...\n\n    def from_langchain(self, response) -&gt; AgentResponse:\n        \"\"\"Convert LangChain response to our domain.\"\"\"\n        ...\n</code></pre>"},{"location":"engineering-handoff/#step-4-implement-the-adapter","title":"Step 4: Implement the Adapter","text":"<pre><code># adapter.py\nfrom dcaf.core.application.ports import AgentRuntime\n\nclass LangChainAdapter(AgentRuntime):\n    def __init__(self, model: str):\n        self._tool_converter = LangChainToolConverter()\n        self._message_converter = LangChainMessageConverter()\n        # Initialize LangChain components\n\n    def invoke(self, messages, tools) -&gt; AgentResponse:\n        lc_messages = self._message_converter.to_langchain(messages)\n        lc_tools = [self._tool_converter.to_langchain(t) for t in tools]\n\n        response = self._chain.invoke(lc_messages, tools=lc_tools)\n\n        return self._message_converter.from_langchain(response)\n</code></pre>"},{"location":"engineering-handoff/#step-5-export-from-__init__py","title":"Step 5: Export from <code>__init__.py</code>","text":"<pre><code>from .adapter import LangChainAdapter\n__all__ = [\"LangChainAdapter\"]\n</code></pre>"},{"location":"engineering-handoff/#testing-philosophy","title":"Testing Philosophy","text":""},{"location":"engineering-handoff/#test-against-abstractions","title":"Test Against Abstractions","text":"<p>We test business logic using fake implementations of ports, not real frameworks:</p> <pre><code># tests/test_execute_agent.py\ndef test_execute_agent_with_approval():\n    fake_runtime = FakeAgentRuntime()\n    fake_runtime.will_return_tool_call(\"kubectl_delete\", requires_approval=True)\n\n    service = AgentService(runtime=fake_runtime, ...)\n    response = service.execute(request)\n\n    assert response.pending_approvals == 1\n</code></pre>"},{"location":"engineering-handoff/#testing-layers","title":"Testing Layers","text":"Layer What to Test How to Test Domain Entities, VOs, Services Unit tests, no mocks needed Application Use cases Fake implementations of ports Adapters Converters, integration Real framework, integration tests"},{"location":"engineering-handoff/#where-to-find-things","title":"Where to Find Things","text":"<pre><code>dcaf/core/\n\u251c\u2500\u2500 domain/                    # Pure business logic\n\u2502   \u251c\u2500\u2500 entities/              # ToolCall, Message, Conversation\n\u2502   \u251c\u2500\u2500 value_objects/         # ToolCallId, ToolInput, etc.\n\u2502   \u251c\u2500\u2500 services/              # ApprovalPolicy\n\u2502   \u251c\u2500\u2500 events/                # Domain events\n\u2502   \u2514\u2500\u2500 exceptions.py          # Domain exceptions\n\u2502\n\u251c\u2500\u2500 application/               # Use case orchestration\n\u2502   \u251c\u2500\u2500 services/             # ExecuteAgent, ApproveToolCall\n\u2502   \u251c\u2500\u2500 ports/                 # AgentRuntime, ConversationRepository\n\u2502   \u2514\u2500\u2500 dto/                   # Request/Response objects\n\u2502\n\u251c\u2500\u2500 adapters/                  # External integrations\n\u2502   \u251c\u2500\u2500 inbound/               # HTTP controllers\n\u2502   \u2514\u2500\u2500 outbound/              # Framework adapters\n\u2502       \u251c\u2500\u2500 agno/              # Agno-specific code\n\u2502       \u2514\u2500\u2500 langchain/         # LangChain-specific code\n\u2502\n\u251c\u2500\u2500 infrastructure/            # Cross-cutting concerns\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u2514\u2500\u2500 logging.py\n\u2502\n\u2514\u2500\u2500 testing/                   # Test support\n    \u251c\u2500\u2500 fakes.py               # Fake implementations\n    \u251c\u2500\u2500 builders.py            # Test data builders\n    \u2514\u2500\u2500 fixtures.py            # pytest fixtures\n</code></pre>"},{"location":"engineering-handoff/#a2a-agent-to-agent-protocol","title":"A2A (Agent-to-Agent) Protocol","text":"<p>DCAF supports the A2A (Agent-to-Agent) protocol developed by Google, enabling agents to discover and communicate with each other using standardized HTTP/JSON-RPC interfaces.</p>"},{"location":"engineering-handoff/#what-is-a2a","title":"What is A2A?","text":"<p>A2A is an open protocol for agent-to-agent communication that enables:</p> <ul> <li>Agent Discovery: Agents expose a card describing their capabilities</li> <li>Task Execution: Agents can send tasks to other agents</li> <li>Async Support: Long-running tasks can execute asynchronously</li> <li>Standard Protocol: Uses HTTP, JSON-RPC, and SSE (Server-Sent Events)</li> </ul>"},{"location":"engineering-handoff/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         A2A ARCHITECTURE                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n  \u2502 Orchestrator \u2502                          \u2502 K8s Agent    \u2502\n  \u2502   Agent      \u2502                          \u2502 (Specialist) \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u25b2\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                                         \u2502\n         \u2502  1. Fetch Agent Card                   \u2502\n         \u2502  GET /.well-known/agent.json           \u2502\n         \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n         \u2502                                         \u2502\n         \u2502  2. Send Task                           \u2502\n         \u2502  POST /a2a/tasks/send                   \u2502\n         \u2502  {\"message\": \"List failing pods\"}       \u2502\n         \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n         \u2502                                         \u2502\n         \u2502  3. TaskResult                          \u2502\n         \u2502  {\"text\": \"Found 3 failing pods...\"}    \u2502\n         \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n         \u2502                                         \u2502\n</code></pre>"},{"location":"engineering-handoff/#code-structure","title":"Code Structure","text":"<pre><code>dcaf/core/a2a/\n\u251c\u2500\u2500 __init__.py          # Public exports: RemoteAgent, AgentCard, etc.\n\u251c\u2500\u2500 models.py            # AgentCard, Task, TaskResult, Artifact\n\u251c\u2500\u2500 client.py            # RemoteAgent (user-facing client)\n\u251c\u2500\u2500 server.py            # A2A server routes/utilities\n\u251c\u2500\u2500 protocols.py         # Abstract interfaces (for swapping implementations)\n\u2514\u2500\u2500 adapters/\n    \u251c\u2500\u2500 __init__.py\n    \u2514\u2500\u2500 agno.py          # Agno A2A implementation (hidden from users)\n</code></pre>"},{"location":"engineering-handoff/#user-facing-api_1","title":"User-Facing API","text":"<p>Server Side (Exposing an Agent):</p> <pre><code>from dcaf.core import Agent, serve\n\nagent = Agent(\n    name=\"k8s-assistant\",              # A2A identity\n    description=\"Kubernetes helper\",   # A2A description\n    tools=[list_pods, delete_pod],\n)\n\n# Enable A2A alongside REST API\nserve(agent, port=8000, a2a=True)\n</code></pre> <p>Client Side (Calling Remote Agents):</p> <pre><code>from dcaf.core.a2a import RemoteAgent\n\n# Connect to remote agent\nk8s = RemoteAgent(url=\"http://k8s-agent:8000\")\n\n# Direct call\nresult = k8s.send(\"What pods are failing in production?\")\nprint(result.text)\n\n# Use as a tool for another agent\norchestrator = Agent(\n    tools=[k8s.as_tool()],\n    system=\"Route requests to specialist agents\"\n)\n</code></pre>"},{"location":"engineering-handoff/#internal-implementation","title":"Internal Implementation","text":"<p>The A2A implementation follows DCAF's adapter pattern to remain framework-agnostic:</p> <ol> <li>Protocols (<code>protocols.py</code>): Abstract interfaces for A2A client and server</li> <li>Models (<code>models.py</code>): Framework-agnostic data structures (AgentCard, Task, etc.)</li> <li>Adapters (<code>adapters/agno.py</code>): Concrete implementation using Agno's A2A support</li> <li>Facades (<code>client.py</code>, <code>server.py</code>): User-facing APIs that hide implementation details</li> </ol> <p>This allows swapping A2A implementations (e.g., from Agno to a custom implementation) without changing user code.</p>"},{"location":"engineering-handoff/#a2a-protocol-endpoints","title":"A2A Protocol Endpoints","text":"<p>When <code>serve(agent, a2a=True)</code> is called, these endpoints are added:</p> Endpoint Method Purpose <code>/.well-known/agent.json</code> GET Agent card (discovery) <code>/a2a/tasks/send</code> POST Receive tasks from other agents <code>/a2a/tasks/{id}</code> GET Task status (for async tasks)"},{"location":"engineering-handoff/#agentcard-generation","title":"AgentCard Generation","text":"<p>Agent cards are automatically generated from DCAF Agent configuration:</p> <pre><code>{\n  \"name\": \"k8s-assistant\",                    # From agent.name\n  \"description\": \"Manages Kubernetes...\",     # From agent.description\n  \"url\": \"http://k8s-agent:8000\",            # From server URL\n  \"skills\": [\"list_pods\", \"delete_pod\"],     # From agent.tools\n  \"version\": \"1.0\",                          # A2A protocol version\n  \"metadata\": {\n    \"framework\": \"dcaf\",\n    \"model\": \"anthropic.claude-3-sonnet...\",\n    \"provider\": \"bedrock\"\n  }\n}\n</code></pre>"},{"location":"engineering-handoff/#multi-agent-patterns","title":"Multi-Agent Patterns","text":"<p>Peer-to-Peer:</p> <pre><code># Agent 1\nk8s = Agent(name=\"k8s\", tools=[...])\nserve(k8s, port=8001, a2a=True)\n\n# Agent 2\naws = Agent(name=\"aws\", tools=[...])\nserve(aws, port=8002, a2a=True)\n\n# Each can call the other\nk8s_remote = RemoteAgent(url=\"http://localhost:8001\")\naws_remote = RemoteAgent(url=\"http://localhost:8002\")\n</code></pre> <p>Orchestration:</p> <pre><code># Specialist agents\nk8s = RemoteAgent(url=\"http://k8s-agent:8000\")\naws = RemoteAgent(url=\"http://aws-agent:8000\")\n\n# Orchestrator routes to specialists\norchestrator = Agent(\n    name=\"orchestrator\",\n    tools=[k8s.as_tool(), aws.as_tool()],\n    system=\"Route to the appropriate specialist agent\"\n)\n</code></pre>"},{"location":"engineering-handoff/#testing-a2a-agents","title":"Testing A2A Agents","text":"<p>Use the <code>RemoteAgent</code> client to test A2A-enabled agents:</p> <pre><code>from dcaf.core.a2a import RemoteAgent\n\n# Start agent with A2A\nagent = Agent(name=\"test\", tools=[...])\nserve(agent, port=8000, a2a=True)\n\n# Test from another process/terminal\nremote = RemoteAgent(url=\"http://localhost:8000\")\n\n# Check agent card\nprint(remote.card.name)       # \"test\"\nprint(remote.card.skills)     # Tool names\n\n# Send task\nresult = remote.send(\"List pods\")\nassert result.status == \"completed\"\n</code></pre>"},{"location":"engineering-handoff/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Dynamic Discovery: Agent registry/service mesh integration</li> <li>Streaming Tasks: Real-time task updates via SSE</li> <li>Hierarchical Teams: Agents managing sub-agents</li> <li>Workflow Orchestration: Complex multi-agent workflows</li> </ul>"},{"location":"engineering-handoff/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-001: Clean Architecture</li> <li>ADR-002: DDD Tactical Patterns</li> <li>ADR-003: Adapter Pattern for Frameworks</li> <li>ADR-004: Approval-First Design</li> <li>ADR-005: Cohesive Provider Modules</li> <li>ADR-006: Strangler Fig Migration</li> <li>ADR-007: Lowercase Chat Endpoints</li> </ul>"},{"location":"getting-started/","title":"Getting Started with DCAF","text":"<p>This guide walks you through building AI agents with DCAF (DuploCloud Agent Framework). You'll learn to create agents, define tools, serve them as APIs, and implement human-in-the-loop approval for dangerous operations.</p>"},{"location":"getting-started/#what-is-dcaf","title":"What is DCAF?","text":"<p>DCAF is a framework for building AI agents that can:</p> <ul> <li>Execute tools safely - Dangerous operations require human approval before execution</li> <li>Persist state - Session management across conversation turns</li> <li>Switch LLM providers - Swap between Bedrock, OpenAI, Anthropic without code changes</li> <li>Stream responses - Real-time token-by-token output</li> </ul> <pre><code>from dcaf.core import Agent, serve\nfrom dcaf.tools import tool\n\n@tool(requires_approval=True, description=\"Delete a Kubernetes pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n\nagent = Agent(tools=[delete_pod])\nserve(agent, port=8000)\n</code></pre>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":""},{"location":"getting-started/#required","title":"Required","text":"<ul> <li>Python 3.11+ - DCAF supports Python 3.11, 3.12, and 3.13</li> <li>AWS Account - With access to AWS Bedrock</li> <li>AWS Credentials - With permissions to invoke Bedrock models</li> </ul>"},{"location":"getting-started/#optional","title":"Optional","text":"<ul> <li>DuploCloud Account - For credential management CLI</li> <li>Docker - For containerized deployments</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#from-github","title":"From GitHub","text":"<pre><code>pip install git+https://github.com/duplocloud/service-desk-agents.git\n</code></pre>"},{"location":"getting-started/#for-development","title":"For Development","text":"<pre><code>git clone https://github.com/duplocloud/service-desk-agents.git\ncd service-desk-agents\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/#verify-installation","title":"Verify Installation","text":"<pre><code>from dcaf.core import Agent, serve\nprint(\"DCAF installed successfully!\")\n</code></pre>"},{"location":"getting-started/#environment-setup","title":"Environment Setup","text":""},{"location":"getting-started/#option-1-aws-profiles-recommended","title":"Option 1: AWS Profiles (Recommended)","text":"<p>Use AWS profiles from <code>~/.aws/credentials</code>:</p> <pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    aws_profile=\"my-profile\",    # Use this AWS profile\n    aws_region=\"us-east-1\",      # Optional region override\n)\n</code></pre> <p>Configure profiles in <code>~/.aws/credentials</code>:</p> <pre><code>[default]\naws_access_key_id = AKIA...\naws_secret_access_key = ...\n\n[production]\naws_access_key_id = AKIA...\naws_secret_access_key = ...\nregion = us-west-2\n</code></pre>"},{"location":"getting-started/#option-2-environment-variables","title":"Option 2: Environment Variables","text":"<p>Create a <code>.env</code> file:</p> <pre><code># AWS Credentials\nAWS_ACCESS_KEY_ID=your_access_key_id\nAWS_SECRET_ACCESS_KEY=your_secret_access_key\nAWS_SESSION_TOKEN=your_session_token  # Optional\nAWS_REGION=us-east-1\n\n# Optional: Bedrock Configuration\nBEDROCK_MODEL_ID=us.anthropic.claude-3-5-sonnet-20240620-v1:0\n\n# For other providers\nANTHROPIC_API_KEY=sk-ant-...\nOPENAI_API_KEY=sk-...\n</code></pre>"},{"location":"getting-started/#option-3-duplocloud-optional","title":"Option 3: DuploCloud (Optional)","text":"<pre><code># Update AWS credentials via DuploCloud\ndcaf env-update-aws-creds --tenant=your-tenant --host=https://your-duplo-host.duplocloud.net\n</code></pre>"},{"location":"getting-started/#1-the-agent","title":"1. The Agent","text":"<p>The <code>Agent</code> class is the core of DCAF. It orchestrates conversations, manages tool execution, and handles the approval workflow.</p>"},{"location":"getting-started/#creating-an-agent","title":"Creating an Agent","text":"<pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    tools=[...],                         # Tools the agent can use\n    system=\"You are a helpful assistant\", # System prompt\n    model=\"anthropic.claude-3-sonnet\",   # LLM model (optional)\n)\n</code></pre>"},{"location":"getting-started/#running-the-agent","title":"Running the Agent","text":"<pre><code>from dcaf.core import Agent, ChatMessage\n\nagent = Agent(tools=[...])\n\n# Simple - pass messages\nresponse = agent.run(messages=[\n    ChatMessage.user(\"What pods are running?\")\n])\nprint(response.text)\n\n# With conversation history\nresponse = agent.run(messages=[\n    ChatMessage.user(\"What pods are running?\"),\n    ChatMessage.assistant(\"There are 3 pods: nginx, redis, api\"),\n    ChatMessage.user(\"Tell me more about nginx\"),  # \u2190 Current message\n])\n</code></pre>"},{"location":"getting-started/#using-plain-dicts-json-compatible","title":"Using Plain Dicts (JSON Compatible)","text":"<p>You can pass plain dictionaries, useful when receiving messages from JSON APIs:</p> <pre><code># From JSON/API request\nresponse = agent.run(messages=[\n    {\"role\": \"user\", \"content\": \"What pods are running?\"},\n    {\"role\": \"assistant\", \"content\": \"There are 3 pods...\"},\n    {\"role\": \"user\", \"content\": \"Tell me more\"},\n])\n</code></pre>"},{"location":"getting-started/#choosing-a-provider","title":"Choosing a Provider","text":"<p>DCAF supports multiple LLM providers:</p> Provider Description Model Examples <code>bedrock</code> AWS Bedrock (default) <code>anthropic.claude-3-sonnet-20240229-v1:0</code> <code>anthropic</code> Direct Anthropic API <code>claude-3-sonnet-20240229</code> <code>openai</code> OpenAI API <code>gpt-4</code>, <code>gpt-4-turbo</code>, <code>gpt-3.5-turbo</code> <code>azure</code> Azure OpenAI Deployment names <code>google</code> Google AI <code>gemini-pro</code> <code>ollama</code> Local Ollama <code>llama2</code>, <code>mistral</code>, <code>codellama</code> <pre><code># AWS Bedrock (default)\nagent = Agent(provider=\"bedrock\", model=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n\n# OpenAI\nagent = Agent(provider=\"openai\", model=\"gpt-4\", api_key=\"sk-...\")\n\n# Local Ollama (free, runs locally)\nagent = Agent(provider=\"ollama\", model=\"llama2\")\n</code></pre>"},{"location":"getting-started/#custom-agent-functions","title":"Custom Agent Functions","text":"<p>For complex logic beyond simple tool calling, define a custom function:</p> <pre><code>from dcaf.core import Agent, Session, serve\nfrom dcaf.core.primitives import AgentResult\n\ndef my_custom_agent(messages: list, context: dict, session: Session) -&gt; AgentResult:\n    \"\"\"Custom agent with multi-step logic and session access.\"\"\"\n    # Track call count in session\n    call_count = session.get(\"call_count\", 0)\n    session.set(\"call_count\", call_count + 1)\n\n    # Step 1: Classify intent\n    classifier = Agent(system=\"Classify the user's intent\")\n    intent = classifier.run(messages).text\n\n    # Step 2: Route to appropriate handler\n    if \"kubernetes\" in intent.lower():\n        k8s_agent = Agent(tools=[list_pods, delete_pod])\n        response = k8s_agent.run(messages, session=session.to_dict())\n    else:\n        general_agent = Agent(system=\"You are a helpful assistant\")\n        response = general_agent.run(messages)\n\n    # Return result with updated session\n    return AgentResult(\n        text=response.text,\n        session=session.to_dict(),\n    )\n\n# Serve the custom function\nserve(my_custom_agent, port=8000)\n</code></pre> <p>Note: The <code>session</code> parameter is optional for backward compatibility. Functions without it still work.</p>"},{"location":"getting-started/#2-tools","title":"2. Tools","text":"<p>Tools are capabilities your agent can use. DCAF provides three ways to define tool schemas.</p>"},{"location":"getting-started/#option-1-auto-generate-simplest","title":"Option 1: Auto-Generate (Simplest)","text":"<p>Let DCAF generate the schema from your function signature:</p> <pre><code>from dcaf.tools import tool\n\n@tool(description=\"Get current weather for a city\")\ndef get_weather(city: str, units: str = \"celsius\") -&gt; str:\n    \"\"\"Fetch weather data.\"\"\"\n    return weather_api.get(city, units)\n</code></pre> <p>DCAF automatically creates a JSON schema from the type hints:</p> <pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"city\": {\"type\": \"string\"},\n    \"units\": {\"type\": \"string\", \"default\": \"celsius\"}\n  },\n  \"required\": [\"city\"]\n}\n</code></pre>"},{"location":"getting-started/#option-2-dict-schema-full-control","title":"Option 2: Dict Schema (Full Control)","text":"<p>Define the exact JSON schema yourself:</p> <pre><code>@tool(\n    description=\"Get current weather for a city\",\n    schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"city\": {\n                \"type\": \"string\",\n                \"description\": \"City name (e.g., 'London', 'New York')\"\n            },\n            \"units\": {\n                \"type\": \"string\",\n                \"enum\": [\"celsius\", \"fahrenheit\"],\n                \"description\": \"Temperature units\"\n            }\n        },\n        \"required\": [\"city\"]\n    }\n)\ndef get_weather(city: str, units: str = \"celsius\") -&gt; str:\n    return weather_api.get(city, units)\n</code></pre>"},{"location":"getting-started/#option-3-pydantic-model-type-safe","title":"Option 3: Pydantic Model (Type-Safe)","text":"<p>Use Pydantic for IDE autocomplete, validation, and reusable schemas:</p> <pre><code>from pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass WeatherInput(BaseModel):\n    \"\"\"Schema for weather requests.\"\"\"\n    city: str = Field(..., description=\"City name\")\n    units: Literal[\"celsius\", \"fahrenheit\"] = Field(\n        default=\"celsius\",\n        description=\"Temperature units\"\n    )\n\n@tool(description=\"Get current weather\", schema=WeatherInput)\ndef get_weather(city: str, units: str = \"celsius\") -&gt; str:\n    return weather_api.get(city, units)\n</code></pre> <p>Just pass the Pydantic class - DCAF automatically converts it to JSON schema.</p>"},{"location":"getting-started/#tool-options","title":"Tool Options","text":"Option Default Description <code>description</code> Docstring What the tool does (shown to LLM) <code>requires_approval</code> <code>False</code> Whether to require human approval <code>schema</code> Auto-generated Dict schema OR Pydantic model class"},{"location":"getting-started/#complete-tools-example","title":"Complete Tools Example","text":"<pre><code>from dcaf.core import Agent, serve\nfrom dcaf.tools import tool\nfrom pydantic import BaseModel, Field\n\n# Auto-generated schema (safe operation)\n@tool(description=\"List Kubernetes pods\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n\n# Pydantic schema (dangerous operation)\nclass DeletePodInput(BaseModel):\n    name: str = Field(..., description=\"Pod name to delete\")\n    namespace: str = Field(default=\"default\")\n    force: bool = Field(default=False, description=\"Force immediate deletion\")\n\n@tool(\n    description=\"Delete a Kubernetes pod\",\n    requires_approval=True,\n    schema=DeletePodInput\n)\ndef delete_pod(name: str, namespace: str = \"default\", force: bool = False) -&gt; str:\n    cmd = f\"kubectl delete pod {name} -n {namespace}\"\n    if force:\n        cmd += \" --force --grace-period=0\"\n    return kubectl(cmd)\n\n# Create and serve the agent\nagent = Agent(\n    tools=[list_pods, delete_pod],\n    system=\"You are a Kubernetes assistant.\"\n)\nserve(agent, port=8000)\n</code></pre>"},{"location":"getting-started/#3-serving-your-agent","title":"3. Serving Your Agent","text":"<p>Expose your agent as a REST API with one line:</p> <pre><code>from dcaf.core import Agent, serve\n\nagent = Agent(tools=[...])\nserve(agent, port=8000)\n</code></pre>"},{"location":"getting-started/#available-endpoints","title":"Available Endpoints","text":"Endpoint Method Description <code>/health</code> GET Health check <code>/api/chat</code> POST Synchronous chat <code>/api/chat-stream</code> POST Streaming (NDJSON)"},{"location":"getting-started/#testing-your-agent","title":"Testing Your Agent","text":"<p>With curl:</p> <pre><code>curl -X POST http://localhost:8000/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"messages\": [{\"role\": \"user\", \"content\": \"List all pods\"}]}'\n</code></pre> <p>With Python:</p> <pre><code>import requests\n\nresponse = requests.post(\n    \"http://localhost:8000/api/chat\",\n    json={\"messages\": [{\"role\": \"user\", \"content\": \"List all pods\"}]}\n)\nprint(response.json())\n</code></pre>"},{"location":"getting-started/#streaming-responses","title":"Streaming Responses","text":"<p>For real-time token-by-token output:</p> <pre><code>curl -X POST http://localhost:8000/api/chat-stream \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"messages\": [{\"role\": \"user\", \"content\": \"Explain Kubernetes\"}]}'\n</code></pre> <p>Response (NDJSON):</p> <pre><code>{\"type\": \"text_delta\", \"text\": \"Kubernetes\"}\n{\"type\": \"text_delta\", \"text\": \" is\"}\n{\"type\": \"text_delta\", \"text\": \" a container orchestration platform...\"}\n{\"type\": \"done\"}\n</code></pre>"},{"location":"getting-started/#adding-custom-routes","title":"Adding Custom Routes","text":"<pre><code>from fastapi import APIRouter\n\ncustom_router = APIRouter()\n\n@custom_router.get(\"/custom/status\")\ndef get_status():\n    return {\"status\": \"operational\"}\n\nserve(agent, port=8000, additional_routers=[custom_router])\n</code></pre>"},{"location":"getting-started/#4-human-in-the-loop-approval","title":"4. Human-in-the-Loop Approval","text":"<p>A core feature of DCAF is requiring human approval for dangerous operations before execution.</p>"},{"location":"getting-started/#why-approval-matters","title":"Why Approval Matters","text":"<p>Autonomous agents executing infrastructure operations is risky:</p> <ul> <li>Destructive actions: <code>kubectl delete pod</code> or <code>aws ec2 terminate-instances</code></li> <li>Irreversible changes: Data deletion, resource destruction</li> <li>Compliance: Some environments require human sign-off</li> <li>Cost: Expensive operations should be reviewed</li> </ul>"},{"location":"getting-started/#marking-tools-for-approval","title":"Marking Tools for Approval","text":"<pre><code>@tool(requires_approval=True, description=\"Delete a pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n</code></pre>"},{"location":"getting-started/#the-approval-flow","title":"The Approval Flow","text":"<pre><code>User: \"Delete the failing pod\"\n           \u2502\n           \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Agent calls \u2502\n    \u2502  delete_pod  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  requires_approval=True  \u2502\n    \u2502  \u2192 Pause execution       \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Return pending tool     \u2502\n    \u2502  call to user            \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  User reviews:           \u2502\n    \u2502  [Approve] or [Reject]   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510\n     \u25bc           \u25bc\n  Approved    Rejected\n     \u2502           \u2502\n     \u25bc           \u25bc\n  Execute    Skip tool,\n  the tool   continue\n</code></pre>"},{"location":"getting-started/#response-format-pending-approval","title":"Response Format: Pending Approval","text":"<p>When a tool requires approval, the response includes the pending tool call:</p> <pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"I'll delete the pod. This requires your approval.\",\n  \"data\": {\n    \"tool_calls\": [\n      {\n        \"id\": \"tc_abc123\",\n        \"name\": \"delete_pod\",\n        \"input\": {\"name\": \"my-pod\", \"namespace\": \"default\"},\n        \"execute\": false\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"getting-started/#approving-a-tool-call","title":"Approving a Tool Call","text":"<p>Send back the tool call with <code>execute: true</code>:</p> <pre><code>{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"\",\n      \"data\": {\n        \"tool_calls\": [\n          {\n            \"id\": \"tc_abc123\",\n            \"name\": \"delete_pod\",\n            \"input\": {\"name\": \"my-pod\", \"namespace\": \"default\"},\n            \"execute\": true\n          }\n        ]\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"getting-started/#rejecting-a-tool-call","title":"Rejecting a Tool Call","text":"<p>To reject, simply don't include it or set <code>execute: false</code>:</p> <pre><code>{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"No, don't delete that pod.\"\n    }\n  ]\n}\n</code></pre>"},{"location":"getting-started/#programmatic-handling","title":"Programmatic Handling","text":"<p>When using the Agent directly (not via HTTP):</p> <pre><code>response = agent.run(messages)\n\nif response.needs_approval:\n    print(\"Tools pending approval:\")\n    for tool in response.pending_tools:\n        print(f\"  - {tool.name}: {tool.input}\")\n\n    # Option 1: Approve all\n    response = response.approve_all()\n\n    # Option 2: Reject all\n    response = response.reject_all(\"User declined\")\n\n    # Option 3: Handle individually\n    for tool in response.pending_tools:\n        if should_approve(tool):\n            tool.approve()\n        else:\n            tool.reject(\"Not allowed\")\n    response = agent.resume(response.conversation_id)\n\nprint(response.text)\n</code></pre>"},{"location":"getting-started/#approval-rules","title":"Approval Rules","text":"<p>Simple rule: Tools with <code>requires_approval=True</code> need human approval before execution.</p> <pre><code>@tool(requires_approval=True)\ndef restart_service(name: str) -&gt; str:\n    \"\"\"Restart a service - requires approval.\"\"\"\n    return kubectl(f\"rollout restart deployment {name}\")\n</code></pre>"},{"location":"getting-started/#5-session-management","title":"5. Session Management","text":"<p>Sessions allow you to persist state across conversation turns - perfect for multi-step workflows.</p>"},{"location":"getting-started/#what-is-a-session","title":"What is a Session?","text":"<p>A Session is a key-value store that:</p> <ul> <li>Persists across turns - Data survives between user messages</li> <li>Travels with the protocol - Automatically serialized in responses</li> <li>Supports typed models - Store Pydantic models and dataclasses with auto-serialization</li> <li>Available everywhere - In tools, interceptors, custom agent functions, and <code>agent.run()</code></li> </ul>"},{"location":"getting-started/#using-session-in-agentrun","title":"Using Session in agent.run()","text":"<p>You can pass session data directly to <code>agent.run()</code>:</p> <pre><code>from dcaf.core import Agent\n\nagent = Agent(tools=[...])\n\n# Pass session as a dict\nresponse = agent.run(\n    messages=[{\"role\": \"user\", \"content\": \"Continue the wizard\"}],\n    session={\"wizard_step\": 2, \"user_name\": \"Alice\"},\n)\n\n# Access updated session from response\nprint(response.session)  # {\"wizard_step\": 3, ...}\n\n# Pass session to next request\nnext_response = agent.run(\n    messages=[{\"role\": \"user\", \"content\": \"Next step\"}],\n    session=response.session,\n)\n</code></pre>"},{"location":"getting-started/#using-session-in-tools","title":"Using Session in Tools","text":"<pre><code>from dcaf.core import Session\nfrom dcaf.tools import tool\n\n@tool(description=\"Add item to shopping cart\")\ndef add_to_cart(item: str, quantity: int, session: Session) -&gt; str:\n    \"\"\"Session is automatically injected by DCAF.\"\"\"\n    cart = session.get(\"cart\", [])\n    cart.append({\"item\": item, \"quantity\": quantity})\n    session.set(\"cart\", cart)\n    return f\"Added {quantity}x {item}. Cart now has {len(cart)} items.\"\n\n@tool(description=\"View shopping cart\")\ndef view_cart(session: Session) -&gt; str:\n    cart = session.get(\"cart\", [])\n    if not cart:\n        return \"Cart is empty\"\n    return \"\\n\".join(f\"- {i['quantity']}x {i['item']}\" for i in cart)\n\n@tool(description=\"Checkout\")\ndef checkout(session: Session) -&gt; str:\n    cart = session.get(\"cart\", [])\n    total_items = sum(i[\"quantity\"] for i in cart)\n    session.delete(\"cart\")  # Clear after checkout\n    return f\"Checked out {total_items} items!\"\n</code></pre>"},{"location":"getting-started/#typed-session-storage","title":"Typed Session Storage","text":"<p>Store Pydantic models or dataclasses with automatic serialization/deserialization:</p> <pre><code>from pydantic import BaseModel, Field\nfrom dcaf.core import Session\nfrom dcaf.tools import tool\n\nclass CartItem(BaseModel):\n    name: str\n    quantity: int\n    price: float\n\nclass ShoppingCart(BaseModel):\n    items: list[CartItem] = Field(default_factory=list)\n    discount_code: str | None = None\n\n@tool(description=\"Add item to cart\")\ndef add_to_cart(name: str, quantity: int, price: float, session: Session) -&gt; str:\n    # Get as typed model (auto-deserializes from stored JSON)\n    cart = session.get(\"cart\", as_type=ShoppingCart) or ShoppingCart()\n\n    # Work with the typed model\n    cart.items.append(CartItem(name=name, quantity=quantity, price=price))\n\n    # Store it back (auto-serializes to JSON)\n    session.set(\"cart\", cart)\n\n    total = sum(item.price * item.quantity for item in cart.items)\n    return f\"Added {quantity}x {name}. Cart total: ${total:.2f}\"\n\n@tool(description=\"Apply discount code\")\ndef apply_discount(code: str, session: Session) -&gt; str:\n    cart = session.get(\"cart\", as_type=ShoppingCart)\n    if not cart:\n        return \"Cart is empty\"\n\n    cart.discount_code = code\n    session.set(\"cart\", cart)\n    return f\"Applied discount code: {code}\"\n</code></pre> <p>Dataclasses work too:</p> <pre><code>from dataclasses import dataclass\n\n@dataclass\nclass UserPrefs:\n    theme: str = \"light\"\n    language: str = \"en\"\n    notifications: bool = True\n\n# Store dataclass (auto-serializes)\nsession.set(\"prefs\", UserPrefs(theme=\"dark\"))\n\n# Retrieve as typed (auto-deserializes)\nprefs = session.get(\"prefs\", as_type=UserPrefs)\nprint(prefs.theme)  # \"dark\"\n</code></pre>"},{"location":"getting-started/#session-api","title":"Session API","text":"<pre><code>from dcaf.core import Session\n\nsession = Session()\n\n# Basic operations\nsession.set(\"user_id\", \"12345\")\nuser_id = session.get(\"user_id\")\nsession.delete(\"user_id\")\n\n# With defaults\ncount = session.get(\"count\", 0)  # Returns 0 if not set\n\n# Typed retrieval\ncart = session.get(\"cart\", as_type=ShoppingCart)  # Returns ShoppingCart or None\ncart = session.get(\"cart\", ShoppingCart(), as_type=ShoppingCart)  # With default\n\n# Check existence\nif session.has(\"user_id\"):\n    ...\n\n# Dict-like access\nsession[\"key\"] = \"value\"\nvalue = session[\"key\"]\n\n# Iteration\nfor key in session.keys():\n    print(key, session[key])\n\n# Bulk operations\nsession.update({\"a\": 1, \"b\": 2})\nsession.clear()\n</code></pre>"},{"location":"getting-started/#session-in-the-protocol","title":"Session in the Protocol","text":"<p>Session data is included in the <code>data.session</code> field of messages:</p> <p>Response with session:</p> <pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"Added 2x Widget to cart.\",\n  \"data\": {\n    \"session\": {\n      \"cart\": [{\"item\": \"Widget\", \"quantity\": 2}],\n      \"user_preference\": \"dark_mode\"\n    }\n  }\n}\n</code></pre> <p>Subsequent request (session travels back):</p> <pre><code>{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"What's in my cart?\",\n      \"data\": {\n        \"session\": {\n          \"cart\": [{\"item\": \"Widget\", \"quantity\": 2}],\n          \"user_preference\": \"dark_mode\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"getting-started/#multi-turn-workflow-example","title":"Multi-Turn Workflow Example","text":"<pre><code>Turn 1:\n  User: \"Add 2 widgets to cart\"\n  Agent: \"Added 2x Widget\" \n  Session: {\"cart\": [{\"item\": \"Widget\", \"qty\": 2}]}\n\nTurn 2:\n  User: \"Add 3 gadgets\"\n  Agent: \"Added 3x Gadget. Cart has 2 items.\"\n  Session: {\"cart\": [..., {\"item\": \"Gadget\", \"qty\": 3}]}\n\nTurn 3:\n  User: \"Checkout\"\n  Agent: \"Checked out 5 items!\"\n  Session: {}  \u2190 Cart cleared\n</code></pre>"},{"location":"getting-started/#6-advanced-topics","title":"6. Advanced Topics","text":""},{"location":"getting-started/#interceptors","title":"Interceptors","text":"<p>Interceptors let you hook into the request/response pipeline. They also have access to session data:</p> <pre><code>from dcaf.core import Agent, LLMRequest, LLMResponse, InterceptorError\n\ndef add_context(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Add tenant info and session data before sending to LLM.\"\"\"\n    tenant = request.context.get(\"tenant_name\", \"unknown\")\n    request.add_system_context(f\"User's tenant: {tenant}\")\n\n    # Access session in interceptor\n    user_name = request.session.get(\"user_name\", \"User\")\n    request.add_system_context(f\"User: {user_name}\")\n\n    # Track request count\n    count = request.session.get(\"request_count\", 0)\n    request.session.set(\"request_count\", count + 1)\n\n    return request\n\ndef redact_secrets(response: LLMResponse) -&gt; LLMResponse:\n    \"\"\"Remove leaked secrets from response.\"\"\"\n    response.text = response.text.replace(\"sk-secret\", \"[REDACTED]\")\n\n    # Update session with response metrics\n    response.session.set(\"last_response_length\", len(response.text))\n\n    return response\n\nagent = Agent(\n    tools=[...],\n    request_interceptors=[add_context],\n    response_interceptors=[redact_secrets],\n)\n</code></pre> <p>See the Interceptors Guide for more details.</p>"},{"location":"getting-started/#event-handling","title":"Event Handling","text":"<p>Subscribe to events for logging, notifications, or audit trails:</p> <pre><code>def log_events(event):\n    print(f\"[{event.event_type}] at {event.timestamp}\")\n\ndef notify_slack(event):\n    if event.event_type == \"ApprovalRequested\":\n        slack.post(\"Approval needed!\")\n\nagent = Agent(tools=[...], on_event=[log_events, notify_slack])\n</code></pre> <p>Event Types:</p> <ul> <li><code>ConversationStarted</code> - New conversation began</li> <li><code>ApprovalRequested</code> - Tools need approval</li> <li><code>ToolCallApproved</code> - User approved a tool</li> <li><code>ToolCallRejected</code> - User rejected a tool</li> <li><code>ToolExecuted</code> - Tool ran successfully</li> <li><code>ToolExecutionFailed</code> - Tool execution failed</li> </ul>"},{"location":"getting-started/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/#aws-credentials-expired","title":"AWS Credentials Expired","text":"<pre><code>ExpiredTokenException: The security token included in the request is expired\n</code></pre> <p>Solution:</p> <pre><code># Using DuploCloud\ndcaf env-update-aws-creds --tenant=your-tenant --host=your-duplo-host\n\n# Or manually update .env with fresh credentials\n</code></pre>"},{"location":"getting-started/#model-not-found","title":"Model Not Found","text":"<pre><code>ResourceNotFoundException: Could not find model with id...\n</code></pre> <p>Solution:</p> <ul> <li>Verify the model ID is correct</li> <li>Check Bedrock is enabled in your AWS account</li> <li>Ensure your region has access to the model</li> </ul>"},{"location":"getting-started/#expected-toolresult-blocks","title":"Expected toolResult Blocks","text":"<pre><code>ValidationException: Expected toolResult blocks...\n</code></pre> <p>Solution:</p> <p>This occurs when Bedrock receives tool-related messages in an invalid state. DCAF automatically handles this by:</p> <ol> <li>Filtering tool messages from conversation history</li> <li>Limiting parallel tool calls to 1</li> <li>Adding a system prompt instruction for single tool calls</li> </ol>"},{"location":"getting-started/#message-alternation-error","title":"Message Alternation Error","text":"<pre><code>ValidationException: Messages must alternate between user and assistant\n</code></pre> <p>Solution:</p> <p>DCAF automatically enforces message alternation. If you see this:</p> <ol> <li>Check for manual message manipulation</li> <li>Ensure you're not passing raw Bedrock-style messages</li> </ol>"},{"location":"getting-started/#connection-timeout","title":"Connection Timeout","text":"<pre><code>ReadTimeoutError: Read timed out\n</code></pre> <p>Solution:</p> <pre><code>export BOTO3_READ_TIMEOUT=60\nexport BOTO3_CONNECT_TIMEOUT=30\n</code></pre>"},{"location":"getting-started/#import-errors","title":"Import Errors","text":"<pre><code>ModuleNotFoundError: No module named 'dcaf'\n</code></pre> <p>Solution:</p> <pre><code>pip install git+https://github.com/duplocloud/service-desk-agents.git\n</code></pre>"},{"location":"getting-started/#provider-package-missing","title":"Provider Package Missing","text":"<pre><code>ImportError: OpenAI provider requires the 'openai' package...\n</code></pre> <p>Solution:</p> <pre><code># For OpenAI/Azure\npip install openai\n\n# For Google AI\npip install google-generativeai\n\n# For Ollama\npip install ollama\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Core Overview - Full Agent API documentation</li> <li>Building Tools - Advanced tool creation</li> <li>Custom Agents - Complex multi-step agents</li> <li>Server - Deployment and configuration</li> <li>Interceptors - Request/response hooks</li> <li>Examples - More code examples</li> </ul>"},{"location":"getting-started/#getting-help","title":"Getting Help","text":"<ul> <li>Check GitHub Issues</li> <li>Enable debug logging: <code>export LOG_LEVEL=DEBUG</code></li> <li>Contact DuploCloud: support@duplocloud.com</li> </ul>"},{"location":"logging-architecture/","title":"DCAF Logging Architecture","text":""},{"location":"logging-architecture/#overview","title":"Overview","text":"<p>DCAF implements a comprehensive, multi-layer logging system that provides visibility into the entire LLM invocation pipeline, from high-level application parameters down to raw AWS Bedrock API calls. The system uses unified logging control where a single <code>LOG_LEVEL</code> environment variable controls both DCAF and Agno SDK logging.</p>"},{"location":"logging-architecture/#architecture","title":"Architecture","text":""},{"location":"logging-architecture/#three-layer-logging-model","title":"Three-Layer Logging Model","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Layer 1: Agent Runtime Parameters (DEBUG)                   \u2502\n\u2502 Location: dcaf/core/adapters/outbound/agno/adapter.py       \u2502\n\u2502 Shows: Messages, Tools, System Prompts, Platform Context    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Layer 2: Raw Bedrock API Calls (INFO)                       \u2502\n\u2502 Location: dcaf/core/adapters/outbound/agno/caching_bedrock.py\u2502\n\u2502 Shows: Request/Response JSON sent to/from AWS Bedrock       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Layer 3: Agno SDK Internal Debug (DEBUG)                    \u2502\n\u2502 Location: Agno SDK (external library)                       \u2502\n\u2502 Shows: Agno's internal operations, tool processing, etc.    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"logging-architecture/#layer-details","title":"Layer Details","text":""},{"location":"logging-architecture/#layer-1-agent-runtime-parameters-debug-level","title":"Layer 1: Agent Runtime Parameters (DEBUG Level)","text":"<p>Purpose: Shows what DCAF's application layer passes to the Agno adapter before any SDK processing.</p> <p>Log Level: <code>DEBUG</code> (requires explicit DEBUG logging)</p> <p>Location: <code>dcaf/core/adapters/outbound/agno/adapter.py:450-469</code> (ainvoke) and <code>533-552</code> (ainvoke_stream)</p> <p>What's Logged: - Message count and full content (role + text) - Tool names (list of available tools) - System prompt (combined, truncated to 200 chars) - Static system prompt (cached portion, truncated) - Dynamic system prompt (non-cached portion, truncated) - Platform context (tenant, session, metadata)</p> <p>Example Output: <pre><code>DEBUG:dcaf.core.adapters.outbound.agno.adapter:\ud83d\udd0d AGENT RUNTIME INVOKE PARAMETERS:\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:  Messages: 2 total\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:    [0] user: What is the capital of France?\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:    [1] assistant: The capital of France is Paris.\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:  Tools: 1 total\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:    - get_weather\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:  System Prompt: You are a helpful assistant...\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:  Platform Context: {'tenant': 'acme-corp'}\n</code></pre></p>"},{"location":"logging-architecture/#layer-2-raw-bedrock-api-calls-info-level","title":"Layer 2: Raw Bedrock API Calls (INFO Level)","text":"<p>Purpose: Shows the exact request sent to AWS Bedrock and the exact response received, capturing the real API interaction.</p> <p>Log Level: <code>INFO</code> (enabled by default)</p> <p>Location: <code>dcaf/core/adapters/outbound/agno/caching_bedrock.py:299-327</code> (ainvoke) and <code>375-411</code> (ainvoke_stream)</p> <p>What's Logged:</p> <p>Request: - Model ID (e.g., <code>anthropic.claude-3-5-sonnet-20241022-v2:0</code>) - Complete formatted message array in Bedrock's format - Request body including:   - <code>system</code>: System prompt with cache checkpoints   - <code>toolConfig</code>: Tool definitions in Bedrock format   - <code>inferenceConfig</code>: Temperature, max_tokens, etc.</p> <p>Response: - Complete JSON response from Bedrock including:   - Response content (text, tool calls)   - Token usage metrics (<code>inputTokens</code>, <code>outputTokens</code>, <code>totalTokens</code>)   - Cache metrics (<code>cacheReadInputTokens</code>, <code>cacheCreationInputTokens</code>)   - Stop reason   - Model metadata</p> <p>Example Output: <pre><code>INFO:dcaf.core.adapters.outbound.agno.caching_bedrock:\ud83d\udd0d RAW LLM REQUEST TO BEDROCK:\nINFO:dcaf.core.adapters.outbound.agno.caching_bedrock:  Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0\nINFO:dcaf.core.adapters.outbound.agno.caching_bedrock:  Messages (1 total):\nINFO:dcaf.core.adapters.outbound.agno.caching_bedrock:[\n    {\n        \"role\": \"user\",\n        \"content\": [{\"text\": \"What is the capital of France?\"}]\n    }\n]\nINFO:dcaf.core.adapters.outbound.agno.caching_bedrock:  Request Body:\nINFO:dcaf.core.adapters.outbound.agno.caching_bedrock:{\n    \"system\": [\n        {\"text\": \"You are a helpful assistant.\"},\n        {\"cachePoint\": {\"type\": \"default\"}}\n    ],\n    \"inferenceConfig\": {\n        \"maxTokens\": 4096,\n        \"temperature\": 0.1\n    }\n}\n\nINFO:dcaf.core.adapters.outbound.agno.caching_bedrock:\ud83d\udd0d RAW LLM RESPONSE FROM BEDROCK:\nINFO:dcaf.core.adapters.outbound.agno.caching_bedrock:{\n    \"output\": {\n        \"message\": {\n            \"role\": \"assistant\",\n            \"content\": [{\"text\": \"The capital of France is Paris.\"}]\n        }\n    },\n    \"stopReason\": \"end_turn\",\n    \"usage\": {\n        \"inputTokens\": 23,\n        \"outputTokens\": 12,\n        \"totalTokens\": 35,\n        \"cacheReadInputTokens\": 15\n    }\n}\n</code></pre></p>"},{"location":"logging-architecture/#layer-3-agno-sdk-internal-debug-debug-level","title":"Layer 3: Agno SDK Internal Debug (DEBUG Level)","text":"<p>Purpose: Shows Agno SDK's internal operations, controlled automatically by DCAF's log level.</p> <p>Log Level: <code>DEBUG</code> (enabled when DCAF is at DEBUG level)</p> <p>Location: Agno SDK library (external)</p> <p>What's Logged: - Agno's internal debug messages (when <code>debug_level=2</code>) - Messages like \"Calling bedrock with request parameters: {...}\" - Tool processing details - Agent state transitions</p> <p>Controlled By: <code>_sync_agno_log_level()</code> function in adapter.py</p>"},{"location":"logging-architecture/#unified-logging-control","title":"Unified Logging Control","text":""},{"location":"logging-architecture/#design-philosophy","title":"Design Philosophy","text":"<p>One Environment Variable to Rule Them All</p> <p>Instead of requiring separate configuration for DCAF and Agno logging, the system uses a single <code>LOG_LEVEL</code> environment variable (Python standard) that automatically controls both frameworks.</p>"},{"location":"logging-architecture/#how-it-works","title":"How It Works","text":""},{"location":"logging-architecture/#1-initialization","title":"1. Initialization","text":"<p>When <code>AgnoAdapter</code> is initialized, it calls <code>_sync_agno_log_level()</code>:</p> <pre><code>def _sync_agno_log_level() -&gt; None:\n    \"\"\"\n    Sync Agno's debug mode with DCAF's logging level.\n\n    Maps Python logging levels to Agno debug modes:\n    - DEBUG (10): Enable Agno debug mode with level=2 (verbose)\n    - INFO (20) or higher: Disable Agno debug mode (INFO level only)\n    \"\"\"\n    root_logger = logging.getLogger()\n    current_level = root_logger.level\n\n    if current_level &lt;= logging.DEBUG:\n        # Enable Agno debug mode with maximum verbosity\n        set_log_level_to_debug(level=2)\n        logger.debug(\"Agno debug mode enabled (level=2)\")\n    else:\n        # Disable Agno debug mode (INFO level)\n        set_log_level_to_info()\n        logger.debug(\"Agno debug mode disabled (INFO only)\")\n</code></pre> <p>Location: <code>dcaf/core/adapters/outbound/agno/adapter.py:42-68</code></p> <p>Called From: <code>AgnoAdapter.__init__()</code> at line 351</p>"},{"location":"logging-architecture/#2-log-level-mapping","title":"2. Log Level Mapping","text":"<code>LOG_LEVEL</code> Python Level DCAF Layers Agno SDK Behavior <code>DEBUG</code> 10 Layer 1 + Layer 2 <code>set_log_level_to_debug(level=2)</code> - Verbose debug <code>INFO</code> 20 Layer 2 only <code>set_log_level_to_info()</code> - No debug logs <code>WARNING</code> 30 Warnings only <code>set_log_level_to_info()</code> - No debug logs <code>ERROR</code> 40 Errors only <code>set_log_level_to_info()</code> - No debug logs"},{"location":"logging-architecture/#3-agno-debug-levels-explained","title":"3. Agno Debug Levels Explained","text":"<p>Agno SDK uses a verbosity filter on top of Python's logging levels:</p> <ul> <li><code>log_level=1</code> (default): Basic debug messages</li> <li>Example: \"Connection already established\", \"Getting video data\"</li> <li> <p>Most <code>log_debug()</code> calls without explicit <code>log_level</code> parameter</p> </li> <li> <p><code>log_level=2</code> (verbose): Detailed request parameters</p> </li> <li>Example: \"Calling bedrock with request parameters: {...}\"</li> <li>Used by all LLM provider models to log raw request data</li> </ul> <p>When DCAF calls <code>set_log_level_to_debug(level=2)</code>, it enables all Agno debug logs (level 1 and 2).</p> <p>Agno's Implementation: <pre><code>def log_debug(msg, log_level: Literal[1, 2] = 1, ...):\n    global debug_on, debug_level\n\n    if debug_on:\n        if debug_level &gt;= log_level:  # Show if global level &gt;= message level\n            logger.debug(msg)\n</code></pre></p>"},{"location":"logging-architecture/#usage-examples","title":"Usage Examples","text":""},{"location":"logging-architecture/#standard-usage-info-shows-raw-bedrock-api-only","title":"Standard Usage (INFO - Shows Raw Bedrock API Only)","text":"<pre><code>import logging\n\n# Setup logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\"\n)\n\n# Or via environment variable\n# export LOG_LEVEL=INFO\n\n# Create adapter - automatically syncs Agno to INFO level\nadapter = AgnoAdapter(\n    model_id=\"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n    provider=\"bedrock\"\n)\n\n# You'll see Layer 2 logs (raw Bedrock API calls)\n</code></pre>"},{"location":"logging-architecture/#debug-mode-debug-shows-everything","title":"Debug Mode (DEBUG - Shows Everything)","text":"<pre><code>import logging\n\n# Setup logging at DEBUG level\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format=\"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\"\n)\n\n# Or via environment variable\n# export LOG_LEVEL=DEBUG\n\n# Create adapter - automatically syncs Agno to DEBUG level=2\nadapter = AgnoAdapter(\n    model_id=\"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n    provider=\"bedrock\"\n)\n\n# You'll see:\n# - Layer 1: Agent Runtime Parameters (DCAF)\n# - Layer 2: Raw Bedrock API Calls (DCAF)\n# - Layer 3: Agno SDK Internal Debug (Agno)\n</code></pre>"},{"location":"logging-architecture/#quiet-mode-warning-minimal-logging","title":"Quiet Mode (WARNING - Minimal Logging)","text":"<pre><code>import logging\n\nlogging.basicConfig(level=logging.WARNING)\n\n# Or via environment variable\n# export LOG_LEVEL=WARNING\n\n# Only warnings and errors will be shown\n</code></pre>"},{"location":"logging-architecture/#implementation-details","title":"Implementation Details","text":""},{"location":"logging-architecture/#file-structure","title":"File Structure","text":"<pre><code>dcaf/core/adapters/outbound/agno/\n\u251c\u2500\u2500 adapter.py              # Layer 1 logging + unified control\n\u251c\u2500\u2500 caching_bedrock.py      # Layer 2 logging\n\u251c\u2500\u2500 message_converter.py    # (no logging)\n\u251c\u2500\u2500 tool_converter.py       # (no logging)\n\u2514\u2500\u2500 types.py               # (no logging)\n</code></pre>"},{"location":"logging-architecture/#key-functions","title":"Key Functions","text":""},{"location":"logging-architecture/#1-_sync_agno_log_level-adapterpy42-68","title":"1. <code>_sync_agno_log_level()</code> (adapter.py:42-68)","text":"<ul> <li>Purpose: Sync Agno's debug mode with DCAF's log level</li> <li>Called: Once during <code>AgnoAdapter.__init__()</code></li> <li>Imports: <code>from agno.utils.log import set_log_level_to_debug, set_log_level_to_info</code></li> <li>Logic: Checks root logger level, maps to Agno</li> </ul>"},{"location":"logging-architecture/#2-layer-1-logging-adapterpy450-469-533-552","title":"2. Layer 1 Logging (adapter.py:450-469, 533-552)","text":"<ul> <li>Purpose: Log runtime parameters before Agno processing</li> <li>Methods: <code>ainvoke()</code> and <code>ainvoke_stream()</code></li> <li>Level: <code>logger.debug()</code> - DEBUG level</li> <li>Truncation: System prompts truncated to 200 chars to reduce noise</li> </ul>"},{"location":"logging-architecture/#3-layer-2-logging-caching_bedrockpy299-327-375-411","title":"3. Layer 2 Logging (caching_bedrock.py:299-327, 375-411)","text":"<ul> <li>Purpose: Log raw Bedrock API request/response</li> <li>Methods: <code>ainvoke()</code> and <code>ainvoke_stream()</code> overrides</li> <li>Level: <code>logger.info()</code> - INFO level</li> <li>Format: Full JSON with <code>json.dumps(indent=4, default=str)</code></li> <li>No Truncation: Complete messages and responses logged</li> </ul>"},{"location":"logging-architecture/#logger-names","title":"Logger Names","text":"<p>Each module uses <code>logging.getLogger(__name__)</code>:</p> <ul> <li>Layer 1: <code>dcaf.core.adapters.outbound.agno.adapter</code></li> <li>Layer 2: <code>dcaf.core.adapters.outbound.agno.caching_bedrock</code></li> <li>Layer 3 (Agno): <code>agno</code> (controlled by Agno SDK)</li> </ul> <p>You can selectively disable loggers if needed:</p> <pre><code>import logging\n\n# Disable only Layer 2 (raw Bedrock logs)\nbedrock_logger = logging.getLogger('dcaf.core.adapters.outbound.agno.caching_bedrock')\nbedrock_logger.setLevel(logging.WARNING)\n\n# Disable only Layer 1 (runtime parameters)\nadapter_logger = logging.getLogger('dcaf.core.adapters.outbound.agno.adapter')\nadapter_logger.setLevel(logging.INFO)\n\n# Disable Agno SDK logs\nagno_logger = logging.getLogger('agno')\nagno_logger.setLevel(logging.WARNING)\n</code></pre>"},{"location":"logging-architecture/#performance-considerations","title":"Performance Considerations","text":""},{"location":"logging-architecture/#overhead","title":"Overhead","text":"<p>The logging system has minimal performance impact:</p> <ul> <li>JSON serialization: ~1-5ms per call (using <code>json.dumps()</code>)</li> <li>File I/O: Buffered by Python's logging framework</li> <li>Overall impact: &lt; 0.1% of total LLM call time (typically 1-5 seconds)</li> </ul>"},{"location":"logging-architecture/#when-to-disable","title":"When to Disable","text":"<p>Consider disabling verbose logging in production:</p> <pre><code>import logging\nimport os\n\n# Use environment variable for production control\nlog_level = os.getenv(\"LOG_LEVEL\", \"WARNING\")\nlogging.basicConfig(level=getattr(logging, log_level))\n</code></pre> <p>Or disable specific layers:</p> <pre><code># Keep Layer 2 (raw API) but disable Layer 1 (runtime params)\nlogging.basicConfig(level=logging.INFO)\n\n# This disables Layer 1 since it requires DEBUG\n</code></pre>"},{"location":"logging-architecture/#use-cases","title":"Use Cases","text":""},{"location":"logging-architecture/#1-development-debugging","title":"1. Development &amp; Debugging","text":"<p>Problem: LLM not responding as expected</p> <p>Solution: Enable DEBUG logging to see: - Layer 1: Are the right messages being passed? Is the system prompt correct? - Layer 2: What exactly was sent to Bedrock? What did it return? - Layer 3: How did Agno process the messages and tools?</p> <pre><code>export LOG_LEVEL=DEBUG\npython my_app.py\n</code></pre>"},{"location":"logging-architecture/#2-production-monitoring","title":"2. Production Monitoring","text":"<p>Problem: Need to audit LLM API calls for billing/compliance</p> <p>Solution: Enable INFO logging to capture raw API calls:</p> <pre><code>export LOG_LEVEL=INFO\npython my_app.py 2&gt;&amp;1 | tee llm_audit.log\n</code></pre> <p>Parse <code>llm_audit.log</code> to extract: - Request/response pairs (search for \"\ud83d\udd0d RAW LLM\") - Token usage from responses (<code>inputTokens</code>, <code>outputTokens</code>) - Cache performance (<code>cacheReadInputTokens</code>)</p>"},{"location":"logging-architecture/#3-performance-analysis","title":"3. Performance Analysis","text":"<p>Problem: LLM calls are slow or expensive</p> <p>Solution: Analyze Layer 2 logs for: - Token counts per request (optimize prompt length) - Cache hit rates (improve caching strategy) - Response sizes (adjust <code>max_tokens</code>)</p> <p>Example script: <pre><code>import json\nimport re\n\n# Parse logs\nwith open('llm_audit.log') as f:\n    logs = f.read()\n\n# Extract token usage\nusage_pattern = r'\"usage\": \\{[^}]+\\}'\nfor match in re.finditer(usage_pattern, logs):\n    usage = json.loads('{' + match.group() + '}')\n    print(f\"Tokens: {usage['totalTokens']}, Cache hits: {usage.get('cacheReadInputTokens', 0)}\")\n</code></pre></p>"},{"location":"logging-architecture/#4-troubleshooting-caching","title":"4. Troubleshooting Caching","text":"<p>Problem: Prompt caching not working as expected</p> <p>Solution: Check Layer 2 logs for: - Cache checkpoint placement in request body - Cache metrics in response (<code>cacheReadInputTokens</code>, <code>cacheCreationInputTokens</code>) - Warnings about prompts being too short</p> <p>Look for: <pre><code>{\n    \"system\": [\n        {\"text\": \"Your static prompt...\"},\n        {\"cachePoint\": {\"type\": \"default\"}},  // \u2190 Should be present\n        {\"text\": \"Dynamic context...\"}\n    ]\n}\n</code></pre></p> <p>And in response: <pre><code>{\n    \"usage\": {\n        \"cacheReadInputTokens\": 1500,  // \u2190 Cache HIT\n        \"cacheCreationInputTokens\": 0\n    }\n}\n</code></pre></p>"},{"location":"logging-architecture/#environment-variables","title":"Environment Variables","text":""},{"location":"logging-architecture/#primary-control","title":"Primary Control","text":"<ul> <li><code>LOG_LEVEL</code>: Controls both DCAF and Agno logging</li> <li>Values: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code></li> <li>Default: <code>INFO</code> (if not set)</li> <li>Example: <code>export LOG_LEVEL=DEBUG</code></li> </ul>"},{"location":"logging-architecture/#legacy-agno-variables-not-recommended","title":"Legacy Agno Variables (Not Recommended)","text":"<p>These still work but are not necessary since DCAF controls Agno automatically:</p> <ul> <li><code>AGNO_DEBUG</code>: Enable Agno debug mode</li> <li>Values: <code>true</code>, <code>false</code></li> <li> <p>Overridden by DCAF's <code>_sync_agno_log_level()</code></p> </li> <li> <p><code>AGNO_DEBUG_LEVEL</code>: Set Agno debug verbosity</p> </li> <li>Values: <code>1</code> (basic), <code>2</code> (verbose)</li> <li>DCAF always uses <code>2</code> when DEBUG is enabled</li> </ul> <p>Recommendation: Use <code>LOG_LEVEL</code> only for unified control.</p>"},{"location":"logging-architecture/#testing-validation","title":"Testing &amp; Validation","text":""},{"location":"logging-architecture/#verify-logging-setup","title":"Verify Logging Setup","text":"<pre><code>import logging\n\n# Check root logger level\nroot = logging.getLogger()\nprint(f\"Root logger level: {logging.getLevelName(root.level)}\")\n\n# Check DCAF loggers\nadapter_logger = logging.getLogger('dcaf.core.adapters.outbound.agno.adapter')\nprint(f\"Adapter logger level: {logging.getLevelName(adapter_logger.level)}\")\n\nbedrock_logger = logging.getLogger('dcaf.core.adapters.outbound.agno.caching_bedrock')\nprint(f\"Bedrock logger level: {logging.getLevelName(bedrock_logger.level)}\")\n\n# Check Agno logger\nagno_logger = logging.getLogger('agno')\nprint(f\"Agno logger level: {logging.getLevelName(agno_logger.level)}\")\n</code></pre>"},{"location":"logging-architecture/#verify-agno-sync","title":"Verify Agno Sync","text":"<p>After creating <code>AgnoAdapter</code>, check if Agno was synced:</p> <pre><code>from agno.utils.log import debug_on, debug_level\n\nadapter = AgnoAdapter(...)\n\nprint(f\"Agno debug_on: {debug_on}\")      # Should be True if LOG_LEVEL=DEBUG\nprint(f\"Agno debug_level: {debug_level}\") # Should be 2 if LOG_LEVEL=DEBUG\n</code></pre>"},{"location":"logging-architecture/#best-practices","title":"Best Practices","text":""},{"location":"logging-architecture/#development","title":"Development","text":"<ol> <li> <p>Use DEBUG level during development:    <pre><code>export LOG_LEVEL=DEBUG\n</code></pre></p> </li> <li> <p>Use structured logging for parsing:    <pre><code>logging.basicConfig(\n    level=logging.DEBUG,\n    format=\"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\"\n)\n</code></pre></p> </li> <li> <p>Filter verbose logs if needed:    <pre><code># Disable Agno's verbose tool logging\nlogging.getLogger('agno.tools').setLevel(logging.WARNING)\n</code></pre></p> </li> </ol>"},{"location":"logging-architecture/#production","title":"Production","text":"<ol> <li> <p>Use INFO level for audit logs:    <pre><code>export LOG_LEVEL=INFO\n</code></pre></p> </li> <li> <p>Pipe to log aggregation (DataDog, Splunk, CloudWatch):    <pre><code>python app.py 2&gt;&amp;1 | logger -t dcaf-app\n</code></pre></p> </li> <li> <p>Rotate logs to prevent disk space issues:    <pre><code>from logging.handlers import RotatingFileHandler\n\nhandler = RotatingFileHandler(\n    'dcaf.log',\n    maxBytes=10_000_000,  # 10MB\n    backupCount=5\n)\nlogging.getLogger().addHandler(handler)\n</code></pre></p> </li> <li> <p>Sanitize sensitive data if needed:    <pre><code>import logging\nimport re\n\nclass SanitizingFilter(logging.Filter):\n    def filter(self, record):\n        # Redact API keys, tokens, etc.\n        record.msg = re.sub(r'(api[_-]?key[\"\\s:]+)[^\"]+', r'\\1***REDACTED***', record.msg)\n        return True\n\nlogging.getLogger().addFilter(SanitizingFilter())\n</code></pre></p> </li> </ol>"},{"location":"logging-architecture/#compliance-security","title":"Compliance &amp; Security","text":"<ol> <li>Be aware of PII in logs:</li> <li>User messages may contain sensitive information</li> <li>System prompts may contain proprietary instructions</li> <li> <p>Consider GDPR/privacy regulations</p> </li> <li> <p>Use appropriate retention policies:</p> </li> <li>Delete old logs after X days</li> <li>Encrypt logs at rest</li> <li> <p>Restrict access to log files</p> </li> <li> <p>Monitor log volume:</p> </li> <li>DEBUG level can generate significant data</li> <li>Estimate: ~10-50KB per LLM call at DEBUG level</li> <li>Use INFO level in production to reduce volume</li> </ol>"},{"location":"logging-architecture/#troubleshooting","title":"Troubleshooting","text":""},{"location":"logging-architecture/#logs-not-appearing","title":"Logs Not Appearing","text":"<p>Problem: No logs are showing up</p> <p>Solutions:</p> <ol> <li> <p>Check root logger level:    <pre><code>print(logging.getLogger().level)  # Should be &lt;= 20 for INFO\n</code></pre></p> </li> <li> <p>Ensure handlers are configured:    <pre><code>logging.basicConfig(level=logging.INFO)  # Sets up default handler\n</code></pre></p> </li> <li> <p>Check if loggers are disabled:    <pre><code>logger = logging.getLogger('dcaf.core.adapters.outbound.agno.caching_bedrock')\nprint(logger.disabled)  # Should be False\n</code></pre></p> </li> </ol>"},{"location":"logging-architecture/#too-much-output","title":"Too Much Output","text":"<p>Problem: Logs are overwhelming</p> <p>Solutions:</p> <ol> <li> <p>Increase log level:    <pre><code>export LOG_LEVEL=WARNING  # Only show warnings and errors\n</code></pre></p> </li> <li> <p>Disable specific loggers:    <pre><code>logging.getLogger('agno').setLevel(logging.WARNING)\n</code></pre></p> </li> <li> <p>Filter streaming chunk logs:    <pre><code>class NoStreamChunkFilter(logging.Filter):\n    def filter(self, record):\n        return 'Stream chunk #' not in record.getMessage()\n\nlogging.getLogger('dcaf.core.adapters.outbound.agno.caching_bedrock').addFilter(NoStreamChunkFilter())\n</code></pre></p> </li> </ol>"},{"location":"logging-architecture/#agno-debug-not-working","title":"Agno Debug Not Working","text":"<p>Problem: Agno debug logs not appearing even at DEBUG level</p> <p>Solutions:</p> <ol> <li>Verify <code>_sync_agno_log_level()</code> was called:</li> <li>It's called automatically in <code>AgnoAdapter.__init__()</code></li> <li> <p>Check logs for \"Agno debug mode enabled\"</p> </li> <li> <p>Check Agno's global state:    <pre><code>from agno.utils.log import debug_on, debug_level\nprint(f\"debug_on={debug_on}, debug_level={debug_level}\")\n</code></pre></p> </li> <li> <p>Manually enable if needed:    <pre><code>from agno.utils.log import set_log_level_to_debug\nset_log_level_to_debug(level=2)\n</code></pre></p> </li> </ol>"},{"location":"logging-architecture/#related-documentation","title":"Related Documentation","text":"<ul> <li>raw-llm-logging.md - User guide for enabling and using raw LLM logging</li> </ul>"},{"location":"logging-architecture/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements for the logging system:</p> <ul> <li> Structured logging (JSON format) for easier parsing</li> <li> Sanitization hooks to automatically redact sensitive data</li> <li> Token cost calculation in logs (based on model pricing)</li> <li> Integration with observability platforms (DataDog, Splunk)</li> <li> Log filtering by conversation session or tenant</li> <li> Automatic log rotation and compression</li> <li> Performance metrics (latency, throughput)</li> <li> Configurable log levels per layer (via environment variables)</li> </ul>"},{"location":"raw-llm-logging/","title":"Raw LLM Request/Response Logging","text":""},{"location":"raw-llm-logging/#overview","title":"Overview","text":"<p>DCAF now includes comprehensive logging at multiple layers of the LLM invocation pipeline. This gives you complete visibility from high-level runtime parameters down to the raw Bedrock API calls.</p>"},{"location":"raw-llm-logging/#what-gets-logged","title":"What Gets Logged","text":"<p>DCAF logs at two levels:</p>"},{"location":"raw-llm-logging/#level-1-agent-runtime-parameters-agnoadapter-debug-level","title":"Level 1: Agent Runtime Parameters (AgnoAdapter) - DEBUG Level","text":"<p>Logs what DCAF's agent runtime passes to the Agno adapter:</p> <ul> <li>Messages: Count and content of conversation messages</li> <li>Role (user/assistant)</li> <li>Text content</li> <li>Tools: List of available tools by name</li> <li>System Prompts:</li> <li><code>system_prompt</code>: Combined prompt</li> <li><code>static_system</code>: Cached static portion</li> <li><code>dynamic_system</code>: Non-cached dynamic portion</li> <li>Platform Context: Tenant, session, and other contextual data</li> </ul> <p>Log Level: DEBUG (requires explicit DEBUG logging to see) Location: <code>dcaf/core/adapters/outbound/agno/adapter.py</code> (lines 447-460)</p>"},{"location":"raw-llm-logging/#level-2-raw-bedrock-api-calls-cachingawsbedrock-info-level","title":"Level 2: Raw Bedrock API Calls (CachingAwsBedrock) - INFO Level","text":"<p>Logs the exact request sent to and response received from AWS Bedrock:</p> <p>Request (Sent to Bedrock): - Model ID: The Bedrock model identifier (e.g., <code>anthropic.claude-3-5-sonnet-20241022-v2:0</code>) - Messages: The complete formatted message array in Bedrock's format - Request Body: Including:   - <code>system</code>: System prompt with cache checkpoints (if enabled)   - <code>toolConfig</code>: Tool definitions   - <code>inferenceConfig</code>: Temperature, max_tokens, etc.</p> <p>Response (Received from Bedrock): - Complete JSON response from Bedrock, including:   - Response content (text, tool calls)   - Token usage metrics   - Cache metrics (if caching enabled)   - Stop reason   - Model metadata</p> <p>Log Level: INFO (enabled by default) Location: <code>dcaf/core/adapters/outbound/agno/caching_bedrock.py</code> (lines 299-319)</p>"},{"location":"raw-llm-logging/#how-to-enable","title":"How to Enable","text":"<p>DCAF uses unified logging control - one <code>LOG_LEVEL</code> environment variable controls both DCAF and Agno logging.</p>"},{"location":"raw-llm-logging/#level-2-only-raw-bedrock-api-recommended-for-most-users","title":"Level 2 Only (Raw Bedrock API - Recommended for most users)","text":"<p>The raw Bedrock API logging is automatically enabled at INFO level:</p> <pre><code># Via environment variable\nexport LOG_LEVEL=INFO\npython your_script.py\n\n# Or in your code\nimport logging\nlogging.basicConfig(level=logging.INFO)\n</code></pre> <p>That's it! You'll see the raw Bedrock requests/responses by default.</p> <p>What happens behind the scenes: - DCAF loggers show INFO level messages - Agno SDK is automatically set to INFO level (no debug logs)</p>"},{"location":"raw-llm-logging/#level-1-level-2-full-pipeline-visibility","title":"Level 1 + Level 2 (Full Pipeline Visibility)","text":"<p>To see BOTH the agent runtime parameters AND raw Bedrock API calls:</p> <pre><code># Via environment variable\nexport LOG_LEVEL=DEBUG\npython your_script.py\n\n# Or in your code\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre> <p>This shows the complete flow from DCAF \u2192 Agno \u2192 Bedrock.</p> <p>What happens behind the scenes: - DCAF loggers show DEBUG + INFO level messages - Agno SDK is automatically set to DEBUG mode with level=2 (verbose)   - This includes Agno's internal debug logs showing request parameters, tool calls, etc.   - You'll see messages like \"Calling bedrock with request parameters: {...}\"</p>"},{"location":"raw-llm-logging/#unified-logging-control","title":"Unified Logging Control","text":"<p>DCAF automatically syncs Agno's logging with Python's standard logging level. This means one environment variable controls everything:</p> <code>LOG_LEVEL</code> DCAF Behavior Agno Behavior <code>WARNING</code> (30) Shows WARNING+ messages INFO level only (no debug) <code>INFO</code> (20) Shows INFO+ messages INFO level only (no debug) <code>DEBUG</code> (10) Shows DEBUG+ messages DEBUG mode with level=2 (verbose)"},{"location":"raw-llm-logging/#how-it-works","title":"How It Works","text":"<p>When you initialize <code>AgnoAdapter</code>, it automatically: 1. Checks Python's root logger level 2. Calls Agno's <code>set_log_level_to_debug(level=2)</code> if DEBUG 3. Calls Agno's <code>set_log_level_to_info()</code> otherwise</p> <p>This happens transparently - you don't need to configure Agno separately.</p>"},{"location":"raw-llm-logging/#environment-variable-support","title":"Environment Variable Support","text":"<p>DCAF respects the standard <code>LOG_LEVEL</code> environment variable:</p> <pre><code># Maximum verbosity (DCAF DEBUG + Agno DEBUG level=2)\nexport LOG_LEVEL=DEBUG\n\n# Standard verbosity (DCAF INFO + Agno INFO)\nexport LOG_LEVEL=INFO\n\n# Quiet mode (DCAF WARNING+ only)\nexport LOG_LEVEL=WARNING\n</code></pre> <p>Note: You can still use Agno's native <code>AGNO_DEBUG=true</code> if needed, but it's not necessary since DCAF controls it automatically.</p>"},{"location":"raw-llm-logging/#disable-raw-logging-if-needed","title":"Disable Raw Logging (If Needed)","text":"<p>Disable Level 2 (Raw Bedrock API) only: <pre><code>import logging\n\n# Set root logger to INFO\nlogging.basicConfig(level=logging.INFO)\n\n# Disable raw Bedrock logging\nbedrock_logger = logging.getLogger('dcaf.core.adapters.outbound.agno.caching_bedrock')\nbedrock_logger.setLevel(logging.WARNING)\n</code></pre></p> <p>Disable Both Levels: <pre><code>import logging\n\n# Set root logger to WARNING (disables INFO and DEBUG)\nlogging.basicConfig(level=logging.WARNING)\n</code></pre></p>"},{"location":"raw-llm-logging/#example-output","title":"Example Output","text":""},{"location":"raw-llm-logging/#level-1-agent-runtime-parameters-debug-level","title":"Level 1: Agent Runtime Parameters (DEBUG level)","text":"<pre><code>DEBUG:dcaf.core.adapters.outbound.agno.adapter:\ud83d\udd0d AGENT RUNTIME INVOKE PARAMETERS:\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:  Messages: 2 total\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:    [0] user: What is the capital of France?\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:    [1] assistant: The capital of France is Paris.\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:  Tools: 1 total\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:    - get_weather\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:  System Prompt: You are a helpful assistant with access to weather data.\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:  Static System: None\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:  Dynamic System: None\nDEBUG:dcaf.core.adapters.outbound.agno.adapter:  Platform Context: {'tenant': 'acme-corp', 'session_id': '123'}\n</code></pre>"},{"location":"raw-llm-logging/#level-2-raw-bedrock-request-info-level","title":"Level 2: Raw Bedrock Request (INFO level)","text":"<pre><code>INFO:dcaf.core.adapters.outbound.agno.caching_bedrock:\ud83d\udd0d RAW LLM REQUEST TO BEDROCK:\nINFO:dcaf.core.adapters.outbound.agno.caching_bedrock:  Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0\nDEBUG:dcaf.core.adapters.outbound.agno.caching_bedrock:  Messages (2 total):\nDEBUG:dcaf.core.adapters.outbound.agno.caching_bedrock:[\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"text\": \"What is the capital of France?\"\n            }\n        ]\n    }\n]\nDEBUG:dcaf.core.adapters.outbound.agno.caching_bedrock:  Request Body:\nDEBUG:dcaf.core.adapters.outbound.agno.caching_bedrock:{\n    \"system\": [\n        {\n            \"text\": \"You are a helpful assistant.\"\n        },\n        {\n            \"cachePoint\": {\n                \"type\": \"default\"\n            }\n        }\n    ],\n    \"inferenceConfig\": {\n        \"maxTokens\": 4096,\n        \"temperature\": 0.1\n    }\n}\n</code></pre>"},{"location":"raw-llm-logging/#level-2-raw-bedrock-response-info-level","title":"Level 2: Raw Bedrock Response (INFO level)","text":"<pre><code>INFO:dcaf.core.adapters.outbound.agno.caching_bedrock:\ud83d\udd0d RAW LLM RESPONSE FROM BEDROCK:\nDEBUG:dcaf.core.adapters.outbound.agno.caching_bedrock:{\n    \"output\": {\n        \"message\": {\n            \"role\": \"assistant\",\n            \"content\": [\n                {\n                    \"text\": \"The capital of France is Paris.\"\n                }\n            ]\n        }\n    },\n    \"stopReason\": \"end_turn\",\n    \"usage\": {\n        \"inputTokens\": 23,\n        \"outputTokens\": 12,\n        \"totalTokens\": 35,\n        \"cacheReadInputTokens\": 15,\n        \"cacheCreationInputTokens\": 0\n    }\n}\n</code></pre>"},{"location":"raw-llm-logging/#use-cases","title":"Use Cases","text":""},{"location":"raw-llm-logging/#1-debugging-llm-issues","title":"1. Debugging LLM Issues","text":"<p>With two-level logging, you can trace issues from top to bottom:</p> <p>Level 1 (Runtime Parameters): - Are the right messages being passed from the application? - Are tools being registered correctly? - Is the system prompt structure correct (static vs dynamic)? - Is platform context being injected?</p> <p>Level 2 (Raw Bedrock): - Did Agno format the messages correctly? - Are tools being passed in Bedrock's format? - Are cache checkpoints in the right place?</p>"},{"location":"raw-llm-logging/#2-performance-analysis","title":"2. Performance Analysis","text":"<p>Examine token usage and cache performance: - How many tokens are in each request? - Is prompt caching working (check <code>cacheReadInputTokens</code>)? - What's the cache hit rate?</p>"},{"location":"raw-llm-logging/#3-cost-tracking","title":"3. Cost Tracking","text":"<p>Audit exact API calls for billing purposes: - Count total requests - Sum input/output tokens - Calculate cache savings</p>"},{"location":"raw-llm-logging/#4-compliance-auditing","title":"4. Compliance &amp; Auditing","text":"<p>Maintain a record of all LLM interactions: - What data was sent to the LLM? - What did the LLM return? - When did each call happen?</p>"},{"location":"raw-llm-logging/#streaming-vs-non-streaming","title":"Streaming vs Non-Streaming","text":""},{"location":"raw-llm-logging/#non-streaming-ainvoke","title":"Non-Streaming (<code>ainvoke</code>)","text":"<p>Logs the complete request and complete response.</p>"},{"location":"raw-llm-logging/#streaming-ainvoke_stream","title":"Streaming (<code>ainvoke_stream</code>)","text":"<ul> <li>Logs the complete request before streaming starts</li> <li>Logs each chunk as it arrives (very verbose)</li> <li>Logs total chunk count when streaming completes</li> </ul> <p>Note: Streaming chunk logs can be very verbose. Consider filtering or reducing log level for production streaming use.</p>"},{"location":"raw-llm-logging/#implementation-details","title":"Implementation Details","text":"<p>The logging is implemented in <code>dcaf/core/adapters/outbound/agno/caching_bedrock.py</code> by overriding: - <code>ainvoke()</code> - Async non-streaming invocation - <code>ainvoke_stream()</code> - Async streaming invocation</p> <p>The logging happens after message formatting but before the boto3 <code>converse()</code> call, capturing the exact parameters sent to Bedrock.</p>"},{"location":"raw-llm-logging/#security-considerations","title":"Security Considerations","text":"<p>\u26a0\ufe0f WARNING: Raw request/response logs may contain: - User input (potentially sensitive) - System prompts (proprietary instructions) - Tool definitions (business logic) - API responses (potentially sensitive data)</p> <p>Best Practices: - Only enable DEBUG logging in development/staging environments - Sanitize logs before sharing - Use appropriate log retention policies - Consider GDPR/privacy regulations when logging user data - Rotate logs regularly</p>"},{"location":"raw-llm-logging/#performance-impact","title":"Performance Impact","text":"<p>The logging overhead is minimal: - <code>json.dumps()</code> serialization: ~1-5ms per call - File I/O: Handled by Python's logging framework (buffered) - Overall impact: &lt; 0.1% of total LLM call time</p> <p>If you need to disable it in production for performance reasons, set the logger level to WARNING (see \"Disable Raw Logging\" above).</p>"},{"location":"raw-llm-logging/#troubleshooting","title":"Troubleshooting","text":""},{"location":"raw-llm-logging/#logs-not-appearing","title":"Logs Not Appearing","text":"<ol> <li> <p>Check log level: Ensure INFO is enabled (it should be by default)    <pre><code>import logging\nprint(logging.getLogger().level)  # Should be 20 (INFO) or lower\n</code></pre></p> </li> <li> <p>Check logger configuration: Verify the logger is configured    <pre><code>logger = logging.getLogger('dcaf.core.adapters.outbound.agno.caching_bedrock')\nprint(logger.level)\nprint(logger.handlers)\n</code></pre></p> </li> <li> <p>Check if CachingAwsBedrock is being used: Verify your adapter is using the caching model    <pre><code># In adapter.py\nprint(type(model))  # Should be CachingAwsBedrock\n</code></pre></p> </li> </ol>"},{"location":"raw-llm-logging/#too-much-output","title":"Too Much Output","text":"<p>If streaming logs are too verbose, you can filter them:</p> <pre><code>import logging\n\nclass NoStreamChunkFilter(logging.Filter):\n    def filter(self, record):\n        # Skip individual stream chunk logs\n        return 'Stream chunk #' not in record.getMessage()\n\nlogger = logging.getLogger('dcaf.core.adapters.outbound.agno.caching_bedrock')\nlogger.addFilter(NoStreamChunkFilter())\n</code></pre>"},{"location":"raw-llm-logging/#future-enhancements","title":"Future Enhancements","text":"<p>Potential improvements for the future: - [ ] Configurable log formatting (JSON, plain text, etc.) - [ ] Sanitization hooks to redact sensitive data - [ ] Token cost calculation in logs - [ ] Structured logging (e.g., JSON logs for parsing) - [ ] Export to observability platforms (DataDog, Splunk, etc.)</p>"},{"location":"raw-llm-logging/#related-documentation","title":"Related Documentation","text":"<ul> <li>AWS Bedrock Documentation</li> </ul>"},{"location":"adrs/000-template/","title":"ADR-XXX: Title","text":""},{"location":"adrs/000-template/#status","title":"Status","text":"<p>Proposed | Accepted | Deprecated | Superseded by ADR-YYY</p>"},{"location":"adrs/000-template/#context","title":"Context","text":"<p>What is the issue we're facing? What forces are at play?</p>"},{"location":"adrs/000-template/#decision","title":"Decision","text":"<p>What is the change we're proposing and/or doing?</p>"},{"location":"adrs/000-template/#consequences","title":"Consequences","text":"<p>What becomes easier or harder as a result of this decision?</p>"},{"location":"adrs/000-template/#positive-consequences","title":"Positive Consequences","text":"<ul> <li>[List positive outcomes]</li> </ul>"},{"location":"adrs/000-template/#negative-consequences","title":"Negative Consequences","text":"<ul> <li>[List negative outcomes or trade-offs]</li> </ul>"},{"location":"adrs/000-template/#related-adrs","title":"Related ADRs","text":"<ul> <li>[List related ADR numbers and titles]</li> </ul>"},{"location":"adrs/001-clean-architecture/","title":"ADR-001: Clean Architecture","text":""},{"location":"adrs/001-clean-architecture/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adrs/001-clean-architecture/#context","title":"Context","text":"<p>The DCAF agent framework needs to support multiple LLM provider frameworks (Agno, LangChain, Strands, etc.) while maintaining a stable core domain. The current implementation has tight coupling between agents and the Bedrock LLM provider, making it difficult to:</p> <ol> <li>Switch between LLM frameworks without modifying business logic</li> <li>Test business logic in isolation from infrastructure</li> <li>Maintain consistent behavior across different adapters</li> </ol> <p>We need an architecture that allows the core business logic to remain stable while external integrations can vary.</p>"},{"location":"adrs/001-clean-architecture/#decision","title":"Decision","text":"<p>We adopt Clean Architecture with the following layered structure:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    External Frameworks                       \u2502\n\u2502              (FastAPI, Agno SDK, LangChain, DB)             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                         Adapters                             \u2502\n\u2502         (Controllers, Repositories, Framework Adapters)     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                       Application                            \u2502\n\u2502                  (Use Cases, Ports/Interfaces)               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                         Domain                               \u2502\n\u2502        (Entities, Value Objects, Domain Services)           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>The Dependency Rule: All dependencies point inward. Outer layers depend on inner layers, never the reverse.</p> <ul> <li>Domain Layer: Pure business logic with no external dependencies. Contains entities, value objects, domain services, and domain events.</li> <li>Application Layer: Use cases that orchestrate domain logic. Defines ports (interfaces) for external systems.</li> <li>Adapter Layer: Implementations of ports. Translates between our domain and external frameworks.</li> <li>Infrastructure Layer: Cross-cutting concerns like configuration and logging.</li> </ul>"},{"location":"adrs/001-clean-architecture/#consequences","title":"Consequences","text":""},{"location":"adrs/001-clean-architecture/#positive-consequences","title":"Positive Consequences","text":"<ul> <li>Domain logic is testable without any infrastructure</li> <li>Framework changes don't affect business rules</li> <li>Clear boundaries make the codebase navigable</li> <li>New adapters can be added without touching existing code</li> <li>The approval flow (human-in-the-loop) remains consistent across all frameworks</li> </ul>"},{"location":"adrs/001-clean-architecture/#negative-consequences","title":"Negative Consequences","text":"<ul> <li>More files and directories to navigate initially</li> <li>Requires discipline to maintain layer boundaries</li> <li>Some ceremony in creating DTOs and converters</li> <li>Steeper learning curve for new team members</li> </ul>"},{"location":"adrs/001-clean-architecture/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-002: DDD Tactical Patterns</li> <li>ADR-003: Adapter Pattern for Frameworks</li> </ul>"},{"location":"adrs/002-ddd-tactical-patterns/","title":"ADR-002: DDD Tactical Patterns","text":""},{"location":"adrs/002-ddd-tactical-patterns/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adrs/002-ddd-tactical-patterns/#context","title":"Context","text":"<p>The DCAF framework manages conversations, tool executions, and approval workflows. These concepts have:</p> <ul> <li>Identity: A tool call has a unique ID that persists across approval cycles</li> <li>Lifecycle: Tool calls transition through states (pending \u2192 approved \u2192 executed)</li> <li>Invariants: A conversation cannot proceed while approvals are pending</li> <li>Business rules: Approval policies determine what requires human review</li> </ul> <p>We need patterns to model these concepts correctly and protect business invariants.</p>"},{"location":"adrs/002-ddd-tactical-patterns/#decision","title":"Decision","text":"<p>We adopt Domain-Driven Design tactical patterns:</p>"},{"location":"adrs/002-ddd-tactical-patterns/#entities","title":"Entities","text":"<p>Objects with identity and lifecycle. Equality based on identity, not attributes.</p> <pre><code>class ToolCall:\n    \"\"\"Entity with identity and state transitions.\"\"\"\n    id: ToolCallId  # Identity\n    status: ToolCallStatus  # Mutable state\n\n    def approve(self) -&gt; None: ...\n    def reject(self, reason: str) -&gt; None: ...\n    def complete(self, result: str) -&gt; None: ...\n</code></pre>"},{"location":"adrs/002-ddd-tactical-patterns/#value-objects","title":"Value Objects","text":"<p>Immutable objects without identity. Equality based on attributes.</p> <pre><code>@dataclass(frozen=True)\nclass ToolCallId:\n    value: str\n\n@dataclass(frozen=True)\nclass ToolInput:\n    parameters: Mapping[str, Any]\n</code></pre>"},{"location":"adrs/002-ddd-tactical-patterns/#aggregates","title":"Aggregates","text":"<p>Clusters of entities with a root that protects invariants.</p> <pre><code>class Conversation:  # Aggregate Root\n    \"\"\"Protects invariant: can't add messages while approvals pending.\"\"\"\n\n    def add_user_message(self, content: MessageContent) -&gt; None:\n        if self._pending_approvals:\n            raise ConversationBlocked(\"Resolve pending approvals first\")\n        ...\n</code></pre>"},{"location":"adrs/002-ddd-tactical-patterns/#domain-services","title":"Domain Services","text":"<p>Stateless operations that don't belong to a single entity.</p> <pre><code>class ApprovalPolicy:\n    \"\"\"Determines what requires human approval.\"\"\"\n\n    def requires_approval(self, tool: Tool, context: PlatformContext) -&gt; bool: ...\n</code></pre>"},{"location":"adrs/002-ddd-tactical-patterns/#domain-events","title":"Domain Events","text":"<p>Record of something significant that happened in the domain.</p> <pre><code>@dataclass(frozen=True)\nclass ApprovalRequested:\n    conversation_id: ConversationId\n    tool_calls: List[ToolCall]\n    timestamp: datetime\n</code></pre>"},{"location":"adrs/002-ddd-tactical-patterns/#consequences","title":"Consequences","text":""},{"location":"adrs/002-ddd-tactical-patterns/#positive-consequences","title":"Positive Consequences","text":"<ul> <li>Business rules are explicit and testable</li> <li>State transitions are controlled and validated</li> <li>Invariants are protected at the aggregate boundary</li> <li>Events enable loose coupling and audit trails</li> <li>Code reads like the ubiquitous language</li> </ul>"},{"location":"adrs/002-ddd-tactical-patterns/#negative-consequences","title":"Negative Consequences","text":"<ul> <li>More classes than a simple data-centric approach</li> <li>Requires understanding of DDD concepts</li> <li>Aggregate boundaries need careful design</li> <li>May feel like overkill for simple CRUD operations</li> </ul>"},{"location":"adrs/002-ddd-tactical-patterns/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-001: Clean Architecture</li> <li>ADR-004: Approval-First Design</li> </ul>"},{"location":"adrs/003-adapter-pattern-for-frameworks/","title":"ADR-003: Adapter Pattern for Frameworks","text":""},{"location":"adrs/003-adapter-pattern-for-frameworks/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adrs/003-adapter-pattern-for-frameworks/#context","title":"Context","text":"<p>DCAF needs to support multiple LLM agent frameworks:</p> <ul> <li>Agno: Primary framework for agent orchestration</li> <li>LangChain: Popular alternative with extensive ecosystem</li> <li>Strands: AWS-native agent framework</li> <li>Direct Bedrock: Existing implementation for backwards compatibility</li> </ul> <p>Each framework has its own: - Message format (different structures for user/assistant/tool messages) - Tool definition format (different JSON schema conventions) - Streaming protocol (different event types) - Error handling patterns</p> <p>Without proper isolation, framework-specific code would leak into business logic, causing: - Tight coupling to specific frameworks - Difficulty testing without framework dependencies - Code duplication across agents - Inconsistent behavior</p>"},{"location":"adrs/003-adapter-pattern-for-frameworks/#decision","title":"Decision","text":"<p>We use the Adapter Pattern with cohesive modules per framework:</p> <pre><code>dcaf/core/adapters/outbound/\n\u251c\u2500\u2500 agno/                          # ALL Agno-specific code\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 adapter.py                 # Implements AgentRuntime\n\u2502   \u251c\u2500\u2500 tool_converter.py          # dcaf Tool \u2192 Agno format\n\u2502   \u251c\u2500\u2500 message_converter.py       # dcaf Message \u2194 Agno format\n\u2502   \u2514\u2500\u2500 types.py                   # Agno-specific type definitions\n\u251c\u2500\u2500 langchain/                     # ALL LangChain-specific code\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 strands/                       # ALL Strands-specific code\n    \u2514\u2500\u2500 ...\n</code></pre> <p>Each adapter folder contains:</p> <ol> <li>Adapter (<code>adapter.py</code>): Implements the <code>AgentRuntime</code> port</li> <li>Tool Converter (<code>tool_converter.py</code>): Converts dcaf <code>Tool</code> objects to framework format</li> <li>Message Converter (<code>message_converter.py</code>): Converts messages bidirectionally</li> </ol> <p>The domain and application layers never import from these adapter packages.</p>"},{"location":"adrs/003-adapter-pattern-for-frameworks/#agentruntime-port","title":"AgentRuntime Port","text":"<pre><code>class AgentRuntime(Protocol):\n    \"\"\"Port that adapters implement.\"\"\"\n\n    def invoke(\n        self, \n        messages: List[Message],\n        tools: List[Tool],\n    ) -&gt; AgentResponse: ...\n\n    def invoke_stream(\n        self, \n        messages: List[Message],\n        tools: List[Tool],\n    ) -&gt; Iterator[StreamEvent]: ...\n</code></pre>"},{"location":"adrs/003-adapter-pattern-for-frameworks/#adapter-implementation","title":"Adapter Implementation","text":"<pre><code>class AgnoAdapter(AgentRuntime):\n    def invoke(self, messages: List[Message], tools: List[Tool]) -&gt; AgentResponse:\n        # 1. Convert to Agno format\n        agno_messages = self._message_converter.to_agno(messages)\n        agno_tools = [self._tool_converter.to_agno(t) for t in tools]\n\n        # 2. Call Agno SDK\n        response = self._agent.run(messages=agno_messages, tools=agno_tools)\n\n        # 3. Convert back to our domain\n        return self._message_converter.from_agno(response)\n</code></pre>"},{"location":"adrs/003-adapter-pattern-for-frameworks/#consequences","title":"Consequences","text":""},{"location":"adrs/003-adapter-pattern-for-frameworks/#positive-consequences","title":"Positive Consequences","text":"<ul> <li>Framework-specific code is isolated and replaceable</li> <li>Adding a new framework means adding a new folder, not modifying existing code</li> <li>Testing can use fake adapters instead of real frameworks</li> <li>Consistent behavior regardless of underlying framework</li> <li>Human-in-the-loop approval flow works identically across frameworks</li> </ul>"},{"location":"adrs/003-adapter-pattern-for-frameworks/#negative-consequences","title":"Negative Consequences","text":"<ul> <li>Conversion overhead at adapter boundaries</li> <li>Need to maintain converters as frameworks evolve</li> <li>Some framework features may not map cleanly to our abstractions</li> <li>Initial setup requires understanding each framework's model</li> </ul>"},{"location":"adrs/003-adapter-pattern-for-frameworks/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-001: Clean Architecture</li> <li>ADR-005: Cohesive Provider Modules</li> </ul>"},{"location":"adrs/004-approval-first-design/","title":"ADR-004: Approval-First Design","text":""},{"location":"adrs/004-approval-first-design/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adrs/004-approval-first-design/#context","title":"Context","text":"<p>DCAF manages infrastructure operations (Kubernetes, AWS, etc.) that can have significant consequences:</p> <ul> <li>Deleting pods or namespaces</li> <li>Modifying AWS resources</li> <li>Executing shell commands</li> <li>Changing configurations</li> </ul> <p>Autonomous agents executing such operations without human oversight poses risks:</p> <ul> <li>Unintended destructive actions</li> <li>Compliance violations</li> <li>Security incidents</li> <li>Difficult-to-reverse mistakes</li> </ul> <p>The existing implementation has a human-in-the-loop pattern using <code>requires_approval</code> on tools and an <code>execute</code> flag on tool calls, but this is implemented inconsistently across agents.</p>"},{"location":"adrs/004-approval-first-design/#decision","title":"Decision","text":"<p>We make human-in-the-loop approval a first-class protocol concern, not an afterthought.</p>"},{"location":"adrs/004-approval-first-design/#approval-flow","title":"Approval Flow","text":"<pre><code>User Request\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Agent Processes   \u2502\n\u2502   Determines Tools  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     requires_approval=False\n\u2502  Check Approval     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba Execute Immediately\n\u2502  Policy             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502 requires_approval=True\n          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Return ToolCall    \u2502\n\u2502  (status=PENDING)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Human Reviews      \u2502\n\u2502  Approves/Rejects   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Continue with      \u2502\n\u2502  Approved Actions   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"adrs/004-approval-first-design/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li> <p>ToolCall as Entity: Tool calls have identity and lifecycle (pending \u2192 approved \u2192 executed \u2192 completed)</p> </li> <li> <p>Approval Policy as Domain Service: Business rules for what needs approval are explicit and testable</p> </li> <li> <p>Conversation Blocking: The conversation aggregate enforces that you cannot proceed while approvals are pending</p> </li> <li> <p>ApprovalCallback as Port: The mechanism for requesting approval is abstracted, allowing different UIs (CLI, web, Slack)</p> </li> </ol>"},{"location":"adrs/004-approval-first-design/#tool-configuration","title":"Tool Configuration","text":"<pre><code>class Tool:\n    requires_approval: bool = False  # Default: no approval needed\n    is_read_only: bool = True        # Hint for approval policy\n</code></pre>"},{"location":"adrs/004-approval-first-design/#approval-policy","title":"Approval Policy","text":"<pre><code>class ApprovalPolicy:\n    def requires_approval(self, tool: Tool, context: PlatformContext) -&gt; bool:\n        # Business rule: read-only operations don't need approval\n        if tool.is_read_only:\n            return False\n        # Respect tool-level configuration\n        return tool.requires_approval\n</code></pre>"},{"location":"adrs/004-approval-first-design/#consequences","title":"Consequences","text":""},{"location":"adrs/004-approval-first-design/#positive-consequences","title":"Positive Consequences","text":"<ul> <li>Human oversight is guaranteed for dangerous operations</li> <li>Approval flow works consistently across all frameworks</li> <li>Easy to audit what was approved and by whom</li> <li>Policy changes don't require code changes in agents</li> <li>Supports different approval mechanisms (sync/async)</li> </ul>"},{"location":"adrs/004-approval-first-design/#negative-consequences","title":"Negative Consequences","text":"<ul> <li>Additional latency for operations requiring approval</li> <li>More complex conversation state management</li> <li>Users may find approval prompts disruptive for routine operations</li> <li>Need to design timeout/expiry for pending approvals</li> </ul>"},{"location":"adrs/004-approval-first-design/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-002: DDD Tactical Patterns</li> <li>ADR-003: Adapter Pattern for Frameworks</li> </ul>"},{"location":"adrs/005-cohesive-provider-modules/","title":"ADR-005: Cohesive Provider Modules","text":""},{"location":"adrs/005-cohesive-provider-modules/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adrs/005-cohesive-provider-modules/#context","title":"Context","text":"<p>When integrating with external frameworks (Agno, LangChain, etc.), there are multiple types of code:</p> <ul> <li>Adapter classes implementing our ports</li> <li>Converters for tools, messages, events</li> <li>Type definitions and constants</li> <li>Framework-specific utilities</li> </ul> <p>These pieces are highly cohesive\u2014they all deal with the same framework and change together. Spreading them across the codebase by type (all converters in one place, all adapters in another) would:</p> <ul> <li>Make it harder to understand a single integration</li> <li>Increase coupling between unrelated framework integrations</li> <li>Make it harder to add or remove framework support</li> <li>Complicate testing of a single integration</li> </ul>"},{"location":"adrs/005-cohesive-provider-modules/#decision","title":"Decision","text":"<p>We organize code by provider/framework rather than by technical concern:</p>"},{"location":"adrs/005-cohesive-provider-modules/#recommended-structure-by-provider","title":"Recommended Structure (by provider)","text":"<pre><code>dcaf/core/adapters/outbound/\n\u251c\u2500\u2500 agno/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 adapter.py           # AgnoAdapter\n\u2502   \u251c\u2500\u2500 tool_converter.py    # AgnoToolConverter\n\u2502   \u251c\u2500\u2500 message_converter.py # AgnoMessageConverter\n\u2502   \u2514\u2500\u2500 types.py             # Agno-specific types\n\u251c\u2500\u2500 langchain/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 adapter.py\n\u2502   \u251c\u2500\u2500 tool_converter.py\n\u2502   \u2514\u2500\u2500 message_converter.py\n\u2514\u2500\u2500 bedrock/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 adapter.py           # Wraps existing BedrockLLM\n    \u2514\u2500\u2500 message_converter.py\n</code></pre>"},{"location":"adrs/005-cohesive-provider-modules/#not-recommended-by-concern","title":"NOT Recommended (by concern)","text":"<pre><code>dcaf/core/adapters/\n\u251c\u2500\u2500 adapters/\n\u2502   \u251c\u2500\u2500 agno_adapter.py\n\u2502   \u251c\u2500\u2500 langchain_adapter.py\n\u2502   \u2514\u2500\u2500 bedrock_adapter.py\n\u251c\u2500\u2500 converters/\n\u2502   \u251c\u2500\u2500 agno_tool_converter.py\n\u2502   \u251c\u2500\u2500 agno_message_converter.py\n\u2502   \u251c\u2500\u2500 langchain_tool_converter.py\n\u2502   \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"adrs/005-cohesive-provider-modules/#benefits-of-cohesive-modules","title":"Benefits of Cohesive Modules","text":"<ol> <li>Single Point of Change: Adding Strands support means creating one new folder</li> <li>Easy Removal: Removing LangChain support means deleting one folder</li> <li>Clear Dependencies: All Agno code imports from <code>agno/</code>, nothing else does</li> <li>Focused Testing: Test the entire Agno integration in one test module</li> <li>Framework Isolation: Agno and LangChain never share implementation code</li> </ol>"},{"location":"adrs/005-cohesive-provider-modules/#module-interface","title":"Module Interface","text":"<p>Each provider module exports a consistent interface:</p> <pre><code># dcaf/core/adapters/outbound/agno/__init__.py\nfrom .adapter import AgnoAdapter\nfrom .tool_converter import AgnoToolConverter\nfrom .message_converter import AgnoMessageConverter\n\n__all__ = [\"AgnoAdapter\", \"AgnoToolConverter\", \"AgnoMessageConverter\"]\n</code></pre>"},{"location":"adrs/005-cohesive-provider-modules/#consequences","title":"Consequences","text":""},{"location":"adrs/005-cohesive-provider-modules/#positive-consequences","title":"Positive Consequences","text":"<ul> <li>High cohesion within provider modules</li> <li>Low coupling between provider modules</li> <li>Easy to understand what code relates to which framework</li> <li>Simple to add/remove framework support</li> <li>Natural testing boundaries</li> </ul>"},{"location":"adrs/005-cohesive-provider-modules/#negative-consequences","title":"Negative Consequences","text":"<ul> <li>Some code patterns may be duplicated across providers</li> <li>Need to maintain similar structures in each provider folder</li> <li>Cannot easily share utilities between providers (by design)</li> </ul>"},{"location":"adrs/005-cohesive-provider-modules/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-003: Adapter Pattern for Frameworks</li> <li>ADR-001: Clean Architecture</li> </ul>"},{"location":"adrs/006-strangler-fig-migration/","title":"ADR-006: Strangler Fig Migration","text":""},{"location":"adrs/006-strangler-fig-migration/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"adrs/006-strangler-fig-migration/#context","title":"Context","text":"<p>DCAF has an existing codebase with:</p> <ul> <li>Working agents (<code>cmd_agent.py</code>, <code>aws_agent.py</code>, <code>k8s_agent.py</code>)</li> <li>Established <code>AgentProtocol</code> interface</li> <li>Production usage via <code>agent_server.py</code></li> <li>Existing schemas and tools</li> </ul> <p>We want to introduce a new Core abstraction layer without:</p> <ul> <li>Breaking existing functionality</li> <li>Requiring a big-bang migration</li> <li>Disrupting current users</li> <li>Losing the ability to rollback</li> </ul>"},{"location":"adrs/006-strangler-fig-migration/#decision","title":"Decision","text":"<p>We apply the Strangler Fig Pattern:</p> <ol> <li>Build the new Core system alongside the existing system</li> <li>Route new functionality through Core</li> <li>Gradually migrate existing agents</li> <li>Eventually remove the old system</li> </ol>"},{"location":"adrs/006-strangler-fig-migration/#implementation-strategy","title":"Implementation Strategy","text":"<pre><code>dcaf/\n\u251c\u2500\u2500 agents/              # EXISTING - Keep working\n\u2502   \u251c\u2500\u2500 cmd_agent.py\n\u2502   \u251c\u2500\u2500 aws_agent.py\n\u2502   \u2514\u2500\u2500 k8s_agent.py\n\u251c\u2500\u2500 agent_server.py      # EXISTING - Still works with AgentProtocol\n\u251c\u2500\u2500 schemas/             # EXISTING - Reused by Core\n\u251c\u2500\u2500 tools.py             # EXISTING - Reused by Core\n\u2502\n\u2514\u2500\u2500 core/                # NEW - Built in parallel\n    \u251c\u2500\u2500 domain/\n    \u251c\u2500\u2500 application/\n    \u2514\u2500\u2500 adapters/\n</code></pre>"},{"location":"adrs/006-strangler-fig-migration/#migration-phases","title":"Migration Phases","text":"<p>Phase 1: Parallel Construction - Build Core in <code>dcaf/core/</code> without touching existing code - Existing agents continue to work unchanged - Core can import from existing <code>schemas/</code> and <code>tools.py</code></p> <p>Phase 2: Facade Adapter - Create a <code>BedrockDirectAdapter</code> that wraps existing <code>BedrockLLM</code> - Allows Core use cases to work with existing infrastructure - Proves Core architecture without new framework dependencies</p> <p>Phase 3: New Agents on Core - New agents (e.g., using Agno) are built on Core - Old and new agents coexist in <code>agent_server.py</code> - Both implement <code>AgentProtocol</code> for compatibility</p> <p>Phase 4: Gradual Migration - Migrate existing agents one at a time - Each migration is a separate, reversible change - Old implementations kept until migration is verified</p> <p>Phase 5: Cleanup - Remove old agent implementations - Core becomes the primary implementation - Old <code>AgentProtocol</code> may remain for backwards compatibility</p>"},{"location":"adrs/006-strangler-fig-migration/#compatibility-bridge","title":"Compatibility Bridge","text":"<pre><code># dcaf/core/adapters/inbound/agent_protocol_bridge.py\nclass CoreAgentBridge:\n    \"\"\"Wraps a Core use case to implement legacy AgentProtocol.\"\"\"\n\n    def __init__(self, execute_agent_service: AgentService):\n        self._service = execute_agent_service\n\n    def invoke(self, messages: Dict) -&gt; AgentMessage:\n        # Convert legacy format to Core request\n        request = self._convert_to_request(messages)\n        response = self._service.execute(request)\n        return self._convert_to_agent_message(response)\n</code></pre>"},{"location":"adrs/006-strangler-fig-migration/#consequences","title":"Consequences","text":""},{"location":"adrs/006-strangler-fig-migration/#positive-consequences","title":"Positive Consequences","text":"<ul> <li>Zero downtime during migration</li> <li>Easy rollback if issues discovered</li> <li>Can migrate incrementally by agent</li> <li>New features can use Core immediately</li> <li>Team can learn Core patterns on new work</li> </ul>"},{"location":"adrs/006-strangler-fig-migration/#negative-consequences","title":"Negative Consequences","text":"<ul> <li>Temporary code duplication</li> <li>Two mental models during transition</li> <li>Need to maintain compatibility layer</li> <li>Longer overall timeline than big-bang</li> </ul>"},{"location":"adrs/006-strangler-fig-migration/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-001: Clean Architecture</li> <li>ADR-003: Adapter Pattern for Frameworks</li> </ul>"},{"location":"adrs/007-lowercase-chat-endpoints/","title":"ADR-007: Lowercase Chat Endpoint Naming","text":"<p>Status: Accepted Date: 2024-12-22 Deciders: Engineering Team</p>"},{"location":"adrs/007-lowercase-chat-endpoints/#context","title":"Context","text":"<p>The original API endpoints used camelCase naming: - <code>POST /api/sendMessage</code> - <code>POST /api/sendMessageStream</code></p> <p>We need to establish a naming convention for the DCAF Core API endpoints that: 1. Avoids future compatibility issues 2. Accurately describes the operation 3. Follows REST best practices</p>"},{"location":"adrs/007-lowercase-chat-endpoints/#decision","title":"Decision","text":"<p>Adopt lowercase, hyphenated endpoint names: - <code>POST /api/chat</code> (replaces <code>/api/sendMessage</code>) - <code>POST /api/chat-stream</code> (replaces <code>/api/sendMessageStream</code>)</p> <p>Legacy endpoints are preserved for backwards compatibility but marked as deprecated.</p>"},{"location":"adrs/007-lowercase-chat-endpoints/#rationale","title":"Rationale","text":""},{"location":"adrs/007-lowercase-chat-endpoints/#1-future-proofing-for-encryptionsecurity","title":"1. Future-Proofing for Encryption/Security","text":"<p>If we later need to enable case-sensitive URL matching (e.g., for encrypted tokens, signed URLs, or security middleware), mixed-case endpoints become a liability.</p> <p>Problem scenario: <pre><code># Original endpoint\nPOST /api/sendMessage\n\n# With case-sensitive matching enabled, these would be DIFFERENT endpoints:\nPOST /api/sendmessage  \u2190 404\nPOST /api/SendMessage  \u2190 404\nPOST /api/SENDMESSAGE  \u2190 404\n</code></pre></p> <p>A customer using <code>sendmessage</code> (all lowercase) in their integration would experience a breaking change when case-sensitivity is enabled.</p> <p>Solution: By starting with all lowercase (<code>/api/chat</code>), we avoid this entire class of issues. Lowercase URLs are: - Case-insensitive by default on most servers - Still work correctly when case-sensitivity is enabled - Consistent regardless of client behavior</p>"},{"location":"adrs/007-lowercase-chat-endpoints/#2-semantic-accuracy","title":"2. Semantic Accuracy","text":"<p>The original name <code>sendMessage</code> is misleading:</p> Name Implies Reality <code>sendMessage</code> Agent sends a message Agent receives a message and responds <code>chat</code> Bidirectional conversation \u2705 Accurately describes the interaction <p>The agent doesn't \"send\" messages\u2014it receives them from the helpdesk middleware and responds. The term \"chat\" correctly conveys: - A conversation is happening - Messages flow both directions - The user and agent are participants</p>"},{"location":"adrs/007-lowercase-chat-endpoints/#3-rest-best-practices","title":"3. REST Best Practices","text":"<p>RESTful API conventions favor: - Lowercase paths - Hyphen-separated words (not camelCase) - Nouns over verbs (resources, not actions)</p> Convention Example \u274c camelCase <code>/api/sendMessage</code> \u274c Verb-first <code>/api/sendMessage</code> \u2705 Lowercase <code>/api/chat</code> \u2705 Hyphenated <code>/api/chat-stream</code> \u2705 Noun/resource <code>/api/chat</code>"},{"location":"adrs/007-lowercase-chat-endpoints/#consequences","title":"Consequences","text":""},{"location":"adrs/007-lowercase-chat-endpoints/#positive","title":"Positive","text":"<ul> <li>No future breaking changes from case-sensitivity requirements</li> <li>Clearer semantics for developers integrating with the API</li> <li>Follows standards that developers expect</li> <li>Backwards compatible via legacy endpoint aliases</li> </ul>"},{"location":"adrs/007-lowercase-chat-endpoints/#negative","title":"Negative","text":"<ul> <li>Two endpoints per function (during transition period)</li> <li>Documentation overhead to explain deprecation</li> </ul>"},{"location":"adrs/007-lowercase-chat-endpoints/#migration-path","title":"Migration Path","text":"<ol> <li>New integrations should use <code>/api/chat</code> and <code>/api/chat-stream</code></li> <li>Existing integrations continue working with <code>/api/sendMessage</code> and <code>/api/sendMessageStream</code></li> <li>Legacy endpoints will be removed in a future major version (with ample warning)</li> </ol>"},{"location":"adrs/007-lowercase-chat-endpoints/#endpoints-summary","title":"Endpoints Summary","text":"New (Preferred) Legacy (Deprecated) Description <code>GET /health</code> \u2014 Health check <code>POST /api/chat</code> <code>POST /api/sendMessage</code> Synchronous chat <code>POST /api/chat-stream</code> <code>POST /api/sendMessageStream</code> Streaming chat"},{"location":"adrs/007-lowercase-chat-endpoints/#related","title":"Related","text":"<ul> <li>REST API Naming Conventions</li> <li>URI Case Sensitivity (RFC 3986)</li> </ul>"},{"location":"api-reference/","title":"API Reference (Legacy)","text":"<p>Legacy API</p> <p>This documents the v1 API. For new projects, use the Core API.</p> <p>See Migration Guide to upgrade existing code.</p> <p>This section provides detailed API documentation for all DCAF v1 components.</p>"},{"location":"api-reference/#components","title":"Components","text":"Component Description BedrockLLM AWS Bedrock Converse API wrapper for model invocation Tools Tool creation system with <code>@tool</code> decorator and approval workflows Agents Pre-built agent classes and the <code>AgentProtocol</code> interface Agent Server FastAPI server for hosting agents Schemas Message schemas for the Help Desk protocol Channel Routing Slack and channel-specific response routing CLI Command-line tools for credential management"},{"location":"api-reference/#quick-links","title":"Quick Links","text":""},{"location":"api-reference/#creating-tools","title":"Creating Tools","text":"<pre><code>from dcaf.tools import tool\n\n@tool(\n    schema={\n        \"name\": \"my_tool\",\n        \"description\": \"Does something useful\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"param\": {\"type\": \"string\"}\n            }\n        }\n    },\n    requires_approval=True\n)\ndef my_tool(param: str) -&gt; str:\n    return f\"Result: {param}\"\n</code></pre>"},{"location":"api-reference/#creating-agents","title":"Creating Agents","text":"<pre><code>from dcaf.agents import ToolCallingAgent\nfrom dcaf.llm import BedrockLLM\n\nllm = BedrockLLM(region_name=\"us-east-1\")\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[my_tool],\n    system_prompt=\"You are a helpful assistant.\",\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n)\n</code></pre>"},{"location":"api-reference/#serving-agents","title":"Serving Agents","text":"<pre><code>from dcaf.agent_server import create_chat_app\nimport uvicorn\n\napp = create_chat_app(agent)\nuvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"api-reference/#core-api-reference","title":"Core API Reference","text":"<p>For the Core architecture with Clean Architecture, see:</p> <ul> <li>Core Overview</li> <li>Domain Layer</li> <li>Application Layer</li> <li>Adapters</li> </ul>"},{"location":"api-reference/agent-server/","title":"Agent Server API Reference (Legacy)","text":"<p>Legacy API</p> <p>This documents the v1 API. For new projects, use <code>serve(agent)</code> from the Core API.</p> <p>See Migration Guide to upgrade existing code.</p> <p>The Agent Server module provides a FastAPI-based server for hosting DCAF agents with RESTful endpoints.</p>"},{"location":"api-reference/agent-server/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>create_chat_app()</li> <li>API Endpoints</li> <li>Request/Response Formats</li> <li>Streaming</li> <li>Error Handling</li> <li>Channel Routing</li> <li>Examples</li> </ol>"},{"location":"api-reference/agent-server/#overview","title":"Overview","text":"<p>The Agent Server wraps any <code>AgentProtocol</code>-compliant agent in a FastAPI application with standardized endpoints for chat interactions.</p>"},{"location":"api-reference/agent-server/#import","title":"Import","text":"<pre><code>from dcaf.agent_server import create_chat_app, AgentProtocol\n\n# Or from the main module\nfrom dcaf import create_chat_app, AgentProtocol\n</code></pre>"},{"location":"api-reference/agent-server/#features","title":"Features","text":"<ul> <li>REST API: Standard HTTP endpoints</li> <li>WebSocket: Bidirectional streaming via <code>/api/chat-ws</code></li> <li>Streaming: NDJSON streaming support</li> <li>Validation: Pydantic schema validation</li> <li>Logging: Built-in request/response logging</li> <li>Health Check: Endpoint for monitoring</li> <li>Channel Routing: Optional Slack integration</li> </ul>"},{"location":"api-reference/agent-server/#agentprotocol-interface","title":"AgentProtocol Interface","text":"<p>Any agent passed to <code>create_chat_app()</code> must satisfy the <code>AgentProtocol</code>:</p> <pre><code>from typing import Protocol, runtime_checkable\n\n@runtime_checkable\nclass AgentProtocol(Protocol):\n    def invoke(self, messages: dict[str, list[dict[str, Any]]]) -&gt; AgentMessage: ...\n</code></pre> <p>Required:</p> <ul> <li><code>invoke(messages) -&gt; AgentMessage</code>: Process messages and return a response. Can be sync or async.</li> </ul> <p>Optional:</p> <ul> <li><code>invoke_stream(messages) -&gt; Iterator[StreamEvent]</code>: Stream responses. If not implemented, streaming endpoints fall back to <code>invoke()</code> and wrap the response in stream events.</li> </ul> <p>Backwards Compatibility</p> <p>The protocol only requires <code>invoke()</code>. V1 agents that don't implement <code>invoke_stream()</code> will still work with all endpoints\u2014streaming endpoints automatically fall back to wrapping the <code>invoke()</code> response in stream events.</p>"},{"location":"api-reference/agent-server/#create_chat_app","title":"create_chat_app()","text":"<p>Create a FastAPI application from an agent.</p> <pre><code>def create_chat_app(\n    agent: AgentProtocol, \n    router: ChannelResponseRouter = None\n) -&gt; FastAPI\n</code></pre>"},{"location":"api-reference/agent-server/#parameters","title":"Parameters","text":"Parameter Type Required Description <code>agent</code> <code>AgentProtocol</code> Yes Agent implementation <code>router</code> <code>ChannelResponseRouter</code> No Channel-specific routing"},{"location":"api-reference/agent-server/#returns","title":"Returns","text":"<p><code>FastAPI</code> - A configured FastAPI application instance.</p>"},{"location":"api-reference/agent-server/#raises","title":"Raises","text":"<ul> <li><code>TypeError</code> - If agent doesn't satisfy <code>AgentProtocol</code></li> </ul>"},{"location":"api-reference/agent-server/#example","title":"Example","text":"<pre><code>from dcaf.agent_server import create_chat_app\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.llm import BedrockLLM\nimport uvicorn\n\n# Create agent\nllm = BedrockLLM()\nagent = ToolCallingAgent(llm=llm, tools=[...], system_prompt=\"...\")\n\n# Create app\napp = create_chat_app(agent)\n\n# Run server\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"api-reference/agent-server/#with-channel-router","title":"With Channel Router","text":"<pre><code>from dcaf.agent_server import create_chat_app\nfrom dcaf.channel_routing import SlackResponseRouter\nfrom dcaf.llm import BedrockLLM\n\nllm = BedrockLLM()\n\n# Create router for Slack\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"MyBot\",\n    agent_description=\"A helpful assistant\"\n)\n\n# Create app with router\napp = create_chat_app(agent, router=router)\n</code></pre>"},{"location":"api-reference/agent-server/#api-endpoints","title":"API Endpoints","text":"<p>Endpoint Naming</p> <p>The legacy endpoints (<code>/api/sendMessage</code>, <code>/api/sendMessageStream</code>) are still fully functional but deprecated. New integrations should use the preferred endpoints (<code>/api/chat</code>, <code>/api/chat-stream</code>).</p> Legacy (Deprecated) Preferred Description <code>POST /api/sendMessage</code> <code>POST /api/chat</code> Synchronous chat <code>POST /api/sendMessageStream</code> <code>POST /api/chat-stream</code> Streaming chat \u2014 <code>WS /api/chat-ws</code> WebSocket chat (new)"},{"location":"api-reference/agent-server/#get-health","title":"GET /health","text":"<p>Health check endpoint for monitoring.</p> <pre><code>GET /health\n</code></pre>"},{"location":"api-reference/agent-server/#response","title":"Response","text":"<pre><code>{\n    \"status\": \"ok\"\n}\n</code></pre>"},{"location":"api-reference/agent-server/#example_1","title":"Example","text":"<pre><code>curl http://localhost:8000/health\n# {\"status\":\"ok\"}\n</code></pre>"},{"location":"api-reference/agent-server/#post-apisendmessage","title":"POST /api/sendMessage","text":"<p>Deprecated</p> <p>This endpoint is deprecated. Use <code>POST /api/chat</code> instead for new integrations.</p> <p>The endpoint remains fully functional for backwards compatibility.</p> <p>Send a message to the agent and receive a response.</p> <pre><code>POST /api/sendMessage\nContent-Type: application/json\n</code></pre>"},{"location":"api-reference/agent-server/#request-body","title":"Request Body","text":"<pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Hello!\",\n            \"data\": {},\n            \"platform_context\": {\n                \"tenant_name\": \"production\",\n                \"user_id\": \"user123\"\n            }\n        }\n    ],\n    \"source\": \"help-desk\"\n}\n</code></pre>"},{"location":"api-reference/agent-server/#fields","title":"Fields","text":"Field Type Required Description <code>messages</code> <code>array</code> Yes Array of message objects <code>source</code> <code>string</code> No Message source (e.g., \"slack\", \"help-desk\")"},{"location":"api-reference/agent-server/#response_1","title":"Response","text":"<pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"Hello! How can I help you today?\",\n    \"data\": {\n        \"cmds\": [],\n        \"executed_cmds\": [],\n        \"tool_calls\": [],\n        \"executed_tool_calls\": [],\n        \"url_configs\": []\n    },\n    \"meta_data\": {},\n    \"timestamp\": null,\n    \"user\": null,\n    \"agent\": null\n}\n</code></pre>"},{"location":"api-reference/agent-server/#example_2","title":"Example","text":"<pre><code>curl -X POST http://localhost:8000/api/sendMessage \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"What is the weather in NYC?\"}\n    ]\n  }'\n</code></pre>"},{"location":"api-reference/agent-server/#error-responses","title":"Error Responses","text":"Code Description <code>400</code> Missing <code>messages</code> field <code>422</code> Validation error in messages <code>500</code> Agent error or invalid response"},{"location":"api-reference/agent-server/#post-apisendmessagestream","title":"POST /api/sendMessageStream","text":"<p>Deprecated</p> <p>This endpoint is deprecated. Use <code>POST /api/chat-stream</code> instead for new integrations.</p> <p>The endpoint remains fully functional for backwards compatibility.</p> <p>Stream a response from the agent.</p> <pre><code>POST /api/sendMessageStream\nContent-Type: application/json\n</code></pre>"},{"location":"api-reference/agent-server/#request-body_1","title":"Request Body","text":"<p>Same as <code>/api/sendMessage</code>.</p>"},{"location":"api-reference/agent-server/#response_2","title":"Response","text":"<p>NDJSON (Newline-delimited JSON) stream:</p> <pre><code>{\"type\":\"text_delta\",\"text\":\"Hello\"}\n{\"type\":\"text_delta\",\"text\":\" there!\"}\n{\"type\":\"tool_calls\",\"tool_calls\":[...]}\n{\"type\":\"done\",\"stop_reason\":\"end_turn\"}\n</code></pre>"},{"location":"api-reference/agent-server/#example_3","title":"Example","text":"<pre><code>curl -X POST http://localhost:8000/api/sendMessageStream \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a story\"}]}'\n</code></pre>"},{"location":"api-reference/agent-server/#ws-apichat-ws","title":"WS /api/chat-ws","text":"<p>Bidirectional streaming chat over WebSocket. The connection stays open for multiple conversation turns.</p> <pre><code>WS /api/chat-ws\n</code></pre>"},{"location":"api-reference/agent-server/#client-frame","title":"Client Frame","text":"<p>Each text frame from the client is a JSON object with the same shape as the HTTP endpoints:</p> <pre><code>{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}\n</code></pre>"},{"location":"api-reference/agent-server/#server-frames","title":"Server Frames","text":"<p>The server streams back the same event types as <code>/api/sendMessageStream</code> (text_delta, tool_calls, done, error, etc.), one JSON object per text frame. Each turn ends with a <code>done</code> event, after which the client can send the next turn.</p>"},{"location":"api-reference/agent-server/#error-behavior","title":"Error Behavior","text":"<p>Errors (invalid JSON, missing fields, agent exceptions) are sent as <code>error</code> events without closing the connection. The client can continue sending messages after receiving an error.</p>"},{"location":"api-reference/agent-server/#example_4","title":"Example","text":"<pre><code>import asyncio\nimport json\nimport websockets\n\nasync def chat():\n    async with websockets.connect(\"ws://localhost:8000/api/chat-ws\") as ws:\n        await ws.send(json.dumps({\n            \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]\n        }))\n\n        async for frame in ws:\n            event = json.loads(frame)\n            if event[\"type\"] == \"text_delta\":\n                print(event[\"text\"], end=\"\", flush=True)\n            elif event[\"type\"] == \"done\":\n                print(\"\\n--- Done ---\")\n                break\n            elif event[\"type\"] == \"error\":\n                print(f\"\\nError: {event['error']}\")\n                break\n\nasyncio.run(chat())\n</code></pre>"},{"location":"api-reference/agent-server/#requestresponse-formats","title":"Request/Response Formats","text":""},{"location":"api-reference/agent-server/#message-object","title":"Message Object","text":"<pre><code>{\n    \"role\": \"user\" | \"assistant\",\n    \"content\": \"Message text\",\n    \"data\": {\n        \"cmds\": [...],              # Suggested commands\n        \"executed_cmds\": [...],     # Executed commands\n        \"tool_calls\": [...],        # Tools needing approval\n        \"executed_tool_calls\": [...] # Executed tools\n    },\n    \"platform_context\": {           # Only for user messages\n        \"tenant_name\": \"string\",\n        \"user_id\": \"string\",\n        \"k8s_namespace\": \"string\",\n        \"duplo_base_url\": \"string\",\n        \"duplo_token\": \"string\",\n        \"kubeconfig\": \"base64-string\",\n        \"aws_credentials\": {...}\n    },\n    \"timestamp\": \"ISO-8601\",\n    \"user\": {\"name\": \"string\", \"id\": \"string\"},\n    \"agent\": {\"name\": \"string\", \"id\": \"string\"}\n}\n</code></pre>"},{"location":"api-reference/agent-server/#agentmessage-response","title":"AgentMessage Response","text":"<pre><code>class AgentMessage(BaseModel):\n    role: Literal[\"assistant\"] = \"assistant\"\n    content: str = \"\"\n    data: Data = Data()\n    meta_data: Dict[str, Any] = {}\n    timestamp: Optional[datetime] = None\n    user: Optional[User] = None\n    agent: Optional[Agent] = None\n</code></pre>"},{"location":"api-reference/agent-server/#data-object","title":"Data Object","text":"<pre><code>class Data(BaseModel):\n    cmds: List[Command] = []           # Suggested terminal commands\n    executed_cmds: List[ExecutedCommand] = []\n    tool_calls: List[ToolCall] = []    # Tools needing approval\n    executed_tool_calls: List[ExecutedToolCall] = []\n    url_configs: List[URLConfig] = []\n</code></pre>"},{"location":"api-reference/agent-server/#streaming","title":"Streaming","text":""},{"location":"api-reference/agent-server/#stream-event-types","title":"Stream Event Types","text":"<p>DCAF supports 7 event types for streaming:</p>"},{"location":"api-reference/agent-server/#1-text_delta","title":"1. text_delta","text":"<p>Streaming text tokens from the LLM.</p> <pre><code>{\"type\": \"text_delta\", \"text\": \"Hello\"}\n</code></pre>"},{"location":"api-reference/agent-server/#2-tool_calls","title":"2. tool_calls","text":"<p>Tool calls requiring user approval.</p> <pre><code>{\n    \"type\": \"tool_calls\",\n    \"tool_calls\": [\n        {\n            \"id\": \"tool-123\",\n            \"name\": \"delete_file\",\n            \"input\": {\"path\": \"/tmp/file.txt\"},\n            \"execute\": false,\n            \"tool_description\": \"Delete a file\",\n            \"input_description\": {...}\n        }\n    ]\n}\n</code></pre>"},{"location":"api-reference/agent-server/#3-executed_tool_calls","title":"3. executed_tool_calls","text":"<p>Tools that were executed.</p> <pre><code>{\n    \"type\": \"executed_tool_calls\",\n    \"executed_tool_calls\": [\n        {\n            \"id\": \"tool-456\",\n            \"name\": \"get_weather\",\n            \"input\": {\"location\": \"NYC\"},\n            \"output\": \"72\u00b0F, sunny\"\n        }\n    ]\n}\n</code></pre>"},{"location":"api-reference/agent-server/#4-commands","title":"4. commands","text":"<p>Terminal commands for approval.</p> <pre><code>{\n    \"type\": \"commands\",\n    \"commands\": [\n        {\n            \"command\": \"kubectl get pods\",\n            \"execute\": false,\n            \"files\": []\n        }\n    ]\n}\n</code></pre>"},{"location":"api-reference/agent-server/#5-executed_commands","title":"5. executed_commands","text":"<p>Commands that were executed.</p> <pre><code>{\n    \"type\": \"executed_commands\",\n    \"executed_cmds\": [\n        {\n            \"command\": \"ls -la\",\n            \"output\": \"total 0\\ndrwxr-xr-x ...\"\n        }\n    ]\n}\n</code></pre>"},{"location":"api-reference/agent-server/#6-done","title":"6. done","text":"<p>Stream completed successfully.</p> <pre><code>{\"type\": \"done\", \"stop_reason\": \"end_turn\"}\n</code></pre>"},{"location":"api-reference/agent-server/#7-error","title":"7. error","text":"<p>Error during streaming.</p> <pre><code>{\"type\": \"error\", \"error\": \"Connection timeout\"}\n</code></pre>"},{"location":"api-reference/agent-server/#consuming-streams","title":"Consuming Streams","text":""},{"location":"api-reference/agent-server/#python","title":"Python","text":"<pre><code>import requests\n\nresponse = requests.post(\n    \"http://localhost:8000/api/sendMessageStream\",\n    json={\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]},\n    stream=True\n)\n\nfor line in response.iter_lines():\n    if line:\n        import json\n        event = json.loads(line)\n\n        if event[\"type\"] == \"text_delta\":\n            print(event[\"text\"], end=\"\", flush=True)\n        elif event[\"type\"] == \"done\":\n            print(\"\\n[Done]\")\n            break\n        elif event[\"type\"] == \"error\":\n            print(f\"\\n[Error: {event['error']}]\")\n            break\n</code></pre>"},{"location":"api-reference/agent-server/#javascript","title":"JavaScript","text":"<pre><code>const response = await fetch('/api/sendMessageStream', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({\n        messages: [{ role: 'user', content: 'Hello' }]\n    })\n});\n\nconst reader = response.body.getReader();\nconst decoder = new TextDecoder();\n\nwhile (true) {\n    const { value, done } = await reader.read();\n    if (done) break;\n\n    const lines = decoder.decode(value).split('\\n');\n    for (const line of lines) {\n        if (line.trim()) {\n            const event = JSON.parse(line);\n            console.log(event);\n        }\n    }\n}\n</code></pre>"},{"location":"api-reference/agent-server/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/agent-server/#error-responses_1","title":"Error Responses","text":"<pre><code># 400 Bad Request - Missing messages\n{\n    \"detail\": \"'messages' field missing from request body\"\n}\n\n# 422 Unprocessable Entity - Validation error\n{\n    \"detail\": [\n        {\n            \"loc\": [\"body\", \"messages\", 0, \"role\"],\n            \"msg\": \"value is not a valid enumeration member\",\n            \"type\": \"type_error.enum\"\n        }\n    ]\n}\n\n# 500 Internal Server Error - Agent error\n{\n    \"detail\": \"Agent returned invalid Message: ...\"\n}\n</code></pre>"},{"location":"api-reference/agent-server/#handling-errors-in-client","title":"Handling Errors in Client","text":"<pre><code>import requests\n\ntry:\n    response = requests.post(\n        \"http://localhost:8000/api/sendMessage\",\n        json={\"messages\": [{\"role\": \"user\", \"content\": \"Hi\"}]},\n        timeout=30\n    )\n    response.raise_for_status()\n    data = response.json()\nexcept requests.exceptions.HTTPError as e:\n    if e.response.status_code == 400:\n        print(\"Bad request:\", e.response.json())\n    elif e.response.status_code == 422:\n        print(\"Validation error:\", e.response.json())\n    elif e.response.status_code == 500:\n        print(\"Server error:\", e.response.json())\nexcept requests.exceptions.Timeout:\n    print(\"Request timed out\")\nexcept requests.exceptions.ConnectionError:\n    print(\"Connection error\")\n</code></pre>"},{"location":"api-reference/agent-server/#channel-routing","title":"Channel Routing","text":"<p>The Agent Server supports channel-specific routing, particularly for Slack.</p>"},{"location":"api-reference/agent-server/#slack-integration","title":"Slack Integration","text":"<pre><code>from dcaf.agent_server import create_chat_app\nfrom dcaf.channel_routing import SlackResponseRouter\nfrom dcaf.llm import BedrockLLM\n\nllm = BedrockLLM()\n\n# Create Slack router\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"DuploBot\",\n    agent_description=\"A helpful DuploCloud assistant\",\n    model_id=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\"  # Fast model for routing\n)\n\n# Create app with router\napp = create_chat_app(agent, router=router)\n</code></pre>"},{"location":"api-reference/agent-server/#how-routing-works","title":"How Routing Works","text":"<ol> <li>Request includes <code>\"source\": \"slack\"</code></li> <li>Router's <code>should_agent_respond()</code> is called</li> <li>If <code>False</code>, returns empty response (agent stays silent)</li> <li>If <code>True</code>, proceeds with agent invocation</li> </ol>"},{"location":"api-reference/agent-server/#request-with-source","title":"Request with Source","text":"<pre><code>{\n    \"messages\": [...],\n    \"source\": \"slack\"\n}\n</code></pre>"},{"location":"api-reference/agent-server/#examples","title":"Examples","text":""},{"location":"api-reference/agent-server/#example-1-basic-server","title":"Example 1: Basic Server","text":"<pre><code>from dcaf.agent_server import create_chat_app, AgentProtocol\nfrom dcaf.schemas.messages import AgentMessage\nimport uvicorn\n\nclass SimpleAgent(AgentProtocol):\n    def invoke(self, messages):\n        return AgentMessage(content=\"Hello from SimpleAgent!\")\n\nagent = SimpleAgent()\napp = create_chat_app(agent)\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"api-reference/agent-server/#example-2-production-server","title":"Example 2: Production Server","text":"<pre><code>from dcaf.agent_server import create_chat_app\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.tools import tool\nimport uvicorn\nimport dotenv\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Load environment\ndotenv.load_dotenv()\n\n# Define tools\n@tool(schema={...}, requires_approval=False)\ndef my_tool(param: str) -&gt; str:\n    return f\"Result: {param}\"\n\n# Create components\nllm = BedrockLLM(region_name=\"us-east-1\")\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[my_tool],\n    system_prompt=\"You are a helpful assistant.\"\n)\n\n# Create app\napp = create_chat_app(agent)\n\n# Add middleware (optional)\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\nif __name__ == \"__main__\":\n    uvicorn.run(\n        app,\n        host=\"0.0.0.0\",\n        port=8000,\n        log_level=\"info\",\n        workers=1  # Use 1 worker for stateful agents\n    )\n</code></pre>"},{"location":"api-reference/agent-server/#example-3-docker-deployment","title":"Example 3: Docker Deployment","text":"<pre><code># Dockerfile\nFROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nEXPOSE 8000\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre> <pre><code># main.py\nfrom dcaf.agent_server import create_chat_app\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.llm import BedrockLLM\nimport dotenv\n\ndotenv.load_dotenv()\n\nllm = BedrockLLM()\nagent = ToolCallingAgent(llm=llm, tools=[], system_prompt=\"...\")\napp = create_chat_app(agent)\n</code></pre>"},{"location":"api-reference/agent-server/#example-4-testing-the-server","title":"Example 4: Testing the Server","text":"<pre><code># test_server.py\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom main import app\n\nclient = TestClient(app)\n\ndef test_health():\n    response = client.get(\"/health\")\n    assert response.status_code == 200\n    assert response.json() == {\"status\": \"ok\"}\n\ndef test_send_message():\n    response = client.post(\n        \"/api/sendMessage\",\n        json={\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"Hello!\"}\n            ]\n        }\n    )\n    assert response.status_code == 200\n    data = response.json()\n    assert \"content\" in data\n    assert data[\"role\"] == \"assistant\"\n\ndef test_missing_messages():\n    response = client.post(\n        \"/api/sendMessage\",\n        json={}\n    )\n    assert response.status_code == 400\n\ndef test_invalid_role():\n    response = client.post(\n        \"/api/sendMessage\",\n        json={\n            \"messages\": [\n                {\"role\": \"invalid\", \"content\": \"Hello!\"}\n            ]\n        }\n    )\n    assert response.status_code == 422\n</code></pre>"},{"location":"api-reference/agent-server/#see-also","title":"See Also","text":"<ul> <li>Agents API Reference</li> <li>Schemas API Reference</li> <li>Channel Routing API Reference</li> <li>Streaming Guide</li> </ul>"},{"location":"api-reference/agents/","title":"Agents API Reference (Legacy)","text":"<p>Legacy API</p> <p>This documents the v1 API. For new projects, use the Core API instead.</p> <p>See Migration Guide to upgrade existing code.</p> <p>The Agents module provides pre-built agent implementations and the <code>AgentProtocol</code> interface for creating custom agents.</p>"},{"location":"api-reference/agents/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>AgentProtocol</li> <li>ToolCallingAgent</li> <li>ToolCallingCmdAgent</li> <li>Other Agents</li> <li>Creating Custom Agents</li> <li>Examples</li> </ol>"},{"location":"api-reference/agents/#overview","title":"Overview","text":"<p>DCAF provides several agent implementations:</p> Agent Description Use Case <code>ToolCallingAgent</code> Full-featured agent with tool execution General purpose with tools <code>ToolCallingCmdAgent</code> Agent with terminal command support CLI-style interactions <code>EchoAgent</code> Simple echo for testing Development/testing <code>LLMPassthroughAgent</code> Direct LLM passthrough Simple chat <code>BoilerplateAgent</code> Template for custom agents Starting point <code>AWSAgent</code> AWS CLI command agent AWS operations <code>K8sAgent</code> Kubernetes/Helm agent K8s operations <code>CommandAgent</code> Terminal command agent Shell operations"},{"location":"api-reference/agents/#import","title":"Import","text":"<pre><code>from dcaf.agents import ToolCallingAgent, ToolCallingCmdAgent\n\n# Or individual agents\nfrom dcaf.agents.tool_calling_agent import ToolCallingAgent\nfrom dcaf.agents.echo_agent import EchoAgent\n</code></pre>"},{"location":"api-reference/agents/#agentprotocol","title":"AgentProtocol","text":"<p>The <code>AgentProtocol</code> defines the interface that all agents must implement.</p> <pre><code>from typing import Protocol, runtime_checkable, Dict, Any, List\nfrom dcaf.schemas.messages import AgentMessage\n\n@runtime_checkable            \nclass AgentProtocol(Protocol):\n    \"\"\"Any agent that can respond to a chat.\"\"\"\n\n    def invoke(self, messages: Dict[str, List[Dict[str, Any]]]) -&gt; AgentMessage:\n        \"\"\"Process messages and return a response.\"\"\"\n        ...\n</code></pre>"},{"location":"api-reference/agents/#method-invoke","title":"Method: invoke()","text":"<pre><code>def invoke(\n    self, \n    messages: Dict[str, List[Dict[str, Any]]]\n) -&gt; AgentMessage\n</code></pre>"},{"location":"api-reference/agents/#parameters","title":"Parameters","text":"Parameter Type Description <code>messages</code> <code>Dict</code> Message dictionary with <code>\"messages\"</code> key"},{"location":"api-reference/agents/#message-format","title":"Message Format","text":"<pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Hello!\",\n            \"data\": {...},           # Optional: Data payload\n            \"platform_context\": {...} # Optional: Runtime context\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"Hi there!\",\n            \"data\": {...}\n        }\n    ]\n}\n</code></pre>"},{"location":"api-reference/agents/#returns","title":"Returns","text":"<p><code>AgentMessage</code> - The agent's response with content and data.</p>"},{"location":"api-reference/agents/#toolcallingagent","title":"ToolCallingAgent","text":"<p>The primary agent for tool-based interactions with approval workflows.</p> <pre><code>class ToolCallingAgent:\n    \"\"\"Agent that can call tools and suggest terminal commands.\"\"\"\n</code></pre>"},{"location":"api-reference/agents/#constructor","title":"Constructor","text":"<pre><code>def __init__(\n    self,\n    llm: BedrockLLM,\n    tools: List[Tool],\n    system_prompt: str = \"You are a helpful assistant.\",\n    model_id: str = \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_iterations: int = 10,\n    enable_terminal_cmds: bool = False,\n    llm_visible_platform_context_fields: List[str] = [\"tenant_name\"]\n)\n</code></pre>"},{"location":"api-reference/agents/#parameters_1","title":"Parameters","text":"Parameter Type Default Description <code>llm</code> <code>BedrockLLM</code> Required LLM instance for model calls <code>tools</code> <code>List[Tool]</code> Required List of tools available to agent <code>system_prompt</code> <code>str</code> <code>\"You are a helpful assistant.\"</code> System prompt for LLM <code>model_id</code> <code>str</code> <code>\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"</code> Bedrock model ID <code>max_iterations</code> <code>int</code> <code>10</code> Max LLM call iterations <code>enable_terminal_cmds</code> <code>bool</code> <code>False</code> Enable terminal command suggestions <code>llm_visible_platform_context_fields</code> <code>List[str]</code> <code>[\"tenant_name\"]</code> Context fields visible to LLM"},{"location":"api-reference/agents/#attributes","title":"Attributes","text":"Attribute Type Description <code>llm</code> <code>BedrockLLM</code> LLM client <code>tools</code> <code>Dict[str, Tool]</code> Tools by name <code>system_prompt</code> <code>str</code> System prompt <code>model_id</code> <code>str</code> Model ID <code>max_iterations</code> <code>int</code> Max iterations <code>tool_schemas</code> <code>List[Dict]</code> LLM-ready tool schemas"},{"location":"api-reference/agents/#methods","title":"Methods","text":""},{"location":"api-reference/agents/#invoke","title":"invoke()","text":"<p>Main entry point for agent interaction.</p> <pre><code>def invoke(\n    self,\n    messages: Dict[str, List[Dict[str, Any]]]\n) -&gt; AgentMessage\n</code></pre> <p>Behavior: 1. Extracts platform context from last user message 2. Processes any approved tool calls 3. Runs LLM loop until response or max iterations 4. Handles tool execution and approval requests</p>"},{"location":"api-reference/agents/#execute_tool","title":"execute_tool()","text":"<p>Execute a specific tool.</p> <pre><code>def execute_tool(\n    self, \n    tool_name: str, \n    tool_input: Dict[str, Any],\n    platform_context: Dict[str, Any]\n) -&gt; str\n</code></pre>"},{"location":"api-reference/agents/#create_tool_call_for_approval","title":"create_tool_call_for_approval()","text":"<p>Create a <code>ToolCall</code> object for user approval.</p> <pre><code>def create_tool_call_for_approval(\n    self,\n    tool_name: str,\n    tool_input: Dict[str, Any],\n    tool_use_id: str\n) -&gt; ToolCall\n</code></pre>"},{"location":"api-reference/agents/#process_approved_tool_calls","title":"process_approved_tool_calls()","text":"<p>Process approved tools from incoming messages.</p> <pre><code>def process_approved_tool_calls(\n    self,\n    messages: Dict[str, List[Dict[str, Any]]],\n    platform_context: Dict[str, Any]\n) -&gt; List[ExecutedToolCall]\n</code></pre>"},{"location":"api-reference/agents/#process_tool_calls","title":"process_tool_calls()","text":"<p>Process tool calls from LLM response.</p> <pre><code>def process_tool_calls(\n    self,\n    response_content: List[Dict[str, Any]],\n    platform_context: Dict[str, Any]\n) -&gt; tuple[List[ExecutedToolCall], List[ToolCall]]\n</code></pre> <p>Returns: - <code>executed</code>: Tools that ran immediately - <code>approval_needed</code>: Tools requiring user approval</p>"},{"location":"api-reference/agents/#preprocess_messages","title":"preprocess_messages()","text":"<p>Convert input messages to LLM format with context injection.</p> <pre><code>def preprocess_messages(\n    self,\n    messages: Dict[str, List[Dict[str, Any]]]\n) -&gt; List[Dict[str, Any]]\n</code></pre>"},{"location":"api-reference/agents/#complete-example","title":"Complete Example","text":"<pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.tools import tool\nfrom dcaf.agent_server import create_chat_app\nimport uvicorn\nimport dotenv\n\ndotenv.load_dotenv()\n\n# Define tools\n@tool(\n    schema={\n        \"name\": \"get_weather\",\n        \"description\": \"Get current weather for a location\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"City and state, e.g., 'San Francisco, CA'\"\n                },\n                \"unit\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"celsius\", \"fahrenheit\"],\n                    \"default\": \"fahrenheit\"\n                }\n            },\n            \"required\": [\"location\"]\n        }\n    },\n    requires_approval=False\n)\ndef get_weather(location: str, unit: str = \"fahrenheit\") -&gt; str:\n    # Simulated weather\n    return f\"The weather in {location} is 72\u00b0{unit[0].upper()}, sunny\"\n\n@tool(\n    schema={\n        \"name\": \"send_notification\",\n        \"description\": \"Send a notification to a user\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"user\": {\"type\": \"string\", \"description\": \"Username\"},\n                \"message\": {\"type\": \"string\", \"description\": \"Notification message\"}\n            },\n            \"required\": [\"user\", \"message\"]\n        }\n    },\n    requires_approval=True  # Requires user approval\n)\ndef send_notification(user: str, message: str) -&gt; str:\n    return f\"Notification sent to {user}: {message}\"\n\n# Create agent\nllm = BedrockLLM(region_name=\"us-east-1\")\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[get_weather, send_notification],\n    system_prompt=\"\"\"You are a helpful assistant.\n    Use tools when appropriate to help the user.\"\"\",\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_iterations=10\n)\n\n# Create and run server\napp = create_chat_app(agent)\nuvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"api-reference/agents/#tool-execution-flow","title":"Tool Execution Flow","text":"<pre><code>User Message\n    \u2502\n    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 preprocess_messages\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 process_approved  \u2502\u25c4\u2500\u2500\u2510\n\u2502 _tool_calls       \u2502   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n          \u2502             \u2502\n          \u25bc             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   LLM.invoke()    \u2502   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n          \u2502             \u2502\n          \u25bc             \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n    \u2502Tool Calls?\u2502       \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n          \u2502             \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n    \u2502           \u2502       \u2502\n    \u25bc           \u25bc       \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502Execute\u2502  \u2502Approval\u2502   \u2502\n\u2502 Auto  \u2502  \u2502Required\u2502   \u2502\n\u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518   \u2502\n    \u2502           \u2502       \u2502\n    \u25bc           \u25bc       \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502Add to \u2502  \u2502 Return \u2502   \u2502\n\u2502Context\u2502  \u2502ToolCall\u2502   \u2502\n\u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n    \u2502                   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502\n          \u25bc (after approval)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Return Response  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/agents/#toolcallingcmdagent","title":"ToolCallingCmdAgent","text":"<p>Agent with built-in terminal command support and example tools.</p> <pre><code>class ToolCallingCmdAgent(AgentProtocol):\n    def __init__(self, llm: BedrockLLM)\n</code></pre>"},{"location":"api-reference/agents/#built-in-tools","title":"Built-in Tools","text":"Tool Description <code>get_weather</code> Get weather for a location <code>get_stock_price</code> Get stock price for a ticker <code>get_current_time</code> Get current date and time <code>return_final_response_to_user</code> Return structured response with commands"},{"location":"api-reference/agents/#example","title":"Example","text":"<pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.agents import ToolCallingCmdAgent\nfrom dcaf.agent_server import create_chat_app\n\nllm = BedrockLLM()\nagent = ToolCallingCmdAgent(llm)\napp = create_chat_app(agent)\n</code></pre>"},{"location":"api-reference/agents/#other-agents","title":"Other Agents","text":""},{"location":"api-reference/agents/#echoagent","title":"EchoAgent","text":"<p>Simple agent that echoes back user messages. Useful for testing.</p> <pre><code>from dcaf.agents.echo_agent import EchoAgent\nfrom dcaf.agent_server import create_chat_app\n\nagent = EchoAgent()\napp = create_chat_app(agent)\n\n# Test\n# Input: {\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]}\n# Output: {\"role\": \"assistant\", \"content\": \"Echo: Hello!\"}\n</code></pre>"},{"location":"api-reference/agents/#llmpassthroughagent","title":"LLMPassthroughAgent","text":"<p>Direct passthrough to LLM without tool support.</p> <pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.agents.llm_passthrough_agent import LLMPassthroughAgent\n\nllm = BedrockLLM()\nagent = LLMPassthroughAgent(llm)\n</code></pre>"},{"location":"api-reference/agents/#boilerplateagent","title":"BoilerplateAgent","text":"<p>Template for creating custom agents.</p> <pre><code>from dcaf.agents.boilerplate_agent import BoilerplateAgent\nfrom dcaf.schemas.messages import AgentMessage\n\nclass MyAgent(BoilerplateAgent):\n    def invoke(self, messages):\n        # Your custom logic here\n        return AgentMessage(content=\"Custom response\")\n</code></pre>"},{"location":"api-reference/agents/#awsagent","title":"AWSAgent","text":"<p>Agent specialized for AWS CLI operations.</p> <pre><code>from dcaf.agents.aws_agent import AWSAgent\nfrom dcaf.llm import BedrockLLM\n\nllm = BedrockLLM()\nagent = AWSAgent(\n    llm=llm,\n    system_prompt=\"Custom AWS assistant prompt\"  # Optional\n)\n</code></pre> <p>Features: - AWS CLI command suggestions - Command approval workflow - Structured response schema - DuploCloud context awareness</p>"},{"location":"api-reference/agents/#k8sagent","title":"K8sAgent","text":"<p>Agent specialized for Kubernetes and Helm operations.</p> <pre><code>from dcaf.agents.k8s_agent import K8sAgent\nfrom dcaf.llm import BedrockLLM\n\nllm = BedrockLLM()\nagent = K8sAgent(llm)\n</code></pre> <p>Features: - kubectl command suggestions - Helm chart creation - Docker Compose to Helm conversion - Service rollback support - Kubeconfig handling (base64 encoded) - File creation for commands</p>"},{"location":"api-reference/agents/#commandagent","title":"CommandAgent","text":"<p>General-purpose terminal command agent.</p> <pre><code>from dcaf.agents.cmd_agent import CommandAgent\nfrom dcaf.llm import BedrockLLM\n\nllm = BedrockLLM()\nagent = CommandAgent(\n    llm=llm,\n    system_prompt=\"Custom terminal assistant\"  # Optional\n)\n</code></pre>"},{"location":"api-reference/agents/#creating-custom-agents","title":"Creating Custom Agents","text":""},{"location":"api-reference/agents/#method-1-implement-agentprotocol","title":"Method 1: Implement AgentProtocol","text":"<pre><code>from dcaf.agent_server import AgentProtocol\nfrom dcaf.schemas.messages import AgentMessage, Data, ToolCall\nfrom typing import Dict, Any, List\n\nclass MyCustomAgent(AgentProtocol):\n    \"\"\"Custom agent implementation.\"\"\"\n\n    def __init__(self, config: dict = None):\n        self.config = config or {}\n\n    def invoke(\n        self, \n        messages: Dict[str, List[Dict[str, Any]]]\n    ) -&gt; AgentMessage:\n        # Extract messages\n        messages_list = messages.get(\"messages\", [])\n\n        # Get last user message\n        last_user = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            None\n        )\n\n        if not last_user:\n            return AgentMessage(content=\"No message received\")\n\n        user_content = last_user.get(\"content\", \"\")\n\n        # Your custom logic here\n        response = self.process_message(user_content)\n\n        return AgentMessage(content=response)\n\n    def process_message(self, content: str) -&gt; str:\n        # Custom processing\n        return f\"Processed: {content}\"\n</code></pre>"},{"location":"api-reference/agents/#method-2-extend-boilerplateagent","title":"Method 2: Extend BoilerplateAgent","text":"<pre><code>from dcaf.agents.boilerplate_agent import BoilerplateAgent\nfrom dcaf.schemas.messages import AgentMessage\n\nclass SmartBoilerplate(BoilerplateAgent):\n    def __init__(self, name: str = \"Bot\"):\n        self.name = name\n\n    def invoke(self, messages):\n        messages_list = messages.get(\"messages\", [])\n\n        # Count messages\n        user_msgs = sum(1 for m in messages_list if m.get(\"role\") == \"user\")\n\n        return AgentMessage(\n            content=f\"Hello! I'm {self.name}. \"\n                   f\"You've sent {user_msgs} message(s) so far.\"\n        )\n</code></pre>"},{"location":"api-reference/agents/#method-3-extend-toolcallingagent","title":"Method 3: Extend ToolCallingAgent","text":"<pre><code>from dcaf.agents.tool_calling_agent import ToolCallingAgent\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.tools import tool\nfrom dcaf.schemas.messages import AgentMessage\n\nclass EnhancedToolAgent(ToolCallingAgent):\n    \"\"\"ToolCallingAgent with custom pre/post processing.\"\"\"\n\n    def __init__(self, llm: BedrockLLM, **kwargs):\n        # Create custom tools\n        my_tools = self.create_tools()\n        super().__init__(llm=llm, tools=my_tools, **kwargs)\n\n    def create_tools(self):\n        @tool(\n            schema={\n                \"name\": \"custom_action\",\n                \"description\": \"Perform custom action\",\n                \"input_schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"action\": {\"type\": \"string\"}\n                    },\n                    \"required\": [\"action\"]\n                }\n            }\n        )\n        def custom_action(action: str) -&gt; str:\n            return f\"Performed: {action}\"\n\n        return [custom_action]\n\n    def invoke(self, messages):\n        # Pre-processing\n        self.log_request(messages)\n\n        # Call parent implementation\n        response = super().invoke(messages)\n\n        # Post-processing\n        self.log_response(response)\n\n        return response\n\n    def log_request(self, messages):\n        print(f\"Received {len(messages.get('messages', []))} messages\")\n\n    def log_response(self, response):\n        print(f\"Responding with: {response.content[:50]}...\")\n</code></pre>"},{"location":"api-reference/agents/#examples","title":"Examples","text":""},{"location":"api-reference/agents/#example-1-simple-qa-agent","title":"Example 1: Simple Q&amp;A Agent","text":"<pre><code>from dcaf.agent_server import AgentProtocol, create_chat_app\nfrom dcaf.schemas.messages import AgentMessage\nimport uvicorn\n\nclass QAAgent(AgentProtocol):\n    \"\"\"Simple Q&amp;A agent with predefined answers.\"\"\"\n\n    def __init__(self):\n        self.answers = {\n            \"what is dcaf\": \"DCAF is the DuploCloud Agent Framework\",\n            \"who made dcaf\": \"DCAF was created by DuploCloud\",\n            \"how do i use dcaf\": \"See the documentation at docs/index.md\"\n        }\n\n    def invoke(self, messages):\n        messages_list = messages.get(\"messages\", [])\n        last_user = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            {\"content\": \"\"}\n        )\n\n        question = last_user.get(\"content\", \"\").lower().strip(\"?\")\n\n        # Find matching answer\n        for key, answer in self.answers.items():\n            if key in question:\n                return AgentMessage(content=answer)\n\n        return AgentMessage(\n            content=\"I don't know the answer to that. \"\n                   \"Try asking about DCAF!\"\n        )\n\nagent = QAAgent()\napp = create_chat_app(agent)\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, port=8000)\n</code></pre>"},{"location":"api-reference/agents/#example-2-stateful-agent","title":"Example 2: Stateful Agent","text":"<pre><code>from dcaf.agent_server import AgentProtocol, create_chat_app\nfrom dcaf.schemas.messages import AgentMessage\nfrom collections import defaultdict\nimport uvicorn\n\nclass StatefulAgent(AgentProtocol):\n    \"\"\"Agent that maintains state across requests.\"\"\"\n\n    def __init__(self):\n        self.user_data = defaultdict(dict)\n\n    def invoke(self, messages):\n        messages_list = messages.get(\"messages\", [])\n\n        # Get user from platform context\n        last_user_msg = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            {}\n        )\n        platform_context = last_user_msg.get(\"platform_context\", {})\n        user_id = platform_context.get(\"user_id\", \"anonymous\")\n\n        content = last_user_msg.get(\"content\", \"\")\n\n        # Track interaction count\n        if \"count\" not in self.user_data[user_id]:\n            self.user_data[user_id][\"count\"] = 0\n        self.user_data[user_id][\"count\"] += 1\n\n        count = self.user_data[user_id][\"count\"]\n\n        return AgentMessage(\n            content=f\"Hello {user_id}! This is interaction #{count}. \"\n                   f\"You said: {content}\"\n        )\n\nagent = StatefulAgent()\napp = create_chat_app(agent)\n</code></pre>"},{"location":"api-reference/agents/#example-3-multi-tool-agent","title":"Example 3: Multi-Tool Agent","text":"<pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.tools import tool\nfrom dcaf.agent_server import create_chat_app\nimport dotenv\n\ndotenv.load_dotenv()\n\n# Define multiple tools\n@tool(\n    schema={\n        \"name\": \"search_products\",\n        \"description\": \"Search for products in the catalog\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\"type\": \"string\"},\n                \"category\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"electronics\", \"clothing\", \"home\", \"all\"]\n                },\n                \"max_results\": {\"type\": \"integer\", \"default\": 5}\n            },\n            \"required\": [\"query\"]\n        }\n    },\n    requires_approval=False\n)\ndef search_products(query: str, category: str = \"all\", max_results: int = 5) -&gt; str:\n    return f\"Found {max_results} products for '{query}' in {category}\"\n\n@tool(\n    schema={\n        \"name\": \"add_to_cart\",\n        \"description\": \"Add a product to the shopping cart\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"product_id\": {\"type\": \"string\"},\n                \"quantity\": {\"type\": \"integer\", \"minimum\": 1}\n            },\n            \"required\": [\"product_id\", \"quantity\"]\n        }\n    },\n    requires_approval=True  # Requires confirmation\n)\ndef add_to_cart(product_id: str, quantity: int, platform_context: dict) -&gt; str:\n    user = platform_context.get(\"user_id\", \"guest\")\n    return f\"Added {quantity}x {product_id} to {user}'s cart\"\n\n@tool(\n    schema={\n        \"name\": \"checkout\",\n        \"description\": \"Process checkout for the cart\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"payment_method\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"credit_card\", \"paypal\", \"bank_transfer\"]\n                }\n            },\n            \"required\": [\"payment_method\"]\n        }\n    },\n    requires_approval=True\n)\ndef checkout(payment_method: str, platform_context: dict) -&gt; str:\n    user = platform_context.get(\"user_id\", \"guest\")\n    return f\"Checkout completed for {user} via {payment_method}\"\n\n# Create agent\nllm = BedrockLLM()\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[search_products, add_to_cart, checkout],\n    system_prompt=\"\"\"You are a helpful shopping assistant.\n    Help users find products, add them to cart, and checkout.\n    Always confirm before adding to cart or checking out.\"\"\"\n)\n\napp = create_chat_app(agent)\n</code></pre>"},{"location":"api-reference/agents/#see-also","title":"See Also","text":"<ul> <li>Agent Server API Reference</li> <li>Tools API Reference</li> <li>Creating Custom Agents Guide</li> <li>Schemas API Reference</li> </ul>"},{"location":"api-reference/channel-routing/","title":"Channel Routing API Reference","text":"<p>The Channel Routing module provides intelligent routing for different messaging channels, determining when agents should respond to messages.</p>"},{"location":"api-reference/channel-routing/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>ChannelResponseRouter</li> <li>SlackResponseRouter</li> <li>Configuration</li> <li>Examples</li> </ol>"},{"location":"api-reference/channel-routing/#overview","title":"Overview","text":"<p>Channel routing helps agents make intelligent decisions about when to respond in multi-party conversations. This is particularly useful for:</p> <ul> <li>Slack threads with multiple participants</li> <li>Multi-agent systems where different agents handle different topics</li> <li>Smart filtering to avoid responding to off-topic messages</li> </ul>"},{"location":"api-reference/channel-routing/#import","title":"Import","text":"<pre><code>from dcaf.channel_routing import SlackResponseRouter, ChannelResponseRouter\n\n# Or from the core module\nfrom dcaf.core import SlackResponseRouter, ChannelResponseRouter\n\n# Or from the top-level module\nfrom dcaf import SlackResponseRouter\n</code></pre>"},{"location":"api-reference/channel-routing/#channelresponserouter","title":"ChannelResponseRouter","text":"<p>Base class for channel-specific routers.</p> <pre><code>class ChannelResponseRouter:\n    \"\"\"\n    Generic class which will be inherited by subclasses for various channel routers.\n    \"\"\"\n\n    def should_agent_respond(self):\n        \"\"\"Determine if the agent should respond.\"\"\"\n        pass\n</code></pre>"},{"location":"api-reference/channel-routing/#extending-the-base-class","title":"Extending the Base Class","text":"<pre><code>from dcaf.channel_routing import ChannelResponseRouter\nfrom dcaf.llm import BedrockLLM\n\nclass CustomRouter(ChannelResponseRouter):\n    def __init__(self, llm: BedrockLLM):\n        self.llm = llm\n\n    def should_agent_respond(self, messages: list) -&gt; dict:\n        # Custom routing logic\n        return {\n            \"should_respond\": True,\n            \"reasoning\": \"Custom routing decision\"\n        }\n</code></pre>"},{"location":"api-reference/channel-routing/#slackresponserouter","title":"SlackResponseRouter","text":"<p>Router that determines whether an agent should respond in Slack threads.</p>"},{"location":"api-reference/channel-routing/#class-definition","title":"Class Definition","text":"<pre><code>class SlackResponseRouter(ChannelResponseRouter):\n    \"\"\"\n    A router that decides whether a bot should respond to Slack messages.\n\n    This class uses an LLM to analyze conversation context and determine if\n    the bot should engage or remain silent based on the conversation flow.\n    \"\"\"\n</code></pre>"},{"location":"api-reference/channel-routing/#constructor","title":"Constructor","text":"<pre><code>def __init__(\n    self, \n    llm_client: BedrockLLM, \n    agent_name: str = \"Assistant\", \n    agent_description: str = \"\",\n    model_id: str = None\n)\n</code></pre>"},{"location":"api-reference/channel-routing/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>llm_client</code> <code>BedrockLLM</code> Required LLM client for routing decisions <code>agent_name</code> <code>str</code> <code>\"Assistant\"</code> Name of the agent <code>agent_description</code> <code>str</code> <code>\"\"</code> Description of the agent's capabilities <code>model_id</code> <code>str</code> <code>None</code> Model ID (defaults to Claude Haiku)"},{"location":"api-reference/channel-routing/#attributes","title":"Attributes","text":"Attribute Type Description <code>llm_client</code> <code>BedrockLLM</code> LLM client <code>agent_name</code> <code>str</code> Agent name <code>agent_description</code> <code>str</code> Agent description <code>model_id</code> <code>str</code> Model for routing decisions"},{"location":"api-reference/channel-routing/#methods","title":"Methods","text":""},{"location":"api-reference/channel-routing/#should_agent_respond","title":"should_agent_respond()","text":"<p>Determine if the agent should respond to the latest message.</p> <pre><code>def should_agent_respond(\n    self,\n    slack_thread: str\n) -&gt; dict\n</code></pre>"},{"location":"api-reference/channel-routing/#parameters_1","title":"Parameters","text":"Parameter Type Description <code>slack_thread</code> <code>str</code> Complete Slack thread conversation"},{"location":"api-reference/channel-routing/#returns","title":"Returns","text":"<pre><code>{\n    \"should_respond\": bool,  # True if agent should respond\n    \"reasoning\": str         # Brief explanation\n}\n</code></pre>"},{"location":"api-reference/channel-routing/#decision-criteria","title":"Decision Criteria","text":"<p>RESPOND when: - Bot is directly mentioned (@BotName) - User asks for clarification on agent's previous response - User reports an error with agent's suggestion - Follow-up request (\"also can you...\", \"now do...\") - Contains question words directed at agent - Direct question immediately after agent responded - Someone asks a direct question the bot can help with</p> <p>REMAIN SILENT when: - Just acknowledgment (\"thanks\", \"got it\", \"ok\") - Shifts to different topic outside agent's domain - Tags a different agent (@other-agent) - Conversation between humans - Off-topic chitchat - Personal/private discussion - Topic outside bot's expertise</p> <p>Default: When in doubt, REMAIN SILENT</p>"},{"location":"api-reference/channel-routing/#configuration","title":"Configuration","text":""},{"location":"api-reference/channel-routing/#creating-a-router","title":"Creating a Router","text":"<pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.channel_routing import SlackResponseRouter\n\n# Create LLM client\nllm = BedrockLLM(region_name=\"us-east-1\")\n\n# Create router with description\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"K8sBot\",\n    agent_description=\"\"\"\n    K8sBot is a Kubernetes and DevOps assistant that helps with:\n    - Kubernetes troubleshooting and management\n    - Helm chart creation and deployment\n    - Docker and container issues\n    - DuploCloud platform operations\n    \"\"\",\n    model_id=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\"  # Fast model\n)\n</code></pre>"},{"location":"api-reference/channel-routing/#using-with-core-api-serve-create_app","title":"Using with Core API (<code>serve()</code> / <code>create_app()</code>)","text":"<p>The recommended way to use channel routing with DCAF Core agents:</p> <pre><code>from dcaf.core import Agent, serve, SlackResponseRouter\nfrom dcaf.llm import BedrockLLM\n\nagent = Agent(\n    tools=[...],\n    system_prompt=\"You are a Kubernetes assistant.\",\n)\n\nllm = BedrockLLM()\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"k8s-agent\",\n    agent_description=\"Kubernetes and container orchestration specialist\",\n)\n\n# Pass channel_router to serve()\nserve(agent, channel_router=router, port=8000)\n</code></pre> <p>Or with <code>create_app()</code> for programmatic control:</p> <pre><code>from dcaf.core import Agent, create_app, SlackResponseRouter\nfrom dcaf.llm import BedrockLLM\nimport uvicorn\n\nagent = Agent(tools=[...])\nllm = BedrockLLM()\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"k8s-agent\",\n    agent_description=\"Kubernetes specialist\",\n)\n\napp = create_app(agent, channel_router=router)\nuvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"api-reference/channel-routing/#using-with-agent-server-legacy","title":"Using with Agent Server (Legacy)","text":"<pre><code>from dcaf.agent_server import create_chat_app\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.channel_routing import SlackResponseRouter\n\n# Create components\nllm = BedrockLLM()\nagent = ToolCallingAgent(llm=llm, tools=[...], system_prompt=\"...\")\n\n# Create router\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"HelpBot\",\n    agent_description=\"A general-purpose help assistant\"\n)\n\n# Create app with router\napp = create_chat_app(agent, router=router)\n</code></pre>"},{"location":"api-reference/channel-routing/#request-format-for-slack","title":"Request Format for Slack","text":"<pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Can someone help with this deployment issue?\",\n            \"user\": {\"name\": \"alice\", \"id\": \"U123\"}\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"I can help! What's the error message?\",\n            \"agent\": {\"name\": \"HelpBot\", \"id\": \"B456\"}\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"@charlie can you check the logs?\",\n            \"user\": {\"name\": \"bob\", \"id\": \"U789\"}\n        }\n    ],\n    \"source\": \"slack\"\n}\n</code></pre>"},{"location":"api-reference/channel-routing/#examples","title":"Examples","text":""},{"location":"api-reference/channel-routing/#example-1-basic-slack-router","title":"Example 1: Basic Slack Router","text":"<pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.channel_routing import SlackResponseRouter\n\nllm = BedrockLLM()\n\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"SupportBot\",\n    agent_description=\"Technical support assistant\"\n)\n\n# Test with a thread\nthread = \"\"\"\n[alice]: Hey team, anyone know how to fix this Kubernetes error?\n[SupportBot]: I can help! What's the error message?\n[alice]: Thanks!\n\"\"\"\n\nresult = router.should_agent_respond(thread)\nprint(f\"Should respond: {result['should_respond']}\")\nprint(f\"Reasoning: {result['reasoning']}\")\n# Should respond: False (just a \"thanks\" acknowledgment)\n</code></pre>"},{"location":"api-reference/channel-routing/#example-2-multi-agent-routing","title":"Example 2: Multi-Agent Routing","text":"<pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.channel_routing import SlackResponseRouter\n\nllm = BedrockLLM()\n\n# Create specialized routers\nk8s_router = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"K8sBot\",\n    agent_description=\"Kubernetes and container orchestration specialist\"\n)\n\naws_router = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"AWSBot\",\n    agent_description=\"AWS cloud infrastructure specialist\"\n)\n\n# Test with a thread\nthread = \"\"\"\n[user1]: My pods keep crashing with OOMKilled\n[K8sBot]: This usually means your containers are running out of memory. \n         Try increasing the memory limits in your deployment.\n[user1]: Actually, I think this might be an AWS issue with the node\n\"\"\"\n\n# Check each router\nk8s_result = k8s_router.should_agent_respond(thread)\naws_result = aws_router.should_agent_respond(thread)\n\nprint(f\"K8sBot should respond: {k8s_result['should_respond']}\")\nprint(f\"AWSBot should respond: {aws_result['should_respond']}\")\n</code></pre>"},{"location":"api-reference/channel-routing/#example-3-full-server-integration-core-api","title":"Example 3: Full Server Integration (Core API)","text":"<pre><code>from dcaf.core import Agent, serve, SlackResponseRouter\nfrom dcaf.tools import tool\nfrom dcaf.llm import BedrockLLM\n\n# Create tools\n@tool(description=\"Check the status of Kubernetes pods\")\ndef check_pod_status(namespace: str = \"default\") -&gt; str:\n    return f\"All pods in {namespace} are running\"\n\n# Create agent\nagent = Agent(\n    tools=[check_pod_status],\n    system_prompt=\"You are K8sBot, a Kubernetes expert.\",\n)\n\n# Create router\nllm = BedrockLLM()\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"K8sBot\",\n    agent_description=\"\"\"\n    K8sBot specializes in:\n    - Kubernetes troubleshooting\n    - Pod and deployment management\n    - Container orchestration\n    - kubectl commands\n    \"\"\",\n)\n\n# Serve with channel routing\nif __name__ == \"__main__\":\n    serve(agent, channel_router=router, port=8000)\n</code></pre>"},{"location":"api-reference/channel-routing/#example-3b-full-server-integration-legacy-api","title":"Example 3b: Full Server Integration (Legacy API)","text":"<pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.tools import tool\nfrom dcaf.channel_routing import SlackResponseRouter\nfrom dcaf.agent_server import create_chat_app\nimport uvicorn\n\n# Create LLM\nllm = BedrockLLM()\n\n# Create tools\n@tool(\n    schema={\n        \"name\": \"check_pod_status\",\n        \"description\": \"Check the status of Kubernetes pods\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"namespace\": {\"type\": \"string\"}\n            },\n            \"required\": [\"namespace\"]\n        }\n    },\n    requires_approval=False\n)\ndef check_pod_status(namespace: str) -&gt; str:\n    return f\"All pods in {namespace} are running\"\n\n# Create agent\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[check_pod_status],\n    system_prompt=\"You are K8sBot, a Kubernetes expert.\"\n)\n\n# Create router\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"K8sBot\",\n    agent_description=\"\"\"\n    K8sBot specializes in:\n    - Kubernetes troubleshooting\n    - Pod and deployment management\n    - Container orchestration\n    - kubectl commands\n    \"\"\"\n)\n\n# Create app with router\napp = create_chat_app(agent, router=router)\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, port=8000)\n</code></pre>"},{"location":"api-reference/channel-routing/#example-4-testing-router-decisions","title":"Example 4: Testing Router Decisions","text":"<pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.channel_routing import SlackResponseRouter\n\nllm = BedrockLLM()\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"HelpBot\",\n    agent_description=\"General help assistant\"\n)\n\n# Test cases\ntest_threads = [\n    # Should respond - direct mention\n    (\"\"\"\n    [alice]: @HelpBot can you help with this?\n    \"\"\", True),\n\n    # Should respond - follow-up question\n    (\"\"\"\n    [alice]: How do I deploy to production?\n    [HelpBot]: You can use kubectl apply -f deploy.yaml\n    [alice]: What namespace should I use?\n    \"\"\", True),\n\n    # Should NOT respond - acknowledgment\n    (\"\"\"\n    [alice]: Help me with deployment\n    [HelpBot]: Here's the command: kubectl apply...\n    [alice]: Thanks!\n    \"\"\", False),\n\n    # Should NOT respond - different agent mentioned\n    (\"\"\"\n    [alice]: @OtherBot can you check the logs?\n    \"\"\", False),\n\n    # Should NOT respond - off-topic\n    (\"\"\"\n    [alice]: Anyone want to grab lunch?\n    [bob]: Sure, let's go!\n    \"\"\", False),\n]\n\nprint(\"Router Decision Tests\")\nprint(\"=\" * 50)\n\nfor thread, expected in test_threads:\n    result = router.should_agent_respond(thread)\n    status = \"\u2713\" if result[\"should_respond\"] == expected else \"\u2717\"\n    print(f\"{status} Expected: {expected}, Got: {result['should_respond']}\")\n    if result[\"should_respond\"] != expected:\n        print(f\"   Reasoning: {result['reasoning']}\")\n</code></pre>"},{"location":"api-reference/channel-routing/#example-5-custom-router-implementation","title":"Example 5: Custom Router Implementation","text":"<pre><code>from dcaf.channel_routing import ChannelResponseRouter\nfrom dcaf.llm import BedrockLLM\nimport re\n\nclass KeywordRouter(ChannelResponseRouter):\n    \"\"\"\n    Simple keyword-based router that doesn't use LLM.\n    \"\"\"\n\n    def __init__(self, agent_name: str, keywords: list):\n        self.agent_name = agent_name\n        self.keywords = keywords\n\n    def should_agent_respond(self, messages: list) -&gt; dict:\n        # Get last user message\n        last_user = next(\n            (m for m in reversed(messages) if m.get(\"role\") == \"user\"),\n            None\n        )\n\n        if not last_user:\n            return {\"should_respond\": False, \"reasoning\": \"No user message\"}\n\n        content = last_user.get(\"content\", \"\").lower()\n\n        # Check for direct mention\n        if f\"@{self.agent_name.lower()}\" in content:\n            return {\n                \"should_respond\": True,\n                \"reasoning\": \"Direct mention\"\n            }\n\n        # Check for keywords\n        for keyword in self.keywords:\n            if keyword.lower() in content:\n                return {\n                    \"should_respond\": True,\n                    \"reasoning\": f\"Matched keyword: {keyword}\"\n                }\n\n        return {\n            \"should_respond\": False,\n            \"reasoning\": \"No matching keywords\"\n        }\n\n# Usage\nrouter = KeywordRouter(\n    agent_name=\"K8sBot\",\n    keywords=[\"kubernetes\", \"kubectl\", \"pod\", \"deployment\", \"k8s\"]\n)\n\n# Test\nmessages = [\n    {\"role\": \"user\", \"content\": \"My kubernetes pods are failing\"}\n]\n\nresult = router.should_agent_respond(messages)\nprint(result)\n# {'should_respond': True, 'reasoning': 'Matched keyword: kubernetes'}\n</code></pre>"},{"location":"api-reference/channel-routing/#see-also","title":"See Also","text":"<ul> <li>Core Server \u2014 Channel Routing - Using channel routing with <code>serve()</code> and <code>create_app()</code></li> <li>Agent Server API Reference</li> <li>Agents API Reference</li> <li>BedrockLLM API Reference</li> </ul>"},{"location":"api-reference/cli/","title":"CLI API Reference","text":"<p>The DCAF Command Line Interface provides utilities for managing AWS credentials, Docker images, and agent deployments.</p>"},{"location":"api-reference/cli/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Installation</li> <li>Commands</li> <li>Environment Variables</li> <li>Examples</li> </ol>"},{"location":"api-reference/cli/#overview","title":"Overview","text":"<p>The <code>dcaf</code> CLI provides tools for:</p> <ul> <li>AWS credential management - Update <code>.env</code> files with fresh credentials</li> <li>Docker builds - Build and push images to Amazon ECR</li> <li>Agent deployment - Deploy agents to DuploCloud (coming soon)</li> </ul>"},{"location":"api-reference/cli/#installation","title":"Installation","text":"<p>When you install DCAF, the CLI is automatically available:</p> <pre><code># Install DCAF\npip install git+https://github.com/duplocloud/service-desk-agents.git\n\n# Verify installation\ndcaf --help\n</code></pre>"},{"location":"api-reference/cli/#installation_1","title":"Installation","text":""},{"location":"api-reference/cli/#requirements","title":"Requirements","text":"<ul> <li>Python 3.9+</li> <li>AWS CLI (for ECR commands)</li> <li>Docker (for build/push commands)</li> <li>duplo-jit (for DuploCloud credential management)</li> </ul>"},{"location":"api-reference/cli/#installing-duplo-jit","title":"Installing duplo-jit","text":"<pre><code># See DuploCloud documentation for installation\n# https://docs.duplocloud.com/docs/overview/use-cases/jit-access\n</code></pre>"},{"location":"api-reference/cli/#commands","title":"Commands","text":""},{"location":"api-reference/cli/#dcaf-help","title":"dcaf --help","text":"<p>Display available commands.</p> <pre><code>dcaf --help\n</code></pre> <p>Output: <pre><code>usage: dcaf [-h] {env-update-aws-creds,docker-build-push-ecr,deploy-agent} ...\n\nDuploCloud Agent Builder CLI\n\npositional arguments:\n  {env-update-aws-creds,docker-build-push-ecr,deploy-agent}\n                        Available commands\n\noptional arguments:\n  -h, --help            show this help message and exit\n</code></pre></p>"},{"location":"api-reference/cli/#dcaf-env-update-aws-creds","title":"dcaf env-update-aws-creds","text":"<p>Update AWS credentials in the <code>.env</code> file using DuploCloud JIT access.</p> <pre><code>dcaf env-update-aws-creds [--tenant TENANT] [--host HOST]\n</code></pre>"},{"location":"api-reference/cli/#options","title":"Options","text":"Option Environment Variable Description <code>--tenant</code> <code>DUPLO_TENANT</code> DuploCloud tenant name <code>--host</code> <code>DUPLO_HOST</code> DuploCloud host URL"},{"location":"api-reference/cli/#behavior","title":"Behavior","text":"<ol> <li>Calls <code>duplo-jit aws</code> to fetch temporary credentials</li> <li>Parses the JSON response</li> <li>Updates or creates <code>.env</code> file with:</li> <li><code>AWS_ACCESS_KEY_ID</code></li> <li><code>AWS_SECRET_ACCESS_KEY</code></li> <li><code>AWS_SESSION_TOKEN</code></li> </ol>"},{"location":"api-reference/cli/#requirements_1","title":"Requirements","text":"<ul> <li><code>duplo-jit</code> must be installed and configured</li> <li>Interactive authentication may be required</li> </ul>"},{"location":"api-reference/cli/#examples","title":"Examples","text":"<pre><code># Using command line arguments\ndcaf env-update-aws-creds --tenant=my-tenant --host=https://my-duplo.duplocloud.net\n\n# Using environment variables\nexport DUPLO_TENANT=my-tenant\nexport DUPLO_HOST=https://my-duplo.duplocloud.net\ndcaf env-update-aws-creds\n\n# Mixed usage (env vars with override)\nexport DUPLO_HOST=https://my-duplo.duplocloud.net\ndcaf env-update-aws-creds --tenant=different-tenant\n</code></pre>"},{"location":"api-reference/cli/#output","title":"Output","text":"<pre><code>Using tenant: my-tenant\nUsing host: https://my-duplo.duplocloud.net\nFetching AWS credentials using duplo-jit...\nUpdating existing .env file...\n\u2705 AWS credentials updated in /path/to/project/.env\n\u26a0\ufe0f  Make sure .env is in your .gitignore!\n</code></pre>"},{"location":"api-reference/cli/#error-handling","title":"Error Handling","text":"<pre><code># Missing tenant\nError: Tenant not specified. Set DUPLO_TENANT env var or use --tenant flag\n\n# Missing host\nError: Host not specified. Set DUPLO_HOST env var or use --host flag\n\n# duplo-jit not installed\nError: duplo-jit is not installed or not in PATH\nPlease install duplo-jit: https://docs.duplocloud.com/docs/overview/use-cases/jit-access\n</code></pre>"},{"location":"api-reference/cli/#dcaf-docker-build-push-ecr","title":"dcaf docker-build-push-ecr","text":"<p>Build a Docker image and push it to Amazon ECR.</p> <pre><code>dcaf docker-build-push-ecr TAG [--repo-name NAME] [--registry URI] [--aws-profile PROFILE] [--region REGION] [--dockerfile PATH]\n</code></pre>"},{"location":"api-reference/cli/#arguments","title":"Arguments","text":"Argument Required Description <code>TAG</code> Yes Image tag (e.g., <code>latest</code>, <code>v1.0.0</code>)"},{"location":"api-reference/cli/#options_1","title":"Options","text":"Option Environment Variable Default Description <code>--repo-name</code> <code>ECR_REPOSITORY_NAME</code> - ECR repository name <code>--registry</code> <code>ECR_REGISTRY</code> - ECR registry URI <code>--aws-profile</code> - - AWS profile to use <code>--region</code> <code>AWS_DEFAULT_REGION</code> <code>us-east-1</code> AWS region <code>--dockerfile</code> - <code>Dockerfile</code> Path to Dockerfile"},{"location":"api-reference/cli/#steps","title":"Steps","text":"<ol> <li>Authenticate - <code>aws ecr get-login-password | docker login</code></li> <li>Build - <code>docker build -t repo:tag -f Dockerfile .</code></li> <li>Tag - <code>docker tag repo:tag registry/repo:tag</code></li> <li>Push - <code>docker push registry/repo:tag</code></li> </ol>"},{"location":"api-reference/cli/#requirements_2","title":"Requirements","text":"<ul> <li>Docker installed and running</li> <li>AWS CLI configured</li> <li>ECR repository exists</li> </ul>"},{"location":"api-reference/cli/#examples_1","title":"Examples","text":"<pre><code># Using all command line arguments\ndcaf docker-build-push-ecr v1.0.0 \\\n  --repo-name=my-agent \\\n  --registry=123456789012.dkr.ecr.us-east-1.amazonaws.com \\\n  --region=us-east-1\n\n# Using environment variables\nexport ECR_REPOSITORY_NAME=my-agent\nexport ECR_REGISTRY=123456789012.dkr.ecr.us-east-1.amazonaws.com\nexport AWS_DEFAULT_REGION=us-east-1\ndcaf docker-build-push-ecr latest\n\n# With AWS profile\ndcaf docker-build-push-ecr v2.0.0 \\\n  --repo-name=my-agent \\\n  --registry=123456789012.dkr.ecr.us-east-1.amazonaws.com \\\n  --aws-profile=production\n\n# Custom Dockerfile\ndcaf docker-build-push-ecr latest \\\n  --repo-name=my-agent \\\n  --registry=123456789012.dkr.ecr.us-east-1.amazonaws.com \\\n  --dockerfile=Dockerfile.prod\n</code></pre>"},{"location":"api-reference/cli/#output_1","title":"Output","text":"<pre><code>[1/4] Authenticating Docker to ECR registry...\nRunning: aws ecr get-login-password --region us-east-1  | docker login --username AWS --password-stdin 123456789012.dkr.ecr.us-east-1.amazonaws.com\n\u2713 Successfully authenticated to ECR\n\n[2/4] Building Docker image...\nRunning: docker build -t my-agent:v1.0.0 -f Dockerfile .\n\u2713 Successfully built my-agent:v1.0.0\n\n[3/4] Tagging image for ECR...\nRunning: docker tag my-agent:v1.0.0 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-agent:v1.0.0\n\u2713 Tagged as 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-agent:v1.0.0\n\n[4/4] Pushing to ECR...\nRunning: docker push 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-agent:v1.0.0\n\n\u2705 Successfully pushed 123456789012.dkr.ecr.us-east-1.amazonaws.com/my-agent:v1.0.0\n</code></pre>"},{"location":"api-reference/cli/#dcaf-deploy-agent","title":"dcaf deploy-agent","text":"<p>Deploy an agent to DuploCloud.</p> <pre><code>dcaf deploy-agent AGENT_NAME [--token TOKEN]\n</code></pre> <p>Note: This command is not yet fully implemented.</p>"},{"location":"api-reference/cli/#arguments_1","title":"Arguments","text":"Argument Required Description <code>AGENT_NAME</code> Yes Name of the agent to deploy"},{"location":"api-reference/cli/#options_2","title":"Options","text":"Option Environment Variable Description <code>--token</code> <code>DUPLO_TOKEN</code> DuploCloud API token"},{"location":"api-reference/cli/#example","title":"Example","text":"<pre><code>dcaf deploy-agent my-k8s-agent --token=eyJ...\n</code></pre>"},{"location":"api-reference/cli/#environment-variables","title":"Environment Variables","text":""},{"location":"api-reference/cli/#summary","title":"Summary","text":"Variable Command Description <code>DUPLO_TENANT</code> <code>env-update-aws-creds</code> DuploCloud tenant name <code>DUPLO_HOST</code> <code>env-update-aws-creds</code> DuploCloud host URL <code>DUPLO_TOKEN</code> <code>deploy-agent</code> DuploCloud API token <code>ECR_REPOSITORY_NAME</code> <code>docker-build-push-ecr</code> ECR repository name <code>ECR_REGISTRY</code> <code>docker-build-push-ecr</code> ECR registry URI <code>AWS_DEFAULT_REGION</code> <code>docker-build-push-ecr</code> AWS region"},{"location":"api-reference/cli/#example-env-file","title":"Example .env File","text":"<pre><code># DuploCloud Configuration\nDUPLO_HOST=https://my-duplo.duplocloud.net\nDUPLO_TENANT=production\nDUPLO_TOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\n\n# AWS Configuration (auto-updated by dcaf env-update-aws-creds)\nAWS_ACCESS_KEY_ID=\"AKIAIOSFODNN7EXAMPLE\"\nAWS_SECRET_ACCESS_KEY=\"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"\nAWS_SESSION_TOKEN=\"FwoGZXIvYXdzEBY...\"\nAWS_DEFAULT_REGION=us-east-1\n\n# ECR Configuration\nECR_REPOSITORY_NAME=my-agent\nECR_REGISTRY=123456789012.dkr.ecr.us-east-1.amazonaws.com\n\n# Bedrock Configuration\nBEDROCK_MODEL_ID=us.anthropic.claude-3-5-sonnet-20240620-v1:0\n</code></pre>"},{"location":"api-reference/cli/#examples_2","title":"Examples","text":""},{"location":"api-reference/cli/#example-1-complete-deployment-workflow","title":"Example 1: Complete Deployment Workflow","text":"<pre><code>#!/bin/bash\n# deploy.sh - Complete deployment script\n\nset -e\n\n# Load environment\nsource .env\n\n# 1. Refresh AWS credentials\necho \"Refreshing AWS credentials...\"\ndcaf env-update-aws-creds \\\n  --tenant=$DUPLO_TENANT \\\n  --host=$DUPLO_HOST\n\n# Reload .env with new credentials\nsource .env\n\n# 2. Build and push Docker image\nVERSION=$(git describe --tags --always)\necho \"Building version: $VERSION\"\n\ndcaf docker-build-push-ecr $VERSION \\\n  --repo-name=$ECR_REPOSITORY_NAME \\\n  --registry=$ECR_REGISTRY \\\n  --region=$AWS_DEFAULT_REGION\n\n# 3. Deploy (when implemented)\n# dcaf deploy-agent my-agent --token=$DUPLO_TOKEN\n\necho \"Deployment complete!\"\n</code></pre>"},{"location":"api-reference/cli/#example-2-cicd-integration","title":"Example 2: CI/CD Integration","text":"<pre><code># .github/workflows/deploy.yml\nname: Deploy Agent\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.11'\n\n      - name: Install DCAF\n        run: pip install git+https://github.com/duplocloud/service-desk-agents.git\n\n      - name: Configure AWS\n        uses: aws-actions/configure-aws-credentials@v2\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: us-east-1\n\n      - name: Build and Push\n        env:\n          ECR_REPOSITORY_NAME: my-agent\n          ECR_REGISTRY: ${{ secrets.ECR_REGISTRY }}\n        run: |\n          VERSION=${GITHUB_REF#refs/tags/}\n          dcaf docker-build-push-ecr $VERSION\n</code></pre>"},{"location":"api-reference/cli/#example-3-local-development-workflow","title":"Example 3: Local Development Workflow","text":"<pre><code># Terminal 1: Set up credentials\nexport DUPLO_HOST=https://dev.duplocloud.net\nexport DUPLO_TENANT=dev-tenant\ndcaf env-update-aws-creds\n\n# Terminal 2: Run the agent locally\nsource .env\npython main.py\n\n# Terminal 3: Test the agent\ncurl -X POST http://localhost:8000/api/sendMessage \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]}'\n</code></pre>"},{"location":"api-reference/cli/#example-4-multi-environment-setup","title":"Example 4: Multi-Environment Setup","text":"<pre><code># .env.development\nDUPLO_HOST=https://dev.duplocloud.net\nDUPLO_TENANT=dev-tenant\nECR_REGISTRY=123456789012.dkr.ecr.us-east-1.amazonaws.com\nECR_REPOSITORY_NAME=my-agent-dev\n\n# .env.production\nDUPLO_HOST=https://prod.duplocloud.net\nDUPLO_TENANT=prod-tenant\nECR_REGISTRY=123456789012.dkr.ecr.us-east-1.amazonaws.com\nECR_REPOSITORY_NAME=my-agent-prod\n\n# Deploy to development\ncp .env.development .env\ndcaf env-update-aws-creds\ndcaf docker-build-push-ecr dev-$(git rev-parse --short HEAD)\n\n# Deploy to production\ncp .env.production .env\ndcaf env-update-aws-creds\ndcaf docker-build-push-ecr $(git describe --tags)\n</code></pre>"},{"location":"api-reference/cli/#troubleshooting","title":"Troubleshooting","text":""},{"location":"api-reference/cli/#duplo-jit-not-found","title":"duplo-jit Not Found","text":"<pre><code>Error: duplo-jit is not installed or not in PATH\n</code></pre> <p>Solution: 1. Install duplo-jit from DuploCloud documentation 2. Ensure it's in your PATH: <code>which duplo-jit</code></p>"},{"location":"api-reference/cli/#docker-not-running","title":"Docker Not Running","text":"<pre><code>Error: Docker is not installed or not in PATH\n</code></pre> <p>Solution: 1. Install Docker: https://docs.docker.com/get-docker/ 2. Start Docker daemon 3. Verify: <code>docker --version</code></p>"},{"location":"api-reference/cli/#ecr-authentication-failed","title":"ECR Authentication Failed","text":"<pre><code>Error authenticating to ECR: ...\n</code></pre> <p>Solution: 1. Verify AWS credentials are valid 2. Check ECR repository exists 3. Ensure IAM permissions include <code>ecr:GetAuthorizationToken</code></p>"},{"location":"api-reference/cli/#credential-parsing-error","title":"Credential Parsing Error","text":"<pre><code>Error parsing duplo-jit output: ...\n</code></pre> <p>Solution: 1. Ensure duplo-jit is properly configured 2. Try running <code>duplo-jit aws --tenant=xxx --host=xxx</code> directly 3. Check for authentication issues</p>"},{"location":"api-reference/cli/#see-also","title":"See Also","text":"<ul> <li>Getting Started</li> <li>DuploCloud JIT Access Documentation</li> <li>AWS ECR User Guide</li> </ul>"},{"location":"api-reference/llm/","title":"BedrockLLM API Reference (Legacy)","text":"<p>Legacy API</p> <p>This documents the v1 API. For new projects, use the Core API which handles LLM configuration internally.</p> <p>See Migration Guide to upgrade existing code.</p> <p>The <code>BedrockLLM</code> class provides a unified interface for interacting with AWS Bedrock models using the Converse API. It handles message formatting, tool configuration, and response processing.</p>"},{"location":"api-reference/llm/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Class: BedrockLLM</li> <li>Methods</li> <li>Message Formats</li> <li>Tool Configuration</li> <li>Configuration Options</li> <li>Examples</li> <li>Error Handling</li> </ol>"},{"location":"api-reference/llm/#overview","title":"Overview","text":"<p><code>BedrockLLM</code> wraps the AWS Bedrock Converse API, providing:</p> <ul> <li>Consistent interface across all Bedrock-supported models</li> <li>Automatic message normalization (role alternation)</li> <li>Tool schema formatting</li> <li>Streaming support</li> <li>Configurable timeouts and retries</li> </ul>"},{"location":"api-reference/llm/#import","title":"Import","text":"<pre><code>from dcaf.llm import BedrockLLM\n\n# Or from the base module\nfrom dcaf import BedrockLLM\n</code></pre>"},{"location":"api-reference/llm/#class-bedrockllm","title":"Class: BedrockLLM","text":"<pre><code>class BedrockLLM(LLM):\n    \"\"\"\n    A class for interacting with AWS Bedrock LLMs using the Converse API.\n    Provides consistent interface across all Bedrock models.\n    \"\"\"\n</code></pre>"},{"location":"api-reference/llm/#constructor","title":"Constructor","text":"<pre><code>def __init__(\n    self,\n    region_name: str = 'us-east-1',\n    boto3_config: Optional[Config] = None\n)\n</code></pre>"},{"location":"api-reference/llm/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>region_name</code> <code>str</code> <code>'us-east-1'</code> AWS region for Bedrock service <code>boto3_config</code> <code>Optional[Config]</code> <code>None</code> Custom boto3 configuration"},{"location":"api-reference/llm/#configuration-priority","title":"Configuration Priority","text":"<ol> <li>Explicit <code>boto3_config</code> - Full control, overrides everything</li> <li>Environment Variables - Deployment-time configuration</li> <li>Defaults - Sensible out-of-the-box settings</li> </ol>"},{"location":"api-reference/llm/#environment-variables","title":"Environment Variables","text":"<p>When <code>boto3_config=None</code>, these environment variables are used:</p> Variable Default Description <code>BOTO3_READ_TIMEOUT</code> <code>20</code> Read timeout in seconds <code>BOTO3_CONNECT_TIMEOUT</code> <code>10</code> Connect timeout in seconds <code>BOTO3_MAX_ATTEMPTS</code> <code>3</code> Maximum retry attempts <code>BOTO3_RETRY_MODE</code> <code>standard</code> Retry mode (<code>standard</code>, <code>adaptive</code>, <code>legacy</code>)"},{"location":"api-reference/llm/#examples","title":"Examples","text":"<pre><code># 1. Using defaults\nllm = BedrockLLM()\n\n# 2. Specify region\nllm = BedrockLLM(region_name=\"us-west-2\")\n\n# 3. Using environment variables\n# export BOTO3_READ_TIMEOUT=30\n# export BOTO3_MAX_ATTEMPTS=5\nllm = BedrockLLM()  # Picks up env vars\n\n# 4. Custom boto3 config (takes precedence)\nfrom botocore.config import Config\n\ncustom_config = Config(\n    read_timeout=60,\n    connect_timeout=15,\n    retries={\n        'max_attempts': 5,\n        'mode': 'adaptive'\n    }\n)\nllm = BedrockLLM(boto3_config=custom_config)\n</code></pre>"},{"location":"api-reference/llm/#methods","title":"Methods","text":""},{"location":"api-reference/llm/#invoke","title":"invoke()","text":"<p>Invoke the LLM and get a complete response.</p> <pre><code>def invoke(\n    self,\n    messages: List[Dict[str, Any]],\n    model_id: str,\n    max_tokens: int = 1000,\n    temperature: float = 0.0,\n    top_p: float = 0.9,\n    system_prompt: Optional[str] = None,\n    tools: Optional[List[Dict[str, Any]]] = None,\n    tool_choice: Optional[Union[str, Dict[str, Any]]] = None,\n    additional_model_request_fields: Optional[Dict[str, Any]] = None,\n    performance_config: Optional[Dict[str, str]] = None,\n    **kwargs\n) -&gt; Dict[str, Any]\n</code></pre>"},{"location":"api-reference/llm/#parameters_1","title":"Parameters","text":"Parameter Type Required Description <code>messages</code> <code>List[Dict]</code> Yes Conversation messages <code>model_id</code> <code>str</code> Yes Bedrock model ID <code>max_tokens</code> <code>int</code> No Maximum tokens to generate (default: 1000) <code>temperature</code> <code>float</code> No Sampling temperature 0-1 (default: 0.0) <code>top_p</code> <code>float</code> No Nucleus sampling parameter (default: 0.9) <code>system_prompt</code> <code>str</code> No System prompt for model behavior <code>tools</code> <code>List[Dict]</code> No Tool specifications <code>tool_choice</code> <code>str|Dict</code> No Tool choice strategy <code>additional_model_request_fields</code> <code>Dict</code> No Model-specific parameters <code>performance_config</code> <code>Dict</code> No Performance settings"},{"location":"api-reference/llm/#returns","title":"Returns","text":"<p>Returns the raw Converse API response:</p> <pre><code>{\n    \"output\": {\n        \"message\": {\n            \"role\": \"assistant\",\n            \"content\": [\n                {\"text\": \"Response text...\"},\n                # Or tool use blocks\n                {\n                    \"toolUse\": {\n                        \"toolUseId\": \"unique-id\",\n                        \"name\": \"tool_name\",\n                        \"input\": {...}\n                    }\n                }\n            ]\n        }\n    },\n    \"stopReason\": \"end_turn|tool_use|max_tokens\",\n    \"usage\": {\n        \"inputTokens\": 100,\n        \"outputTokens\": 50\n    }\n}\n</code></pre>"},{"location":"api-reference/llm/#example","title":"Example","text":"<pre><code># Simple invocation\nresponse = llm.invoke(\n    messages=[\n        {\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms\"}\n    ],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_tokens=500,\n    temperature=0.7\n)\n\n# Extract text response\ntext = response['output']['message']['content'][0]['text']\nprint(text)\n</code></pre>"},{"location":"api-reference/llm/#invoke_stream","title":"invoke_stream()","text":"<p>Stream responses from the LLM.</p> <pre><code>def invoke_stream(\n    self,\n    messages: list,\n    model_id: str,\n    system_prompt: Optional[str] = None,\n    tools: Optional[list] = None,\n    max_tokens: int = 1000,\n    temperature: float = 0.0,\n    additional_params: Optional[Dict[str, Any]] = None\n) -&gt; Generator[Dict, None, None]\n</code></pre>"},{"location":"api-reference/llm/#parameters_2","title":"Parameters","text":"Parameter Type Required Description <code>messages</code> <code>list</code> Yes Messages in Converse format <code>model_id</code> <code>str</code> Yes Bedrock model ID <code>system_prompt</code> <code>str</code> No System prompt <code>tools</code> <code>list</code> No Tool configurations <code>max_tokens</code> <code>int</code> No Maximum tokens (default: 1000) <code>temperature</code> <code>float</code> No Temperature (default: 0.0) <code>additional_params</code> <code>Dict</code> No Additional inference config"},{"location":"api-reference/llm/#yields","title":"Yields","text":"<p>Raw event dictionaries from the Bedrock stream:</p> <pre><code># Text delta event\n{\"contentBlockDelta\": {\"delta\": {\"text\": \"Hello\"}}}\n\n# Content block start\n{\"contentBlockStart\": {...}}\n\n# Message complete\n{\"messageStop\": {\"stopReason\": \"end_turn\"}}\n</code></pre>"},{"location":"api-reference/llm/#example_1","title":"Example","text":"<pre><code># Streaming response\nfor event in llm.invoke_stream(\n    messages=[{\"role\": \"user\", \"content\": \"Tell me a story\"}],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_tokens=500\n):\n    if \"contentBlockDelta\" in event:\n        delta = event[\"contentBlockDelta\"].get(\"delta\", {})\n        if \"text\" in delta:\n            print(delta[\"text\"], end=\"\", flush=True)\n</code></pre>"},{"location":"api-reference/llm/#normalize_message_roles","title":"normalize_message_roles()","text":"<p>Normalize messages to ensure proper role alternation.</p> <pre><code>def normalize_message_roles(\n    self,\n    messages: List[Dict[str, Any]]\n) -&gt; List[Dict[str, Any]]\n</code></pre>"},{"location":"api-reference/llm/#purpose","title":"Purpose","text":"<p>Bedrock's Converse API requires strict role alternation between 'user' and 'assistant'. This method:</p> <ul> <li>Merges consecutive messages with the same role</li> <li>Removes empty messages</li> <li>Handles both string and list content formats</li> </ul>"},{"location":"api-reference/llm/#example_2","title":"Example","text":"<pre><code># Input: Consecutive user messages\nmessages = [\n    {\"role\": \"user\", \"content\": \"Hello\"},\n    {\"role\": \"user\", \"content\": \"How are you?\"},  # Same role!\n    {\"role\": \"assistant\", \"content\": \"Hi there!\"},\n    {\"role\": \"user\", \"content\": \"Great!\"}\n]\n\n# After normalization\nnormalized = llm.normalize_message_roles(messages)\n# [\n#     {\"role\": \"user\", \"content\": \"Hello\\nHow are you?\"},  # Merged\n#     {\"role\": \"assistant\", \"content\": \"Hi there!\"},\n#     {\"role\": \"user\", \"content\": \"Great!\"}\n# ]\n</code></pre>"},{"location":"api-reference/llm/#message-formats","title":"Message Formats","text":""},{"location":"api-reference/llm/#simple-string-content","title":"Simple String Content","text":"<pre><code>messages = [\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n    {\"role\": \"assistant\", \"content\": \"I'm doing well, thanks!\"},\n    {\"role\": \"user\", \"content\": \"Great to hear!\"}\n]\n</code></pre>"},{"location":"api-reference/llm/#list-content-multiple-blocks","title":"List Content (Multiple Blocks)","text":"<pre><code>messages = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"text\": \"Look at this image:\"},\n            {\"image\": {\"format\": \"png\", \"source\": {\"bytes\": b\"...\"}}}\n        ]\n    }\n]\n</code></pre>"},{"location":"api-reference/llm/#tool-results","title":"Tool Results","text":"<pre><code>messages = [\n    {\"role\": \"user\", \"content\": \"What's the weather in NYC?\"},\n    {\n        \"role\": \"assistant\",\n        \"content\": [\n            {\n                \"toolUse\": {\n                    \"toolUseId\": \"tool123\",\n                    \"name\": \"get_weather\",\n                    \"input\": {\"location\": \"New York, NY\"}\n                }\n            }\n        ]\n    },\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\n                \"toolResult\": {\n                    \"toolUseId\": \"tool123\",\n                    \"content\": [{\"text\": \"72\u00b0F, sunny\"}]\n                }\n            }\n        ]\n    }\n]\n</code></pre>"},{"location":"api-reference/llm/#tool-configuration","title":"Tool Configuration","text":""},{"location":"api-reference/llm/#tool-schema-format","title":"Tool Schema Format","text":"<pre><code>tools = [\n    {\n        \"name\": \"get_weather\",\n        \"description\": \"Get the current weather for a location\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"City and state, e.g., San Francisco, CA\"\n                },\n                \"unit\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"celsius\", \"fahrenheit\"],\n                    \"description\": \"Temperature unit\"\n                }\n            },\n            \"required\": [\"location\"]\n        }\n    }\n]\n</code></pre>"},{"location":"api-reference/llm/#tool-choice-options","title":"Tool Choice Options","text":"<pre><code># Auto (default) - Model decides whether to use tools\nresponse = llm.invoke(messages=..., tools=tools, tool_choice=\"auto\")\n\n# Any - Model must use at least one tool\nresponse = llm.invoke(messages=..., tools=tools, tool_choice=\"any\")\n\n# Specific tool - Force use of a specific tool\nresponse = llm.invoke(\n    messages=..., \n    tools=tools, \n    tool_choice={\"type\": \"tool\", \"name\": \"get_weather\"}\n)\n</code></pre>"},{"location":"api-reference/llm/#complete-tool-example","title":"Complete Tool Example","text":"<pre><code>from dcaf.llm import BedrockLLM\n\nllm = BedrockLLM()\n\n# Define tools\ntools = [\n    {\n        \"name\": \"get_stock_price\",\n        \"description\": \"Get the current stock price for a ticker symbol\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"ticker\": {\n                    \"type\": \"string\",\n                    \"description\": \"Stock ticker symbol (e.g., AAPL)\"\n                }\n            },\n            \"required\": [\"ticker\"]\n        }\n    }\n]\n\n# Invoke with tools\nresponse = llm.invoke(\n    messages=[{\"role\": \"user\", \"content\": \"What's Apple's stock price?\"}],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    system_prompt=\"You are a financial assistant.\",\n    tools=tools\n)\n\n# Check if model wants to use a tool\ncontent = response['output']['message']['content']\nfor block in content:\n    if 'toolUse' in block:\n        tool_use = block['toolUse']\n        print(f\"Tool: {tool_use['name']}\")\n        print(f\"Input: {tool_use['input']}\")\n</code></pre>"},{"location":"api-reference/llm/#configuration-options","title":"Configuration Options","text":""},{"location":"api-reference/llm/#performance-configuration","title":"Performance Configuration","text":"<pre><code># Optimize for latency\nresponse = llm.invoke(\n    messages=...,\n    model_id=...,\n    performance_config={\"latency\": \"optimized\"}\n)\n</code></pre>"},{"location":"api-reference/llm/#additional-model-fields","title":"Additional Model Fields","text":"<p>For model-specific parameters:</p> <pre><code># Anthropic-specific parameters\nresponse = llm.invoke(\n    messages=...,\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    additional_model_request_fields={\n        \"anthropic_version\": \"bedrock-2023-05-31\"\n    }\n)\n</code></pre>"},{"location":"api-reference/llm/#examples_1","title":"Examples","text":""},{"location":"api-reference/llm/#basic-chat","title":"Basic Chat","text":"<pre><code>from dcaf.llm import BedrockLLM\n\nllm = BedrockLLM(region_name=\"us-east-1\")\n\nresponse = llm.invoke(\n    messages=[\n        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n    ],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_tokens=200,\n    temperature=0\n)\n\n# Extract response text\ntext = response['output']['message']['content'][0]['text']\nprint(text)  # \"The capital of France is Paris.\"\n</code></pre>"},{"location":"api-reference/llm/#multi-turn-conversation","title":"Multi-Turn Conversation","text":"<pre><code>conversation = [\n    {\"role\": \"user\", \"content\": \"My name is Alice.\"},\n    {\"role\": \"assistant\", \"content\": \"Nice to meet you, Alice!\"},\n    {\"role\": \"user\", \"content\": \"What is my name?\"}\n]\n\nresponse = llm.invoke(\n    messages=conversation,\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    system_prompt=\"You are a helpful assistant with a good memory.\"\n)\n\n# \"Your name is Alice!\"\n</code></pre>"},{"location":"api-reference/llm/#with-system-prompt","title":"With System Prompt","text":"<pre><code>response = llm.invoke(\n    messages=[{\"role\": \"user\", \"content\": \"Explain photosynthesis\"}],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    system_prompt=\"\"\"You are a biology teacher for 5th graders. \n    Explain concepts using simple language and fun analogies.\"\"\",\n    max_tokens=500\n)\n</code></pre>"},{"location":"api-reference/llm/#streaming-chat","title":"Streaming Chat","text":"<pre><code>import sys\n\n# Stream a long response\nfor event in llm.invoke_stream(\n    messages=[{\"role\": \"user\", \"content\": \"Write a haiku about coding\"}],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_tokens=100\n):\n    if \"contentBlockDelta\" in event:\n        text = event[\"contentBlockDelta\"].get(\"delta\", {}).get(\"text\", \"\")\n        sys.stdout.write(text)\n        sys.stdout.flush()\n</code></pre>"},{"location":"api-reference/llm/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/llm/#common-exceptions","title":"Common Exceptions","text":"<pre><code>from botocore.exceptions import ClientError\n\ntry:\n    response = llm.invoke(\n        messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n        model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n    )\nexcept ClientError as e:\n    error_code = e.response['Error']['Code']\n\n    if error_code == 'ExpiredTokenException':\n        print(\"AWS credentials expired. Refresh them.\")\n    elif error_code == 'ResourceNotFoundException':\n        print(\"Model not found. Check model ID and region.\")\n    elif error_code == 'ThrottlingException':\n        print(\"Rate limited. Implement backoff.\")\n    elif error_code == 'ValidationException':\n        print(\"Invalid request. Check message format.\")\n    else:\n        print(f\"Error: {e}\")\n</code></pre>"},{"location":"api-reference/llm/#retry-configuration","title":"Retry Configuration","text":"<pre><code>from botocore.config import Config\n\n# Aggressive retry for production\nconfig = Config(\n    retries={\n        'max_attempts': 10,\n        'mode': 'adaptive'  # Smart backoff\n    }\n)\n\nllm = BedrockLLM(boto3_config=config)\n</code></pre>"},{"location":"api-reference/llm/#model-ids","title":"Model IDs","text":""},{"location":"api-reference/llm/#common-bedrock-model-ids","title":"Common Bedrock Model IDs","text":"Model ID Claude 3.5 Sonnet <code>us.anthropic.claude-3-5-sonnet-20240620-v1:0</code> Claude 3 Sonnet <code>us.anthropic.claude-3-sonnet-20240229-v1:0</code> Claude 3 Haiku <code>us.anthropic.claude-3-5-haiku-20241022-v1:0</code> Claude 3 Opus <code>us.anthropic.claude-opus-4-20250514-v1:0</code>"},{"location":"api-reference/llm/#cross-region-inference","title":"Cross-Region Inference","text":"<p>Use the <code>us.</code> prefix for cross-region inference profiles:</p> <pre><code># Cross-region (recommended)\nmodel_id = \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n\n# Single region\nmodel_id = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n</code></pre>"},{"location":"api-reference/llm/#see-also","title":"See Also","text":"<ul> <li>Tools API Reference</li> <li>Agents API Reference</li> <li>Working with AWS Bedrock Guide</li> <li>AWS Bedrock Converse API Documentation</li> </ul>"},{"location":"api-reference/schemas/","title":"Schemas API Reference","text":"<p>The Schemas module defines the data models used throughout DCAF for message handling, tool calls, commands, and events.</p>"},{"location":"api-reference/schemas/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Message Schemas</li> <li>Data Schemas</li> <li>Event Schemas</li> <li>Context Schemas</li> <li>Examples</li> </ol>"},{"location":"api-reference/schemas/#overview","title":"Overview","text":"<p>DCAF uses Pydantic models for type-safe data handling. All schemas are located in:</p> <ul> <li><code>dcaf/schemas/messages.py</code> - Message and data models</li> <li><code>dcaf/schemas/events.py</code> - Streaming event models</li> </ul>"},{"location":"api-reference/schemas/#import","title":"Import","text":"<pre><code>from dcaf.schemas.messages import (\n    AgentMessage,\n    Messages,\n    Message,\n    UserMessage,\n    Data,\n    ToolCall,\n    ExecutedToolCall,\n    Command,\n    ExecutedCommand,\n    PlatformContext\n)\n\nfrom dcaf.schemas.events import (\n    TextDeltaEvent,\n    ToolCallsEvent,\n    ExecutedToolCallsEvent,\n    CommandsEvent,\n    ExecutedCommandsEvent,\n    DoneEvent,\n    ErrorEvent\n)\n</code></pre>"},{"location":"api-reference/schemas/#message-schemas","title":"Message Schemas","text":""},{"location":"api-reference/schemas/#messages","title":"Messages","text":"<p>Container for a list of messages.</p> <pre><code>class Messages(BaseModel):\n    messages: List[Union[UserMessage, AgentMessage]]\n</code></pre>"},{"location":"api-reference/schemas/#example","title":"Example","text":"<pre><code>from dcaf.schemas.messages import Messages, UserMessage\n\nmsgs = Messages(messages=[\n    UserMessage(role=\"user\", content=\"Hello!\"),\n    AgentMessage(role=\"assistant\", content=\"Hi there!\")\n])\n</code></pre>"},{"location":"api-reference/schemas/#message","title":"Message","text":"<p>Base message model.</p> <pre><code>class Message(BaseModel):\n    role: Literal[\"user\", \"assistant\"]\n    content: str = \"\"\n    data: Data = Field(default_factory=Data)\n    meta_data: Dict[str, Any] = Field(default_factory=dict)\n    timestamp: Optional[datetime] = None\n    user: Optional[User] = None\n    agent: Optional[Agent] = None\n</code></pre>"},{"location":"api-reference/schemas/#fields","title":"Fields","text":"Field Type Default Description <code>role</code> <code>\"user\"</code> | <code>\"assistant\"</code> Required Message sender role <code>content</code> <code>str</code> <code>\"\"</code> Message text content <code>data</code> <code>Data</code> <code>Data()</code> Associated data payload <code>meta_data</code> <code>Dict</code> <code>{}</code> Additional metadata <code>timestamp</code> <code>datetime</code> <code>None</code> Message timestamp <code>user</code> <code>User</code> <code>None</code> User information <code>agent</code> <code>Agent</code> <code>None</code> Agent information"},{"location":"api-reference/schemas/#usermessage","title":"UserMessage","text":"<p>Message from a user.</p> <pre><code>class UserMessage(Message):\n    role: Literal[\"user\"] = \"user\"\n    platform_context: Optional[PlatformContext] = None\n    ambient_context: Optional[AmbientContext] = None\n</code></pre>"},{"location":"api-reference/schemas/#additional-fields","title":"Additional Fields","text":"Field Type Description <code>platform_context</code> <code>PlatformContext</code> Runtime platform context <code>ambient_context</code> <code>AmbientContext</code> Ambient user context"},{"location":"api-reference/schemas/#example_1","title":"Example","text":"<pre><code>from dcaf.schemas.messages import UserMessage, PlatformContext\n\nuser_msg = UserMessage(\n    content=\"Deploy my application\",\n    platform_context=PlatformContext(\n        tenant_name=\"production\",\n        k8s_namespace=\"my-app\"\n    )\n)\n</code></pre>"},{"location":"api-reference/schemas/#agentmessage","title":"AgentMessage","text":"<p>Response message from an agent.</p> <pre><code>class AgentMessage(Message):\n    role: Literal[\"assistant\"] = \"assistant\"\n</code></pre>"},{"location":"api-reference/schemas/#example_2","title":"Example","text":"<pre><code>from dcaf.schemas.messages import AgentMessage, Data, Command\n\nresponse = AgentMessage(\n    content=\"I'll help you deploy. Please approve the command below.\",\n    data=Data(\n        cmds=[\n            Command(command=\"kubectl apply -f deployment.yaml\")\n        ]\n    )\n)\n</code></pre>"},{"location":"api-reference/schemas/#user","title":"User","text":"<p>User identification.</p> <pre><code>class User(BaseModel):\n    name: str\n    id: str\n</code></pre>"},{"location":"api-reference/schemas/#agent","title":"Agent","text":"<p>Agent identification.</p> <pre><code>class Agent(BaseModel):\n    name: str\n    id: str\n</code></pre>"},{"location":"api-reference/schemas/#data-schemas","title":"Data Schemas","text":""},{"location":"api-reference/schemas/#data","title":"Data","text":"<p>Container for all data associated with a message.</p> <pre><code>class Data(BaseModel):\n    cmds: List[Command] = Field(default_factory=list)\n    executed_cmds: List[ExecutedCommand] = Field(default_factory=list)\n    tool_calls: List[ToolCall] = Field(default_factory=list)\n    executed_tool_calls: List[ExecutedToolCall] = Field(default_factory=list)\n    url_configs: List[URLConfig] = Field(default_factory=list)\n</code></pre>"},{"location":"api-reference/schemas/#fields_1","title":"Fields","text":"Field Type Description <code>cmds</code> <code>List[Command]</code> Suggested terminal commands <code>executed_cmds</code> <code>List[ExecutedCommand]</code> Commands that were executed <code>tool_calls</code> <code>List[ToolCall]</code> Tools requiring approval <code>executed_tool_calls</code> <code>List[ExecutedToolCall]</code> Tools that were executed <code>url_configs</code> <code>List[URLConfig]</code> URL configurations"},{"location":"api-reference/schemas/#command","title":"Command","text":"<p>A suggested terminal command.</p> <pre><code>class Command(BaseModel):\n    command: str\n    execute: bool = False\n    rejection_reason: Optional[str] = None\n    files: Optional[List[FileObject]] = None\n</code></pre>"},{"location":"api-reference/schemas/#fields_2","title":"Fields","text":"Field Type Default Description <code>command</code> <code>str</code> Required Command string to execute <code>execute</code> <code>bool</code> <code>False</code> Whether to execute (set by client) <code>rejection_reason</code> <code>str</code> <code>None</code> Reason for rejection <code>files</code> <code>List[FileObject]</code> <code>None</code> Files to create before command"},{"location":"api-reference/schemas/#example_3","title":"Example","text":"<pre><code>from dcaf.schemas.messages import Command, FileObject\n\ncmd = Command(\n    command=\"helm install my-app ./chart\",\n    files=[\n        FileObject(\n            file_path=\"chart/values.yaml\",\n            file_content=\"replicaCount: 3\\n...\"\n        )\n    ]\n)\n</code></pre>"},{"location":"api-reference/schemas/#executedcommand","title":"ExecutedCommand","text":"<p>A command that was executed.</p> <pre><code>class ExecutedCommand(BaseModel):\n    command: str\n    output: str\n</code></pre>"},{"location":"api-reference/schemas/#fields_3","title":"Fields","text":"Field Type Description <code>command</code> <code>str</code> The command that was executed <code>output</code> <code>str</code> Command output (stdout/stderr)"},{"location":"api-reference/schemas/#toolcall","title":"ToolCall","text":"<p>A tool call requiring user approval.</p> <pre><code>class ToolCall(BaseModel):\n    id: str\n    name: str\n    input: Dict[str, Any]\n    execute: bool = False\n    tool_description: str\n    input_description: Dict[str, Any]\n    intent: Optional[str] = None\n    rejection_reason: Optional[str] = None\n</code></pre>"},{"location":"api-reference/schemas/#fields_4","title":"Fields","text":"Field Type Default Description <code>id</code> <code>str</code> Required Unique tool use ID <code>name</code> <code>str</code> Required Tool name <code>input</code> <code>Dict</code> Required Tool input parameters <code>execute</code> <code>bool</code> <code>False</code> Whether to execute <code>tool_description</code> <code>str</code> Required Human-readable description <code>input_description</code> <code>Dict</code> Required Parameter descriptions <code>intent</code> <code>str</code> <code>None</code> Intent description <code>rejection_reason</code> <code>str</code> <code>None</code> Reason for rejection"},{"location":"api-reference/schemas/#example_4","title":"Example","text":"<pre><code>from dcaf.schemas.messages import ToolCall\n\ntool_call = ToolCall(\n    id=\"toolu_abc123\",\n    name=\"delete_file\",\n    input={\"path\": \"/tmp/old-file.txt\"},\n    tool_description=\"Delete a file from the filesystem\",\n    input_description={\n        \"path\": {\n            \"type\": \"string\",\n            \"description\": \"Path to the file to delete\"\n        }\n    },\n    intent=\"Remove temporary file\"\n)\n</code></pre>"},{"location":"api-reference/schemas/#executedtoolcall","title":"ExecutedToolCall","text":"<p>A tool that was executed.</p> <pre><code>class ExecutedToolCall(BaseModel):\n    id: str\n    name: str\n    input: Dict[str, Any]\n    output: str\n</code></pre>"},{"location":"api-reference/schemas/#fields_5","title":"Fields","text":"Field Type Description <code>id</code> <code>str</code> Tool use ID <code>name</code> <code>str</code> Tool name <code>input</code> <code>Dict</code> Input parameters used <code>output</code> <code>str</code> Tool output result"},{"location":"api-reference/schemas/#fileobject","title":"FileObject","text":"<p>A file to be created for command execution.</p> <pre><code>class FileObject(BaseModel):\n    file_path: str\n    file_content: str\n</code></pre>"},{"location":"api-reference/schemas/#urlconfig","title":"URLConfig","text":"<p>URL configuration for display.</p> <pre><code>class URLConfig(BaseModel):\n    url: HttpUrl\n    description: str\n</code></pre>"},{"location":"api-reference/schemas/#event-schemas","title":"Event Schemas","text":"<p>Events are used for streaming responses.</p>"},{"location":"api-reference/schemas/#streamevent-base","title":"StreamEvent (Base)","text":"<pre><code>class StreamEvent(BaseModel):\n    \"\"\"Base for all stream events. Type field discriminates.\"\"\"\n    type: str\n</code></pre>"},{"location":"api-reference/schemas/#textdeltaevent","title":"TextDeltaEvent","text":"<p>Streaming text tokens.</p> <pre><code>class TextDeltaEvent(StreamEvent):\n    type: Literal[\"text_delta\"] = \"text_delta\"\n    text: str\n</code></pre>"},{"location":"api-reference/schemas/#example_5","title":"Example","text":"<pre><code>{\"type\": \"text_delta\", \"text\": \"Hello\"}\n</code></pre>"},{"location":"api-reference/schemas/#toolcallsevent","title":"ToolCallsEvent","text":"<p>Tool calls requiring approval.</p> <pre><code>class ToolCallsEvent(StreamEvent):\n    type: Literal[\"tool_calls\"] = \"tool_calls\"\n    tool_calls: List[ToolCall]\n</code></pre>"},{"location":"api-reference/schemas/#example_6","title":"Example","text":"<pre><code>{\n    \"type\": \"tool_calls\",\n    \"tool_calls\": [\n        {\n            \"id\": \"toolu_123\",\n            \"name\": \"get_weather\",\n            \"input\": {\"location\": \"NYC\"},\n            \"execute\": false,\n            \"tool_description\": \"Get weather\",\n            \"input_description\": {}\n        }\n    ]\n}\n</code></pre>"},{"location":"api-reference/schemas/#executedtoolcallsevent","title":"ExecutedToolCallsEvent","text":"<p>Tools that were executed.</p> <pre><code>class ExecutedToolCallsEvent(StreamEvent):\n    type: Literal[\"executed_tool_calls\"] = \"executed_tool_calls\"\n    executed_tool_calls: List[ExecutedToolCall]\n</code></pre>"},{"location":"api-reference/schemas/#commandsevent","title":"CommandsEvent","text":"<p>Commands for approval.</p> <pre><code>class CommandsEvent(StreamEvent):\n    type: Literal[\"commands\"] = \"commands\"\n    commands: List[Command]\n</code></pre>"},{"location":"api-reference/schemas/#executedcommandsevent","title":"ExecutedCommandsEvent","text":"<p>Commands that were executed.</p> <pre><code>class ExecutedCommandsEvent(StreamEvent):\n    type: Literal[\"executed_commands\"] = \"executed_commands\"\n    executed_cmds: List[ExecutedCommand]\n</code></pre>"},{"location":"api-reference/schemas/#doneevent","title":"DoneEvent","text":"<p>Stream completed.</p> <pre><code>class DoneEvent(StreamEvent):\n    type: Literal[\"done\"] = \"done\"\n    stop_reason: Optional[str] = None\n</code></pre>"},{"location":"api-reference/schemas/#example_7","title":"Example","text":"<pre><code>{\"type\": \"done\", \"stop_reason\": \"end_turn\"}\n</code></pre>"},{"location":"api-reference/schemas/#errorevent","title":"ErrorEvent","text":"<p>Error during streaming.</p> <pre><code>class ErrorEvent(StreamEvent):\n    type: Literal[\"error\"] = \"error\"\n    error: str\n</code></pre>"},{"location":"api-reference/schemas/#example_8","title":"Example","text":"<pre><code>{\"type\": \"error\", \"error\": \"Connection timeout\"}\n</code></pre>"},{"location":"api-reference/schemas/#context-schemas","title":"Context Schemas","text":""},{"location":"api-reference/schemas/#platformcontext","title":"PlatformContext","text":"<p>Runtime context passed from the platform.</p> <pre><code>class PlatformContext(BaseModel):\n    k8s_namespace: Optional[str] = None\n    duplo_base_url: Optional[str] = None\n    duplo_token: Optional[str] = None\n    tenant_name: Optional[str] = None\n    aws_credentials: Optional[Dict[str, Any]] = None\n    kubeconfig: Optional[str] = None\n</code></pre>"},{"location":"api-reference/schemas/#fields_6","title":"Fields","text":"Field Type Description <code>k8s_namespace</code> <code>str</code> Kubernetes namespace <code>duplo_base_url</code> <code>str</code> DuploCloud API URL <code>duplo_token</code> <code>str</code> DuploCloud API token <code>tenant_name</code> <code>str</code> DuploCloud tenant name <code>aws_credentials</code> <code>Dict</code> AWS credential info <code>kubeconfig</code> <code>str</code> Base64-encoded kubeconfig"},{"location":"api-reference/schemas/#example_9","title":"Example","text":"<pre><code>from dcaf.schemas.messages import PlatformContext\n\ncontext = PlatformContext(\n    tenant_name=\"production\",\n    k8s_namespace=\"my-app-namespace\",\n    duplo_base_url=\"https://api.duplocloud.net\",\n    duplo_token=\"eyJ...\"\n)\n</code></pre>"},{"location":"api-reference/schemas/#ambientcontext","title":"AmbientContext","text":"<p>Ambient context from user environment.</p> <pre><code>class AmbientContext(BaseModel):\n    user_terminal_cmds: List[ExecutedCommand] = Field(default_factory=list)\n</code></pre>"},{"location":"api-reference/schemas/#examples","title":"Examples","text":""},{"location":"api-reference/schemas/#example-1-creating-a-complete-request","title":"Example 1: Creating a Complete Request","text":"<pre><code>from dcaf.schemas.messages import (\n    Messages, UserMessage, PlatformContext, Data, Command\n)\n\n# Create a user message with context and approved command\nrequest = Messages(\n    messages=[\n        UserMessage(\n            content=\"Deploy my app\",\n            platform_context=PlatformContext(\n                tenant_name=\"staging\",\n                k8s_namespace=\"my-app\"\n            ),\n            data=Data(\n                cmds=[\n                    Command(\n                        command=\"kubectl apply -f deploy.yaml\",\n                        execute=True  # User approved this command\n                    )\n                ]\n            )\n        )\n    ]\n)\n\n# Convert to dict for API call\nrequest_dict = request.model_dump()\n</code></pre>"},{"location":"api-reference/schemas/#example-2-parsing-agent-response","title":"Example 2: Parsing Agent Response","text":"<pre><code>from dcaf.schemas.messages import AgentMessage\nimport json\n\n# Parse response from API\nresponse_json = '''{\n    \"role\": \"assistant\",\n    \"content\": \"I've found the issue. Here's a command to fix it:\",\n    \"data\": {\n        \"cmds\": [\n            {\n                \"command\": \"kubectl rollout restart deployment/my-app\",\n                \"execute\": false\n            }\n        ],\n        \"tool_calls\": [],\n        \"executed_tool_calls\": []\n    }\n}'''\n\nresponse = AgentMessage.model_validate_json(response_json)\n\nprint(f\"Content: {response.content}\")\nprint(f\"Commands: {len(response.data.cmds)}\")\n\nfor cmd in response.data.cmds:\n    print(f\"  - {cmd.command}\")\n</code></pre>"},{"location":"api-reference/schemas/#example-3-handling-tool-calls","title":"Example 3: Handling Tool Calls","text":"<pre><code>from dcaf.schemas.messages import AgentMessage, ToolCall\n\n# Agent response with tool calls\nresponse = AgentMessage(\n    content=\"I need to check the weather. Please approve:\",\n    data=Data(\n        tool_calls=[\n            ToolCall(\n                id=\"toolu_weather_123\",\n                name=\"get_weather\",\n                input={\"location\": \"San Francisco, CA\", \"unit\": \"fahrenheit\"},\n                tool_description=\"Get current weather for a location\",\n                input_description={\n                    \"location\": {\"type\": \"string\", \"description\": \"City and state\"},\n                    \"unit\": {\"type\": \"string\", \"description\": \"Temperature unit\"}\n                }\n            )\n        ]\n    )\n)\n\n# Display for user approval\nfor tc in response.data.tool_calls:\n    print(f\"Tool: {tc.name}\")\n    print(f\"Description: {tc.tool_description}\")\n    print(f\"Input: {tc.input}\")\n    print()\n\n    # User approves\n    tc.execute = True\n</code></pre>"},{"location":"api-reference/schemas/#example-4-stream-event-processing","title":"Example 4: Stream Event Processing","text":"<pre><code>from dcaf.schemas.events import (\n    TextDeltaEvent, ToolCallsEvent, DoneEvent, ErrorEvent\n)\nimport json\n\ndef process_stream_event(line: str):\n    \"\"\"Process a single NDJSON line from the stream.\"\"\"\n    event = json.loads(line)\n    event_type = event.get(\"type\")\n\n    if event_type == \"text_delta\":\n        delta = TextDeltaEvent.model_validate(event)\n        print(delta.text, end=\"\", flush=True)\n\n    elif event_type == \"tool_calls\":\n        tc_event = ToolCallsEvent.model_validate(event)\n        print(\"\\n[Tool calls pending approval]\")\n        for tc in tc_event.tool_calls:\n            print(f\"  - {tc.name}: {tc.input}\")\n\n    elif event_type == \"done\":\n        done = DoneEvent.model_validate(event)\n        print(f\"\\n[Stream complete: {done.stop_reason}]\")\n        return True\n\n    elif event_type == \"error\":\n        error = ErrorEvent.model_validate(event)\n        print(f\"\\n[Error: {error.error}]\")\n        return True\n\n    return False\n\n# Example usage\nstream_lines = [\n    '{\"type\": \"text_delta\", \"text\": \"Hello, \"}',\n    '{\"type\": \"text_delta\", \"text\": \"how can I help?\"}',\n    '{\"type\": \"done\", \"stop_reason\": \"end_turn\"}'\n]\n\nfor line in stream_lines:\n    if process_stream_event(line):\n        break\n</code></pre>"},{"location":"api-reference/schemas/#example-5-validation-and-error-handling","title":"Example 5: Validation and Error Handling","text":"<pre><code>from dcaf.schemas.messages import AgentMessage, Messages\nfrom pydantic import ValidationError\n\n# Validate incoming message\ntry:\n    msgs = Messages.model_validate({\n        \"messages\": [\n            {\"role\": \"user\", \"content\": \"Hello\"}\n        ]\n    })\nexcept ValidationError as e:\n    print(f\"Validation error: {e}\")\n\n# Create response safely\ntry:\n    response = AgentMessage(\n        content=\"Response text\",\n        data={\"invalid\": \"data\"}  # This will fail\n    )\nexcept ValidationError as e:\n    print(f\"Invalid response: {e}\")\n\n# Correct way\nresponse = AgentMessage(content=\"Response text\")\n</code></pre>"},{"location":"api-reference/schemas/#see-also","title":"See Also","text":"<ul> <li>Message Protocol Guide</li> <li>Streaming Guide</li> <li>Agent Server API Reference</li> </ul>"},{"location":"api-reference/tools/","title":"Tools API Reference","text":"<p>The Tools module provides a powerful system for creating callable functions that LLM agents can use. It supports JSON Schema validation, approval workflows, and platform context injection.</p>"},{"location":"api-reference/tools/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Class: Tool</li> <li>Decorator: @tool</li> <li>Function: create_tool</li> <li>Schema Definition Options</li> <li>Platform Context</li> <li>Approval Workflows</li> <li>Examples</li> <li>Best Practices</li> </ol>"},{"location":"api-reference/tools/#overview","title":"Overview","text":"<p>The Tools module provides two ways to create tools:</p> <ol> <li><code>@tool</code> decorator - Transform a function into a Tool object</li> <li><code>create_tool()</code> function - Programmatically create tools</li> </ol> <p>And three ways to define tool schemas:</p> <ol> <li>Auto-generate - Schema is inferred from function signature (simplest)</li> <li>Dict schema - Pass a JSON Schema dict (full control)</li> <li>Pydantic model - Pass a Pydantic model class (type-safe with IDE support)</li> </ol>"},{"location":"api-reference/tools/#import","title":"Import","text":"<pre><code>from dcaf.tools import tool, create_tool, Tool\n</code></pre>"},{"location":"api-reference/tools/#key-features","title":"Key Features","text":"<ul> <li>Flexible schema definition - Auto-generate, dict, or Pydantic model</li> <li>JSON Schema validation for tool inputs</li> <li>Automatic platform context detection</li> <li>Approval workflow support</li> <li>LLM-ready schema generation</li> <li>Tool inspection and debugging</li> </ul>"},{"location":"api-reference/tools/#class-tool","title":"Class: Tool","text":"<p>The <code>Tool</code> class is a Pydantic model that represents a callable tool.</p> <pre><code>class Tool(BaseModel):\n    \"\"\"Container for tool metadata and configuration.\"\"\"\n\n    func: Callable           # The wrapped function\n    name: str                # Tool name for LLM\n    description: str         # Tool description\n    schema: Dict[str, Any]   # JSON schema for inputs\n    requires_approval: bool  # Whether approval is needed\n    requires_platform_context: bool  # Whether context is needed\n</code></pre>"},{"location":"api-reference/tools/#attributes","title":"Attributes","text":"Attribute Type Description <code>func</code> <code>Callable</code> The underlying Python function <code>name</code> <code>str</code> Tool name (used by LLM) <code>description</code> <code>str</code> Human-readable description <code>schema</code> <code>Dict</code> Full JSON schema specification <code>requires_approval</code> <code>bool</code> If <code>True</code>, requires user approval <code>requires_platform_context</code> <code>bool</code> If <code>True</code>, expects platform context"},{"location":"api-reference/tools/#methods","title":"Methods","text":""},{"location":"api-reference/tools/#get_schema-dictstr-any","title":"<code>get_schema() -&gt; Dict[str, Any]</code>","text":"<p>Returns the tool's JSON schema in LLM-ready format.</p> <pre><code>schema = my_tool.get_schema()\n# {\n#     \"name\": \"my_tool\",\n#     \"description\": \"Tool description\",\n#     \"input_schema\": {...}\n# }\n</code></pre>"},{"location":"api-reference/tools/#executeinput_args-dict-platform_context-dict-none-str","title":"<code>execute(input_args: Dict, platform_context: Dict = None) -&gt; str</code>","text":"<p>Execute the tool with given inputs.</p> <pre><code># Without platform context\nresult = my_tool.execute({\"param\": \"value\"})\n\n# With platform context\nresult = my_tool.execute(\n    {\"param\": \"value\"},\n    {\"user_id\": \"alice\", \"tenant\": \"prod\"}\n)\n</code></pre>"},{"location":"api-reference/tools/#describe-none","title":"<code>describe() -&gt; None</code>","text":"<p>Print detailed information about the tool.</p> <pre><code>my_tool.describe()\n# Tool: my_tool\n# Description: Tool description\n# Requires Approval: False\n# Has Platform Context: True\n# Schema: {...}\n</code></pre>"},{"location":"api-reference/tools/#__repr__-str","title":"<code>__repr__() -&gt; str</code>","text":"<p>Pretty representation for debugging.</p> <pre><code>print(my_tool)\n# Tool(name='my_tool', requires_approval=False, requires_platform_context=True)\n</code></pre>"},{"location":"api-reference/tools/#decorator-tool","title":"Decorator: @tool","text":"<p>Transform a function into a Tool object.</p> <pre><code>def tool(\n    func: Optional[Callable] = None,\n    *,\n    description: Optional[str] = None,\n    name: Optional[str] = None,\n    requires_approval: bool = False,\n    schema: Optional[Union[Dict[str, Any], Type[BaseModel]]] = None,\n) -&gt; Tool\n</code></pre>"},{"location":"api-reference/tools/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>description</code> <code>str</code> Docstring Tool description shown to LLM <code>name</code> <code>str</code> Function name Override the tool name <code>requires_approval</code> <code>bool</code> <code>False</code> Require user approval before execution <code>schema</code> <code>Dict</code> or <code>BaseModel</code> Auto-generated JSON schema dict OR Pydantic model class"},{"location":"api-reference/tools/#schema-options","title":"Schema Options","text":"<p>The <code>@tool</code> decorator supports three ways to define the input schema:</p>"},{"location":"api-reference/tools/#option-1-auto-generate-simplest","title":"Option 1: Auto-Generate (Simplest)","text":"<p>Let DCAF generate the schema from your function signature:</p> <pre><code>from dcaf.tools import tool\n\n@tool(description=\"Generate a personalized greeting\")\ndef greet(name: str, language: str = \"english\") -&gt; str:\n    \"\"\"Generate a greeting.\"\"\"\n    greetings = {\"english\": \"Hello\", \"spanish\": \"Hola\", \"french\": \"Bonjour\"}\n    return f\"{greetings.get(language, 'Hello')}, {name}!\"\n\n# Schema is auto-generated from function signature\nprint(greet.input_schema)\n# {\n#     \"type\": \"object\",\n#     \"properties\": {\n#         \"name\": {\"type\": \"string\"},\n#         \"language\": {\"type\": \"string\", \"default\": \"english\"}\n#     },\n#     \"required\": [\"name\"]\n# }\n</code></pre>"},{"location":"api-reference/tools/#option-2-dict-schema-full-control","title":"Option 2: Dict Schema (Full Control)","text":"<p>Pass an explicit JSON Schema dict:</p> <pre><code>@tool(\n    description=\"Generate a greeting message\",\n    schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\n                \"type\": \"string\",\n                \"description\": \"Name of the person to greet\",\n                \"minLength\": 1,\n                \"maxLength\": 100\n            },\n            \"language\": {\n                \"type\": \"string\",\n                \"enum\": [\"english\", \"spanish\", \"french\"],\n                \"description\": \"Language for the greeting\",\n                \"default\": \"english\"\n            }\n        },\n        \"required\": [\"name\"]\n    },\n    requires_approval=False\n)\ndef greet(name: str, language: str = \"english\") -&gt; str:\n    \"\"\"Generate a greeting.\"\"\"\n    greetings = {\"english\": \"Hello\", \"spanish\": \"Hola\", \"french\": \"Bonjour\"}\n    return f\"{greetings.get(language, 'Hello')}, {name}!\"\n</code></pre>"},{"location":"api-reference/tools/#option-3-pydantic-model-type-safe","title":"Option 3: Pydantic Model (Type-Safe)","text":"<p>Pass a Pydantic model class for type-safe schemas with IDE support:</p> <pre><code>from pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass GreetInput(BaseModel):\n    \"\"\"Input schema for the greet tool.\"\"\"\n    name: str = Field(..., description=\"Name of the person to greet\", min_length=1, max_length=100)\n    language: Literal[\"english\", \"spanish\", \"french\"] = Field(\n        default=\"english\",\n        description=\"Language for the greeting\"\n    )\n\n@tool(description=\"Generate a greeting message\", schema=GreetInput)\ndef greet(name: str, language: str = \"english\") -&gt; str:\n    \"\"\"Generate a greeting.\"\"\"\n    greetings = {\"english\": \"Hello\", \"spanish\": \"Hola\", \"french\": \"Bonjour\"}\n    return f\"{greetings.get(language, 'Hello')}, {name}!\"\n</code></pre> <p>Pydantic Benefits</p> <p>Using Pydantic models gives you:</p> <ul> <li>IDE autocomplete when defining the schema</li> <li>Type checking at development time</li> <li>Reusable schemas across multiple tools</li> <li>Built-in validation if you want to validate inputs in your tool</li> </ul>"},{"location":"api-reference/tools/#basic-usage","title":"Basic Usage","text":"<pre><code>from dcaf.tools import tool\n\n# Simplest - auto-generate schema\n@tool(description=\"Generate a greeting\")\ndef greet(name: str) -&gt; str:\n    \"\"\"Generate a greeting.\"\"\"\n    return f\"Hello, {name}!\"\n\n# Use the tool\nresult = greet.execute({\"name\": \"Alice\"})\nprint(result)  # \"Hello, Alice!\"\n</code></pre>"},{"location":"api-reference/tools/#with-platform-context","title":"With Platform Context","text":"<p>If your function has a <code>platform_context</code> parameter, DCAF automatically detects it:</p> <pre><code>@tool(\n    schema={\n        \"name\": \"log_action\",\n        \"description\": \"Log an action with user context\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"action\": {\n                    \"type\": \"string\",\n                    \"description\": \"Action to log\"\n                }\n            },\n            \"required\": [\"action\"]\n        }\n    }\n)\ndef log_action(action: str, platform_context: dict) -&gt; str:\n    \"\"\"Log an action with the current user.\"\"\"\n    user = platform_context.get(\"user_id\", \"unknown\")\n    tenant = platform_context.get(\"tenant_name\", \"default\")\n    return f\"[{tenant}/{user}] Action: {action}\"\n\n# Verify detection\nprint(log_action.requires_platform_context)  # True\n\n# Execute with context\nresult = log_action.execute(\n    {\"action\": \"login\"},\n    {\"user_id\": \"alice\", \"tenant_name\": \"prod\"}\n)\nprint(result)  # \"[prod/alice] Action: login\"\n</code></pre>"},{"location":"api-reference/tools/#with-approval-required","title":"With Approval Required","text":"<pre><code>@tool(\n    schema={\n        \"name\": \"delete_resource\",\n        \"description\": \"Delete a resource (requires approval)\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"resource_id\": {\n                    \"type\": \"string\",\n                    \"description\": \"ID of resource to delete\"\n                },\n                \"force\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Force deletion\",\n                    \"default\": False\n                }\n            },\n            \"required\": [\"resource_id\"]\n        }\n    },\n    requires_approval=True  # User must approve\n)\ndef delete_resource(resource_id: str, force: bool = False) -&gt; str:\n    \"\"\"Delete a resource from the system.\"\"\"\n    mode = \"force-deleted\" if force else \"deleted\"\n    return f\"Resource {resource_id} has been {mode}\"\n\n# This tool will require approval before execution\nprint(delete_resource.requires_approval)  # True\n</code></pre>"},{"location":"api-reference/tools/#custom-name-and-description","title":"Custom Name and Description","text":"<pre><code>@tool(\n    schema={\n        \"name\": \"search_db\",\n        \"description\": \"Search the database\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\"type\": \"string\"}\n            },\n            \"required\": [\"query\"]\n        }\n    },\n    name=\"database_search\",           # Override name\n    description=\"Search for records\"  # Override docstring\n)\ndef internal_search(query: str) -&gt; str:\n    \"\"\"This docstring is overridden.\"\"\"\n    return f\"Found 5 results for: {query}\"\n\nprint(internal_search.name)  # \"database_search\"\nprint(internal_search.description)  # \"Search for records\"\n</code></pre>"},{"location":"api-reference/tools/#function-create_tool","title":"Function: create_tool","text":"<p>Create a tool programmatically without using a decorator.</p> <pre><code>def create_tool(\n    func: Callable,\n    description: Optional[str] = None,\n    name: Optional[str] = None,\n    requires_approval: bool = False,\n    schema: Optional[Union[Dict[str, Any], Type[BaseModel]]] = None,\n) -&gt; Tool\n</code></pre>"},{"location":"api-reference/tools/#parameters_1","title":"Parameters","text":"Parameter Type Default Description <code>func</code> <code>Callable</code> Required Function to wrap <code>description</code> <code>str</code> Docstring Tool description <code>name</code> <code>str</code> Function name Tool name <code>requires_approval</code> <code>bool</code> <code>False</code> Require approval <code>schema</code> <code>Dict</code> or <code>BaseModel</code> Auto-generated JSON schema dict OR Pydantic model class"},{"location":"api-reference/tools/#usage","title":"Usage","text":"<pre><code>from dcaf.tools import create_tool\n\n# Define a function\ndef multiply(a: int, b: int) -&gt; str:\n    \"\"\"Multiply two numbers.\"\"\"\n    return f\"{a} \u00d7 {b} = {a * b}\"\n\n# Option 1: Auto-generate schema\nmultiply_tool = create_tool(multiply, description=\"Multiply two integers\")\n\n# Option 2: With explicit dict schema\nmultiply_tool = create_tool(\n    func=multiply,\n    description=\"Multiply two integers\",\n    schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"a\": {\"type\": \"integer\", \"description\": \"First number\", \"minimum\": 0},\n            \"b\": {\"type\": \"integer\", \"description\": \"Second number\", \"minimum\": 0}\n        },\n        \"required\": [\"a\", \"b\"]\n    }\n)\n\n# Option 3: With Pydantic model\nfrom pydantic import BaseModel, Field\n\nclass MultiplyInput(BaseModel):\n    a: int = Field(..., ge=0, description=\"First number\")\n    b: int = Field(..., ge=0, description=\"Second number\")\n\nmultiply_tool = create_tool(\n    func=multiply,\n    description=\"Multiply two integers\",\n    schema=MultiplyInput\n)\n\n# Use the tool\nresult = multiply_tool.execute({\"a\": 6, \"b\": 7})\nprint(result)  # \"6 \u00d7 7 = 42\"\n</code></pre>"},{"location":"api-reference/tools/#when-to-use-create_tool","title":"When to Use create_tool","text":"<ul> <li>Creating tools from existing functions you can't modify</li> <li>Dynamic tool generation at runtime</li> <li>Building tools from configuration files</li> <li>Testing and mocking</li> </ul>"},{"location":"api-reference/tools/#schema-definition-options","title":"Schema Definition Options","text":"<p>DCAF supports three ways to define tool input schemas, giving you flexibility based on your needs.</p>"},{"location":"api-reference/tools/#comparison","title":"Comparison","text":"Approach Best For Pros Cons Auto-generate Simple tools Zero config, fast Limited validation Dict schema Full control Any JSON Schema feature Verbose, no IDE help Pydantic model Production tools Type-safe, IDE support, reusable Extra class definition"},{"location":"api-reference/tools/#option-1-auto-generated-schema","title":"Option 1: Auto-Generated Schema","text":"<p>When you don't provide a schema, DCAF generates one from your function signature:</p> <pre><code>@tool(description=\"Search for users\")\ndef search_users(query: str, limit: int = 10, active_only: bool = True) -&gt; str:\n    ...\n\n# Auto-generates:\n# {\n#     \"type\": \"object\",\n#     \"properties\": {\n#         \"query\": {\"type\": \"string\"},\n#         \"limit\": {\"type\": \"integer\", \"default\": 10},\n#         \"active_only\": {\"type\": \"boolean\", \"default\": true}\n#     },\n#     \"required\": [\"query\"]\n# }\n</code></pre>"},{"location":"api-reference/tools/#option-2-dict-schema","title":"Option 2: Dict Schema","text":"<p>For full control over the JSON Schema:</p> <pre><code>schema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"query\": {\n            \"type\": \"string\",\n            \"description\": \"Search query\",\n            \"minLength\": 1,\n            \"maxLength\": 100\n        },\n        \"limit\": {\n            \"type\": \"integer\",\n            \"description\": \"Max results\",\n            \"minimum\": 1,\n            \"maximum\": 100,\n            \"default\": 10\n        },\n        \"active_only\": {\n            \"type\": \"boolean\",\n            \"description\": \"Only return active users\",\n            \"default\": True\n        }\n    },\n    \"required\": [\"query\"]\n}\n\n@tool(description=\"Search for users\", schema=schema)\ndef search_users(query: str, limit: int = 10, active_only: bool = True) -&gt; str:\n    ...\n</code></pre>"},{"location":"api-reference/tools/#option-3-pydantic-model","title":"Option 3: Pydantic Model","text":"<p>For type-safe schemas with IDE support and validation:</p> <pre><code>from pydantic import BaseModel, Field\n\nclass SearchUsersInput(BaseModel):\n    \"\"\"Input schema for user search.\"\"\"\n    query: str = Field(..., description=\"Search query\", min_length=1, max_length=100)\n    limit: int = Field(default=10, ge=1, le=100, description=\"Max results\")\n    active_only: bool = Field(default=True, description=\"Only return active users\")\n\n@tool(description=\"Search for users\", schema=SearchUsersInput)\ndef search_users(query: str, limit: int = 10, active_only: bool = True) -&gt; str:\n    ...\n</code></pre> <p>How It Works</p> <p>When you pass a Pydantic model, DCAF automatically calls <code>model.model_json_schema()</code>  to convert it to a JSON Schema dict. You don't need to do anything special.</p>"},{"location":"api-reference/tools/#json-schema-structure","title":"JSON Schema Structure","text":"<p>Regardless of how you define it, the final schema follows JSON Schema format:</p>"},{"location":"api-reference/tools/#parameter-types","title":"Parameter Types","text":""},{"location":"api-reference/tools/#string","title":"String","text":"<pre><code>\"username\": {\n    \"type\": \"string\",\n    \"description\": \"The username\",\n    \"minLength\": 3,\n    \"maxLength\": 50\n}\n</code></pre>"},{"location":"api-reference/tools/#integer","title":"Integer","text":"<pre><code>\"count\": {\n    \"type\": \"integer\",\n    \"description\": \"Number of items\",\n    \"minimum\": 1,\n    \"maximum\": 100\n}\n</code></pre>"},{"location":"api-reference/tools/#number-float","title":"Number (Float)","text":"<pre><code>\"price\": {\n    \"type\": \"number\",\n    \"description\": \"Price in dollars\",\n    \"minimum\": 0\n}\n</code></pre>"},{"location":"api-reference/tools/#boolean","title":"Boolean","text":"<pre><code>\"active\": {\n    \"type\": \"boolean\",\n    \"description\": \"Whether the item is active\",\n    \"default\": True\n}\n</code></pre>"},{"location":"api-reference/tools/#enum","title":"Enum","text":"<pre><code>\"status\": {\n    \"type\": \"string\",\n    \"enum\": [\"pending\", \"active\", \"completed\"],\n    \"description\": \"Current status\"\n}\n</code></pre>"},{"location":"api-reference/tools/#array","title":"Array","text":"<pre><code>\"tags\": {\n    \"type\": \"array\",\n    \"items\": {\"type\": \"string\"},\n    \"description\": \"List of tags\"\n}\n</code></pre>"},{"location":"api-reference/tools/#nested-object","title":"Nested Object","text":"<pre><code>\"config\": {\n    \"type\": \"object\",\n    \"description\": \"Configuration options\",\n    \"properties\": {\n        \"timeout\": {\"type\": \"integer\"},\n        \"retries\": {\"type\": \"integer\"}\n    }\n}\n</code></pre>"},{"location":"api-reference/tools/#complete-example","title":"Complete Example","text":"<pre><code>@tool(\n    schema={\n        \"name\": \"create_user\",\n        \"description\": \"Create a new user account\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"username\": {\n                    \"type\": \"string\",\n                    \"description\": \"Unique username\",\n                    \"minLength\": 3,\n                    \"maxLength\": 30\n                },\n                \"email\": {\n                    \"type\": \"string\",\n                    \"description\": \"Email address\",\n                    \"format\": \"email\"\n                },\n                \"role\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"user\", \"admin\", \"moderator\"],\n                    \"description\": \"User role\",\n                    \"default\": \"user\"\n                },\n                \"permissions\": {\n                    \"type\": \"array\",\n                    \"items\": {\"type\": \"string\"},\n                    \"description\": \"List of permissions\"\n                },\n                \"profile\": {\n                    \"type\": \"object\",\n                    \"description\": \"User profile data\",\n                    \"properties\": {\n                        \"display_name\": {\"type\": \"string\"},\n                        \"bio\": {\"type\": \"string\"}\n                    }\n                }\n            },\n            \"required\": [\"username\", \"email\"]\n        }\n    },\n    requires_approval=True\n)\ndef create_user(\n    username: str,\n    email: str,\n    role: str = \"user\",\n    permissions: list = None,\n    profile: dict = None\n) -&gt; str:\n    \"\"\"Create a new user account.\"\"\"\n    return f\"Created user {username} with role {role}\"\n</code></pre>"},{"location":"api-reference/tools/#platform-context","title":"Platform Context","text":"<p>Platform context allows tools to access runtime information like user identity, tenant, and credentials.</p>"},{"location":"api-reference/tools/#how-it-works","title":"How It Works","text":"<ol> <li>If your function has a <code>platform_context</code> parameter, DCAF sets <code>requires_platform_context=True</code></li> <li>When the tool is executed, the agent passes context from the request</li> <li>Your function receives the context and can use it</li> </ol>"},{"location":"api-reference/tools/#available-context-fields","title":"Available Context Fields","text":"Field Type Description <code>user_id</code> <code>str</code> Current user identifier <code>tenant_name</code> <code>str</code> DuploCloud tenant name <code>k8s_namespace</code> <code>str</code> Kubernetes namespace <code>duplo_base_url</code> <code>str</code> DuploCloud API URL <code>duplo_token</code> <code>str</code> DuploCloud API token <code>kubeconfig</code> <code>str</code> Base64-encoded kubeconfig <code>aws_credentials</code> <code>Dict</code> AWS credential information"},{"location":"api-reference/tools/#example-with-context","title":"Example with Context","text":"<pre><code>@tool(\n    schema={\n        \"name\": \"deploy_service\",\n        \"description\": \"Deploy a service to the current tenant\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"service_name\": {\n                    \"type\": \"string\",\n                    \"description\": \"Name of the service to deploy\"\n                },\n                \"image\": {\n                    \"type\": \"string\",\n                    \"description\": \"Docker image to deploy\"\n                }\n            },\n            \"required\": [\"service_name\", \"image\"]\n        }\n    },\n    requires_approval=True\n)\ndef deploy_service(\n    service_name: str,\n    image: str,\n    platform_context: dict\n) -&gt; str:\n    \"\"\"Deploy a service using platform context.\"\"\"\n    tenant = platform_context.get(\"tenant_name\", \"unknown\")\n    namespace = platform_context.get(\"k8s_namespace\", \"default\")\n    user = platform_context.get(\"user_id\", \"system\")\n\n    # Use context for deployment\n    return f\"Deployed {service_name} ({image}) to {tenant}/{namespace} by {user}\"\n</code></pre>"},{"location":"api-reference/tools/#optional-platform-context","title":"Optional Platform Context","text":"<p>You can make platform context optional with a default value:</p> <pre><code>@tool(\n    schema={...}\n)\ndef flexible_tool(data: str, platform_context: dict = None) -&gt; str:\n    \"\"\"Tool that works with or without context.\"\"\"\n    if platform_context:\n        user = platform_context.get(\"user_id\", \"unknown\")\n        return f\"User {user} processed: {data}\"\n    return f\"Processed: {data}\"\n\n# Works both ways\nresult1 = flexible_tool.execute({\"data\": \"test\"})\nresult2 = flexible_tool.execute({\"data\": \"test\"}, {\"user_id\": \"alice\"})\n</code></pre>"},{"location":"api-reference/tools/#approval-workflows","title":"Approval Workflows","text":"<p>Tools that modify state or perform sensitive operations should require approval.</p>"},{"location":"api-reference/tools/#how-approval-works","title":"How Approval Works","text":"<ol> <li>Agent calls tool with <code>requires_approval=True</code></li> <li>Instead of executing, the agent returns a <code>ToolCall</code> object</li> <li>Client presents the tool call to the user for approval</li> <li>User approves or rejects (with optional reason)</li> <li>Client sends the decision back to the agent</li> <li>If approved, agent executes the tool</li> </ol>"},{"location":"api-reference/tools/#marking-tools-for-approval","title":"Marking Tools for Approval","text":"<pre><code>@tool(\n    schema={\n        \"name\": \"terminate_instance\",\n        \"description\": \"Terminate an EC2 instance\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"instance_id\": {\n                    \"type\": \"string\",\n                    \"description\": \"EC2 instance ID\"\n                }\n            },\n            \"required\": [\"instance_id\"]\n        }\n    },\n    requires_approval=True  # This is the key!\n)\ndef terminate_instance(instance_id: str) -&gt; str:\n    \"\"\"Terminate an EC2 instance.\"\"\"\n    # This only runs after user approval\n    return f\"Instance {instance_id} terminated\"\n</code></pre>"},{"location":"api-reference/tools/#approval-response-format","title":"Approval Response Format","text":"<p>When a tool requires approval, the agent returns:</p> <pre><code>AgentMessage(\n    content=\"I need your approval to execute the following tools:\",\n    data=Data(\n        tool_calls=[\n            ToolCall(\n                id=\"unique-tool-use-id\",\n                name=\"terminate_instance\",\n                input={\"instance_id\": \"i-1234567890abcdef0\"},\n                tool_description=\"Terminate an EC2 instance\",\n                input_description={\n                    \"instance_id\": {\n                        \"type\": \"string\",\n                        \"description\": \"EC2 instance ID\"\n                    }\n                },\n                execute=False  # Not yet approved\n            )\n        ]\n    )\n)\n</code></pre>"},{"location":"api-reference/tools/#sending-approval","title":"Sending Approval","text":"<pre><code># Client sends back with execute=True or rejection_reason\nmessages = {\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Terminate the instance\",\n            \"data\": {\n                \"tool_calls\": [\n                    {\n                        \"id\": \"unique-tool-use-id\",\n                        \"name\": \"terminate_instance\",\n                        \"input\": {\"instance_id\": \"i-1234567890abcdef0\"},\n                        \"execute\": True  # Approved!\n                        # OR\n                        # \"rejection_reason\": \"Wrong instance\"\n                    }\n                ]\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"api-reference/tools/#examples","title":"Examples","text":""},{"location":"api-reference/tools/#example-1-simple-calculator","title":"Example 1: Simple Calculator","text":"<pre><code>from dcaf.tools import tool\n\n@tool(\n    schema={\n        \"name\": \"calculate\",\n        \"description\": \"Perform arithmetic operations\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"operation\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"],\n                    \"description\": \"The operation to perform\"\n                },\n                \"a\": {\"type\": \"number\", \"description\": \"First operand\"},\n                \"b\": {\"type\": \"number\", \"description\": \"Second operand\"}\n            },\n            \"required\": [\"operation\", \"a\", \"b\"]\n        }\n    },\n    requires_approval=False\n)\ndef calculate(operation: str, a: float, b: float) -&gt; str:\n    ops = {\n        \"add\": lambda x, y: x + y,\n        \"subtract\": lambda x, y: x - y,\n        \"multiply\": lambda x, y: x * y,\n        \"divide\": lambda x, y: x / y if y != 0 else \"undefined\"\n    }\n    result = ops[operation](a, b)\n    return f\"{a} {operation} {b} = {result}\"\n\n# Test\nprint(calculate.execute({\"operation\": \"multiply\", \"a\": 7, \"b\": 8}))\n# \"7 multiply 8 = 56\"\n</code></pre>"},{"location":"api-reference/tools/#example-2-database-query-tool","title":"Example 2: Database Query Tool","text":"<pre><code>@tool(\n    schema={\n        \"name\": \"query_database\",\n        \"description\": \"Execute a read-only database query\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"table\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"users\", \"orders\", \"products\"],\n                    \"description\": \"Table to query\"\n                },\n                \"limit\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum rows to return\",\n                    \"default\": 10,\n                    \"minimum\": 1,\n                    \"maximum\": 100\n                },\n                \"filters\": {\n                    \"type\": \"object\",\n                    \"description\": \"Filter conditions\"\n                }\n            },\n            \"required\": [\"table\"]\n        }\n    },\n    requires_approval=False\n)\ndef query_database(\n    table: str,\n    limit: int = 10,\n    filters: dict = None,\n    platform_context: dict = None\n) -&gt; str:\n    \"\"\"Query the database with optional filters.\"\"\"\n    tenant = platform_context.get(\"tenant_name\", \"default\") if platform_context else \"default\"\n\n    # Simulated query\n    return f\"Queried {table} in {tenant}, limit={limit}, filters={filters}\"\n</code></pre>"},{"location":"api-reference/tools/#example-3-tool-registry","title":"Example 3: Tool Registry","text":"<pre><code>from dcaf.tools import tool, Tool\nfrom typing import List\n\n# Create multiple tools\n@tool(schema={...}, requires_approval=False)\ndef tool_a(x: str) -&gt; str:\n    return f\"A: {x}\"\n\n@tool(schema={...}, requires_approval=True)\ndef tool_b(y: str, platform_context: dict) -&gt; str:\n    return f\"B: {y}\"\n\n@tool(schema={...}, requires_approval=False)\ndef tool_c(z: int) -&gt; str:\n    return f\"C: {z}\"\n\n# Create a registry\ntools: List[Tool] = [tool_a, tool_b, tool_c]\n\n# Analyze tools\nprint(\"Tool Analysis:\")\nprint(\"-\" * 50)\nfor t in tools:\n    ctx = \"\u2713\" if t.requires_platform_context else \"\u2717\"\n    app = \"\u2713\" if t.requires_approval else \"\u2717\"\n    print(f\"  {t.name:20} Context: {ctx}  Approval: {app}\")\n\n# Filter by requirements\napproval_tools = [t for t in tools if t.requires_approval]\ncontext_tools = [t for t in tools if t.requires_platform_context]\n</code></pre>"},{"location":"api-reference/tools/#best-practices","title":"Best Practices","text":""},{"location":"api-reference/tools/#1-clear-descriptions","title":"1. Clear Descriptions","text":"<pre><code># Good: Specific and actionable\n\"description\": \"Delete a user account and all associated data permanently\"\n\n# Bad: Vague\n\"description\": \"Delete user\"\n</code></pre>"},{"location":"api-reference/tools/#2-appropriate-approval","title":"2. Appropriate Approval","text":"<pre><code># Require approval for:\n# - Destructive operations (delete, terminate, drop)\n# - State changes (create, update, modify)\n# - Cost-incurring actions (deploy, scale up)\n# - Security-sensitive operations\n\n# No approval needed for:\n# - Read-only operations (get, list, describe)\n# - Calculations\n# - Information retrieval\n</code></pre>"},{"location":"api-reference/tools/#3-parameter-validation","title":"3. Parameter Validation","text":"<pre><code># Use constraints in schema\n\"count\": {\n    \"type\": \"integer\",\n    \"minimum\": 1,\n    \"maximum\": 1000,\n    \"description\": \"Number of items (1-1000)\"\n}\n</code></pre>"},{"location":"api-reference/tools/#4-helpful-error-messages","title":"4. Helpful Error Messages","text":"<pre><code>def my_tool(param: str) -&gt; str:\n    if not param:\n        return \"Error: Parameter cannot be empty\"\n    if len(param) &gt; 100:\n        return f\"Error: Parameter too long ({len(param)} &gt; 100)\"\n    # ...\n</code></pre>"},{"location":"api-reference/tools/#5-use-enums-for-fixed-options","title":"5. Use Enums for Fixed Options","text":"<pre><code>\"status\": {\n    \"type\": \"string\",\n    \"enum\": [\"pending\", \"active\", \"completed\"],\n    \"description\": \"One of: pending, active, completed\"\n}\n</code></pre>"},{"location":"api-reference/tools/#see-also","title":"See Also","text":"<ul> <li>Agents API Reference</li> <li>Building Tools Guide</li> <li>Examples</li> </ul>"},{"location":"core/","title":"DCAF Core","text":"<p>DCAF Core provides a simple, Pythonic API for building AI agents with tool calling and human-in-the-loop approval.</p>"},{"location":"core/#quick-start","title":"Quick Start","text":"<pre><code>from dcaf.core import Agent, ChatMessage\nfrom dcaf.tools import tool\n\n# 1. Define a tool\n@tool(description=\"List Kubernetes pods\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    \"\"\"List pods in a namespace.\"\"\"\n    return kubectl(f\"get pods -n {namespace}\")\n\n@tool(requires_approval=True, description=\"Delete a pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    \"\"\"Delete a pod. Requires approval.\"\"\"\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n\n# 2. Create an agent\nagent = Agent(tools=[list_pods, delete_pod])\n\n# 3. Run it with messages\nresponse = agent.run(messages=[\n    ChatMessage.user(\"What pods are running? Delete any failing ones.\")\n])\n\n# 4. Handle approvals\nif response.needs_approval:\n    for pending in response.pending_tools:\n        print(f\"Approve {pending.name}? {pending.input}\")\n\n    # Approve all and continue\n    response = response.approve_all()\n\nprint(response.text)\n</code></pre>"},{"location":"core/#key-features","title":"Key Features","text":"Feature Description Simple API One class (<code>Agent</code>) for most use cases Tool Calling Easy decorator-based tool definitions Human-in-the-Loop Built-in approval flow for dangerous operations HelpDesk Compatible Full compatibility with DuploCloud HelpDesk protocol Event Hooks Subscribe to events for logging, notifications Framework Agnostic Swap LLM providers without code changes"},{"location":"core/#the-agent-class","title":"The Agent Class","text":"<p>The <code>Agent</code> class is the main entry point:</p> <pre><code>agent = Agent(\n    tools=[...],                    # List of tools the agent can use\n    model=\"anthropic.claude-3-sonnet\",  # LLM model (optional)\n    system_prompt=\"You are...\",     # Static system prompt (optional)\n    system_context=\"Dynamic context\",   # Dynamic context (optional, for caching)\n    model_config={...},             # Model configuration (optional, e.g., caching)\n    on_event=my_handler,            # Event handler(s) (optional)\n)\n</code></pre>"},{"location":"core/#prompt-caching-bedrock-only","title":"Prompt Caching (Bedrock Only)","text":"<p>Reduce costs by up to 90% and latency by up to 85% with prompt caching. Separate static instructions from dynamic context:</p> <pre><code>agent = Agent(\n    # Static part - cached (same for all requests)\n    system_prompt=\"\"\"\n    You are a Kubernetes expert. Your role is to help users manage clusters.\n    [Add detailed guidelines here - aim for 1024+ tokens for caching]\n    \"\"\",\n\n    # Dynamic part - NOT cached (changes per request)\n    system_context=lambda ctx: f\"\"\"\n    Tenant: {ctx.get('tenant_name')}\n    Namespace: {ctx.get('k8s_namespace')}\n    User: {ctx.get('user_email')}\n    \"\"\",\n\n    # Enable caching\n    model_config={\"cache_system_prompt\": True},\n\n    tools=[...],\n)\n</code></pre> <p>See Prompt Caching Guide for details.</p>"},{"location":"core/#running-the-agent","title":"Running the Agent","text":"<pre><code>from dcaf.core import Agent, ChatMessage\n\nagent = Agent(tools=[...])\n\n# Simple - single message\nresponse = agent.run(messages=[\n    ChatMessage.user(\"What's the status?\")\n])\nprint(response.text)\n\n# With conversation history\nresponse = agent.run(messages=[\n    ChatMessage.user(\"What pods are running?\"),\n    ChatMessage.assistant(\"There are 3 pods: nginx, redis, api\"),\n    ChatMessage.user(\"Tell me more about nginx\"),  # \u2190 Current message (last)\n])\n</code></pre> <p>Important: The last message in the list is always treated as the current user message. All previous messages are conversation history.</p>"},{"location":"core/#using-plain-dicts-json-compatible","title":"Using Plain Dicts (JSON Compatible)","text":"<p>You can also pass plain dictionaries, which is useful when receiving messages from JSON:</p> <pre><code># From JSON/API request\nresponse = agent.run(messages=[\n    {\"role\": \"user\", \"content\": \"What pods are running?\"},\n    {\"role\": \"assistant\", \"content\": \"There are 3 pods...\"},\n    {\"role\": \"user\", \"content\": \"Tell me more\"},\n])\n\n# Or directly from request data\nresponse = agent.run(\n    messages=request_data[\"messages\"],\n    context=request_data.get(\"context\"),\n)\n</code></pre>"},{"location":"core/#handling-approvals","title":"Handling Approvals","text":"<pre><code>response = agent.run(\"Delete the pod\")\n\nif response.needs_approval:\n    # Option 1: Approve all\n    response = response.approve_all()\n\n    # Option 2: Reject all\n    response = response.reject_all(\"Too risky\")\n\n    # Option 3: Handle individually\n    for tool in response.pending_tools:\n        if confirm(f\"Run {tool.name}?\"):\n            tool.approve()\n        else:\n            tool.reject(\"User declined\")\n    response = agent.resume(response.conversation_id)\n</code></pre>"},{"location":"core/#defining-tools","title":"Defining Tools","text":"<p>Use the <code>@tool</code> decorator with one of three schema approaches:</p>"},{"location":"core/#option-1-auto-generate-simplest","title":"Option 1: Auto-Generate (Simplest)","text":"<pre><code>from dcaf.tools import tool\n\n@tool(description=\"Get current weather\")\ndef get_weather(city: str, units: str = \"celsius\") -&gt; str:\n    \"\"\"Get weather for a city.\"\"\"\n    return weather_api.get(city, units)\n</code></pre>"},{"location":"core/#option-2-dict-schema-full-control","title":"Option 2: Dict Schema (Full Control)","text":"<pre><code>@tool(\n    description=\"Get current weather\",\n    schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"city\": {\"type\": \"string\", \"description\": \"City name\"},\n            \"units\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n        },\n        \"required\": [\"city\"]\n    }\n)\ndef get_weather(city: str, units: str = \"celsius\") -&gt; str:\n    return weather_api.get(city, units)\n</code></pre>"},{"location":"core/#option-3-pydantic-model-type-safe","title":"Option 3: Pydantic Model (Type-Safe)","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass WeatherInput(BaseModel):\n    city: str = Field(..., description=\"City name\")\n    units: Literal[\"celsius\", \"fahrenheit\"] = Field(default=\"celsius\")\n\n@tool(description=\"Get current weather\", schema=WeatherInput)\ndef get_weather(city: str, units: str = \"celsius\") -&gt; str:\n    return weather_api.get(city, units)\n</code></pre>"},{"location":"core/#tool-options","title":"Tool Options","text":"Option Default Description <code>description</code> Docstring What the tool does (shown to LLM) <code>requires_approval</code> <code>False</code> Whether to require human approval <code>schema</code> Auto-generated Dict schema OR Pydantic model class"},{"location":"core/#approval-rules","title":"Approval Rules","text":"<p>Simple rule: Tools with <code>requires_approval=True</code> need human approval before execution.</p> <pre><code>@tool(requires_approval=True)\ndef delete_pod(name: str) -&gt; str:\n    \"\"\"Delete a pod - requires approval.\"\"\"\n    return kubectl(f\"delete pod {name}\")\n</code></pre>"},{"location":"core/#event-handling","title":"Event Handling","text":"<p>Subscribe to events for logging, notifications, or audit trails:</p> <pre><code>def log_events(event):\n    print(f\"[{event.event_type}] at {event.timestamp}\")\n\ndef notify_slack(event):\n    if event.event_type == \"ApprovalRequested\":\n        slack.post(\"Approval needed!\")\n\n# Single handler\nagent = Agent(tools=[...], on_event=log_events)\n\n# Multiple handlers\nagent = Agent(tools=[...], on_event=[log_events, notify_slack])\n</code></pre>"},{"location":"core/#event-types","title":"Event Types","text":"<ul> <li><code>ConversationStarted</code> - New conversation began</li> <li><code>ApprovalRequested</code> - Tools need approval</li> <li><code>ToolCallApproved</code> - User approved a tool</li> <li><code>ToolCallRejected</code> - User rejected a tool</li> <li><code>ToolExecuted</code> - Tool ran successfully</li> <li><code>ToolExecutionFailed</code> - Tool execution failed</li> </ul>"},{"location":"core/#interceptors","title":"Interceptors","text":"<p>Interceptors let you hook into the request/response pipeline. Use them to:</p> <ul> <li>Add context before sending to the LLM</li> <li>Validate or block suspicious input</li> <li>Clean up or redact responses</li> </ul> <pre><code>from dcaf.core import Agent, LLMRequest, LLMResponse, InterceptorError\n\n# Request interceptor - runs BEFORE the LLM call\ndef add_tenant_context(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Add tenant info to help the AI understand the environment.\"\"\"\n    tenant = request.context.get(\"tenant_name\", \"unknown\")\n    request.add_system_context(f\"User's tenant: {tenant}\")\n    return request\n\n# Security interceptor - block bad input\ndef block_prompt_injection(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Block suspicious prompts.\"\"\"\n    user_message = request.get_latest_user_message().lower()\n\n    if \"ignore previous instructions\" in user_message:\n        raise InterceptorError(\n            user_message=\"I can't process this request.\",\n            code=\"BLOCKED\",\n        )\n\n    return request\n\n# Response interceptor - runs AFTER the LLM call\ndef redact_secrets(response: LLMResponse) -&gt; LLMResponse:\n    \"\"\"Remove any leaked secrets.\"\"\"\n    response.text = response.text.replace(\"sk-secret123\", \"[REDACTED]\")\n    return response\n\n# Use interceptors\nagent = Agent(\n    tools=[...],\n    request_interceptors=[block_prompt_injection, add_tenant_context],\n    response_interceptors=redact_secrets,\n)\n</code></pre>"},{"location":"core/#async-interceptors","title":"Async Interceptors","text":"<p>Interceptors can be async (for database lookups, API calls, etc.):</p> <pre><code>async def get_user_preferences(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Look up user preferences from the database.\"\"\"\n    user_id = request.context.get(\"user_id\")\n    if user_id:\n        prefs = await database.get_preferences(user_id)\n        request.context[\"preferences\"] = prefs\n    return request\n\nagent = Agent(\n    request_interceptors=get_user_preferences,\n)\n</code></pre> <p>See the Interceptors Guide for comprehensive documentation.</p>"},{"location":"core/#session-management","title":"Session Management","text":"<p>Sessions persist state across conversation turns for multi-step workflows. They support typed storage with Pydantic models and dataclasses:</p> <pre><code>from pydantic import BaseModel, Field\nfrom dcaf.core import Session\nfrom dcaf.tools import tool\n\nclass CartItem(BaseModel):\n    name: str\n    quantity: int\n    price: float\n\nclass ShoppingCart(BaseModel):\n    items: list[CartItem] = Field(default_factory=list)\n\n@tool(description=\"Add item to cart\")\ndef add_to_cart(name: str, quantity: int, price: float, session: Session) -&gt; str:\n    # Get as typed model (auto-deserializes)\n    cart = session.get(\"cart\", as_type=ShoppingCart) or ShoppingCart()\n\n    cart.items.append(CartItem(name=name, quantity=quantity, price=price))\n\n    # Store typed model (auto-serializes)\n    session.set(\"cart\", cart)\n    return f\"Added {quantity}x {name}. {len(cart.items)} items in cart.\"\n\n@tool(description=\"Checkout\")\ndef checkout(session: Session) -&gt; str:\n    cart = session.get(\"cart\", as_type=ShoppingCart)\n    if not cart:\n        return \"Cart is empty\"\n\n    total = sum(item.price * item.quantity for item in cart.items)\n    session.delete(\"cart\")\n    return f\"Checked out ${total:.2f}!\"\n</code></pre> <p>Session data travels with the protocol in <code>data.session</code>:</p> <pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"Added 2x Widget.\",\n  \"data\": {\n    \"session\": {\"cart\": {\"items\": [{\"name\": \"Widget\", \"quantity\": 2, \"price\": 9.99}]}}\n  }\n}\n</code></pre> <p>See the Session Management Guide for comprehensive documentation.</p>"},{"location":"core/#streaming","title":"Streaming","text":"<p>For real-time token-by-token responses:</p> <pre><code>from dcaf.core import Agent, ChatMessage, TextDeltaEvent, DoneEvent\n\nagent = Agent(tools=[...])\n\nfor event in agent.run_stream(messages=[\n    ChatMessage.user(\"Tell me about Kubernetes\")\n]):\n    if isinstance(event, TextDeltaEvent):\n        print(event.text, end=\"\", flush=True)\n    elif isinstance(event, DoneEvent):\n        print(\"\\n--- Done ---\")\n</code></pre>"},{"location":"core/#running-as-a-server","title":"Running as a Server","text":"<p>Expose your agent as a REST API with one line:</p> <pre><code>from dcaf.core import Agent, serve\n\nagent = Agent(tools=[...])\nserve(agent, port=8000)  # Server at http://0.0.0.0:8000\n</code></pre> <p>Endpoints: - <code>GET /health</code> - Health check - <code>POST /api/chat</code> - Synchronous chat - <code>POST /api/chat-stream</code> - Streaming (NDJSON)</p> <p>See Server Documentation for full details.</p>"},{"location":"core/#a2a-agent-to-agent","title":"A2A (Agent-to-Agent)","text":"<p>DCAF supports the A2A protocol for agent-to-agent communication, enabling agents to discover and call each other.</p>"},{"location":"core/#server-expose-an-agent","title":"Server: Expose an Agent","text":"<pre><code>from dcaf.core import Agent, serve\n\nagent = Agent(\n    name=\"k8s-assistant\",              # A2A identity\n    description=\"Kubernetes helper\",   # A2A description\n    tools=[list_pods, delete_pod],\n)\n\n# Enable A2A protocol\nserve(agent, port=8000, a2a=True)\n</code></pre> <p>This adds A2A endpoints: - <code>GET /.well-known/agent.json</code> - Agent card (discovery) - <code>POST /a2a/tasks/send</code> - Receive tasks - <code>GET /a2a/tasks/{id}</code> - Task status</p>"},{"location":"core/#client-call-remote-agents","title":"Client: Call Remote Agents","text":"<pre><code>from dcaf.core.a2a import RemoteAgent\n\n# Connect to remote agent\nk8s = RemoteAgent(url=\"http://k8s-agent:8000\")\n\n# Send a task\nresult = k8s.send(\"List failing pods in production\")\nprint(result.text)\n</code></pre>"},{"location":"core/#multi-agent-orchestration","title":"Multi-Agent Orchestration","text":"<p>Remote agents can be used as tools for other agents:</p> <pre><code>from dcaf.core import Agent\nfrom dcaf.core.a2a import RemoteAgent\n\n# Connect to specialist agents\nk8s = RemoteAgent(url=\"http://k8s-agent:8000\")\naws = RemoteAgent(url=\"http://aws-agent:8000\")\n\n# Orchestrator routes to specialists\norchestrator = Agent(\n    name=\"orchestrator\",\n    tools=[k8s.as_tool(), aws.as_tool()],\n    system=\"Route requests to the appropriate specialist agent\"\n)\n\n# LLM decides which specialist to call\nresponse = orchestrator.run([\n    {\"role\": \"user\", \"content\": \"What's the status of my infrastructure?\"}\n])\n</code></pre> <p>Learn more: See the complete A2A Guide for patterns, examples, and best practices.</p>"},{"location":"core/#documentation","title":"Documentation","text":"<ul> <li>Server - Running agents as REST APIs</li> <li>Domain Layer - Core concepts: Conversation, ToolCall, Events</li> <li>Application Layer - Services and Ports</li> <li>Adapters - LLM framework adapters</li> <li>Testing - Test utilities and patterns</li> </ul>"},{"location":"core/#architecture","title":"Architecture","text":"<p>For those interested in the internals:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Agent                                 \u2502\n\u2502                   (Simple Facade)                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                     Application Layer                         \u2502\n\u2502              AgentService    ApprovalService                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      Domain Layer                             \u2502\n\u2502         Conversation   ToolCall   Message   Events            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                     Adapters Layer                            \u2502\n\u2502              AgnoAdapter    InMemoryRepository                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>The <code>Agent</code> class is a simple facade over the Clean Architecture internals. Most users only need the <code>Agent</code> class and the <code>@tool</code> decorator.</p>"},{"location":"core/a2a/","title":"A2A (Agent-to-Agent) Protocol","text":"<p>DCAF supports the A2A (Agent-to-Agent) protocol developed by Google, enabling agents to discover and communicate with each other using standardized HTTP/JSON-RPC interfaces.</p>"},{"location":"core/a2a/#overview","title":"Overview","text":"<p>A2A is an open protocol for agent-to-agent communication that enables:</p> <ul> <li>\ud83d\udd0d Agent Discovery: Agents expose a card describing their capabilities</li> <li>\ud83d\udce1 Task Execution: Agents can send tasks to other agents</li> <li>\u26a1 Async Support: Long-running tasks can execute asynchronously</li> <li>\ud83c\udf10 Standard Protocol: Uses HTTP, JSON-RPC, and SSE (Server-Sent Events)</li> </ul>"},{"location":"core/a2a/#why-a2a","title":"Why A2A?","text":"<p>Traditional monolithic agents try to do everything. With A2A, you can:</p> <ul> <li>Specialize: Build focused agents that excel at specific domains (K8s, AWS, databases)</li> <li>Compose: Combine specialist agents into powerful multi-agent systems</li> <li>Scale: Distribute work across multiple agents</li> <li>Interoperate: Work with agents from other frameworks that support A2A</li> </ul>"},{"location":"core/a2a/#quick-start","title":"Quick Start","text":""},{"location":"core/a2a/#server-expose-an-agent-via-a2a","title":"Server: Expose an Agent via A2A","text":"<pre><code>from dcaf.core import Agent, serve\nfrom dcaf.tools import tool\n\n@tool(description=\"List Kubernetes pods\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n\n# Create agent with A2A identity\nagent = Agent(\n    name=\"k8s-assistant\",              # A2A name (required for A2A)\n    description=\"Kubernetes helper\",   # A2A description\n    tools=[list_pods],\n)\n\n# Enable A2A alongside regular REST API\nserve(agent, port=8000, a2a=True)\n</code></pre> <p>When A2A is enabled, these endpoints are added:</p> Endpoint Purpose <code>GET /.well-known/agent.json</code> Agent card (discovery) <code>POST /a2a/tasks/send</code> Receive tasks <code>GET /a2a/tasks/{id}</code> Task status"},{"location":"core/a2a/#client-call-a-remote-agent","title":"Client: Call a Remote Agent","text":"<pre><code>from dcaf.core.a2a import RemoteAgent\n\n# Connect to remote agent\nk8s = RemoteAgent(url=\"http://k8s-agent:8000\")\n\n# Send a task\nresult = k8s.send(\"What pods are failing in production?\")\nprint(result.text)\n\n# Check agent capabilities\nprint(f\"Agent: {k8s.name}\")           # \"k8s-assistant\"\nprint(f\"Skills: {k8s.skills}\")        # [\"list_pods\", ...]\n</code></pre>"},{"location":"core/a2a/#agent-card-discovery","title":"Agent Card (Discovery)","text":"<p>When you expose an agent via A2A, it automatically generates an Agent Card that describes its capabilities. You can also provide a custom card for full control over the A2A discovery metadata.</p>"},{"location":"core/a2a/#auto-generated-card","title":"Auto-Generated Card","text":"<p>By default, the card is generated from your <code>Agent</code> instance:</p> <pre><code>{\n  \"name\": \"k8s-assistant\",\n  \"description\": \"Manages Kubernetes clusters\",\n  \"url\": \"http://k8s-agent:8000\",\n  \"skills\": [\"list_pods\", \"delete_pod\", \"describe_pod\"],\n  \"version\": \"1.0\",\n  \"metadata\": {\n    \"framework\": \"dcaf\",\n    \"model\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n    \"provider\": \"bedrock\"\n  }\n}\n</code></pre>"},{"location":"core/a2a/#custom-agent-card","title":"Custom Agent Card","text":"<p>For full control over the agent card \u2014 including fields from the A2A spec that DCAF doesn't auto-generate \u2014 pass <code>a2a_agent_card</code> to <code>serve()</code> or <code>create_app()</code>.</p>"},{"location":"core/a2a/#using-an-agentcard-instance","title":"Using an AgentCard instance","text":"<pre><code>from dcaf.core import Agent, serve\nfrom dcaf.core.a2a.models import AgentCard\n\nagent = Agent(name=\"my-agent\", tools=[...])\n\ncustom_card = AgentCard(\n    name=\"ci-cd-agent\",\n    description=\"Jenkins CI/CD assistant\",\n    url=\"\",  # Set automatically from request URL\n    skills=[\"fetch_logs\", \"trigger_build\"],\n    version=\"2.0\",\n    metadata={\"org\": \"duplocloud\", \"team\": \"platform\"},\n)\n\nserve(agent, a2a=True, a2a_agent_card=custom_card)\n</code></pre>"},{"location":"core/a2a/#using-a-dict-full-a2a-spec-compliance","title":"Using a dict (full A2A spec compliance)","text":"<p>Pass a dict to include arbitrary fields from the A2A spec without being limited to the <code>AgentCard</code> model:</p> <pre><code>from dcaf.core import Agent, create_app\n\nagent = Agent(name=\"my-agent\", tools=[...])\n\napp = create_app(agent, a2a=True, a2a_agent_card={\n    \"name\": \"ci-cd-agent\",\n    \"description\": \"Jenkins CI/CD assistant\",\n    \"skills\": [\"fetch_logs\", \"trigger_build\"],\n    \"authentication\": {\"schemes\": [\"bearer\"]},\n    \"capabilities\": {\"streaming\": True, \"pushNotifications\": False},\n    \"provider\": {\"organization\": \"DuploCloud\"},\n})\n</code></pre> <p>Note</p> <p>The <code>url</code> field is always set dynamically from the incoming request's base URL, regardless of whether you provide a custom card or use auto-generation.</p>"},{"location":"core/a2a/#accessing-agent-cards","title":"Accessing Agent Cards","text":"<pre><code>from dcaf.core.a2a import RemoteAgent\n\nremote = RemoteAgent(url=\"http://k8s-agent:8000\")\n\n# Card is fetched automatically on first access\nprint(remote.card.name)         # \"k8s-assistant\"\nprint(remote.card.description)  # \"Manages Kubernetes clusters\"\nprint(remote.card.skills)       # [\"list_pods\", \"delete_pod\", ...]\n</code></pre>"},{"location":"core/a2a/#multi-agent-patterns","title":"Multi-Agent Patterns","text":""},{"location":"core/a2a/#pattern-1-peer-to-peer","title":"Pattern 1: Peer-to-Peer","text":"<p>Agents directly communicate with each other.</p> <pre><code># === k8s_agent.py ===\nfrom dcaf.core import Agent, serve\n\nagent = Agent(\n    name=\"k8s-assistant\",\n    tools=[list_pods, delete_pod],\n)\nserve(agent, port=8001, a2a=True)\n\n\n# === aws_agent.py ===\nfrom dcaf.core import Agent, serve\n\nagent = Agent(\n    name=\"aws-assistant\",\n    tools=[list_ec2, describe_vpc],\n)\nserve(agent, port=8002, a2a=True)\n\n\n# === client.py ===\nfrom dcaf.core.a2a import RemoteAgent\n\nk8s = RemoteAgent(url=\"http://localhost:8001\")\naws = RemoteAgent(url=\"http://localhost:8002\")\n\n# Call each agent directly\nk8s_result = k8s.send(\"List pods\")\naws_result = aws.send(\"List EC2 instances\")\n</code></pre>"},{"location":"core/a2a/#pattern-2-orchestration","title":"Pattern 2: Orchestration","text":"<p>An orchestrator agent routes requests to specialist agents.</p> <pre><code>from dcaf.core import Agent\nfrom dcaf.core.a2a import RemoteAgent\n\n# Connect to specialist agents\nk8s = RemoteAgent(url=\"http://k8s-agent:8000\")\naws = RemoteAgent(url=\"http://aws-agent:8000\")\ndb = RemoteAgent(url=\"http://db-agent:8000\")\n\n# Orchestrator uses remote agents as tools\norchestrator = Agent(\n    name=\"orchestrator\",\n    tools=[\n        k8s.as_tool(),  # Wraps remote agent as a tool\n        aws.as_tool(),\n        db.as_tool(),\n    ],\n    system=\"\"\"You are an orchestrator that routes requests to specialist agents.\n    Use k8s_assistant for Kubernetes questions.\n    Use aws_assistant for AWS questions.\n    Use db_assistant for database questions.\"\"\"\n)\n\n# The LLM decides which specialist to call\nresponse = orchestrator.run([\n    {\"role\": \"user\", \"content\": \"How many pods are running and what's my AWS bill?\"}\n])\n# The orchestrator will call both k8s and aws agents\n</code></pre>"},{"location":"core/a2a/#remoteagent-api-reference","title":"RemoteAgent API Reference","text":""},{"location":"core/a2a/#constructor","title":"Constructor","text":"<pre><code>RemoteAgent(\n    url: str,\n    name: str | None = None,\n    adapter: A2AClientAdapter | None = None,\n)\n</code></pre> <p>Parameters:</p> <ul> <li><code>url</code>: Base URL of the remote agent (e.g., \"http://k8s-agent:8000\")</li> <li><code>name</code>: Optional name override (uses card name if not provided)</li> <li><code>adapter</code>: Optional custom A2A client adapter (default: Agno)</li> </ul>"},{"location":"core/a2a/#methods","title":"Methods","text":""},{"location":"core/a2a/#send","title":"send()","text":"<p>Send a message and wait for response (synchronous).</p> <pre><code>def send(\n    message: str,\n    context: dict | None = None,\n    timeout: float = 60.0,\n) -&gt; TaskResult\n</code></pre> <p>Example:</p> <pre><code>result = remote.send(\n    \"List pods in production\",\n    context={\"tenant_name\": \"prod\"},\n    timeout=120.0,\n)\nprint(result.text)\nprint(result.status)  # \"completed\", \"failed\", \"pending\"\n</code></pre>"},{"location":"core/a2a/#send_async","title":"send_async()","text":"<p>Send a message asynchronously (returns immediately).</p> <pre><code>def send_async(\n    message: str,\n    context: dict | None = None,\n) -&gt; str  # Returns task_id\n</code></pre> <p>Example:</p> <pre><code>task_id = remote.send_async(\"Analyze all pod logs\")\n\n# Later, check status\nresult = remote.get_task_status(task_id)\nif result.status == \"completed\":\n    print(result.text)\n</code></pre>"},{"location":"core/a2a/#as_tool","title":"as_tool()","text":"<p>Convert the remote agent to a tool for use by other agents.</p> <pre><code>def as_tool() -&gt; Tool\n</code></pre> <p>Example:</p> <pre><code>k8s = RemoteAgent(url=\"http://k8s-agent:8000\")\n\n# Use as a tool\norchestrator = Agent(\n    tools=[k8s.as_tool()],\n    system=\"Use k8s_assistant for Kubernetes questions\"\n)\n</code></pre>"},{"location":"core/a2a/#properties","title":"Properties","text":"<pre><code>remote.card         # AgentCard: Agent metadata\nremote.name         # str: Agent name\nremote.description  # str: Agent description\nremote.skills       # list[str]: List of tool names\n</code></pre>"},{"location":"core/a2a/#taskresult","title":"TaskResult","text":"<p>Response from a remote agent.</p> <pre><code>@dataclass\nclass TaskResult:\n    task_id: str              # ID of the task\n    text: str                 # Response text\n    status: str               # \"completed\", \"failed\", \"pending\"\n    artifacts: list[dict]     # Structured outputs\n    error: str | None         # Error message (if failed)\n    metadata: dict            # Additional metadata\n</code></pre> <p>Example:</p> <pre><code>result = remote.send(\"List pods\")\n\nprint(result.task_id)    # \"task_abc123\"\nprint(result.text)       # \"Here are the pods: nginx-abc, redis-xyz...\"\nprint(result.status)     # \"completed\"\nprint(result.artifacts)  # []\n</code></pre>"},{"location":"core/a2a/#server-configuration","title":"Server Configuration","text":""},{"location":"core/a2a/#basic-setup","title":"Basic Setup","text":"<pre><code>from dcaf.core import Agent, serve\n\nagent = Agent(\n    name=\"my-agent\",              # Required for A2A\n    description=\"Does X, Y, Z\",   # Recommended for A2A\n    tools=[...],\n)\n\n# Enable A2A\nserve(agent, port=8000, a2a=True)\n</code></pre>"},{"location":"core/a2a/#advanced-setup","title":"Advanced Setup","text":"<p>For more control over the FastAPI app:</p> <pre><code>from dcaf.core import Agent, create_app\nimport uvicorn\n\nagent = Agent(name=\"my-agent\", tools=[...])\n\n# Create app with A2A enabled\napp = create_app(agent, a2a=True)\n\n# Add custom middleware, etc.\n@app.middleware(\"http\")\nasync def log_requests(request, call_next):\n    print(f\"Request: {request.url}\")\n    return await call_next(request)\n\n# Run with custom configuration\nuvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"core/a2a/#custom-a2a-routes","title":"Custom A2A Routes","text":"<p>You can also manually add A2A routes:</p> <pre><code>from dcaf.core import Agent, create_app\nfrom dcaf.core.a2a import create_a2a_routes\n\nagent = Agent(name=\"my-agent\", tools=[...])\n\n# Create base app without A2A\napp = create_app(agent, a2a=False)\n\n# Add A2A routes manually\nfor router in create_a2a_routes(agent):\n    app.include_router(router)\n</code></pre>"},{"location":"core/a2a/#complete-example-multi-agent-system","title":"Complete Example: Multi-Agent System","text":"<p>This example shows a complete multi-agent system with three specialist agents and an orchestrator.</p>"},{"location":"core/a2a/#specialist-agent-1-kubernetes","title":"Specialist Agent 1: Kubernetes","text":"<pre><code># k8s_agent.py\nfrom dcaf.core import Agent, serve\nfrom dcaf.tools import tool\nimport subprocess\n\ndef kubectl(cmd: str) -&gt; str:\n    result = subprocess.run(\n        f\"kubectl {cmd}\",\n        shell=True,\n        capture_output=True,\n        text=True\n    )\n    return result.stdout or result.stderr\n\n@tool(description=\"List pods in a namespace\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n\n@tool(requires_approval=True, description=\"Delete a pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n\nagent = Agent(\n    name=\"k8s-assistant\",\n    description=\"Manages Kubernetes clusters\",\n    tools=[list_pods, delete_pod],\n)\n\nif __name__ == \"__main__\":\n    serve(agent, port=8001, a2a=True)\n</code></pre>"},{"location":"core/a2a/#specialist-agent-2-aws","title":"Specialist Agent 2: AWS","text":"<pre><code># aws_agent.py\nfrom dcaf.core import Agent, serve\nfrom dcaf.tools import tool\nimport boto3\n\n@tool(description=\"List EC2 instances\")\ndef list_ec2() -&gt; str:\n    ec2 = boto3.client('ec2')\n    response = ec2.describe_instances()\n    instances = []\n    for reservation in response['Reservations']:\n        for instance in reservation['Instances']:\n            instances.append(f\"{instance['InstanceId']} - {instance['State']['Name']}\")\n    return \"\\n\".join(instances)\n\nagent = Agent(\n    name=\"aws-assistant\",\n    description=\"Manages AWS resources\",\n    tools=[list_ec2],\n)\n\nif __name__ == \"__main__\":\n    serve(agent, port=8002, a2a=True)\n</code></pre>"},{"location":"core/a2a/#orchestrator-agent","title":"Orchestrator Agent","text":"<pre><code># orchestrator.py\nfrom dcaf.core import Agent, serve\nfrom dcaf.core.a2a import RemoteAgent\n\n# Connect to specialist agents\nk8s = RemoteAgent(url=\"http://localhost:8001\")\naws = RemoteAgent(url=\"http://localhost:8002\")\n\n# Orchestrator routes to specialists\norchestrator = Agent(\n    name=\"orchestrator\",\n    description=\"Routes requests to specialist agents\",\n    tools=[k8s.as_tool(), aws.as_tool()],\n    system=\"\"\"You are an intelligent orchestrator for infrastructure management.\n\n    You have access to two specialist agents:\n    - k8s_assistant: For Kubernetes questions (pods, deployments, services)\n    - aws_assistant: For AWS questions (EC2, VPC, billing)\n\n    Route each question to the appropriate specialist. You can call both if needed.\n    \"\"\",\n)\n\nif __name__ == \"__main__\":\n    serve(orchestrator, port=8000, a2a=True)\n</code></pre>"},{"location":"core/a2a/#usage","title":"Usage","text":"<pre><code># client.py\nfrom dcaf.core.a2a import RemoteAgent\n\n# Connect to orchestrator\norchestrator = RemoteAgent(url=\"http://localhost:8000\")\n\n# Ask a question - orchestrator will route to k8s agent\nresult = orchestrator.send(\"How many pods are running in production?\")\nprint(result.text)\n\n# Ask another - orchestrator will route to aws agent\nresult = orchestrator.send(\"List my EC2 instances\")\nprint(result.text)\n\n# Ask complex - orchestrator will call both\nresult = orchestrator.send(\"Give me a status of my infrastructure\")\nprint(result.text)\n</code></pre>"},{"location":"core/a2a/#testing","title":"Testing","text":""},{"location":"core/a2a/#testing-a2a-server","title":"Testing A2A Server","text":"<pre><code>import pytest\nfrom dcaf.core import Agent\nfrom dcaf.core.a2a import RemoteAgent, generate_agent_card\n\ndef test_agent_card_generation():\n    agent = Agent(\n        name=\"test-agent\",\n        description=\"Test agent\",\n        tools=[my_tool],\n    )\n\n    card = generate_agent_card(agent, \"http://localhost:8000\")\n\n    assert card.name == \"test-agent\"\n    assert card.description == \"Test agent\"\n    assert \"my_tool\" in card.skills\n\ndef test_a2a_task_execution():\n    # Start agent with A2A in a fixture\n    # ...\n\n    remote = RemoteAgent(url=\"http://localhost:8000\")\n    result = remote.send(\"Test message\")\n\n    assert result.status == \"completed\"\n    assert len(result.text) &gt; 0\n</code></pre>"},{"location":"core/a2a/#integration-testing","title":"Integration Testing","text":"<pre><code>import pytest\nfrom dcaf.core import Agent, create_app\nfrom fastapi.testclient import TestClient\n\n@pytest.fixture\ndef a2a_agent():\n    agent = Agent(\n        name=\"test\",\n        description=\"Test agent\",\n        tools=[my_tool],\n    )\n    return create_app(agent, a2a=True)\n\ndef test_agent_card_endpoint(a2a_agent):\n    client = TestClient(a2a_agent)\n    response = client.get(\"/.well-known/agent.json\")\n\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"name\"] == \"test\"\n    assert \"my_tool\" in data[\"skills\"]\n\ndef test_task_send_endpoint(a2a_agent):\n    client = TestClient(a2a_agent)\n    response = client.post(\n        \"/a2a/tasks/send\",\n        json={\n            \"id\": \"task_123\",\n            \"message\": \"Test message\",\n            \"context\": {},\n            \"status\": \"pending\",\n        }\n    )\n\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"status\"] in [\"completed\", \"pending\", \"failed\"]\n</code></pre>"},{"location":"core/a2a/#troubleshooting","title":"Troubleshooting","text":""},{"location":"core/a2a/#common-issues","title":"Common Issues","text":"<p>Issue: \"No A2A adapter available\"</p> <pre><code>RuntimeError: No A2A adapter available. Install agno with: pip install agno\n</code></pre> <p>Solution: Install required dependencies:</p> <pre><code>pip install httpx  # For A2A client\npip install agno   # For Agno adapter (optional)\n</code></pre> <p>Issue: \"Cannot reach agent at http://...\"</p> <pre><code>ConnectionError: Cannot reach agent at http://k8s-agent:8000\n</code></pre> <p>Solution:  - Check that the agent is running: <code>curl http://k8s-agent:8000/.well-known/agent.json</code> - Check network connectivity - Verify the URL is correct</p> <p>Issue: Agent card missing tools</p> <pre><code># Agent card shows: \"skills\": []\n</code></pre> <p>Solution: Make sure tools are provided when creating the agent:</p> <pre><code>agent = Agent(\n    name=\"my-agent\",\n    tools=[tool1, tool2],  # Must provide tools\n)\n</code></pre>"},{"location":"core/a2a/#best-practices","title":"Best Practices","text":""},{"location":"core/a2a/#1-name-your-agents","title":"1. Name Your Agents","text":"<p>Always provide a meaningful name for A2A agents:</p> <pre><code># Good\nagent = Agent(\n    name=\"k8s-prod-assistant\",\n    description=\"Manages production Kubernetes cluster\",\n    ...\n)\n\n# Bad\nagent = Agent(...)  # Default name: \"dcaf-agent\"\n</code></pre>"},{"location":"core/a2a/#2-provide-clear-descriptions","title":"2. Provide Clear Descriptions","text":"<p>Help other agents understand what your agent does:</p> <pre><code>agent = Agent(\n    name=\"k8s-assistant\",\n    description=\"Manages Kubernetes clusters. Can list, describe, delete pods and deployments.\",\n    ...\n)\n</code></pre>"},{"location":"core/a2a/#3-handle-errors-gracefully","title":"3. Handle Errors Gracefully","text":"<pre><code>from dcaf.core.a2a import RemoteAgent\n\nremote = RemoteAgent(url=\"http://k8s-agent:8000\")\n\ntry:\n    result = remote.send(\"List pods\", timeout=30.0)\n    if result.status == \"failed\":\n        print(f\"Task failed: {result.error}\")\n    else:\n        print(result.text)\nexcept ConnectionError:\n    print(\"Agent is not available\")\nexcept TimeoutError:\n    print(\"Task timed out\")\n</code></pre>"},{"location":"core/a2a/#4-use-async-for-long-running-tasks","title":"4. Use Async for Long-Running Tasks","text":"<pre><code># For tasks that take &gt; 30 seconds\ntask_id = remote.send_async(\"Analyze all logs\")\n\n# Poll for completion\nimport time\nwhile True:\n    result = remote.get_task_status(task_id)\n    if result.status in [\"completed\", \"failed\"]:\n        break\n    time.sleep(5)\n</code></pre>"},{"location":"core/a2a/#5-secure-your-a2a-endpoints","title":"5. Secure Your A2A Endpoints","text":"<pre><code>from fastapi import Depends, HTTPException\nfrom fastapi.security import HTTPBearer\n\nsecurity = HTTPBearer()\n\nasync def verify_token(credentials = Depends(security)):\n    if credentials.credentials != \"your-secret-token\":\n        raise HTTPException(status_code=401)\n\n# Add to routes\napp = create_app(agent, a2a=True)\n\n@app.middleware(\"http\")\nasync def auth_middleware(request, call_next):\n    # Implement your auth logic\n    return await call_next(request)\n</code></pre>"},{"location":"core/a2a/#see-also","title":"See Also","text":"<ul> <li>Core Overview</li> <li>Server Guide</li> <li>Custom Agents Guide</li> <li>Building Tools</li> <li>A2A Protocol Specification</li> </ul>"},{"location":"core/adapters/","title":"Adapters","text":"<p>Adapters translate between our domain and external systems. Each framework gets its own cohesive module containing all related code.</p>"},{"location":"core/adapters/#overview","title":"Overview","text":"<p>The adapters layer includes:</p> <ul> <li>Inbound Adapters: Handle incoming requests (HTTP, CLI)</li> <li>Outbound Adapters: Implement ports for external services (LLM frameworks, databases)</li> </ul>"},{"location":"core/adapters/#agno-adapter","title":"Agno Adapter","text":"<p>The Agno adapter provides integration with the Agno SDK for agent orchestration with Claude models on AWS Bedrock and other providers.</p> <p>Note: This adapter uses the real Agno SDK (<code>pip install agno</code>). For Bedrock, ensure you have valid AWS credentials configured: <pre><code># Option 1: Environment variables\nexport AWS_ACCESS_KEY_ID=your_access_key\nexport AWS_SECRET_ACCESS_KEY=your_secret_key\nexport AWS_REGION=us-east-1\n\n# Option 2: AWS Profile (recommended)\n# Uses ~/.aws/credentials profiles\nAgent(aws_profile=\"my-profile\")\n</code></pre></p>"},{"location":"core/adapters/#location","title":"Location","text":"<pre><code>dcaf/core/adapters/outbound/agno/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 adapter.py           # AgnoAdapter\n\u251c\u2500\u2500 tool_converter.py    # AgnoToolConverter\n\u251c\u2500\u2500 message_converter.py # AgnoMessageConverter\n\u2514\u2500\u2500 types.py             # Agno-specific types\n</code></pre>"},{"location":"core/adapters/#features","title":"Features","text":"<p>The Agno adapter includes production-proven patterns for reliability:</p> Feature Description Async Support Uses <code>aioboto3</code> for non-blocking AWS calls Message Filtering Removes tool messages to prevent Bedrock errors Alternation Validation Ensures user/assistant message alternation Parallel Tool Workaround Limits concurrent tool calls to prevent bugs Metrics Extraction Captures tokens, duration, and timing Region Inference Extracts region from ARN-style model IDs"},{"location":"core/adapters/#usage","title":"Usage","text":"<pre><code>from dcaf.core.adapters.outbound.agno import AgnoAdapter\n\n# Create adapter with AWS profile\nadapter = AgnoAdapter(\n    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n    provider=\"bedrock\",\n    aws_profile=\"my-profile\",\n    aws_region=\"us-west-2\",\n    max_tokens=4096,\n    temperature=0.1,\n)\n\n# Async invocation (preferred for FastAPI)\nresponse = await adapter.ainvoke(\n    messages=conversation.messages,\n    tools=[my_tool],\n    system_prompt=\"You are helpful.\",\n)\n\n# Sync invocation (wraps async internally)\nresponse = adapter.invoke(\n    messages=conversation.messages,\n    tools=[my_tool],\n)\n</code></pre>"},{"location":"core/adapters/#agnoadapter","title":"AgnoAdapter","text":"<p>Implements the <code>AgentRuntime</code> port with both sync and async interfaces.</p> <pre><code>class AgnoAdapter:\n    def __init__(\n        self,\n        model_id: str = \"anthropic.claude-3-sonnet-20240229-v1:0\",\n        provider: str = \"bedrock\",\n        max_tokens: int = 4096,\n        temperature: float = 0.1,\n        # AWS configuration\n        aws_profile: Optional[str] = None,\n        aws_region: Optional[str] = None,\n        aws_access_key: Optional[str] = None,\n        aws_secret_key: Optional[str] = None,\n        # Generic API key (for non-AWS providers)\n        api_key: Optional[str] = None,\n        # Behavior flags\n        tool_call_limit: Optional[int] = None,\n        disable_history: bool = False,\n        disable_tool_filtering: bool = False,\n    ): ...\n\n    # Async methods (preferred)\n    async def ainvoke(\n        self,\n        messages: List[Any],\n        tools: List[Any],\n        system_prompt: Optional[str] = None,\n    ) -&gt; AgentResponse: ...\n\n    async def ainvoke_stream(\n        self,\n        messages: List[Any],\n        tools: List[Any],\n        system_prompt: Optional[str] = None,\n    ) -&gt; AsyncIterator[StreamEvent]: ...\n\n    # Sync methods (wrap async internally)\n    def invoke(\n        self,\n        messages: List[Message],\n        tools: List[Tool],\n        system_prompt: Optional[str] = None,\n    ) -&gt; AgentResponse: ...\n\n    def invoke_stream(\n        self,\n        messages: List[Message],\n        tools: List[Tool],\n        system_prompt: Optional[str] = None,\n    ) -&gt; Iterator[StreamEvent]: ...\n\n    # Cleanup\n    async def cleanup(self) -&gt; None: ...\n</code></pre>"},{"location":"core/adapters/#tracing-and-observability","title":"Tracing and Observability","text":"<p>The Agno adapter supports distributed tracing through the <code>platform_context</code> parameter. Tracing IDs are passed to the Agno SDK and included in response metadata.</p> <p>Supported Tracing Fields:</p> Field Agno Parameter Description <code>user_id</code> <code>user_id</code> User identifier <code>session_id</code> <code>session_id</code> Session grouping runs <code>run_id</code> <code>run_id</code> Unique execution ID <code>request_id</code> <code>metadata.request_id</code> HTTP correlation ID <code>tenant_id</code> <code>metadata.tenant_id</code> Tenant identifier <p>Usage:</p> <pre><code># Via AgentRequest (recommended)\nrequest = AgentRequest(\n    content=\"What pods are running?\",\n    user_id=\"user-123\",\n    session_id=\"session-abc\",\n    run_id=\"run-xyz\",\n    request_id=\"req-456\",\n    tools=[kubectl_tool],\n)\n\n# Via platform_context dict\nresponse = await adapter.ainvoke(\n    messages=messages,\n    tools=tools,\n    platform_context={\n        \"user_id\": \"user-123\",\n        \"session_id\": \"session-abc\",\n        \"run_id\": \"run-xyz\",\n        \"request_id\": \"req-456\",\n        \"tenant_id\": \"tenant-1\",\n    },\n)\n\n# Tracing IDs returned in response metadata\nprint(response.metadata)\n# {'run_id': 'run-xyz', 'session_id': 'session-abc', ...}\n</code></pre> <p>Debug Mode:</p> <p>Enable Agno's verbose debug logging:</p> <pre><code># Option 1: Set Python log level to DEBUG\nLOG_LEVEL=DEBUG python your_agent.py\n\n# Option 2: Set AGNO_DEBUG directly\nAGNO_DEBUG=true python your_agent.py\n</code></pre> <p>See Tracing and Observability Guide for complete documentation.</p>"},{"location":"core/adapters/#environment-variables","title":"Environment Variables","text":"<p>The adapter supports configuration via environment variables:</p> Variable Default Description <code>AWS_REGION</code> <code>us-west-2</code> Default AWS region <code>AGNO_TOOL_CALL_LIMIT</code> <code>1</code> Max concurrent tool calls <code>AGNO_DISABLE_HISTORY</code> <code>false</code> Disable message history <code>DISABLE_TOOL_FILTERING</code> <code>false</code> Disable tool message filtering <code>LOG_LEVEL</code> <code>INFO</code> Python log level (<code>DEBUG</code> enables Agno verbose mode) <code>AGNO_DEBUG</code> <code>false</code> Enable Agno debug mode directly"},{"location":"core/adapters/#bedrock-compatibility","title":"Bedrock Compatibility","text":"<p>The adapter includes workarounds for Bedrock-specific issues:</p> <p>1. Message Filtering</p> <p>Tool-related messages are filtered from history to prevent <code>ValidationException</code>:</p> <pre><code># These message types are automatically filtered:\n# - Messages with content: null\n# - Messages with empty string content\n# - Messages with content: [...] (tool blocks)\n</code></pre> <p>2. Message Alternation</p> <p>Bedrock requires strict user/assistant alternation:</p> <pre><code># Automatically fixed:\n# - Leading assistant messages removed\n# - Consecutive same-role messages deduplicated\n</code></pre> <p>3. Parallel Tool Prevention</p> <p>A bug in Agno/Bedrock causes errors with parallel tool calls:</p> <pre><code># Workarounds applied:\n# - tool_call_limit=1 (default)\n# - System prompt instruction to call tools one at a time\n</code></pre>"},{"location":"core/adapters/#metrics","title":"Metrics","text":"<p>The adapter extracts metrics from each run:</p> <pre><code>@dataclass\nclass AgnoMetrics:\n    input_tokens: int = 0\n    output_tokens: int = 0\n    total_tokens: int = 0\n    duration: float = 0.0\n    time_to_first_token: Optional[float] = None\n</code></pre> <p>Metrics are logged automatically:</p> <pre><code>\ud83d\udcca Agno Metrics: tokens=1234 (in=100, out=1134), duration=2.345s\n\ud83d\udd27 Agno Tools: Executed 2 tool call(s)\n</code></pre>"},{"location":"core/adapters/#agnotoolconverter","title":"AgnoToolConverter","text":"<p>Converts dcaf Tools to Agno format.</p> <pre><code>from dcaf.core.adapters.outbound.agno import AgnoToolConverter\n\nconverter = AgnoToolConverter()\n\n# Convert single tool\nagno_tool = converter.to_agno(dcaf_tool)\n\n# Convert list of tools\nagno_tools = converter.to_agno_list(dcaf_tools)\n</code></pre>"},{"location":"core/adapters/#agnomessageconverter","title":"AgnoMessageConverter","text":"<p>Converts messages bidirectionally.</p> <pre><code>from dcaf.core.adapters.outbound.agno import AgnoMessageConverter\n\nconverter = AgnoMessageConverter()\n\n# Convert to Agno format\nagno_messages = converter.to_agno(dcaf_messages)\n\n# Convert from Agno response\nresponse = converter.from_agno(agno_response, conversation_id)\n\n# Convert streaming events\nstream_event = converter.stream_event_from_agno(agno_event)\n</code></pre>"},{"location":"core/adapters/#persistence-adapters","title":"Persistence Adapters","text":""},{"location":"core/adapters/#inmemoryconversationrepository","title":"InMemoryConversationRepository","text":"<p>Simple in-memory implementation for testing and development.</p> <pre><code>from dcaf.core.adapters.outbound.persistence import InMemoryConversationRepository\n\nrepo = InMemoryConversationRepository()\n\n# Save conversation\nrepo.save(conversation)\n\n# Retrieve\nloaded = repo.get(conversation.id)\n\n# Check existence\nexists = repo.exists(conversation.id)\n\n# Get or create\nconv = repo.get_or_create(ConversationId(\"new-id\"))\n\n# Delete\ndeleted = repo.delete(conversation.id)\n\n# Utility methods\nrepo.clear()      # Clear all conversations\nrepo.count()      # Get count\nrepo.all()        # Get all conversations\n</code></pre> <p>Thread Safety: Uses a reentrant lock for concurrent access.</p> <p>Limitations: - Data is lost when process ends - Not suitable for distributed systems - Use for testing and single-instance deployments only</p>"},{"location":"core/adapters/#adding-a-new-framework-adapter","title":"Adding a New Framework Adapter","text":"<p>Follow these steps to add support for a new LLM framework (e.g., LangChain).</p>"},{"location":"core/adapters/#step-1-create-the-module-structure","title":"Step 1: Create the Module Structure","text":"<pre><code>dcaf/core/adapters/outbound/langchain/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 adapter.py\n\u251c\u2500\u2500 tool_converter.py\n\u251c\u2500\u2500 message_converter.py\n\u2514\u2500\u2500 types.py\n</code></pre>"},{"location":"core/adapters/#step-2-define-types","title":"Step 2: Define Types","text":"<pre><code># types.py\nfrom typing import TypedDict, List, Dict, Any\n\nclass LangChainMessage(TypedDict):\n    role: str\n    content: str\n\nclass LangChainTool(TypedDict):\n    name: str\n    description: str\n    parameters: Dict[str, Any]\n</code></pre>"},{"location":"core/adapters/#step-3-implement-tool-converter","title":"Step 3: Implement Tool Converter","text":"<pre><code># tool_converter.py\nfrom dcaf.tools import Tool\n\nclass LangChainToolConverter:\n    def to_langchain(self, tool: Tool) -&gt; dict:\n        return {\n            \"name\": tool.name,\n            \"description\": tool.description,\n            \"parameters\": tool.schema.get(\"input_schema\", {}),\n        }\n\n    def to_langchain_list(self, tools: List[Tool]) -&gt; List[dict]:\n        return [self.to_langchain(t) for t in tools]\n</code></pre>"},{"location":"core/adapters/#step-4-implement-message-converter","title":"Step 4: Implement Message Converter","text":"<pre><code># message_converter.py\nfrom dcaf.core.domain.entities import Message, MessageRole\nfrom dcaf.core.application.dto import AgentResponse\n\nclass LangChainMessageConverter:\n    def to_langchain(self, messages: List[Message]) -&gt; List[dict]:\n        return [\n            {\n                \"role\": self._convert_role(m.role),\n                \"content\": m.text or \"\",\n            }\n            for m in messages\n        ]\n\n    def from_langchain(\n        self, \n        response: dict,\n        conversation_id: str,\n    ) -&gt; AgentResponse:\n        # Parse LangChain response format\n        ...\n\n    def _convert_role(self, role: MessageRole) -&gt; str:\n        mapping = {\n            MessageRole.USER: \"human\",\n            MessageRole.ASSISTANT: \"ai\",\n            MessageRole.SYSTEM: \"system\",\n        }\n        return mapping.get(role, \"human\")\n</code></pre>"},{"location":"core/adapters/#step-5-implement-adapter","title":"Step 5: Implement Adapter","text":"<pre><code># adapter.py\nfrom dcaf.core.application.ports import AgentRuntime\nfrom .tool_converter import LangChainToolConverter\nfrom .message_converter import LangChainMessageConverter\n\nclass LangChainAdapter:\n    def __init__(self, model: str):\n        self._tool_converter = LangChainToolConverter()\n        self._message_converter = LangChainMessageConverter()\n        # Initialize LangChain components\n\n    def invoke(\n        self,\n        messages: List[Message],\n        tools: List[Tool],\n        system_prompt: Optional[str] = None,\n    ) -&gt; AgentResponse:\n        # 1. Convert to LangChain format\n        lc_messages = self._message_converter.to_langchain(messages)\n        lc_tools = self._tool_converter.to_langchain_list(tools)\n\n        # 2. Call LangChain\n        response = self._chain.invoke(lc_messages, tools=lc_tools)\n\n        # 3. Convert back\n        return self._message_converter.from_langchain(\n            response, \n            conversation_id=\"...\"\n        )\n</code></pre>"},{"location":"core/adapters/#step-6-export-from-__init__py","title":"Step 6: Export from <code>__init__.py</code>","text":"<pre><code># __init__.py\nfrom .adapter import LangChainAdapter\nfrom .tool_converter import LangChainToolConverter\nfrom .message_converter import LangChainMessageConverter\n\n__all__ = [\n    \"LangChainAdapter\",\n    \"LangChainToolConverter\", \n    \"LangChainMessageConverter\",\n]\n</code></pre>"},{"location":"core/adapters/#best-practices","title":"Best Practices","text":"<ol> <li>Isolate framework code: All framework-specific code stays in its adapter folder</li> <li>Don't leak abstractions: Convert to/from domain types at adapter boundaries</li> <li>Handle errors gracefully: Catch framework exceptions and convert to domain exceptions</li> <li>Support streaming: Implement both sync and streaming methods</li> <li>Test converters independently: Unit test converters without the full framework</li> <li>Document framework requirements: Note which framework version is supported</li> </ol>"},{"location":"core/application/","title":"Application Layer","text":"<p>The application layer orchestrates domain logic with infrastructure through use cases and ports. It contains no business logic itself\u2014that belongs in the domain.</p>"},{"location":"core/application/#overview","title":"Overview","text":"<p>The application layer includes:</p> <ul> <li>Ports: Interfaces (protocols) for external systems</li> <li>Services: Application services that orchestrate operations</li> <li>DTOs: Data transfer objects for communication</li> </ul>"},{"location":"core/application/#ports","title":"Ports","text":"<p>Ports define how the application interacts with external systems. They are implemented by adapters.</p>"},{"location":"core/application/#agentruntime","title":"AgentRuntime","text":"<p>The primary port for LLM framework integration.</p> <pre><code>from dcaf.core.application.ports import AgentRuntime\nfrom typing import Protocol, List, Iterator\n\nclass AgentRuntime(Protocol):\n    \"\"\"Port that adapters implement.\"\"\"\n\n    def invoke(\n        self, \n        messages: List[Message],\n        tools: List[Tool],\n        system_prompt: Optional[str] = None,\n    ) -&gt; AgentResponse:\n        \"\"\"Synchronous agent invocation.\"\"\"\n        ...\n\n    def invoke_stream(\n        self, \n        messages: List[Message],\n        tools: List[Tool],\n        system_prompt: Optional[str] = None,\n    ) -&gt; Iterator[StreamEvent]:\n        \"\"\"Streaming agent invocation.\"\"\"\n        ...\n</code></pre> <p>Implementations: - <code>AgnoAdapter</code> - Agno framework - <code>LangChainAdapter</code> - LangChain framework (future) - <code>BedrockDirectAdapter</code> - Direct Bedrock access (future)</p>"},{"location":"core/application/#conversationrepository","title":"ConversationRepository","text":"<p>Persistence port for conversations.</p> <pre><code>from dcaf.core.application.ports import ConversationRepository\n\nclass ConversationRepository(Protocol):\n    def get(self, id: ConversationId) -&gt; Optional[Conversation]: ...\n    def save(self, conversation: Conversation) -&gt; None: ...\n    def delete(self, id: ConversationId) -&gt; bool: ...\n    def exists(self, id: ConversationId) -&gt; bool: ...\n    def get_or_create(self, id: ConversationId) -&gt; Conversation: ...\n</code></pre> <p>Implementations: - <code>InMemoryConversationRepository</code> - For testing and simple use cases</p>"},{"location":"core/application/#approvalcallback","title":"ApprovalCallback","text":"<p>Port for requesting human approval.</p> <pre><code>from dcaf.core.application.ports import ApprovalCallback, ApprovalDecision\n\nclass ApprovalCallback(Protocol):\n    def request_approval(\n        self, \n        tool_calls: List[ToolCall],\n    ) -&gt; List[ApprovalDecision]:\n        \"\"\"Request approval for tool calls.\"\"\"\n        ...\n\n    def notify_execution_result(\n        self,\n        tool_call_id: str,\n        result: str,\n        success: bool,\n    ) -&gt; None:\n        \"\"\"Notify of execution results.\"\"\"\n        ...\n</code></pre>"},{"location":"core/application/#eventpublisher","title":"EventPublisher","text":"<p>Port for publishing domain events.</p> <pre><code>from dcaf.core.application.ports import EventPublisher\n\nclass EventPublisher(Protocol):\n    def publish(self, event: DomainEvent) -&gt; None: ...\n    def publish_all(self, events: List[DomainEvent]) -&gt; None: ...\n</code></pre>"},{"location":"core/application/#services","title":"Services","text":"<p>Use cases orchestrate the execution of business operations.</p>"},{"location":"core/application/#agentservice","title":"AgentService","text":"<p>The main use case for agent execution.</p> <pre><code>from dcaf.core.application.services import AgentService\nfrom dcaf.core.application.dto import AgentRequest\n\n# Setup\nservice = AgentService(\n    runtime=agno_adapter,\n    conversations=conversation_repo,\n    events=event_publisher,\n    approval_policy=ApprovalPolicy(),\n)\n\n# Execute synchronously\nresponse = service.execute(AgentRequest(\n    content=\"What pods are running?\",\n    tools=[kubectl_tool],\n    conversation_id=\"conv-123\",  # Optional, creates new if not provided\n    context={\"tenant_name\": \"my-tenant\"},\n))\n\n# Handle response\nif response.has_pending_approvals:\n    # Tool calls need approval\n    for tc in response.pending_tool_calls:\n        print(f\"Approve {tc.name}? {tc.input}\")\nelse:\n    # Response is complete\n    print(response.text)\n</code></pre> <p>Streaming:</p> <pre><code># Execute with streaming\nfor event in service.execute_stream(request):\n    if event.event_type == StreamEventType.TEXT_DELTA:\n        print(event.data[\"text\"], end=\"\")\n    elif event.event_type == StreamEventType.MESSAGE_END:\n        final_response = event.data[\"response\"]\n</code></pre> <p>Resume After Approval:</p> <pre><code># After user approves tool calls\nresponse = service.resume(\n    conversation_id=\"conv-123\",\n    tools=[kubectl_tool],\n)\n</code></pre>"},{"location":"core/application/#approvalservice","title":"ApprovalService","text":"<p>Handles approval decisions for pending tool calls.</p> <pre><code>from dcaf.core.application.services import ApprovalService\nfrom dcaf.core.application.dto import ApprovalRequest, ToolCallApproval\n\nservice = ApprovalService(\n    conversations=conversation_repo,\n    events=event_publisher,\n)\n\n# Approve specific tool calls\nresponse = service.execute(ApprovalRequest(\n    conversation_id=\"conv-123\",\n    approvals=[\n        ToolCallApproval(tool_call_id=\"tc-1\", approved=True),\n        ToolCallApproval(tool_call_id=\"tc-2\", approved=False, rejection_reason=\"Too risky\"),\n    ],\n))\n\n# Convenience methods\nresponse = service.approve_single(\"conv-123\", \"tc-1\")\nresponse = service.reject_single(\"conv-123\", \"tc-2\", \"Not needed\")\nresponse = service.approve_all(\"conv-123\")\nresponse = service.reject_all(\"conv-123\", \"User cancelled\")\n</code></pre>"},{"location":"core/application/#dtos","title":"DTOs","text":"<p>Data Transfer Objects for communication between layers.</p>"},{"location":"core/application/#agentrequest","title":"AgentRequest","text":"<p>Request DTO for agent execution.</p> <pre><code>from dcaf.core.application.dto import AgentRequest\n\nrequest = AgentRequest(\n    content=\"What pods are running?\",\n    conversation_id=\"conv-123\",\n    context={\"tenant_name\": \"my-tenant\", \"k8s_namespace\": \"default\"},\n    tools=[kubectl_tool, aws_tool],\n    system_prompt=\"You are a helpful DevOps assistant.\",\n    stream=False,\n    # Tracing fields (optional)\n    user_id=\"user-123\",\n    session_id=\"session-abc\",\n    run_id=\"run-xyz\",\n    request_id=\"req-456\",\n)\n\n# Access helpers\nconv_id = request.get_conversation_id()  # ConversationId value object\ncontext = request.get_platform_context()  # PlatformContext with tracing merged in\n</code></pre> <p>Tracing Fields:</p> Field Description <code>user_id</code> User identifier for tracking and analytics <code>session_id</code> Groups related runs into a session <code>run_id</code> Unique identifier for this execution <code>request_id</code> HTTP request correlation ID <p>See Tracing and Observability Guide for details.</p>"},{"location":"core/application/#agentresponse","title":"AgentResponse","text":"<p>Response DTO from agent execution.</p> <pre><code>from dcaf.core.application.dto import AgentResponse\n\n# Properties\nresponse.conversation_id  # str\nresponse.text             # Optional[str]\nresponse.tool_calls       # List[ToolCallDTO]\nresponse.has_pending_approvals  # bool\nresponse.is_complete      # bool\n\n# Helpers\nresponse.pending_tool_calls   # Tool calls awaiting approval\nresponse.approved_tool_calls  # Tool calls that were approved\nresponse.executed_tool_calls  # Tool calls that completed\n\n# Serialization\nresponse.to_dict()\n</code></pre>"},{"location":"core/application/#toolcalldto","title":"ToolCallDTO","text":"<p>DTO representing a tool call.</p> <pre><code>from dcaf.core.application.dto import ToolCallDTO\n\ntc = ToolCallDTO(\n    id=\"tc-123\",\n    name=\"kubectl\",\n    input={\"command\": \"get pods\"},\n    description=\"Execute kubectl commands\",\n    intent=\"List running pods\",\n    requires_approval=True,\n    status=\"pending\",  # pending, approved, completed, rejected, failed\n    result=None,\n    error=None,\n)\n\n# From domain entity\ntc = ToolCallDTO.from_tool_call(tool_call_entity)\n</code></pre>"},{"location":"core/application/#streamevent","title":"StreamEvent","text":"<p>Streaming event for real-time responses.</p> <pre><code>from dcaf.core.application.dto import StreamEvent, StreamEventType\n\n# Event types\nStreamEventType.TEXT_DELTA       # Text chunk\nStreamEventType.TOOL_USE_START   # Tool call starting\nStreamEventType.TOOL_USE_DELTA   # Tool call input chunk\nStreamEventType.TOOL_USE_END     # Tool call complete\nStreamEventType.MESSAGE_START    # Message starting\nStreamEventType.MESSAGE_END      # Message complete with response\nStreamEventType.ERROR            # Error occurred\n\n# Factory methods\nevent = StreamEvent.text_delta(\"Hello\")\nevent = StreamEvent.tool_use_start(\"tc-123\", \"kubectl\")\nevent = StreamEvent.error(\"Connection failed\", code=\"TIMEOUT\")\n</code></pre>"},{"location":"core/application/#wiring-it-together","title":"Wiring It Together","text":"<p>Here's a complete example of setting up the application layer:</p> <pre><code>from dcaf.core.adapters.outbound.agno import AgnoAdapter\nfrom dcaf.core.adapters.outbound.persistence import InMemoryConversationRepository\nfrom dcaf.core.application.services import AgentService, ApprovalService\nfrom dcaf.core.domain.services import ApprovalPolicy\nfrom dcaf.core.testing import FakeEventPublisher\n\n# Create adapters\nruntime = AgnoAdapter(\n    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n    provider=\"bedrock\",\n)\nconversations = InMemoryConversationRepository()\nevents = FakeEventPublisher()  # Or a real implementation\n\n# Create policy\npolicy = ApprovalPolicy()\n\n# Create use cases\nexecute_agent = AgentService(\n    runtime=runtime,\n    conversations=conversations,\n    events=events,\n    approval_policy=policy,\n)\n\napprove_tool_call = ApprovalService(\n    conversations=conversations,\n    events=events,\n)\n</code></pre>"},{"location":"core/application/#best-practices","title":"Best Practices","text":"<ol> <li>Use DTOs at boundaries: Don't pass domain entities directly to external layers</li> <li>Keep use cases thin: They orchestrate, they don't contain business logic</li> <li>Inject dependencies: Use constructor injection for all ports</li> <li>Handle events: Publish domain events for audit trails and side effects</li> <li>Validate inputs: DTOs should validate their inputs</li> </ol>"},{"location":"core/domain/","title":"Domain Layer","text":"<p>The domain layer contains the core business logic for DCAF. It's pure Python with no external dependencies.</p>"},{"location":"core/domain/#overview","title":"Overview","text":"Component What it is When you use it Conversation Container for messages and tool calls Automatically managed by Agent Message A single message (user, assistant, system) Rarely used directly ToolCall A request to execute a tool Returned when approval is needed ApprovalPolicy Rules for what needs approval Advanced: custom approval rules Domain Events Records of what happened Advanced: audit trails, notifications"},{"location":"core/domain/#conversation","title":"Conversation","text":"<p>The <code>Conversation</code> is the central container that holds: - The ordered list of messages - Pending tool calls awaiting approval - Domain events that occurred</p>"},{"location":"core/domain/#key-rule","title":"Key Rule","text":"<p>You cannot add a new user message while tool calls are pending approval.</p> <p>This prevents the conversation from continuing before the user deals with pending actions.</p>"},{"location":"core/domain/#simple-usage","title":"Simple Usage","text":"<pre><code>from dcaf.core import Conversation\n\n# Create a new conversation\nconversation = Conversation.create()\n\n# Add messages (accepts strings directly)\nconversation.add_user_message(\"Hello!\")\nconversation.add_assistant_message(\"Hi there!\")\nconversation.add_system_message(\"You are a helpful assistant.\")\n\n# Check state\nprint(f\"Messages: {conversation.message_count}\")\nprint(f\"Blocked: {conversation.is_blocked}\")\n</code></pre>"},{"location":"core/domain/#with-system-prompt","title":"With System Prompt","text":"<pre><code>conversation = Conversation.with_system_prompt(\n    \"You are a Kubernetes assistant. Be concise.\"\n)\n</code></pre>"},{"location":"core/domain/#handling-approvals","title":"Handling Approvals","text":"<pre><code># When blocked by pending approvals\nif conversation.has_pending_approvals:\n    for tc in conversation.pending_tool_calls:\n        print(f\"Pending: {tc.tool_name}\")\n\n    # Approve or reject\n    conversation.approve_tool_call(\"tc-123\")\n    # or\n    conversation.reject_tool_call(\"tc-123\", \"Too risky\")\n</code></pre>"},{"location":"core/domain/#toolcall","title":"ToolCall","text":"<p>A <code>ToolCall</code> represents a request to execute a tool. It has a state machine that tracks its lifecycle.</p>"},{"location":"core/domain/#states","title":"States","text":"<pre><code>PENDING \u2192 APPROVED \u2192 EXECUTING \u2192 COMPLETED\n    \u2502                     \u2502\n    \u2514\u2192 REJECTED           \u2514\u2192 FAILED\n</code></pre>"},{"location":"core/domain/#properties","title":"Properties","text":"Property Type Description <code>id</code> str Unique identifier <code>tool_name</code> str Name of the tool <code>input</code> dict Parameters for the tool <code>status</code> enum Current state <code>requires_approval</code> bool Whether approval was needed <code>result</code> str Output (if completed) <code>rejection_reason</code> str Why rejected (if rejected) <code>error</code> str Error message (if failed)"},{"location":"core/domain/#status-checks","title":"Status Checks","text":"<pre><code>tool_call.is_pending     # Waiting for approval\ntool_call.is_approved    # Approved, ready to execute\ntool_call.is_rejected    # User rejected it\ntool_call.is_completed   # Successfully executed\ntool_call.is_failed      # Execution failed\ntool_call.is_terminal    # In a final state (completed/rejected/failed)\n</code></pre>"},{"location":"core/domain/#message","title":"Message","text":"<p>Messages are simple - they have a role and content.</p>"},{"location":"core/domain/#roles","title":"Roles","text":"<ul> <li><code>USER</code> - Messages from the human</li> <li><code>ASSISTANT</code> - Messages from the LLM</li> <li><code>SYSTEM</code> - System prompts/instructions</li> </ul>"},{"location":"core/domain/#creating-messages","title":"Creating Messages","text":"<pre><code>from dcaf.core import Message\n\n# Factory methods (for advanced use)\nmsg = Message.user(\"Hello\")\nmsg = Message.assistant(\"Hi there!\")\nmsg = Message.system(\"You are helpful.\")\n\n# Properties\nmsg.text           # The text content\nmsg.role           # USER, ASSISTANT, or SYSTEM\nmsg.is_user_message\nmsg.is_assistant_message\nmsg.is_system_message\n</code></pre>"},{"location":"core/domain/#approval-policy","title":"Approval Policy","text":"<p>The <code>ApprovalPolicy</code> determines which tools need human approval.</p>"},{"location":"core/domain/#how-approval-works","title":"How Approval Works","text":"<p>Rule: If EITHER the tool OR the policy says it's risky, require approval.</p> Tool Setting Policy Setting Result <code>requires_approval=True</code> (any) Requires approval <code>requires_approval=False</code> Not in high-risk list Auto-executes <code>requires_approval=False</code> In high-risk list Requires approval"},{"location":"core/domain/#simple-usage_1","title":"Simple Usage","text":"<p>Most users just set <code>requires_approval</code> on the tool:</p> <pre><code>from dcaf.tools import tool\n\n@tool(requires_approval=True)  # Always needs approval\ndef delete_pod(name: str) -&gt; str:\n    return kubectl(f\"delete pod {name}\")\n\n@tool(requires_approval=False)  # Auto-executes\ndef list_pods() -&gt; str:\n    return kubectl(\"get pods\")\n</code></pre>"},{"location":"core/domain/#domain-events","title":"Domain Events","text":"<p>Events are immutable records of significant things that happened.</p>"},{"location":"core/domain/#available-events","title":"Available Events","text":"Event When it fires Key data <code>ConversationStarted</code> New conversation created <code>conversation_id</code> <code>ApprovalRequested</code> Tool calls need approval <code>conversation_id</code>, <code>tool_calls</code> <code>ToolCallApproved</code> User approved a tool <code>tool_call_id</code>, <code>approved_by</code> <code>ToolCallRejected</code> User rejected a tool <code>tool_call_id</code>, <code>reason</code> <code>ToolExecuted</code> Tool ran successfully <code>tool_call</code>, <code>result</code> <code>ToolExecutionFailed</code> Tool execution failed <code>tool_call_id</code>, <code>error</code>"},{"location":"core/domain/#subscribing-to-events","title":"Subscribing to Events","text":"<pre><code>from dcaf.core import Agent\n\ndef log_event(event):\n    print(f\"[{event.event_type}] {event.timestamp}\")\n\ndef send_slack_notification(event):\n    if event.event_type == \"ApprovalRequested\":\n        slack.post(f\"Approval needed: {len(event.tool_calls)} tool(s)\")\n\n# Single handler\nagent = Agent(tools=[...], on_event=log_event)\n\n# Multiple handlers\nagent = Agent(tools=[...], on_event=[log_event, send_slack_notification])\n</code></pre>"},{"location":"core/domain/#event-properties","title":"Event Properties","text":"<p>All events have: - <code>timestamp</code> - When the event occurred - <code>event_type</code> - The event class name (e.g., \"ApprovalRequested\")</p>"},{"location":"core/domain/#platformcontext","title":"PlatformContext","text":"<p>The <code>PlatformContext</code> value object carries runtime context through the system, including tenant information, credentials, and tracing identifiers.</p>"},{"location":"core/domain/#tracing-fields","title":"Tracing Fields","text":"Field Description <code>user_id</code> User identifier for tracking and analytics <code>session_id</code> Groups related runs into a session <code>run_id</code> Unique identifier for this execution <code>request_id</code> HTTP request correlation ID"},{"location":"core/domain/#usage","title":"Usage","text":"<pre><code>from dcaf.core.domain.value_objects import PlatformContext\n\n# Create with tracing\ncontext = PlatformContext(\n    tenant_id=\"tenant-1\",\n    user_id=\"user-123\",\n    session_id=\"session-abc\",\n    run_id=\"run-xyz\",\n)\n\n# Add tracing to existing context\ncontext = PlatformContext.from_dict({\"tenant_id\": \"tenant-1\"})\ncontext = context.with_tracing(\n    user_id=\"user-123\",\n    session_id=\"session-abc\",\n)\n\n# Get only tracing fields (safe to log)\ntracing = context.get_tracing_dict()\n# {'user_id': 'user-123', 'session_id': 'session-abc'}\n</code></pre> <p>See Tracing and Observability Guide for details.</p>"},{"location":"core/domain/#advanced-direct-domain-access","title":"Advanced: Direct Domain Access","text":"<p>For advanced use cases, you can work with domain objects directly:</p> <pre><code>from dcaf.core.domain.entities import Conversation, ToolCall, Message\nfrom dcaf.core.domain.value_objects import ToolCallId, ToolInput, PlatformContext\nfrom dcaf.core.domain.events import ApprovalRequested\nfrom dcaf.core.domain.services import ApprovalPolicy\nfrom dcaf.core.domain.exceptions import ConversationBlocked, ToolCallNotFound\n\n# Create a tool call manually\ntool_call = ToolCall(\n    id=ToolCallId.generate(),\n    tool_name=\"kubectl\",\n    input=ToolInput({\"command\": \"get pods\"}),\n    requires_approval=True,\n)\n\n# State transitions\ntool_call.approve()\ntool_call.start_execution()\ntool_call.complete(\"pod-1, pod-2, pod-3\")\n</code></pre> <p>Most users won't need this level of control - the <code>Agent</code> class handles it automatically.</p>"},{"location":"core/helpdesk-protocol/","title":"HelpDesk Protocol Compatibility","text":"<p>DCAF Core provides full compatibility with the DuploCloud HelpDesk messaging protocol. This enables seamless integration with the HelpDesk frontend and existing agent infrastructure.</p>"},{"location":"core/helpdesk-protocol/#overview","title":"Overview","text":"<p>The HelpDesk protocol defines a rich message format that includes:</p> <ul> <li>Commands: Terminal commands for user approval and execution</li> <li>Tool Calls: Structured tool invocations with approval workflow</li> <li>Platform Context: Runtime context (tenant, namespace, credentials)</li> <li>Streaming Events: Real-time updates during agent execution</li> </ul> <p>DCAF Core replicates this protocol in the <code>dcaf.core</code> module, ensuring compatibility while providing a cleaner, more Pythonic API.</p>"},{"location":"core/helpdesk-protocol/#quick-start","title":"Quick Start","text":"<pre><code>from dcaf.core import (\n    Agent,\n    PlatformContext,\n    ChatMessage,\n    # HelpDesk DTOs\n    DataDTO,\n    CommandDTO,\n    ExecutedCommandDTO,\n    ToolCallDTO,\n    ExecutedToolCallDTO,\n    StreamEvent,\n)\nfrom dcaf.tools import tool\n\n# Define tools\n@tool(description=\"List Kubernetes pods\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n\n@tool(requires_approval=True, description=\"Delete a pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n\n# Create agent\nagent = Agent(tools=[list_pods, delete_pod])\n\n# Create message with platform context\ncontext = PlatformContext(\n    tenant_name=\"acme-prod\",\n    k8s_namespace=\"default\",\n    duplo_base_url=\"https://acme.duplocloud.net\",\n)\n\nresponse = agent.run(\n    messages=[ChatMessage.user(\"Delete the nginx pod\", context=context)]\n)\n</code></pre>"},{"location":"core/helpdesk-protocol/#platform-context","title":"Platform Context","text":"<p><code>PlatformContext</code> carries runtime information about the user's environment:</p> <pre><code>from dcaf.core import PlatformContext\n\ncontext = PlatformContext(\n    # Kubernetes\n    k8s_namespace=\"production\",\n    kubeconfig=\"/path/to/kubeconfig\",\n\n    # DuploCloud\n    tenant_name=\"acme-prod\",\n    duplo_base_url=\"https://acme.duplocloud.net\",\n    duplo_token=\"eyJ...\",\n\n    # AWS\n    aws_credentials={\n        \"access_key\": \"AKIA...\",\n        \"secret_key\": \"...\",\n        \"session_token\": \"...\",\n        \"region\": \"us-west-2\",\n    },\n)\n</code></pre>"},{"location":"core/helpdesk-protocol/#fields","title":"Fields","text":"Field Type Description <code>k8s_namespace</code> <code>str</code> Kubernetes namespace for kubectl operations <code>kubeconfig</code> <code>str</code> Path to kubeconfig or inline content <code>tenant_name</code> <code>str</code> DuploCloud tenant name <code>duplo_base_url</code> <code>str</code> DuploCloud API base URL <code>duplo_token</code> <code>str</code> DuploCloud authentication token <code>aws_credentials</code> <code>dict</code> AWS credentials (access_key, secret_key, etc.)"},{"location":"core/helpdesk-protocol/#using-with-messages","title":"Using with Messages","text":"<pre><code>from dcaf.core import ChatMessage, PlatformContext\n\n# Pass context with a message\nmsg = ChatMessage.user(\n    content=\"Delete the nginx pod\",\n    context=PlatformContext(tenant_name=\"acme\", k8s_namespace=\"default\"),\n)\n\n# Or use a dict\nmsg = ChatMessage.user(\n    content=\"Delete the nginx pod\",\n    context={\"tenant_name\": \"acme\", \"k8s_namespace\": \"default\"},\n)\n</code></pre>"},{"location":"core/helpdesk-protocol/#command-dtos","title":"Command DTOs","text":"<p>Commands represent terminal commands for user approval.</p>"},{"location":"core/helpdesk-protocol/#commanddto","title":"CommandDTO","text":"<pre><code>from dcaf.core import CommandDTO\n\n# Command awaiting approval\ncmd = CommandDTO(\n    command=\"kubectl delete pod nginx-1\",\n    execute=False,  # Not yet approved\n)\n\n# Approved command\napproved_cmd = CommandDTO(\n    command=\"kubectl delete pod nginx-1\",\n    execute=True,\n)\n\n# Rejected command\nrejected_cmd = CommandDTO(\n    command=\"rm -rf /\",\n    execute=False,\n    rejection_reason=\"This command is too dangerous\",\n)\n</code></pre>"},{"location":"core/helpdesk-protocol/#executedcommanddto","title":"ExecutedCommandDTO","text":"<pre><code>from dcaf.core import ExecutedCommandDTO\n\n# Result of executed command\nresult = ExecutedCommandDTO(\n    command=\"kubectl get pods\",\n    output=\"NAME         READY   STATUS\\nnginx-1      1/1     Running\",\n)\n</code></pre>"},{"location":"core/helpdesk-protocol/#with-files","title":"With Files","text":"<p>Commands can include files to create before execution:</p> <pre><code>from dcaf.core.application.dto import CommandDTO, FileObject\n\ncmd = CommandDTO(\n    command=\"kubectl apply -f /tmp/deployment.yaml\",\n    files=[\n        FileObject(\n            file_path=\"/tmp/deployment.yaml\",\n            file_content=\"apiVersion: apps/v1\\nkind: Deployment...\",\n        )\n    ],\n)\n</code></pre>"},{"location":"core/helpdesk-protocol/#tool-call-dtos","title":"Tool Call DTOs","text":"<p>Tool calls follow the HelpDesk protocol format with all required fields.</p>"},{"location":"core/helpdesk-protocol/#toolcalldto","title":"ToolCallDTO","text":"<pre><code>from dcaf.core import ToolCallDTO\n\ntool_call = ToolCallDTO(\n    id=\"call_abc123\",\n    name=\"delete_pod\",\n    input={\"name\": \"nginx-1\", \"namespace\": \"default\"},\n    execute=False,  # Awaiting approval\n    tool_description=\"Delete a Kubernetes pod\",\n    input_description={\n        \"name\": {\"type\": \"string\", \"description\": \"Pod name\"},\n        \"namespace\": {\"type\": \"string\", \"description\": \"Namespace\"},\n    },\n    intent=\"User wants to delete the failing nginx pod\",\n)\n</code></pre>"},{"location":"core/helpdesk-protocol/#executedtoolcalldto","title":"ExecutedToolCallDTO","text":"<pre><code>from dcaf.core import ExecutedToolCallDTO\n\nexecuted = ExecutedToolCallDTO(\n    id=\"call_abc123\",\n    name=\"delete_pod\",\n    input={\"name\": \"nginx-1\", \"namespace\": \"default\"},\n    output=\"pod \\\"nginx-1\\\" deleted\",\n)\n</code></pre>"},{"location":"core/helpdesk-protocol/#data-container","title":"Data Container","text":"<p><code>DataDTO</code> is the container that holds all commands and tool calls:</p> <pre><code>from dcaf.core import DataDTO, CommandDTO, ToolCallDTO\n\ndata = DataDTO(\n    cmds=[\n        CommandDTO(command=\"kubectl get pods\"),\n    ],\n    executed_cmds=[\n        ExecutedCommandDTO(command=\"kubectl get nodes\", output=\"...\"),\n    ],\n    tool_calls=[\n        ToolCallDTO(id=\"1\", name=\"list_pods\", input={}),\n    ],\n    executed_tool_calls=[\n        ExecutedToolCallDTO(id=\"0\", name=\"get_status\", input={}, output=\"OK\"),\n    ],\n)\n\n# Check for pending items\nif data.has_pending_items:\n    print(\"User approval required\")\n</code></pre>"},{"location":"core/helpdesk-protocol/#agent-response","title":"Agent Response","text":"<p><code>AgentResponse</code> includes the full HelpDesk data structure:</p> <pre><code>from dcaf.core import Agent\nfrom dcaf.tools import tool\n\n@tool(description=\"List pods\")\ndef list_pods() -&gt; str:\n    return \"nginx-1, nginx-2\"\n\nagent = Agent(tools=[list_pods])\nresponse = agent.run(messages=[{\"role\": \"user\", \"content\": \"List pods\"}])\n\n# Access the response\nprint(response.text)                    # Agent's text response\nprint(response.data.to_dict())          # Full HelpDesk data structure\nprint(response.commands)                # Pending commands\nprint(response.tool_calls)              # Pending tool calls\nprint(response.executed_commands)       # Commands that were run\nprint(response.executed_tool_calls)     # Tools that were run\n\n# Convert to HelpDesk message format\nhelpdesk_msg = response.to_helpdesk_message()\n# {'role': 'assistant', 'content': '...', 'data': {...}, 'meta_data': {...}}\n</code></pre>"},{"location":"core/helpdesk-protocol/#stream-events","title":"Stream Events","text":"<p>DCAF Core supports all HelpDesk streaming event types:</p> <pre><code>from dcaf.core import StreamEvent, StreamEventType\n\n# Create events programmatically\nevents = [\n    # Text streaming\n    StreamEvent.text_delta(\"Hello, \"),\n    StreamEvent.text_delta(\"world!\"),\n\n    # Commands for approval\n    StreamEvent.commands_event([\n        CommandDTO(command=\"kubectl get pods\"),\n    ]),\n\n    # Tool calls for approval\n    StreamEvent.tool_calls_event([\n        ToolCallDTO(id=\"1\", name=\"list_pods\", input={}),\n    ]),\n\n    # Executed items\n    StreamEvent.executed_commands_event([\n        ExecutedCommandDTO(command=\"kubectl get nodes\", output=\"...\"),\n    ]),\n    StreamEvent.executed_tool_calls_event([\n        ExecutedToolCallDTO(id=\"1\", name=\"list_pods\", input={}, output=\"...\"),\n    ]),\n\n    # Completion\n    StreamEvent.done(),\n]\n\n# Convert to HelpDesk NDJSON format\nfor event in events:\n    print(event.to_dict())\n    # {\"type\": \"text_delta\", \"text\": \"Hello, \"}\n    # {\"type\": \"commands\", \"commands\": [...]}\n    # etc.\n</code></pre>"},{"location":"core/helpdesk-protocol/#event-types","title":"Event Types","text":"Event Type Description Data Fields <code>text_delta</code> Streaming text chunk <code>text</code> <code>commands</code> Commands for approval <code>commands</code> <code>tool_calls</code> Tool calls for approval <code>tool_calls</code> <code>executed_commands</code> Executed command results <code>executed_cmds</code> <code>executed_tool_calls</code> Executed tool results <code>executed_tool_calls</code> <code>done</code> Stream complete <code>stop_reason</code> (optional) <code>error</code> Error occurred <code>error</code>, <code>code</code>"},{"location":"core/helpdesk-protocol/#server-integration","title":"Server Integration","text":"<p>When using <code>serve()</code>, responses are automatically formatted for HelpDesk:</p> <pre><code>from dcaf.core import Agent, serve\nfrom dcaf.tools import tool\n\n@tool(description=\"List pods\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n\nagent = Agent(tools=[list_pods])\nserve(agent)  # Responses are HelpDesk-compatible\n</code></pre> <p>The server endpoints return HelpDesk-formatted responses:</p> <pre><code># Synchronous\ncurl -X POST http://localhost:8000/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"messages\": [{\n      \"role\": \"user\",\n      \"content\": \"List pods\",\n      \"platform_context\": {\n        \"tenant_name\": \"acme\",\n        \"k8s_namespace\": \"default\"\n      }\n    }]\n  }'\n\n# Response\n{\n  \"role\": \"assistant\",\n  \"content\": \"Here are the pods...\",\n  \"data\": {\n    \"cmds\": [],\n    \"executed_cmds\": [],\n    \"tool_calls\": [],\n    \"executed_tool_calls\": [...]\n  }\n}\n</code></pre>"},{"location":"core/helpdesk-protocol/#mapping-legacy-vs-core","title":"Mapping: Legacy vs Core","text":"Legacy (dcaf/schemas) Core (dcaf/core) Notes <code>PlatformContext</code> <code>PlatformContext</code> Same structure <code>Command</code> <code>CommandDTO</code> Same structure <code>ExecutedCommand</code> <code>ExecutedCommandDTO</code> Same structure <code>ToolCall</code> <code>ToolCallDTO</code> Same structure <code>ExecutedToolCall</code> <code>ExecutedToolCallDTO</code> Same structure <code>Data</code> <code>DataDTO</code> Same structure <code>AgentMessage</code> <code>AgentResponse</code> Core uses dataclass <code>TextDeltaEvent</code> <code>StreamEvent.text_delta()</code> Factory method <code>CommandsEvent</code> <code>StreamEvent.commands_event()</code> Factory method <code>DoneEvent</code> <code>StreamEvent.done()</code> Factory method"},{"location":"core/helpdesk-protocol/#complete-example","title":"Complete Example","text":"<pre><code>from dcaf.core import (\n    Agent, serve, PlatformContext, ChatMessage,\n    CommandDTO, ToolCallDTO, DataDTO,\n)\nfrom dcaf.tools import tool\n\n# Define tools\n@tool(description=\"Get pod status\")\ndef get_pods(namespace: str = \"default\") -&gt; str:\n    \"\"\"List all pods in a namespace.\"\"\"\n    return subprocess.run(\n        [\"kubectl\", \"get\", \"pods\", \"-n\", namespace],\n        capture_output=True, text=True\n    ).stdout\n\n@tool(requires_approval=True, description=\"Delete a pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    \"\"\"Delete a pod. Requires user approval.\"\"\"\n    return subprocess.run(\n        [\"kubectl\", \"delete\", \"pod\", name, \"-n\", namespace],\n        capture_output=True, text=True\n    ).stdout\n\n# Create agent\nagent = Agent(\n    tools=[get_pods, delete_pod],\n    system_prompt=\"You are a Kubernetes assistant.\",\n)\n\n# Run with full HelpDesk context\ncontext = PlatformContext(\n    tenant_name=\"production\",\n    k8s_namespace=\"default\",\n    duplo_base_url=\"https://prod.duplocloud.net\",\n)\n\nresponse = agent.run(\n    messages=[\n        ChatMessage.user(\"Delete the crashing pod\", context=context)\n    ]\n)\n\n# Check for pending approvals\nif response.has_pending_approvals:\n    print(\"The following actions need approval:\")\n\n    for cmd in response.pending_commands:\n        print(f\"  Command: {cmd.command}\")\n\n    for tc in response.pending_tool_calls:\n        print(f\"  Tool: {tc.name}({tc.input})\")\n        print(f\"  Intent: {tc.intent}\")\n\n# Serve it\nserve(agent)  # http://localhost:8000\n</code></pre>"},{"location":"core/server/","title":"Server","text":"<p>DCAF Core provides simple utilities to expose your agent as a REST API server with minimal configuration.</p>"},{"location":"core/server/#quick-start","title":"Quick Start","text":"<pre><code>from dcaf.core import Agent, serve\nfrom dcaf.tools import tool\n\n@tool(description=\"Get current time\")\ndef get_time() -&gt; str:\n    from datetime import datetime\n    return datetime.now().isoformat()\n\nagent = Agent(tools=[get_time])\nserve(agent)  # Server at http://0.0.0.0:8000\n</code></pre> <p>That's it. Your agent is now accessible via HTTP.</p>"},{"location":"core/server/#configuration","title":"Configuration","text":""},{"location":"core/server/#port-and-host","title":"Port and Host","text":"<pre><code># Custom port\nserve(agent, port=8080)\n\n# Custom host and port\nserve(agent, host=\"0.0.0.0\", port=3000)\n\n# Development mode with auto-reload\nserve(agent, port=8000, reload=True)\n</code></pre>"},{"location":"core/server/#production-configuration","title":"Production Configuration","text":"<p>For production deployments, configure worker processes and keep-alive timeouts:</p> <pre><code>serve(\n    agent,\n    port=8000,\n    workers=4,              # Multiple workers for parallelism\n    timeout_keep_alive=30,  # Match your load balancer's idle timeout\n    log_level=\"warning\",\n)\n</code></pre> Parameter Default Description <code>workers</code> <code>1</code> Number of worker processes. For production, use <code>(2 \u00d7 cpu_cores) + 1</code>. <code>timeout_keep_alive</code> <code>5</code> Keep-alive timeout in seconds. Set this to match or exceed your load balancer's idle timeout (e.g., AWS ALB defaults to 60s). <p>reload and workers are mutually exclusive</p> <p>You cannot use <code>reload=True</code> with <code>workers &gt; 1</code>. Use <code>workers=1</code> for development with hot reload.</p>"},{"location":"core/server/#programmatic-control","title":"Programmatic Control","text":"<p>If you need more control over the FastAPI app:</p> <pre><code>from dcaf.core import Agent, create_app\nimport uvicorn\n\nagent = Agent(tools=[...])\napp = create_app(agent)\n\n# Add custom endpoints\n@app.get(\"/custom\")\ndef custom_endpoint():\n    return {\"message\": \"Hello from custom endpoint\"}\n\n# Run with custom configuration\nuvicorn.run(app, host=\"0.0.0.0\", port=8000, workers=4)\n</code></pre>"},{"location":"core/server/#endpoints","title":"Endpoints","text":"Endpoint Method Description <code>/health</code> GET Health check (always responds immediately) <code>/api/chat</code> POST Synchronous chat <code>/api/chat-stream</code> POST Streaming chat (NDJSON) <code>/api/chat-ws</code> WebSocket Bidirectional streaming chat"},{"location":"core/server/#legacy-endpoints-backwards-compatible","title":"Legacy Endpoints (Backwards Compatible)","text":"<p>For backwards compatibility with existing v1 clients, the following endpoints are preserved as aliases:</p> Legacy Endpoint Preferred Endpoint Status <code>POST /api/sendMessage</code> <code>POST /api/chat</code> Deprecated <code>POST /api/sendMessageStream</code> <code>POST /api/chat-stream</code> Deprecated <p>Full Backwards Compatibility</p> <p>Legacy endpoints are fully functional aliases that route to the same handlers as the new endpoints. They behave identically\u2014same request format, same response format, same streaming behavior.</p> <p>Existing integrations continue to work without any code changes.</p> <p>When to Use Legacy Endpoints</p> <ul> <li>New projects: Use <code>/api/chat</code> and <code>/api/chat-stream</code></li> <li>Existing integrations: Legacy endpoints work indefinitely, but consider migrating when convenient</li> <li>Mixed environments: Both endpoint styles can be used simultaneously</li> </ul>"},{"location":"core/server/#why-the-rename-adr-007","title":"Why the Rename? (ADR-007)","text":"<p>The endpoint names were changed for three reasons:</p> <ol> <li>Future-proofing: Lowercase URLs avoid case-sensitivity issues if security middleware is added later</li> <li>Semantic accuracy: \"chat\" better describes bidirectional conversation than \"sendMessage\"</li> <li>REST conventions: Lowercase, hyphenated paths follow RESTful best practices</li> </ol> <p>See ADR-007: Lowercase Chat Endpoints for the full rationale.</p>"},{"location":"core/server/#request-format","title":"Request Format","text":"<p>All chat endpoints accept the same request body:</p> <pre><code>{\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"What time is it?\"}\n  ]\n}\n</code></pre>"},{"location":"core/server/#with-conversation-history","title":"With Conversation History","text":"<pre><code>{\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"What time is it?\"},\n    {\"role\": \"assistant\", \"content\": \"The current time is 2024-01-15T14:30:00\"},\n    {\"role\": \"user\", \"content\": \"What about in Tokyo?\"}\n  ]\n}\n</code></pre> <p>Last Message is Current</p> <p>The last message in the array is always treated as the current user message. All previous messages are conversation history.</p>"},{"location":"core/server/#with-platform-context","title":"With Platform Context","text":"<pre><code>{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"List the pods\",\n      \"platform_context\": {\n        \"tenant_name\": \"acme-corp\",\n        \"k8s_namespace\": \"production\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"core/server/#response-format","title":"Response Format","text":""},{"location":"core/server/#synchronous-response-apichat","title":"Synchronous Response (<code>/api/chat</code>)","text":"<pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"The current time is 2024-01-15T14:30:00\",\n  \"data\": {\n    \"tool_calls\": [],\n    \"executed_tool_calls\": []\n  }\n}\n</code></pre>"},{"location":"core/server/#tool-approval-required","title":"Tool Approval Required","text":"<p>When a tool requires approval:</p> <pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"I need your approval to execute the following tools:\",\n  \"data\": {\n    \"tool_calls\": [\n      {\n        \"id\": \"tc_123\",\n        \"name\": \"delete_pod\",\n        \"input\": {\"name\": \"nginx-abc\", \"namespace\": \"production\"},\n        \"execute\": false,\n        \"tool_description\": \"Delete a Kubernetes pod\",\n        \"input_description\": {}\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"core/server/#approving-tool-calls","title":"Approving Tool Calls","text":"<p>To approve a tool call, send back the same tool call with <code>execute: true</code>:</p> <pre><code>{\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"Delete the failing pod\"},\n    {\n      \"role\": \"assistant\",\n      \"content\": \"I need your approval...\",\n      \"data\": {\n        \"tool_calls\": [\n          {\n            \"id\": \"tc_123\",\n            \"name\": \"delete_pod\",\n            \"input\": {\"name\": \"nginx-abc\"},\n            \"execute\": true\n          }\n        ]\n      }\n    },\n    {\"role\": \"user\", \"content\": \"Yes, approved\"}\n  ]\n}\n</code></pre>"},{"location":"core/server/#streaming-apichat-stream","title":"Streaming (<code>/api/chat-stream</code>)","text":"<p>The streaming endpoint returns NDJSON (newline-delimited JSON):</p> <pre><code>curl -X POST http://localhost:8000/api/chat-stream \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"messages\": [{\"role\": \"user\", \"content\": \"Tell me about Kubernetes\"}]}'\n</code></pre> <p>Response stream:</p> <pre><code>{\"type\": \"text_delta\", \"text\": \"Kubernetes\"}\n{\"type\": \"text_delta\", \"text\": \" is\"}\n{\"type\": \"text_delta\", \"text\": \" a\"}\n{\"type\": \"text_delta\", \"text\": \" container\"}\n{\"type\": \"text_delta\", \"text\": \" orchestration\"}\n{\"type\": \"text_delta\", \"text\": \" platform...\"}\n{\"type\": \"done\"}\n</code></pre>"},{"location":"core/server/#event-types","title":"Event Types","text":"Event Type Description <code>text_delta</code> Text token(s) from the LLM <code>tool_calls</code> Tool calls requiring approval <code>executed_tool_calls</code> Results from executed tools <code>done</code> Stream completed successfully <code>error</code> An error occurred"},{"location":"core/server/#handling-streams-in-python","title":"Handling Streams in Python","text":"<pre><code>import httpx\n\nwith httpx.stream(\n    \"POST\",\n    \"http://localhost:8000/api/chat-stream\",\n    json={\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]},\n) as response:\n    for line in response.iter_lines():\n        if line:\n            event = json.loads(line)\n            if event[\"type\"] == \"text_delta\":\n                print(event[\"text\"], end=\"\", flush=True)\n            elif event[\"type\"] == \"done\":\n                print(\"\\n--- Done ---\")\n</code></pre>"},{"location":"core/server/#handling-streams-in-javascript","title":"Handling Streams in JavaScript","text":"<pre><code>const response = await fetch(\"http://localhost:8000/api/chat-stream\", {\n  method: \"POST\",\n  headers: { \"Content-Type\": \"application/json\" },\n  body: JSON.stringify({\n    messages: [{ role: \"user\", content: \"Hello\" }]\n  })\n});\n\nconst reader = response.body.getReader();\nconst decoder = new TextDecoder();\n\nwhile (true) {\n  const { done, value } = await reader.read();\n  if (done) break;\n\n  const lines = decoder.decode(value).split(\"\\n\");\n  for (const line of lines) {\n    if (line) {\n      const event = JSON.parse(line);\n      if (event.type === \"text_delta\") {\n        process.stdout.write(event.text);\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"core/server/#async-non-blocking","title":"Async / Non-Blocking","text":"<p>All LLM calls run in a thread pool, so:</p> <ul> <li>Health checks always respond immediately (not blocked by long LLM calls)</li> <li>Multiple concurrent requests are handled properly</li> <li>Kubernetes liveness probes won't timeout during LLM calls</li> </ul> <p>This is critical for production deployments where a 15-second LLM call could otherwise cause health check failures and container restarts.</p>"},{"location":"core/server/#websocket-apichat-ws","title":"WebSocket (<code>/api/chat-ws</code>)","text":"<p>The WebSocket endpoint provides bidirectional streaming chat over a persistent connection. Unlike the HTTP endpoints, a single WebSocket connection stays open for multiple conversation turns.</p>"},{"location":"core/server/#connecting","title":"Connecting","text":"<pre><code>ws://localhost:8000/api/chat-ws\n</code></pre>"},{"location":"core/server/#message-format","title":"Message Format","text":"<p>Each client frame is a JSON object with the same shape as the HTTP endpoints:</p> <pre><code>{\"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}]}\n</code></pre> <p>The server streams back event frames (same types as <code>/api/chat-stream</code>), ending each turn with a <code>done</code> event. The connection remains open for the next turn.</p>"},{"location":"core/server/#python-client","title":"Python Client","text":"<pre><code>import asyncio\nimport json\nimport websockets\n\nasync def chat():\n    async with websockets.connect(\"ws://localhost:8000/api/chat-ws\") as ws:\n        # Turn 1\n        await ws.send(json.dumps({\n            \"messages\": [{\"role\": \"user\", \"content\": \"What is Kubernetes?\"}]\n        }))\n\n        async for frame in ws:\n            event = json.loads(frame)\n            if event[\"type\"] == \"text_delta\":\n                print(event[\"text\"], end=\"\", flush=True)\n            elif event[\"type\"] == \"done\":\n                print()\n                break\n\n        # Turn 2 \u2014 same connection\n        await ws.send(json.dumps({\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"What is Kubernetes?\"},\n                {\"role\": \"assistant\", \"content\": \"Kubernetes is a container orchestration platform...\"},\n                {\"role\": \"user\", \"content\": \"How do I list pods?\"},\n            ]\n        }))\n\n        async for frame in ws:\n            event = json.loads(frame)\n            if event[\"type\"] == \"text_delta\":\n                print(event[\"text\"], end=\"\", flush=True)\n            elif event[\"type\"] == \"done\":\n                print()\n                break\n\nasyncio.run(chat())\n</code></pre>"},{"location":"core/server/#javascript-client","title":"JavaScript Client","text":"<pre><code>const ws = new WebSocket(\"ws://localhost:8000/api/chat-ws\");\n\nws.onopen = () =&gt; {\n  ws.send(JSON.stringify({\n    messages: [{ role: \"user\", content: \"Hello\" }]\n  }));\n};\n\nws.onmessage = (event) =&gt; {\n  const data = JSON.parse(event.data);\n  if (data.type === \"text_delta\") {\n    process.stdout.write(data.text);\n  } else if (data.type === \"done\") {\n    console.log(\"\\n--- Turn complete ---\");\n  } else if (data.type === \"error\") {\n    console.error(\"Error:\", data.error);\n  }\n};\n</code></pre>"},{"location":"core/server/#error-handling","title":"Error Handling","text":"<p>Errors during a turn are sent as <code>error</code> events without closing the connection. The client can continue sending messages after an error:</p> <pre><code>{\"type\": \"error\", \"error\": \"agent exploded\"}\n</code></pre> <p>Invalid JSON or missing <code>messages</code> fields also return error events while keeping the connection alive.</p>"},{"location":"core/server/#connection-stability","title":"Connection Stability","text":"<p>DCAF uses uvicorn's built-in WebSocket ping/pong mechanism to detect dead connections. By default, the server sends a ping frame every 20 seconds and expects a pong reply within 20 seconds. If no pong is received, the server closes the connection.</p> <p>You can tune these values via <code>serve()</code>:</p> <pre><code>serve(\n    agent,\n    ws_ping_interval=30.0,   # Ping every 30s\n    ws_ping_timeout=30.0,    # Wait 30s for pong\n)\n</code></pre> <p>Set to <code>None</code> to disable automatic pings:</p> <pre><code>serve(agent, ws_ping_interval=None, ws_ping_timeout=None)\n</code></pre> <p>Load Balancer Considerations</p> <p>Many load balancers (e.g., AWS ALB, nginx) enforce their own idle timeouts, typically 60\u2013120 seconds. Ensure <code>ws_ping_interval</code> is shorter than your load balancer's idle timeout so that ping frames keep the connection active.</p>"},{"location":"core/server/#client-side-reconnection","title":"Client-Side Reconnection","text":"<p>WebSocket connections can drop due to network issues, server restarts, or load balancer timeouts. Clients should implement reconnection logic:</p> PythonJavaScript <pre><code>import asyncio\nimport json\nimport websockets\nfrom websockets.exceptions import ConnectionClosed\n\nasync def resilient_chat(url: str, message: str):\n    backoff = 1\n    while True:\n        try:\n            async with websockets.connect(url) as ws:\n                backoff = 1  # Reset on successful connect\n                await ws.send(json.dumps({\n                    \"messages\": [{\"role\": \"user\", \"content\": message}]\n                }))\n\n                async for frame in ws:\n                    event = json.loads(frame)\n                    if event[\"type\"] == \"text_delta\":\n                        print(event[\"text\"], end=\"\", flush=True)\n                    elif event[\"type\"] == \"done\":\n                        print()\n                        return  # Success\n                    elif event[\"type\"] == \"error\":\n                        print(f\"\\nError: {event['error']}\")\n                        return\n\n        except (ConnectionClosed, OSError) as e:\n            print(f\"\\nConnection lost: {e}. Reconnecting in {backoff}s...\")\n            await asyncio.sleep(backoff)\n            backoff = min(backoff * 2, 30)  # Exponential backoff, max 30s\n</code></pre> <pre><code>function createResilientWebSocket(url, onEvent) {\n  let backoff = 1000;\n\n  function connect() {\n    const ws = new WebSocket(url);\n\n    ws.onopen = () =&gt; { backoff = 1000; };\n\n    ws.onmessage = (msg) =&gt; {\n      const event = JSON.parse(msg.data);\n      onEvent(event);\n    };\n\n    ws.onclose = (e) =&gt; {\n      if (e.code !== 1000) {  // Abnormal close\n        console.log(`Reconnecting in ${backoff}ms...`);\n        setTimeout(connect, backoff);\n        backoff = Math.min(backoff * 2, 30000);\n      }\n    };\n\n    ws.onerror = () =&gt; ws.close();\n\n    return ws;\n  }\n\n  return connect();\n}\n\n// Usage\ncreateResilientWebSocket(\"ws://localhost:8000/api/chat-ws\", (event) =&gt; {\n  if (event.type === \"text_delta\") process.stdout.write(event.text);\n  else if (event.type === \"done\") console.log(\"\\n--- Done ---\");\n});\n</code></pre>"},{"location":"core/server/#when-to-use-websocket-vs-http","title":"When to Use WebSocket vs HTTP","text":"Use Case Recommended Endpoint Single request/response <code>/api/chat</code> Streaming a single response <code>/api/chat-stream</code> Multi-turn conversation with streaming <code>/api/chat-ws</code> Real-time interactive UI <code>/api/chat-ws</code> Simple integration / cURL testing <code>/api/chat</code> or <code>/api/chat-stream</code>"},{"location":"core/server/#docker-deployment","title":"Docker Deployment","text":"<pre><code>FROM python:3.11-slim\n\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\n\nCMD [\"python\", \"main.py\"]\n</code></pre> <p>With a production-ready entry point:</p> <pre><code># main.py\nimport os\nfrom dcaf.core import Agent, serve\nfrom my_tools import list_pods, delete_pod\n\nagent = Agent(\n    tools=[list_pods, delete_pod],\n    system_prompt=\"You are a Kubernetes assistant.\"\n)\n\nif __name__ == \"__main__\":\n    serve(\n        agent,\n        host=\"0.0.0.0\",\n        port=int(os.getenv(\"PORT\", 8000)),\n        workers=int(os.getenv(\"WORKERS\", 4)),\n        timeout_keep_alive=int(os.getenv(\"KEEP_ALIVE\", 30)),\n        log_level=os.getenv(\"LOG_LEVEL\", \"warning\"),\n    )\n</code></pre> <p>Environment Variables</p> <p>Use environment variables for configuration so you can tune without rebuilding:</p> <pre><code>docker run -e WORKERS=8 -e KEEP_ALIVE=60 my-agent:latest\n</code></pre>"},{"location":"core/server/#kubernetes-health-check","title":"Kubernetes Health Check","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n        - name: agent\n          livenessProbe:\n            httpGet:\n              path: /health\n              port: 8000\n            initialDelaySeconds: 5\n            periodSeconds: 10\n            timeoutSeconds: 5  # Safe: health endpoint is non-blocking\n          readinessProbe:\n            httpGet:\n              path: /health\n              port: 8000\n            periodSeconds: 5\n</code></pre>"},{"location":"core/server/#api-reference","title":"API Reference","text":""},{"location":"core/server/#serve","title":"serve()","text":"<pre><code>def serve(\n    agent: Agent | Callable,\n    port: int = 8000,\n    host: str = \"0.0.0.0\",\n    reload: bool = False,\n    log_level: str = \"info\",\n    workers: int = 1,\n    timeout_keep_alive: int = 5,\n    additional_routers: Sequence[APIRouter] | None = None,\n    channel_router: ChannelResponseRouter | None = None,\n    a2a: bool = False,\n    a2a_adapter: str = \"agno\",\n    a2a_agent_card: AgentCard | dict | None = None,\n    mcp: bool = False,\n    mcp_port: int = 8001,\n    mcp_transport: str = \"sse\",\n    ws_ping_interval: float | None = 20.0,\n    ws_ping_timeout: float | None = 20.0,\n) -&gt; None\n</code></pre> <p>Start a REST server for the agent.</p> Parameter Type Default Description <code>agent</code> <code>Agent</code> or <code>Callable</code> Required Agent instance or callable <code>(messages, context) -&gt; AgentResult</code> <code>port</code> <code>int</code> <code>8000</code> Port to listen on <code>host</code> <code>str</code> <code>\"0.0.0.0\"</code> Host to bind to <code>reload</code> <code>bool</code> <code>False</code> Enable auto-reload on code changes (development only) <code>log_level</code> <code>str</code> <code>\"info\"</code> Logging level (<code>debug</code>, <code>info</code>, <code>warning</code>, <code>error</code>) <code>workers</code> <code>int</code> <code>1</code> Number of worker processes for parallelism <code>timeout_keep_alive</code> <code>int</code> <code>5</code> Keep-alive timeout in seconds <code>additional_routers</code> <code>Sequence[APIRouter]</code> <code>None</code> Custom FastAPI routers to include <code>channel_router</code> <code>ChannelResponseRouter</code> <code>None</code> Channel response router for multi-agent environments. See Channel Routing. <code>a2a</code> <code>bool</code> <code>False</code> Enable A2A (Agent-to-Agent) protocol support <code>a2a_adapter</code> <code>str</code> <code>\"agno\"</code> A2A adapter to use <code>a2a_agent_card</code> <code>AgentCard</code> or <code>dict</code> <code>None</code> Custom agent card for A2A discovery. See A2A Agent Card. <code>mcp</code> <code>bool</code> <code>False</code> Enable MCP server alongside the HTTP server <code>mcp_port</code> <code>int</code> <code>8001</code> Port for the MCP server <code>mcp_transport</code> <code>str</code> <code>\"sse\"</code> MCP transport (<code>\"sse\"</code> or <code>\"stdio\"</code>) <code>ws_ping_interval</code> <code>float</code> or <code>None</code> <code>20.0</code> Seconds between WebSocket ping frames. Set to <code>None</code> to disable. <code>ws_ping_timeout</code> <code>float</code> or <code>None</code> <code>20.0</code> Seconds to wait for a pong reply before closing the connection. <p>Raises:</p> <ul> <li><code>ValueError</code> - If <code>reload=True</code> and <code>workers &gt; 1</code> (mutually exclusive)</li> </ul>"},{"location":"core/server/#create_app","title":"create_app()","text":"<pre><code>def create_app(\n    agent: Agent | Callable,\n    additional_routers: Sequence[APIRouter] | None = None,\n    channel_router: ChannelResponseRouter | None = None,\n    a2a: bool = False,\n    a2a_adapter: str = \"agno\",\n    a2a_agent_card: AgentCard | dict | None = None,\n) -&gt; FastAPI\n</code></pre> <p>Create a FastAPI application without starting the server. Use this for programmatic control or custom uvicorn configuration.</p> Parameter Type Default Description <code>agent</code> <code>Agent</code> or <code>Callable</code> Required Agent instance or callable <code>(messages, context) -&gt; AgentResult</code> <code>additional_routers</code> <code>Sequence[APIRouter]</code> <code>None</code> Custom FastAPI routers to include <code>channel_router</code> <code>ChannelResponseRouter</code> <code>None</code> Channel response router for multi-agent environments. See Channel Routing. <code>a2a</code> <code>bool</code> <code>False</code> Enable A2A (Agent-to-Agent) protocol support <code>a2a_adapter</code> <code>str</code> <code>\"agno\"</code> A2A adapter to use <code>a2a_agent_card</code> <code>AgentCard</code> or <code>dict</code> <code>None</code> Custom agent card for A2A discovery. See A2A Agent Card."},{"location":"core/server/#channel-routing","title":"Channel Routing","text":"<p>Channel routing enables intelligent message filtering in multi-agent environments. When a <code>channel_router</code> is provided and the incoming request includes <code>\"source\": \"slack\"</code>, the router determines whether the agent should respond before processing the message.</p> <p>This is useful when multiple agents share a Slack channel \u2014 each agent uses its own router to decide if a message is relevant to its domain.</p>"},{"location":"core/server/#setup","title":"Setup","text":"<pre><code>from dcaf.core import Agent, serve, SlackResponseRouter\nfrom dcaf.llm import BedrockLLM\n\nagent = Agent(\n    tools=[...],\n    system_prompt=\"You are a Kubernetes assistant.\",\n)\n\nllm = BedrockLLM()\n\nslack_router = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"k8s-agent\",\n    agent_description=\"\"\"\n    Specialized Kubernetes and Helm expert. Responds to:\n    - Kubernetes resource management, kubectl commands\n    - Helm chart operations\n    - DuploCloud service management\n    Does NOT respond to: general cloud infra, CI/CD, database queries.\n    \"\"\",\n)\n\nserve(agent, channel_router=slack_router, port=8000)\n</code></pre>"},{"location":"core/server/#with-create_app","title":"With create_app()","text":"<pre><code>from dcaf.core import Agent, create_app, SlackResponseRouter\nfrom dcaf.llm import BedrockLLM\nimport uvicorn\n\nagent = Agent(tools=[...])\nllm = BedrockLLM()\n\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"aws-agent\",\n    agent_description=\"AWS cloud infrastructure specialist\",\n)\n\napp = create_app(agent, channel_router=router)\nuvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"core/server/#how-it-works","title":"How It Works","text":"<p>When a request arrives with <code>\"source\": \"slack\"</code> in the body:</p> <ol> <li>The <code>SlackResponseRouter.should_agent_respond()</code> method is called with the message thread.</li> <li>The router uses a fast LLM call (Claude 3.5 Haiku) to analyze the conversation and decide if the agent should respond.</li> <li>If the router decides not to respond, the endpoint returns an empty response immediately (or a <code>done</code> event for streaming).</li> <li>If the router decides to respond, the request proceeds to the agent normally.</li> </ol> <p>Requests without <code>\"source\": \"slack\"</code> bypass routing entirely.</p>"},{"location":"core/server/#slack-request-format","title":"Slack Request Format","text":"<pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"My pods keep crashing with OOMKilled\",\n            \"user\": {\"name\": \"alice\", \"id\": \"U123\"}\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"Try increasing memory limits in your deployment.\",\n            \"agent\": {\"name\": \"k8s-agent\", \"id\": \"B456\"}\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Actually, I think this is an AWS node issue\",\n            \"user\": {\"name\": \"alice\", \"id\": \"U123\"}\n        }\n    ],\n    \"source\": \"slack\"\n}\n</code></pre>"},{"location":"core/server/#multi-agent-example","title":"Multi-Agent Example","text":"<p>Run multiple agents on different ports, each with its own router:</p> <pre><code># k8s_server.py\nfrom dcaf.core import Agent, serve, SlackResponseRouter\nfrom dcaf.llm import BedrockLLM\n\nllm = BedrockLLM()\nagent = Agent(tools=[...], system_prompt=\"You are a Kubernetes expert.\")\n\nserve(\n    agent,\n    channel_router=SlackResponseRouter(\n        llm_client=llm,\n        agent_name=\"k8s-agent\",\n        agent_description=\"Kubernetes and container orchestration specialist\",\n    ),\n    port=8000,\n)\n</code></pre> <pre><code># aws_server.py\nfrom dcaf.core import Agent, serve, SlackResponseRouter\nfrom dcaf.llm import BedrockLLM\n\nllm = BedrockLLM()\nagent = Agent(tools=[...], system_prompt=\"You are an AWS infrastructure expert.\")\n\nserve(\n    agent,\n    channel_router=SlackResponseRouter(\n        llm_client=llm,\n        agent_name=\"aws-agent\",\n        agent_description=\"AWS cloud infrastructure and services specialist\",\n    ),\n    port=8001,\n)\n</code></pre> <p>When a Slack message arrives, each agent's router independently decides whether to respond based on the message content and the agent's description.</p>"},{"location":"core/server/#custom-routers","title":"Custom Routers","text":"<p>You can implement your own router by extending <code>ChannelResponseRouter</code>:</p> <pre><code>from dcaf.core import ChannelResponseRouter\n\nclass KeywordRouter(ChannelResponseRouter):\n    def __init__(self, keywords: list[str]):\n        self.keywords = keywords\n\n    def should_agent_respond(self, messages: list) -&gt; dict:\n        last_msg = next(\n            (m for m in reversed(messages) if m.get(\"role\") == \"user\"),\n            None,\n        )\n        if not last_msg:\n            return {\"should_respond\": False, \"reasoning\": \"No user message\"}\n\n        content = last_msg.get(\"content\", \"\").lower()\n        for kw in self.keywords:\n            if kw.lower() in content:\n                return {\"should_respond\": True, \"reasoning\": f\"Matched: {kw}\"}\n\n        return {\"should_respond\": False, \"reasoning\": \"No matching keywords\"}\n\nserve(agent, channel_router=KeywordRouter(keywords=[\"kubernetes\", \"k8s\", \"pod\"]))\n</code></pre> <p>See Also</p> <p>For full API details on <code>SlackResponseRouter</code> (constructor parameters, decision criteria, testing patterns), see the Channel Routing API Reference.</p>"},{"location":"core/server/#see-also","title":"See Also","text":"<ul> <li>Core Overview - Introduction to DCAF Core</li> <li>Channel Routing API Reference - Full <code>SlackResponseRouter</code> and <code>ChannelResponseRouter</code> API details</li> <li>ADR-007: Lowercase Chat Endpoints - Why <code>/api/chat</code> instead of <code>/api/sendMessage</code></li> </ul>"},{"location":"core/testing/","title":"Testing","text":"<p>The Core layer provides comprehensive testing support with fakes, builders, and fixtures that enable fast, isolated unit tests.</p>"},{"location":"core/testing/#overview","title":"Overview","text":"<p>The testing module includes:</p> <ul> <li>Fakes: Fake implementations of all ports</li> <li>Builders: Test data builders for creating domain objects</li> <li>Fixtures: pytest fixtures for common setup</li> </ul>"},{"location":"core/testing/#fakes","title":"Fakes","text":"<p>Fakes are test implementations of ports that allow testing without real infrastructure.</p>"},{"location":"core/testing/#fakeagentruntime","title":"FakeAgentRuntime","text":"<p>Simulates the AgentRuntime port with configurable responses.</p> <pre><code>from dcaf.core.testing import FakeAgentRuntime\n\nfake = FakeAgentRuntime()\n\n# Configure responses\nfake.will_respond_with_text(\"Hello, world!\")\nfake.will_respond_with_tool_call(\n    tool_name=\"kubectl\",\n    tool_input={\"command\": \"get pods\"},\n    requires_approval=True,\n)\n\n# Use in tests\nresponse = fake.invoke(messages, tools)\n\n# Verify calls\nassert fake.invoke_count == 1\nassert fake.last_messages == messages\nassert fake.last_tools == tools\n</code></pre> <p>Methods: - <code>will_respond_with_text(text)</code> - Configure text response - <code>will_respond_with_tool_call(...)</code> - Configure tool call response - <code>will_respond_with(response)</code> - Configure custom response - <code>will_stream_text(text)</code> - Configure streaming text - <code>reset()</code> - Clear all configured responses and recorded calls</p>"},{"location":"core/testing/#fakeconversationrepository","title":"FakeConversationRepository","text":"<p>In-memory repository with tracking.</p> <pre><code>from dcaf.core.testing import FakeConversationRepository\n\nfake = FakeConversationRepository()\n\n# Seed with test data\nconversation = ConversationBuilder.empty()\nfake.seed(conversation)\n\n# Use in tests\nloaded = fake.get(conversation.id)\nfake.save(conversation)\n\n# Verify operations\nassert fake.save_count == 1\nassert fake.get_count == 1\nassert fake.last_saved == conversation\n</code></pre>"},{"location":"core/testing/#fakeapprovalcallback","title":"FakeApprovalCallback","text":"<p>Configurable approval behavior.</p> <pre><code>from dcaf.core.testing import FakeApprovalCallback\n\nfake = FakeApprovalCallback()\n\n# Auto-approve all\nfake.will_approve_all()\ndecisions = fake.request_approval(tool_calls)\nassert all(d.is_approved for d in decisions)\n\n# Auto-reject all\nfake.will_reject_all(\"Test rejection\")\ndecisions = fake.request_approval(tool_calls)\nassert all(d.is_rejected for d in decisions)\n\n# Custom decisions\nfrom dcaf.core.application.ports.approval_callback import ApprovalDecision\nfake.will_return_decisions([\n    ApprovalDecision.approve(\"tc-1\"),\n    ApprovalDecision.reject(\"tc-2\", \"Too risky\"),\n])\n</code></pre>"},{"location":"core/testing/#fakeeventpublisher","title":"FakeEventPublisher","text":"<p>Captures published events for verification.</p> <pre><code>from dcaf.core.testing import FakeEventPublisher\nfrom dcaf.core.domain.events import ApprovalRequested\n\nfake = FakeEventPublisher()\n\n# Publish events\nfake.publish(event)\nfake.publish_all([event1, event2])\n\n# Verify\nassert fake.publish_count == 3\nassert fake.has_event_of_type(ApprovalRequested)\n\n# Get specific event types\napproval_events = fake.get_events_of_type(ApprovalRequested)\n</code></pre>"},{"location":"core/testing/#builders","title":"Builders","text":"<p>Builders create test data with sensible defaults and a fluent API.</p>"},{"location":"core/testing/#messagebuilder","title":"MessageBuilder","text":"<p>Build Message entities.</p> <pre><code>from dcaf.core.testing import MessageBuilder\n\n# Fluent API\nmessage = (MessageBuilder()\n    .as_user()\n    .with_text(\"Hello, can you help me?\")\n    .build())\n\n# Convenience methods\nuser_msg = MessageBuilder.user_message(\"Hello\")\nassistant_msg = MessageBuilder.assistant_message(\"Hi there!\")\nsystem_msg = MessageBuilder.system_message(\"You are helpful\")\n</code></pre>"},{"location":"core/testing/#toolcallbuilder","title":"ToolCallBuilder","text":"<p>Build ToolCall entities.</p> <pre><code>from dcaf.core.testing import ToolCallBuilder\n\n# Fluent API\ntool_call = (ToolCallBuilder()\n    .with_id(\"tc-123\")\n    .with_name(\"kubectl\")\n    .with_input({\"command\": \"get pods\"})\n    .with_description(\"Execute kubectl commands\")\n    .requiring_approval()\n    .build())\n\n# Pre-configured states\napproved = (ToolCallBuilder()\n    .with_name(\"kubectl\")\n    .as_approved()\n    .build())\n\ncompleted = (ToolCallBuilder()\n    .with_name(\"kubectl\")\n    .as_completed(\"Success!\")\n    .build())\n\n# Convenience methods\nkubectl_call = ToolCallBuilder.pending_kubectl_call()\n</code></pre>"},{"location":"core/testing/#conversationbuilder","title":"ConversationBuilder","text":"<p>Build Conversation aggregates.</p> <pre><code>from dcaf.core.testing import ConversationBuilder\n\n# Fluent API\nconversation = (ConversationBuilder()\n    .with_id(\"conv-123\")\n    .with_system_prompt(\"You are a helpful assistant\")\n    .with_user_message(\"Hello\")\n    .with_assistant_message(\"Hi there!\")\n    .with_tenant(\"my-tenant\")\n    .build())\n\n# With pending approvals\nblocked = (ConversationBuilder()\n    .with_user_message(\"Delete the pod\")\n    .with_pending_tool_call(ToolCallBuilder.pending_kubectl_call())\n    .build())\n\nassert blocked.is_blocked\n\n# Convenience methods\nempty = ConversationBuilder.empty()\none_turn = ConversationBuilder.with_single_turn(\"Hello\", \"Hi!\")\n</code></pre>"},{"location":"core/testing/#toolbuilder","title":"ToolBuilder","text":"<p>Build mock Tool objects.</p> <pre><code>from dcaf.core.testing import ToolBuilder\n\n# Fluent API\ntool = (ToolBuilder()\n    .with_name(\"kubectl\")\n    .with_description(\"Execute kubectl commands\")\n    .with_input_schema({\n        \"type\": \"object\",\n        \"properties\": {\"command\": {\"type\": \"string\"}},\n    })\n    .requiring_approval()\n    .requiring_platform_context()\n    .build())\n\n# Execute and track\nresult = tool.execute({\"command\": \"get pods\"}, platform_context)\nassert tool.execute_count == 1\n\n# Convenience methods\nkubectl = ToolBuilder.kubectl_tool()\n</code></pre>"},{"location":"core/testing/#fixtures","title":"Fixtures","text":"<p>pytest fixtures for common test setup.</p>"},{"location":"core/testing/#basic-fixtures","title":"Basic Fixtures","text":"<pre><code>import pytest\nfrom dcaf.core.testing.fixtures import *\n\ndef test_with_fake_runtime(fake_runtime):\n    fake_runtime.will_respond_with_text(\"Hello!\")\n    response = fake_runtime.invoke([], [])\n    assert response.text == \"Hello!\"\n\ndef test_with_fake_conversations(fake_conversations):\n    conversation = ConversationBuilder.empty()\n    fake_conversations.save(conversation)\n    assert fake_conversations.exists(conversation.id)\n\ndef test_with_fake_events(fake_events):\n    fake_events.publish(some_event)\n    assert fake_events.publish_count == 1\n</code></pre>"},{"location":"core/testing/#service-fixtures","title":"Service Fixtures","text":"<pre><code>def test_execute_agent(execute_agent_service, fake_runtime):\n    fake_runtime.will_respond_with_text(\"Hello!\")\n\n    response = execute_agent_service.execute(AgentRequest(\n        content=\"Hi\",\n        tools=[],\n    ))\n\n    assert response.text == \"Hello!\"\n\ndef test_approve_tool_call(\n    approve_tool_call_service, \n    fake_conversations\n):\n    # Setup conversation with pending approval\n    conversation = (ConversationBuilder()\n        .with_pending_tool_call(ToolCallBuilder.pending_kubectl_call())\n        .build())\n    fake_conversations.seed(conversation)\n\n    # Approve\n    response = approve_tool_call_service.approve_all(\n        str(conversation.id)\n    )\n\n    assert not response.has_pending_approvals\n</code></pre>"},{"location":"core/testing/#builder-fixtures","title":"Builder Fixtures","text":"<pre><code>def test_with_builders(\n    message_builder,\n    tool_call_builder,\n    conversation_builder,\n):\n    msg = message_builder.as_user().with_text(\"Test\").build()\n    tc = tool_call_builder.with_name(\"test\").build()\n    conv = conversation_builder.with_message(msg).build()\n</code></pre>"},{"location":"core/testing/#sample-data-fixtures","title":"Sample Data Fixtures","text":"<pre><code>def test_with_sample_data(\n    sample_conversation,\n    sample_kubectl_tool,\n    sample_user_message,\n    sample_pending_tool_call,\n):\n    # Ready-to-use test data\n    assert sample_conversation.message_count == 2\n    assert sample_kubectl_tool.requires_approval\n</code></pre>"},{"location":"core/testing/#integration-test-fixtures","title":"Integration Test Fixtures","text":"<pre><code>def test_approval_flow(\n    approval_required_runtime,\n    auto_approve_callback,\n):\n    # Runtime configured to return tool calls needing approval\n    response = approval_required_runtime.invoke([], [])\n    assert response.has_pending_approvals\n\n    # Callback configured to auto-approve\n    decisions = auto_approve_callback.request_approval(\n        response.pending_tool_calls\n    )\n    assert all(d.is_approved for d in decisions)\n</code></pre>"},{"location":"core/testing/#testing-patterns","title":"Testing Patterns","text":""},{"location":"core/testing/#testing-services","title":"Testing Services","text":"<pre><code>def test_execute_agent_with_approval_required():\n    # Arrange\n    fake_runtime = FakeAgentRuntime()\n    fake_runtime.will_respond_with_tool_call(\n        tool_name=\"kubectl\",\n        tool_input={\"command\": \"delete pod\"},\n        requires_approval=True,\n    )\n    fake_conversations = FakeConversationRepository()\n\n    service = AgentService(\n        runtime=fake_runtime,\n        conversations=fake_conversations,\n    )\n\n    tool = ToolBuilder().with_name(\"kubectl\").requiring_approval().build()\n\n    # Act\n    response = service.execute(AgentRequest(\n        content=\"Delete the pod\",\n        tools=[tool],\n    ))\n\n    # Assert\n    assert response.has_pending_approvals\n    assert len(response.pending_tool_calls) == 1\n    assert response.pending_tool_calls[0].name == \"kubectl\"\n</code></pre>"},{"location":"core/testing/#testing-domain-logic","title":"Testing Domain Logic","text":"<pre><code>def test_conversation_blocks_on_pending_approval():\n    # Arrange\n    conversation = ConversationBuilder.empty()\n    tool_call = ToolCallBuilder.pending_kubectl_call()\n\n    # Act\n    conversation.request_tool_approval([tool_call])\n\n    # Assert\n    assert conversation.is_blocked\n\n    with pytest.raises(ConversationBlocked):\n        conversation.add_user_message(\n            MessageContent.from_text(\"Another message\")\n        )\n</code></pre>"},{"location":"core/testing/#testing-state-transitions","title":"Testing State Transitions","text":"<pre><code>def test_tool_call_lifecycle():\n    tool_call = ToolCallBuilder().requiring_approval().build()\n\n    # Initial state\n    assert tool_call.is_pending\n\n    # Approve\n    tool_call.approve()\n    assert tool_call.is_approved\n\n    # Execute\n    tool_call.start_execution()\n    tool_call.complete(\"Success!\")\n    assert tool_call.is_completed\n    assert tool_call.result == \"Success!\"\n</code></pre>"},{"location":"core/testing/#best-practices","title":"Best Practices","text":"<ol> <li>Use fakes, not mocks: Fakes provide real behavior, mocks just verify calls</li> <li>Use builders for test data: Builders make tests readable and maintainable</li> <li>Test at the right level: Unit test domain logic, integration test use cases</li> <li>Verify side effects: Check that events were published, conversations were saved</li> <li>Test edge cases: Invalid state transitions, empty inputs, error conditions</li> <li>Keep tests fast: Fakes enable millisecond-fast tests</li> </ol>"},{"location":"examples/examples/","title":"DCAF Code Examples","text":"<p>This page contains comprehensive code examples for using DCAF in various scenarios.</p>"},{"location":"examples/examples/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Quick Start Examples</li> <li>Tool Examples</li> <li>Agent Examples</li> <li>Server Examples</li> <li>Client Examples</li> <li>Advanced Examples</li> </ol>"},{"location":"examples/examples/#quick-start-examples","title":"Quick Start Examples","text":""},{"location":"examples/examples/#minimal-agent","title":"Minimal Agent","text":"<p>The simplest possible DCAF agent:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"minimal_agent.py - Simplest DCAF agent\"\"\"\n\nfrom dcaf.agent_server import AgentProtocol, create_chat_app\nfrom dcaf.schemas.messages import AgentMessage\nimport uvicorn\n\nclass MinimalAgent(AgentProtocol):\n    def invoke(self, messages):\n        return AgentMessage(content=\"Hello from DCAF!\")\n\napp = create_chat_app(MinimalAgent())\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"examples/examples/#echo-agent","title":"Echo Agent","text":"<p>Agent that echoes back user messages:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"echo_agent.py - Echo back user messages\"\"\"\n\nfrom dcaf.agent_server import AgentProtocol, create_chat_app\nfrom dcaf.schemas.messages import AgentMessage\nimport uvicorn\n\nclass EchoAgent(AgentProtocol):\n    def invoke(self, messages):\n        messages_list = messages.get(\"messages\", [])\n        last_user = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            {\"content\": \"\"}\n        )\n        text = last_user.get(\"content\", \"\")\n        return AgentMessage(content=f\"You said: {text}\")\n\napp = create_chat_app(EchoAgent())\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, port=8000)\n</code></pre>"},{"location":"examples/examples/#llm-chat-agent","title":"LLM Chat Agent","text":"<p>Basic chat agent using Bedrock:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"chat_agent.py - Basic LLM chat\"\"\"\n\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.agent_server import AgentProtocol, create_chat_app\nfrom dcaf.schemas.messages import AgentMessage\nimport uvicorn\nimport dotenv\n\ndotenv.load_dotenv()\n\nclass ChatAgent(AgentProtocol):\n    def __init__(self):\n        self.llm = BedrockLLM(region_name=\"us-east-1\")\n        self.model_id = \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n\n    def invoke(self, messages):\n        # Preprocess messages\n        msgs = [\n            {\"role\": m[\"role\"], \"content\": m.get(\"content\", \"\")}\n            for m in messages.get(\"messages\", [])\n            if m.get(\"role\") in [\"user\", \"assistant\"]\n        ]\n\n        # Call LLM\n        response = self.llm.invoke(\n            messages=msgs,\n            model_id=self.model_id,\n            system_prompt=\"You are a helpful assistant.\",\n            max_tokens=1000\n        )\n\n        # Extract text\n        content = response[\"output\"][\"message\"][\"content\"]\n        text = next((b[\"text\"] for b in content if \"text\" in b), \"\")\n\n        return AgentMessage(content=text)\n\napp = create_chat_app(ChatAgent())\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, port=8000)\n</code></pre>"},{"location":"examples/examples/#tool-examples","title":"Tool Examples","text":""},{"location":"examples/examples/#basic-calculator-tool","title":"Basic Calculator Tool","text":"<pre><code>from dcaf.tools import tool\n\n@tool(\n    schema={\n        \"name\": \"calculate\",\n        \"description\": \"Perform arithmetic calculations\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"operation\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"],\n                    \"description\": \"The operation to perform\"\n                },\n                \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n                \"b\": {\"type\": \"number\", \"description\": \"Second number\"}\n            },\n            \"required\": [\"operation\", \"a\", \"b\"]\n        }\n    },\n    requires_approval=False\n)\ndef calculate(operation: str, a: float, b: float) -&gt; str:\n    \"\"\"Perform a calculation.\"\"\"\n    ops = {\n        \"add\": lambda x, y: x + y,\n        \"subtract\": lambda x, y: x - y,\n        \"multiply\": lambda x, y: x * y,\n        \"divide\": lambda x, y: x / y if y != 0 else \"undefined\"\n    }\n    result = ops[operation](a, b)\n    return f\"{a} {operation} {b} = {result}\"\n\n# Test\nprint(calculate.execute({\"operation\": \"multiply\", \"a\": 7, \"b\": 8}))\n# Output: 7 multiply 8 = 56\n</code></pre>"},{"location":"examples/examples/#weather-tool-with-enum","title":"Weather Tool with Enum","text":"<pre><code>from dcaf.tools import tool\n\n@tool(\n    schema={\n        \"name\": \"get_weather\",\n        \"description\": \"Get weather for a location\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"City and state, e.g., 'San Francisco, CA'\"\n                },\n                \"unit\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"celsius\", \"fahrenheit\"],\n                    \"description\": \"Temperature unit\",\n                    \"default\": \"fahrenheit\"\n                }\n            },\n            \"required\": [\"location\"]\n        }\n    },\n    requires_approval=False\n)\ndef get_weather(location: str, unit: str = \"fahrenheit\") -&gt; str:\n    \"\"\"Get weather (simulated).\"\"\"\n    # In production, call a real weather API\n    temps = {\"celsius\": \"22\u00b0C\", \"fahrenheit\": \"72\u00b0F\"}\n    return f\"Weather in {location}: {temps[unit]}, sunny with light clouds\"\n\n# Test\nprint(get_weather.execute({\"location\": \"Seattle, WA\"}))\nprint(get_weather.execute({\"location\": \"London, UK\", \"unit\": \"celsius\"}))\n</code></pre>"},{"location":"examples/examples/#tool-with-platform-context","title":"Tool with Platform Context","text":"<pre><code>from dcaf.tools import tool\n\n@tool(\n    schema={\n        \"name\": \"list_user_resources\",\n        \"description\": \"List resources for the current user\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"resource_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"pods\", \"services\", \"deployments\"],\n                    \"description\": \"Type of resource to list\"\n                }\n            },\n            \"required\": [\"resource_type\"]\n        }\n    },\n    requires_approval=False\n)\ndef list_user_resources(resource_type: str, platform_context: dict) -&gt; str:\n    \"\"\"List resources using platform context.\"\"\"\n    tenant = platform_context.get(\"tenant_name\", \"default\")\n    namespace = platform_context.get(\"k8s_namespace\", \"default\")\n    user = platform_context.get(\"user_id\", \"unknown\")\n\n    # Simulated - in production, query Kubernetes\n    return f\"Found 5 {resource_type} in {tenant}/{namespace} for user {user}\"\n\n# Test with context\ncontext = {\"tenant_name\": \"prod\", \"k8s_namespace\": \"web-app\", \"user_id\": \"alice\"}\nprint(list_user_resources.execute({\"resource_type\": \"pods\"}, context))\n</code></pre>"},{"location":"examples/examples/#approval-required-tool","title":"Approval-Required Tool","text":"<pre><code>from dcaf.tools import tool\n\n@tool(\n    schema={\n        \"name\": \"delete_deployment\",\n        \"description\": \"Delete a Kubernetes deployment\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"name\": {\n                    \"type\": \"string\",\n                    \"description\": \"Name of the deployment\"\n                },\n                \"namespace\": {\n                    \"type\": \"string\",\n                    \"description\": \"Kubernetes namespace\",\n                    \"default\": \"default\"\n                },\n                \"force\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Force delete without grace period\",\n                    \"default\": False\n                }\n            },\n            \"required\": [\"name\"]\n        }\n    },\n    requires_approval=True  # Requires user approval\n)\ndef delete_deployment(\n    name: str, \n    namespace: str = \"default\", \n    force: bool = False,\n    platform_context: dict = None\n) -&gt; str:\n    \"\"\"Delete a deployment.\"\"\"\n    user = platform_context.get(\"user_id\", \"system\") if platform_context else \"system\"\n    mode = \"force deleted\" if force else \"deleted\"\n    return f\"Deployment '{name}' in namespace '{namespace}' {mode} by {user}\"\n\n# Verify tool properties\nprint(f\"Requires approval: {delete_deployment.requires_approval}\")  # True\nprint(f\"Has platform context: {delete_deployment.requires_platform_context}\")  # True\n</code></pre>"},{"location":"examples/examples/#programmatic-tool-creation","title":"Programmatic Tool Creation","text":"<pre><code>from dcaf.tools import create_tool\n\n# Define function\ndef search_logs(query: str, limit: int = 100, source: str = None) -&gt; str:\n    \"\"\"Search application logs.\"\"\"\n    sources = f\" from {source}\" if source else \"\"\n    return f\"Found 42 log entries matching '{query}'{sources} (limit: {limit})\"\n\n# Create tool programmatically\nsearch_tool = create_tool(\n    func=search_logs,\n    schema={\n        \"name\": \"search_logs\",\n        \"description\": \"Search application logs for patterns\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"Search query (regex supported)\"\n                },\n                \"limit\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum results\",\n                    \"default\": 100\n                },\n                \"source\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"app\", \"system\", \"security\"],\n                    \"description\": \"Log source to search\"\n                }\n            },\n            \"required\": [\"query\"]\n        }\n    },\n    requires_approval=False\n)\n\n# Test\nprint(search_tool.execute({\"query\": \"error.*timeout\", \"source\": \"app\"}))\n</code></pre>"},{"location":"examples/examples/#agent-examples","title":"Agent Examples","text":""},{"location":"examples/examples/#complete-tool-calling-agent","title":"Complete Tool-Calling Agent","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"tool_agent.py - Complete agent with tools\"\"\"\n\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.tools import tool\nfrom dcaf.agent_server import create_chat_app\nimport uvicorn\nimport dotenv\n\ndotenv.load_dotenv()\n\n# Define tools\n@tool(\n    schema={\n        \"name\": \"get_time\",\n        \"description\": \"Get current date and time\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {},\n            \"required\": []\n        }\n    },\n    requires_approval=False\n)\ndef get_time() -&gt; str:\n    from datetime import datetime\n    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n\n@tool(\n    schema={\n        \"name\": \"calculate\",\n        \"description\": \"Perform arithmetic\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"expression\": {\n                    \"type\": \"string\",\n                    \"description\": \"Math expression (e.g., '2 + 2')\"\n                }\n            },\n            \"required\": [\"expression\"]\n        }\n    },\n    requires_approval=False\n)\ndef calculate(expression: str) -&gt; str:\n    try:\n        # Safe eval for simple math\n        allowed = set(\"0123456789+-*/.() \")\n        if all(c in allowed for c in expression):\n            result = eval(expression)\n            return f\"{expression} = {result}\"\n        return \"Error: Invalid expression\"\n    except Exception as e:\n        return f\"Error: {e}\"\n\n@tool(\n    schema={\n        \"name\": \"send_email\",\n        \"description\": \"Send an email (simulated)\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"to\": {\"type\": \"string\", \"description\": \"Recipient email\"},\n                \"subject\": {\"type\": \"string\", \"description\": \"Email subject\"},\n                \"body\": {\"type\": \"string\", \"description\": \"Email body\"}\n            },\n            \"required\": [\"to\", \"subject\", \"body\"]\n        }\n    },\n    requires_approval=True  # Requires approval\n)\ndef send_email(to: str, subject: str, body: str) -&gt; str:\n    # In production, send actual email\n    return f\"Email sent to {to}: '{subject}'\"\n\n# Create agent\nllm = BedrockLLM(region_name=\"us-east-1\")\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[get_time, calculate, send_email],\n    system_prompt=\"\"\"You are a helpful assistant with access to tools.\n    Use tools when appropriate to help the user.\n    For email sending, always confirm the details before sending.\"\"\",\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_iterations=10\n)\n\napp = create_chat_app(agent)\n\nif __name__ == \"__main__\":\n    print(\"Starting agent on http://localhost:8000\")\n    print(\"Try: curl -X POST http://localhost:8000/api/sendMessage \\\\\")\n    print('  -H \"Content-Type: application/json\" \\\\')\n    print('  -d \\'{\"messages\": [{\"role\": \"user\", \"content\": \"What time is it?\"}]}\\'')\n    uvicorn.run(app, port=8000)\n</code></pre>"},{"location":"examples/examples/#faq-agent","title":"FAQ Agent","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"faq_agent.py - FAQ-based agent\"\"\"\n\nfrom dcaf.agent_server import AgentProtocol, create_chat_app\nfrom dcaf.schemas.messages import AgentMessage\nimport uvicorn\nimport re\n\nclass FAQAgent(AgentProtocol):\n    def __init__(self):\n        self.faqs = [\n            (r\"(what is|explain|define) dcaf\", \n             \"DCAF (DuploCloud Agent Framework) is a Python framework for building \"\n             \"LLM-powered AI agents with tool calling capabilities.\"),\n\n            (r\"how (do i|to) install\",\n             \"Install DCAF with: `pip install git+https://github.com/duplocloud/service-desk-agents.git`\"),\n\n            (r\"(list|what are) (the )?(tools|features)\",\n             \"DCAF features:\\n\"\n             \"- Tool calling with approval workflows\\n\"\n             \"- AWS Bedrock LLM integration\\n\"\n             \"- FastAPI server\\n\"\n             \"- Streaming responses\\n\"\n             \"- Platform context support\"),\n\n            (r\"(hello|hi|hey)\",\n             \"Hello! I'm the FAQ bot. Ask me about DCAF installation, features, or usage.\"),\n\n            (r\"(help|what can you do)\",\n             \"I can answer questions about DCAF. Try asking:\\n\"\n             \"- What is DCAF?\\n\"\n             \"- How do I install DCAF?\\n\"\n             \"- What features does DCAF have?\")\n        ]\n\n        self.default = (\"I don't have a specific answer for that. \"\n                       \"Try asking about DCAF installation or features.\")\n\n    def invoke(self, messages):\n        messages_list = messages.get(\"messages\", [])\n        last_user = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            {}\n        )\n\n        question = last_user.get(\"content\", \"\").lower()\n\n        for pattern, answer in self.faqs:\n            if re.search(pattern, question):\n                return AgentMessage(content=answer)\n\n        return AgentMessage(content=self.default)\n\napp = create_chat_app(FAQAgent())\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, port=8000)\n</code></pre>"},{"location":"examples/examples/#stateful-conversation-agent","title":"Stateful Conversation Agent","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"stateful_agent.py - Agent with conversation memory\"\"\"\n\nfrom dcaf.agent_server import AgentProtocol, create_chat_app\nfrom dcaf.schemas.messages import AgentMessage\nfrom dcaf.llm import BedrockLLM\nfrom collections import defaultdict\nimport uvicorn\nimport dotenv\n\ndotenv.load_dotenv()\n\nclass StatefulAgent(AgentProtocol):\n    def __init__(self):\n        self.llm = BedrockLLM()\n        self.model_id = \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n        self.user_sessions = defaultdict(list)\n\n    def invoke(self, messages):\n        messages_list = messages.get(\"messages\", [])\n\n        # Get user ID\n        user_id = self._get_user_id(messages_list)\n\n        # Get current message\n        last_user = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            {}\n        )\n        current_message = last_user.get(\"content\", \"\")\n\n        # Add to session history\n        self.user_sessions[user_id].append({\n            \"role\": \"user\",\n            \"content\": current_message\n        })\n\n        # Build conversation with history\n        conversation = self.user_sessions[user_id].copy()\n\n        # Call LLM\n        response = self.llm.invoke(\n            messages=conversation,\n            model_id=self.model_id,\n            system_prompt=f\"You are a helpful assistant. The user's ID is {user_id}.\",\n            max_tokens=1000\n        )\n\n        # Extract response\n        content = response[\"output\"][\"message\"][\"content\"]\n        text = next((b[\"text\"] for b in content if \"text\" in b), \"\")\n\n        # Add response to history\n        self.user_sessions[user_id].append({\n            \"role\": \"assistant\",\n            \"content\": text\n        })\n\n        # Limit history length\n        if len(self.user_sessions[user_id]) &gt; 20:\n            self.user_sessions[user_id] = self.user_sessions[user_id][-20:]\n\n        return AgentMessage(content=text)\n\n    def _get_user_id(self, messages_list):\n        for msg in reversed(messages_list):\n            if msg.get(\"role\") == \"user\":\n                ctx = msg.get(\"platform_context\", {})\n                return ctx.get(\"user_id\", \"anonymous\")\n        return \"anonymous\"\n\napp = create_chat_app(StatefulAgent())\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, port=8000)\n</code></pre>"},{"location":"examples/examples/#server-examples","title":"Server Examples","text":""},{"location":"examples/examples/#production-server-with-cors","title":"Production Server with CORS","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"production_server.py - Production-ready server\"\"\"\n\nfrom dcaf.agent_server import create_chat_app\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.tools import tool\nfrom fastapi.middleware.cors import CORSMiddleware\nimport uvicorn\nimport dotenv\nimport logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\ndotenv.load_dotenv()\n\n# Define tools\n@tool(\n    schema={\n        \"name\": \"health_check\",\n        \"description\": \"Check service health\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {},\n            \"required\": []\n        }\n    }\n)\ndef health_check() -&gt; str:\n    return \"All systems operational\"\n\n# Create agent\nllm = BedrockLLM(region_name=\"us-east-1\")\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[health_check],\n    system_prompt=\"You are a production assistant.\"\n)\n\n# Create app\napp = create_chat_app(agent)\n\n# Add CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],  # Configure for your domains\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Add custom middleware\n@app.middleware(\"http\")\nasync def log_requests(request, call_next):\n    logging.info(f\"Request: {request.method} {request.url}\")\n    response = await call_next(request)\n    logging.info(f\"Response: {response.status_code}\")\n    return response\n\nif __name__ == \"__main__\":\n    uvicorn.run(\n        app,\n        host=\"0.0.0.0\",\n        port=8000,\n        log_level=\"info\",\n        access_log=True\n    )\n</code></pre>"},{"location":"examples/examples/#server-with-slack-router","title":"Server with Slack Router","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"slack_server.py - Server with Slack routing\"\"\"\n\nfrom dcaf.agent_server import create_chat_app\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.channel_routing import SlackResponseRouter\nfrom dcaf.tools import tool\nimport uvicorn\nimport dotenv\n\ndotenv.load_dotenv()\n\n# Create LLM\nllm = BedrockLLM()\n\n# Define tools\n@tool(\n    schema={\n        \"name\": \"get_status\",\n        \"description\": \"Get system status\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {},\n            \"required\": []\n        }\n    }\n)\ndef get_status() -&gt; str:\n    return \"All systems running normally\"\n\n# Create agent\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[get_status],\n    system_prompt=\"You are SlackBot, a helpful assistant.\"\n)\n\n# Create Slack router\nrouter = SlackResponseRouter(\n    llm_client=llm,\n    agent_name=\"SlackBot\",\n    agent_description=\"\"\"SlackBot helps with:\n    - System status checks\n    - General questions\n    - Technical support\"\"\",\n    model_id=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\"\n)\n\n# Create app with router\napp = create_chat_app(agent, router=router)\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, port=8000)\n</code></pre>"},{"location":"examples/examples/#client-examples","title":"Client Examples","text":""},{"location":"examples/examples/#python-client","title":"Python Client","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"client.py - Python client example\"\"\"\n\nimport requests\nimport json\n\nBASE_URL = \"http://localhost:8000\"\n\ndef send_message(content: str, history: list = None) -&gt; dict:\n    \"\"\"Send a message to the agent.\"\"\"\n    messages = history or []\n    messages.append({\"role\": \"user\", \"content\": content})\n\n    response = requests.post(\n        f\"{BASE_URL}/api/sendMessage\",\n        json={\"messages\": messages}\n    )\n    response.raise_for_status()\n    return response.json()\n\ndef stream_message(content: str, history: list = None):\n    \"\"\"Stream a message response.\"\"\"\n    messages = history or []\n    messages.append({\"role\": \"user\", \"content\": content})\n\n    response = requests.post(\n        f\"{BASE_URL}/api/sendMessageStream\",\n        json={\"messages\": messages},\n        stream=True\n    )\n\n    for line in response.iter_lines():\n        if line:\n            event = json.loads(line)\n            yield event\n\ndef chat():\n    \"\"\"Interactive chat loop.\"\"\"\n    history = []\n    print(\"Chat with the agent (type 'quit' to exit)\")\n\n    while True:\n        user_input = input(\"\\nYou: \").strip()\n        if user_input.lower() == 'quit':\n            break\n\n        # Send message\n        response = send_message(user_input, history)\n\n        # Print response\n        print(f\"\\nAgent: {response['content']}\")\n\n        # Check for tool calls\n        data = response.get(\"data\", {})\n        if data.get(\"tool_calls\"):\n            print(\"\\n[Tool calls pending approval]\")\n            for tc in data[\"tool_calls\"]:\n                print(f\"  - {tc['name']}: {tc['input']}\")\n\n        # Update history\n        history.append({\"role\": \"user\", \"content\": user_input})\n        history.append({\"role\": \"assistant\", \"content\": response[\"content\"]})\n\nif __name__ == \"__main__\":\n    chat()\n</code></pre>"},{"location":"examples/examples/#streaming-client","title":"Streaming Client","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"streaming_client.py - Streaming client example\"\"\"\n\nimport requests\nimport json\nimport sys\n\ndef stream_chat(message: str):\n    \"\"\"Stream a chat response.\"\"\"\n    response = requests.post(\n        \"http://localhost:8000/api/sendMessageStream\",\n        json={\n            \"messages\": [{\"role\": \"user\", \"content\": message}]\n        },\n        stream=True\n    )\n\n    accumulated = \"\"\n\n    for line in response.iter_lines():\n        if not line:\n            continue\n\n        event = json.loads(line)\n        event_type = event.get(\"type\")\n\n        if event_type == \"text_delta\":\n            text = event.get(\"text\", \"\")\n            accumulated += text\n            sys.stdout.write(text)\n            sys.stdout.flush()\n\n        elif event_type == \"tool_calls\":\n            print(\"\\n\\n[Tools requiring approval:]\")\n            for tc in event.get(\"tool_calls\", []):\n                print(f\"  \u2022 {tc['name']}\")\n                print(f\"    Input: {tc['input']}\")\n\n        elif event_type == \"executed_tool_calls\":\n            print(\"\\n\\n[Executed tools:]\")\n            for tc in event.get(\"executed_tool_calls\", []):\n                print(f\"  \u2022 {tc['name']}: {tc['output'][:100]}...\")\n\n        elif event_type == \"done\":\n            print(f\"\\n\\n[Complete: {event.get('stop_reason')}]\")\n\n        elif event_type == \"error\":\n            print(f\"\\n\\n[Error: {event.get('error')}]\")\n\n    return accumulated\n\nif __name__ == \"__main__\":\n    message = sys.argv[1] if len(sys.argv) &gt; 1 else \"Tell me a short story\"\n    stream_chat(message)\n</code></pre>"},{"location":"examples/examples/#advanced-examples","title":"Advanced Examples","text":""},{"location":"examples/examples/#multi-agent-router","title":"Multi-Agent Router","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"multi_agent.py - Multi-agent routing\"\"\"\n\nfrom dcaf.agent_server import AgentProtocol, create_chat_app\nfrom dcaf.schemas.messages import AgentMessage\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.tools import tool\nfrom dcaf.agents import ToolCallingAgent\nimport uvicorn\nimport dotenv\n\ndotenv.load_dotenv()\n\nclass RouterAgent(AgentProtocol):\n    \"\"\"Routes to specialized agents based on intent.\"\"\"\n\n    def __init__(self):\n        self.llm = BedrockLLM()\n        self.agents = self._create_agents()\n\n    def _create_agents(self):\n        # Weather agent\n        @tool(\n            schema={\n                \"name\": \"get_weather\",\n                \"description\": \"Get weather\",\n                \"input_schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"location\": {\"type\": \"string\"}\n                    },\n                    \"required\": [\"location\"]\n                }\n            }\n        )\n        def get_weather(location: str) -&gt; str:\n            return f\"Weather in {location}: 72\u00b0F, sunny\"\n\n        weather_agent = ToolCallingAgent(\n            llm=self.llm,\n            tools=[get_weather],\n            system_prompt=\"You are a weather assistant.\"\n        )\n\n        # Math agent\n        @tool(\n            schema={\n                \"name\": \"calculate\",\n                \"description\": \"Calculate\",\n                \"input_schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"expr\": {\"type\": \"string\"}\n                    },\n                    \"required\": [\"expr\"]\n                }\n            }\n        )\n        def calculate(expr: str) -&gt; str:\n            try:\n                return str(eval(expr))\n            except:\n                return \"Error\"\n\n        math_agent = ToolCallingAgent(\n            llm=self.llm,\n            tools=[calculate],\n            system_prompt=\"You are a math assistant.\"\n        )\n\n        return {\n            \"weather\": weather_agent,\n            \"math\": math_agent\n        }\n\n    def invoke(self, messages):\n        # Classify intent\n        messages_list = messages.get(\"messages\", [])\n        last_user = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            {}\n        )\n        content = last_user.get(\"content\", \"\").lower()\n\n        # Simple keyword routing\n        if any(w in content for w in [\"weather\", \"temperature\", \"forecast\"]):\n            return self.agents[\"weather\"].invoke(messages)\n        elif any(w in content for w in [\"calculate\", \"math\", \"+\", \"-\", \"*\", \"/\"]):\n            return self.agents[\"math\"].invoke(messages)\n        else:\n            return AgentMessage(\n                content=\"I can help with weather or math. What would you like?\"\n            )\n\napp = create_chat_app(RouterAgent())\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, port=8000)\n</code></pre>"},{"location":"examples/examples/#agent-with-external-api-integration","title":"Agent with External API Integration","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"api_agent.py - Agent with external API integration\"\"\"\n\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.tools import tool\nfrom dcaf.agent_server import create_chat_app\nimport requests\nimport uvicorn\nimport dotenv\n\ndotenv.load_dotenv()\n\n# External API tools\n@tool(\n    schema={\n        \"name\": \"search_github\",\n        \"description\": \"Search GitHub repositories\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\"type\": \"string\", \"description\": \"Search query\"},\n                \"language\": {\"type\": \"string\", \"description\": \"Programming language filter\"}\n            },\n            \"required\": [\"query\"]\n        }\n    },\n    requires_approval=False\n)\ndef search_github(query: str, language: str = None) -&gt; str:\n    \"\"\"Search GitHub via API.\"\"\"\n    search_query = query\n    if language:\n        search_query += f\" language:{language}\"\n\n    response = requests.get(\n        \"https://api.github.com/search/repositories\",\n        params={\"q\": search_query, \"per_page\": 5},\n        headers={\"Accept\": \"application/vnd.github.v3+json\"}\n    )\n\n    if response.status_code != 200:\n        return f\"Error: {response.status_code}\"\n\n    data = response.json()\n    results = []\n    for repo in data.get(\"items\", [])[:5]:\n        results.append(f\"\u2022 {repo['full_name']} ({repo['stargazers_count']}\u2b50)\")\n\n    return f\"Found {data['total_count']} repos:\\n\" + \"\\n\".join(results)\n\n@tool(\n    schema={\n        \"name\": \"get_ip_info\",\n        \"description\": \"Get information about an IP address\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"ip\": {\"type\": \"string\", \"description\": \"IP address to lookup\"}\n            },\n            \"required\": [\"ip\"]\n        }\n    },\n    requires_approval=False\n)\ndef get_ip_info(ip: str) -&gt; str:\n    \"\"\"Get IP information.\"\"\"\n    response = requests.get(f\"https://ipapi.co/{ip}/json/\")\n\n    if response.status_code != 200:\n        return f\"Error: {response.status_code}\"\n\n    data = response.json()\n    return (\n        f\"IP: {data.get('ip')}\\n\"\n        f\"City: {data.get('city')}\\n\"\n        f\"Region: {data.get('region')}\\n\"\n        f\"Country: {data.get('country_name')}\\n\"\n        f\"ISP: {data.get('org')}\"\n    )\n\n# Create agent\nllm = BedrockLLM()\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[search_github, get_ip_info],\n    system_prompt=\"You are a helpful assistant with access to external APIs.\"\n)\n\napp = create_chat_app(agent)\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, port=8000)\n</code></pre>"},{"location":"examples/examples/#complete-production-application","title":"Complete Production Application","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"production_app.py - Complete production application\"\"\"\n\nimport os\nimport logging\nfrom contextlib import asynccontextmanager\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nimport uvicorn\nimport dotenv\n\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.tools import tool\nfrom dcaf.agent_server import create_chat_app\n\n# Load environment\ndotenv.load_dotenv()\n\n# Configure logging\nlogging.basicConfig(\n    level=os.getenv(\"LOG_LEVEL\", \"INFO\"),\n    format=\"%(asctime)s | %(name)s | %(levelname)s | %(message)s\"\n)\nlogger = logging.getLogger(__name__)\n\n# Define tools\n@tool(\n    schema={\n        \"name\": \"get_deployment_status\",\n        \"description\": \"Get status of a deployment\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"name\": {\"type\": \"string\", \"description\": \"Deployment name\"},\n                \"namespace\": {\"type\": \"string\", \"default\": \"default\"}\n            },\n            \"required\": [\"name\"]\n        }\n    }\n)\ndef get_deployment_status(name: str, namespace: str = \"default\", platform_context: dict = None) -&gt; str:\n    tenant = platform_context.get(\"tenant_name\", \"unknown\") if platform_context else \"unknown\"\n    return f\"Deployment {name} in {namespace} ({tenant}): Running (3/3 replicas)\"\n\n@tool(\n    schema={\n        \"name\": \"scale_deployment\",\n        \"description\": \"Scale a deployment\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"name\": {\"type\": \"string\"},\n                \"replicas\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 10}\n            },\n            \"required\": [\"name\", \"replicas\"]\n        }\n    },\n    requires_approval=True\n)\ndef scale_deployment(name: str, replicas: int, platform_context: dict = None) -&gt; str:\n    user = platform_context.get(\"user_id\", \"system\") if platform_context else \"system\"\n    return f\"Deployment {name} scaled to {replicas} replicas by {user}\"\n\n# Create agent\nllm = BedrockLLM(region_name=os.getenv(\"AWS_REGION\", \"us-east-1\"))\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[get_deployment_status, scale_deployment],\n    system_prompt=\"\"\"You are a Kubernetes assistant for DuploCloud.\n    Help users manage their deployments.\n    Always verify the deployment exists before scaling.\"\"\",\n    model_id=os.getenv(\n        \"BEDROCK_MODEL_ID\",\n        \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n    )\n)\n\n# Create app\napp = create_chat_app(agent)\n\n# Add CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=os.getenv(\"CORS_ORIGINS\", \"*\").split(\",\"),\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Add custom endpoints\n@app.get(\"/version\")\ndef version():\n    return {\n        \"version\": os.getenv(\"APP_VERSION\", \"1.0.0\"),\n        \"model\": os.getenv(\"BEDROCK_MODEL_ID\")\n    }\n\nif __name__ == \"__main__\":\n    port = int(os.getenv(\"PORT\", \"8000\"))\n    host = os.getenv(\"HOST\", \"0.0.0.0\")\n\n    logger.info(f\"Starting production server on {host}:{port}\")\n\n    uvicorn.run(\n        app,\n        host=host,\n        port=port,\n        log_level=\"info\",\n        access_log=True\n    )\n</code></pre>"},{"location":"examples/examples/#see-also","title":"See Also","text":"<ul> <li>Getting Started</li> <li>API Reference</li> <li>Building Tools Guide</li> <li>Creating Custom Agents Guide</li> </ul>"},{"location":"guides/building-tools/","title":"Building Tools Guide","text":"<p>This guide covers everything you need to know about creating tools for DCAF agents, from basic tools to advanced patterns.</p>"},{"location":"guides/building-tools/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Your First Tool</li> <li>Schema Definition Options</li> <li>Platform Context</li> <li>Approval Workflows</li> <li>Advanced Patterns</li> <li>Testing Tools</li> <li>Best Practices</li> </ol>"},{"location":"guides/building-tools/#introduction","title":"Introduction","text":"<p>Tools are functions that LLM agents can call to interact with external systems, perform calculations, or execute operations. In DCAF, tools are:</p> <ul> <li>Flexibly defined: Auto-generate schema, use dict, or use Pydantic models</li> <li>Type-safe: JSON Schema validates inputs</li> <li>Context-aware: Can access platform context</li> <li>Approval-enabled: Support human-in-the-loop workflows</li> <li>LLM-ready: Automatically formatted for LLM consumption</li> </ul>"},{"location":"guides/building-tools/#when-to-use-tools","title":"When to Use Tools","text":"<p>\u2705 Use tools for: - External API calls - Database operations - File system operations - Calculations and transformations - Any operation that needs structured input</p> <p>\u274c Don't use tools for: - Simple text responses - Information already in the prompt - Operations the LLM can do directly (math, formatting)</p>"},{"location":"guides/building-tools/#your-first-tool","title":"Your First Tool","text":""},{"location":"guides/building-tools/#step-1-import-the-decorator","title":"Step 1: Import the Decorator","text":"<pre><code>from dcaf.tools import tool\n</code></pre>"},{"location":"guides/building-tools/#step-2-create-the-tool","title":"Step 2: Create the Tool","text":"<p>The simplest approach is to let DCAF auto-generate the schema from your function signature:</p> <pre><code>@tool(description=\"Generate a personalized greeting for a user\")\ndef greet_user(name: str, language: str = \"english\") -&gt; str:\n    \"\"\"Generate a personalized greeting.\"\"\"\n    greetings = {\n        \"english\": f\"Hello, {name}! Welcome!\",\n        \"spanish\": f\"\u00a1Hola, {name}! \u00a1Bienvenido!\",\n        \"french\": f\"Bonjour, {name}! Bienvenue!\"\n    }\n    return greetings.get(language, greetings[\"english\"])\n</code></pre> <p>That's it! DCAF automatically creates the JSON schema from the function parameters.</p>"},{"location":"guides/building-tools/#step-3-use-the-tool","title":"Step 3: Use the Tool","text":"<pre><code># Test directly\nresult = greet_user.execute({\"name\": \"Alice\", \"language\": \"spanish\"})\nprint(result)  # \u00a1Hola, Alice! \u00a1Bienvenido!\n\n# Add to agent\nfrom dcaf.core import Agent\n\nagent = Agent(\n    tools=[greet_user],\n    system_prompt=\"You are a friendly greeter.\"\n)\n</code></pre>"},{"location":"guides/building-tools/#schema-definition-options","title":"Schema Definition Options","text":"<p>DCAF supports three ways to define tool input schemas, giving you flexibility based on your needs.</p>"},{"location":"guides/building-tools/#option-1-auto-generate-recommended-for-simple-tools","title":"Option 1: Auto-Generate (Recommended for Simple Tools)","text":"<p>Let DCAF infer the schema from your function signature:</p> <pre><code>@tool(description=\"Create a new Kubernetes deployment\")\ndef create_deployment(\n    name: str,\n    image: str,\n    replicas: int = 1,\n    force: bool = False\n) -&gt; str:\n    \"\"\"Create a Kubernetes deployment.\"\"\"\n    return f\"Created {name} with image {image}, {replicas} replicas\"\n</code></pre> <p>DCAF automatically generates:</p> <pre><code>{\n    \"type\": \"object\",\n    \"properties\": {\n        \"name\": {\"type\": \"string\"},\n        \"image\": {\"type\": \"string\"},\n        \"replicas\": {\"type\": \"integer\", \"default\": 1},\n        \"force\": {\"type\": \"boolean\", \"default\": false}\n    },\n    \"required\": [\"name\", \"image\"]\n}\n</code></pre>"},{"location":"guides/building-tools/#option-2-dict-schema-full-json-schema-control","title":"Option 2: Dict Schema (Full JSON Schema Control)","text":"<p>For advanced validation (enums, patterns, min/max values):</p> <pre><code>@tool(\n    description=\"Create a new Kubernetes deployment\",\n    requires_approval=True,\n    schema={\n        \"type\": \"object\",\n        \"properties\": {\n            \"name\": {\n                \"type\": \"string\",\n                \"description\": \"Deployment name\",\n                \"minLength\": 1,\n                \"maxLength\": 63,\n                \"pattern\": \"^[a-z0-9]([-a-z0-9]*[a-z0-9])?$\"\n            },\n            \"image\": {\n                \"type\": \"string\",\n                \"description\": \"Docker image (e.g., nginx:latest)\"\n            },\n            \"replicas\": {\n                \"type\": \"integer\",\n                \"description\": \"Number of replicas\",\n                \"minimum\": 1,\n                \"maximum\": 10,\n                \"default\": 1\n            },\n            \"namespace\": {\n                \"type\": \"string\",\n                \"enum\": [\"default\", \"production\", \"staging\"],\n                \"description\": \"Target namespace\"\n            }\n        },\n        \"required\": [\"name\", \"image\"]\n    }\n)\ndef create_deployment(\n    name: str,\n    image: str,\n    replicas: int = 1,\n    namespace: str = \"default\"\n) -&gt; str:\n    \"\"\"Create a Kubernetes deployment.\"\"\"\n    return f\"Created {name} in {namespace}\"\n</code></pre>"},{"location":"guides/building-tools/#option-3-pydantic-model-type-safe-with-ide-support","title":"Option 3: Pydantic Model (Type-Safe with IDE Support)","text":"<p>For production tools with complex schemas, use Pydantic models:</p> <pre><code>from pydantic import BaseModel, Field\nfrom typing import Literal, Optional\n\nclass CreateDeploymentInput(BaseModel):\n    \"\"\"Input schema for deployment creation.\"\"\"\n\n    name: str = Field(\n        ...,\n        description=\"Deployment name\",\n        min_length=1,\n        max_length=63,\n        pattern=\"^[a-z0-9]([-a-z0-9]*[a-z0-9])?$\"\n    )\n    image: str = Field(\n        ...,\n        description=\"Docker image (e.g., nginx:latest)\"\n    )\n    replicas: int = Field(\n        default=1,\n        ge=1,\n        le=10,\n        description=\"Number of replicas\"\n    )\n    namespace: Literal[\"default\", \"production\", \"staging\"] = Field(\n        default=\"default\",\n        description=\"Target namespace\"\n    )\n\n@tool(\n    description=\"Create a new Kubernetes deployment\",\n    requires_approval=True,\n    schema=CreateDeploymentInput  # Just pass the model class!\n)\ndef create_deployment(\n    name: str,\n    image: str,\n    replicas: int = 1,\n    namespace: str = \"default\"\n) -&gt; str:\n    \"\"\"Create a Kubernetes deployment.\"\"\"\n    return f\"Created {name} in {namespace}\"\n</code></pre> <p>Why Pydantic?</p> <p>Pydantic models give you:</p> <ul> <li>IDE autocomplete when defining the schema</li> <li>Type checking at development time</li> <li>Reusable schemas across multiple tools</li> <li>Input validation - you can validate inputs in your tool:   <pre><code>def create_deployment(name: str, image: str, ...) -&gt; str:\n    # Optional: validate inputs\n    validated = CreateDeploymentInput(name=name, image=image, ...)\n    # Now you have type-safe access with IDE support\n</code></pre></li> </ul>"},{"location":"guides/building-tools/#choosing-the-right-approach","title":"Choosing the Right Approach","text":"Use Case Recommended Approach Quick prototyping Auto-generate Simple tools (few params) Auto-generate Need enums/constraints Dict or Pydantic Production tools Pydantic model Sharing schemas across tools Pydantic model Dynamic schema generation Dict schema"},{"location":"guides/building-tools/#json-schema-reference","title":"JSON Schema Reference","text":"<p>When using dict schemas, these are the common JSON Schema features:</p>"},{"location":"guides/building-tools/#string-constraints","title":"String Constraints","text":"<pre><code>\"username\": {\n    \"type\": \"string\",\n    \"description\": \"The username\",\n    \"minLength\": 3,\n    \"maxLength\": 50,\n    \"pattern\": \"^[a-z0-9_]+$\"\n}\n</code></pre>"},{"location":"guides/building-tools/#numeric-constraints","title":"Numeric Constraints","text":"<pre><code>\"count\": {\n    \"type\": \"integer\",\n    \"minimum\": 1,\n    \"maximum\": 100\n}\n\n\"temperature\": {\n    \"type\": \"number\",\n    \"minimum\": -273.15\n}\n</code></pre>"},{"location":"guides/building-tools/#enums","title":"Enums","text":"<pre><code>\"priority\": {\n    \"type\": \"string\",\n    \"enum\": [\"low\", \"medium\", \"high\", \"critical\"]\n}\n</code></pre>"},{"location":"guides/building-tools/#arrays","title":"Arrays","text":"<pre><code>\"tags\": {\n    \"type\": \"array\",\n    \"items\": {\"type\": \"string\"},\n    \"minItems\": 1,\n    \"maxItems\": 10\n}\n</code></pre>"},{"location":"guides/building-tools/#nested-objects","title":"Nested Objects","text":"<pre><code>\"config\": {\n    \"type\": \"object\",\n    \"properties\": {\n        \"timeout\": {\"type\": \"integer\"},\n        \"retries\": {\"type\": \"integer\"}\n    },\n    \"required\": [\"timeout\"]\n}\n</code></pre>"},{"location":"guides/building-tools/#platform-context","title":"Platform Context","text":"<p>Platform context allows tools to access runtime information about the user, tenant, and environment.</p>"},{"location":"guides/building-tools/#enabling-platform-context","title":"Enabling Platform Context","text":"<p>Simply add <code>platform_context: dict</code> as a parameter:</p> <pre><code>@tool(\n    schema={\n        \"name\": \"list_user_resources\",\n        \"description\": \"List resources for the current user\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"resource_type\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"pods\", \"services\", \"deployments\"]\n                }\n            },\n            \"required\": [\"resource_type\"]\n        }\n    }\n)\ndef list_user_resources(\n    resource_type: str,\n    platform_context: dict  # DCAF auto-detects this\n) -&gt; str:\n    \"\"\"List resources in the user's namespace.\"\"\"\n    tenant = platform_context.get(\"tenant_name\", \"default\")\n    namespace = platform_context.get(\"k8s_namespace\", \"default\")\n    user_id = platform_context.get(\"user_id\", \"unknown\")\n\n    # Use context for filtered query\n    return f\"Found 5 {resource_type} in {tenant}/{namespace} for {user_id}\"\n</code></pre>"},{"location":"guides/building-tools/#available-context-fields","title":"Available Context Fields","text":"<pre><code>platform_context = {\n    \"user_id\": \"alice123\",           # Current user ID\n    \"tenant_name\": \"production\",      # DuploCloud tenant\n    \"k8s_namespace\": \"my-app\",        # Kubernetes namespace\n    \"duplo_base_url\": \"https://...\",  # DuploCloud API URL\n    \"duplo_token\": \"eyJ...\",          # DuploCloud token\n    \"kubeconfig\": \"base64...\",        # Encoded kubeconfig\n    \"aws_credentials\": {...}           # AWS credential info\n}\n</code></pre>"},{"location":"guides/building-tools/#using-context-for-authorization","title":"Using Context for Authorization","text":"<pre><code>@tool(\n    schema={\n        \"name\": \"delete_resource\",\n        \"description\": \"Delete a resource\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"resource_id\": {\"type\": \"string\"}\n            },\n            \"required\": [\"resource_id\"]\n        }\n    },\n    requires_approval=True\n)\ndef delete_resource(\n    resource_id: str,\n    platform_context: dict\n) -&gt; str:\n    \"\"\"Delete a resource with authorization check.\"\"\"\n    user_id = platform_context.get(\"user_id\")\n    tenant = platform_context.get(\"tenant_name\")\n\n    # Authorization check\n    if not user_id:\n        return \"Error: User not authenticated\"\n\n    # Audit log\n    print(f\"AUDIT: {user_id} deleting {resource_id} in {tenant}\")\n\n    # Perform deletion\n    return f\"Deleted {resource_id}\"\n</code></pre>"},{"location":"guides/building-tools/#using-context-for-api-calls","title":"Using Context for API Calls","text":"<pre><code>import requests\n\n@tool(\n    schema={\n        \"name\": \"get_tenant_services\",\n        \"description\": \"List all services in the tenant\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {},\n            \"required\": []\n        }\n    }\n)\ndef get_tenant_services(platform_context: dict) -&gt; str:\n    \"\"\"Get services from DuploCloud API.\"\"\"\n    base_url = platform_context.get(\"duplo_base_url\")\n    token = platform_context.get(\"duplo_token\")\n    tenant = platform_context.get(\"tenant_name\")\n\n    if not all([base_url, token, tenant]):\n        return \"Error: Missing DuploCloud credentials\"\n\n    response = requests.get(\n        f\"{base_url}/subscriptions/{tenant}/GetNativeServices\",\n        headers={\"Authorization\": f\"Bearer {token}\"}\n    )\n\n    if response.status_code == 200:\n        services = response.json()\n        return f\"Found {len(services)} services\"\n    else:\n        return f\"Error: {response.status_code}\"\n</code></pre>"},{"location":"guides/building-tools/#approval-workflows","title":"Approval Workflows","text":""},{"location":"guides/building-tools/#when-to-require-approval","title":"When to Require Approval","text":"<p>Require approval for operations that:</p> <ul> <li>Modify state (create, update, delete)</li> <li>Cost money (provision resources, scale up)</li> <li>Are irreversible (delete, terminate)</li> <li>Affect security (change permissions, expose ports)</li> <li>Impact production (deployments, rollbacks)</li> </ul>"},{"location":"guides/building-tools/#creating-approval-required-tools","title":"Creating Approval-Required Tools","text":"<pre><code>@tool(\n    schema={\n        \"name\": \"terminate_instance\",\n        \"description\": \"Terminate an EC2 instance\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"instance_id\": {\n                    \"type\": \"string\",\n                    \"description\": \"EC2 instance ID (e.g., i-1234567890abcdef0)\"\n                },\n                \"force\": {\n                    \"type\": \"boolean\",\n                    \"description\": \"Force termination even if instance is running\",\n                    \"default\": False\n                }\n            },\n            \"required\": [\"instance_id\"]\n        }\n    },\n    requires_approval=True  # &lt;-- Key setting\n)\ndef terminate_instance(\n    instance_id: str,\n    force: bool = False,\n    platform_context: dict = None\n) -&gt; str:\n    \"\"\"Terminate an EC2 instance.\"\"\"\n    user = platform_context.get(\"user_id\", \"system\") if platform_context else \"system\"\n\n    # Only executes after user approval\n    return f\"Instance {instance_id} terminated by {user} (force={force})\"\n</code></pre>"},{"location":"guides/building-tools/#user-approval-flow","title":"User Approval Flow","text":"<ol> <li>Agent calls tool \u2192 DCAF creates <code>ToolCall</code> object</li> <li>Agent returns \u2192 Client receives pending tool call</li> <li>User reviews \u2192 Sees tool, inputs, and description</li> <li>User approves/rejects \u2192 Sets <code>execute=True</code> or <code>rejection_reason</code></li> <li>Client sends back \u2192 Agent receives decision</li> <li>Tool executes \u2192 If approved, runs and returns result</li> </ol>"},{"location":"guides/building-tools/#client-side-display","title":"Client-Side Display","text":"<pre><code># Agent returns this for approval\n{\n    \"content\": \"I need your approval to terminate the instance:\",\n    \"data\": {\n        \"tool_calls\": [\n            {\n                \"id\": \"toolu_abc123\",\n                \"name\": \"terminate_instance\",\n                \"input\": {\n                    \"instance_id\": \"i-1234567890abcdef0\",\n                    \"force\": False\n                },\n                \"tool_description\": \"Terminate an EC2 instance\",\n                \"input_description\": {\n                    \"instance_id\": {\n                        \"type\": \"string\",\n                        \"description\": \"EC2 instance ID\"\n                    },\n                    \"force\": {\n                        \"type\": \"boolean\",\n                        \"description\": \"Force termination\"\n                    }\n                },\n                \"execute\": False\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/building-tools/#sending-approval","title":"Sending Approval","text":"<pre><code># User approves\n{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Terminate the instance\",\n            \"data\": {\n                \"tool_calls\": [\n                    {\n                        \"id\": \"toolu_abc123\",\n                        \"name\": \"terminate_instance\",\n                        \"input\": {\"instance_id\": \"i-123...\", \"force\": False},\n                        \"execute\": True  # Approved!\n                    }\n                ]\n            }\n        }\n    ]\n}\n\n# User rejects\n{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Terminate the instance\",\n            \"data\": {\n                \"tool_calls\": [\n                    {\n                        \"id\": \"toolu_abc123\",\n                        \"name\": \"terminate_instance\",\n                        \"input\": {\"instance_id\": \"i-123...\", \"force\": False},\n                        \"rejection_reason\": \"Wrong instance - I meant i-987...\"\n                    }\n                ]\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/building-tools/#advanced-patterns","title":"Advanced Patterns","text":""},{"location":"guides/building-tools/#pattern-1-tool-composition","title":"Pattern 1: Tool Composition","text":"<pre><code>from dcaf.tools import tool, Tool\nfrom typing import List\n\ndef create_crud_tools(resource_name: str, requires_delete_approval: bool = True) -&gt; List[Tool]:\n    \"\"\"Generate CRUD tools for a resource.\"\"\"\n\n    @tool(\n        schema={\n            \"name\": f\"create_{resource_name}\",\n            \"description\": f\"Create a new {resource_name}\",\n            \"input_schema\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"name\": {\"type\": \"string\"},\n                    \"config\": {\"type\": \"object\"}\n                },\n                \"required\": [\"name\"]\n            }\n        },\n        requires_approval=True\n    )\n    def create_resource(name: str, config: dict = None) -&gt; str:\n        return f\"Created {resource_name}: {name}\"\n\n    @tool(\n        schema={\n            \"name\": f\"get_{resource_name}\",\n            \"description\": f\"Get a {resource_name} by name\",\n            \"input_schema\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"name\": {\"type\": \"string\"}\n                },\n                \"required\": [\"name\"]\n            }\n        },\n        requires_approval=False\n    )\n    def get_resource(name: str) -&gt; str:\n        return f\"Found {resource_name}: {name}\"\n\n    @tool(\n        schema={\n            \"name\": f\"delete_{resource_name}\",\n            \"description\": f\"Delete a {resource_name}\",\n            \"input_schema\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"name\": {\"type\": \"string\"}\n                },\n                \"required\": [\"name\"]\n            }\n        },\n        requires_approval=requires_delete_approval\n    )\n    def delete_resource(name: str) -&gt; str:\n        return f\"Deleted {resource_name}: {name}\"\n\n    return [create_resource, get_resource, delete_resource]\n\n# Usage\nproject_tools = create_crud_tools(\"project\")\nuser_tools = create_crud_tools(\"user\", requires_delete_approval=True)\n</code></pre>"},{"location":"guides/building-tools/#pattern-2-async-tool-execution","title":"Pattern 2: Async Tool Execution","text":"<pre><code>import asyncio\nfrom concurrent.futures import ThreadPoolExecutor\nfrom dcaf.tools import tool\n\nexecutor = ThreadPoolExecutor(max_workers=4)\n\n@tool(\n    schema={\n        \"name\": \"long_running_operation\",\n        \"description\": \"Execute a long-running operation\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"operation_id\": {\"type\": \"string\"}\n            },\n            \"required\": [\"operation_id\"]\n        }\n    }\n)\ndef long_running_operation(operation_id: str) -&gt; str:\n    \"\"\"Execute a long operation with timeout handling.\"\"\"\n    import time\n\n    def do_work():\n        time.sleep(5)  # Simulated work\n        return f\"Operation {operation_id} completed\"\n\n    try:\n        future = executor.submit(do_work)\n        result = future.result(timeout=30)\n        return result\n    except TimeoutError:\n        return f\"Operation {operation_id} timed out\"\n</code></pre>"},{"location":"guides/building-tools/#pattern-3-tool-with-retry-logic","title":"Pattern 3: Tool with Retry Logic","text":"<pre><code>import time\nfrom dcaf.tools import tool\n\n@tool(\n    schema={\n        \"name\": \"api_call_with_retry\",\n        \"description\": \"Make an API call with automatic retry\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"endpoint\": {\"type\": \"string\"},\n                \"max_retries\": {\"type\": \"integer\", \"default\": 3}\n            },\n            \"required\": [\"endpoint\"]\n        }\n    }\n)\ndef api_call_with_retry(endpoint: str, max_retries: int = 3) -&gt; str:\n    \"\"\"Make API call with exponential backoff retry.\"\"\"\n    import requests\n\n    for attempt in range(max_retries):\n        try:\n            response = requests.get(endpoint, timeout=10)\n            response.raise_for_status()\n            return f\"Success: {response.json()}\"\n        except requests.RequestException as e:\n            if attempt &lt; max_retries - 1:\n                wait = 2 ** attempt  # Exponential backoff\n                time.sleep(wait)\n            else:\n                return f\"Failed after {max_retries} attempts: {e}\"\n\n    return \"Unexpected error\"\n</code></pre>"},{"location":"guides/building-tools/#pattern-4-tool-with-validation","title":"Pattern 4: Tool with Validation","text":"<pre><code>import re\nfrom dcaf.tools import tool\n\n@tool(\n    schema={\n        \"name\": \"create_user\",\n        \"description\": \"Create a new user account\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"username\": {\"type\": \"string\"},\n                \"email\": {\"type\": \"string\"},\n                \"role\": {\"type\": \"string\", \"enum\": [\"user\", \"admin\"]}\n            },\n            \"required\": [\"username\", \"email\", \"role\"]\n        }\n    },\n    requires_approval=True\n)\ndef create_user(username: str, email: str, role: str) -&gt; str:\n    \"\"\"Create user with validation.\"\"\"\n    # Validate username\n    if not re.match(r'^[a-z0-9_]{3,20}$', username):\n        return \"Error: Username must be 3-20 lowercase alphanumeric characters\"\n\n    # Validate email\n    if not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', email):\n        return \"Error: Invalid email format\"\n\n    # Validate role\n    if role not in [\"user\", \"admin\"]:\n        return f\"Error: Invalid role '{role}'\"\n\n    # Create user\n    return f\"Created user {username} ({email}) with role {role}\"\n</code></pre>"},{"location":"guides/building-tools/#testing-tools","title":"Testing Tools","text":""},{"location":"guides/building-tools/#unit-testing","title":"Unit Testing","text":"<pre><code>import pytest\nfrom dcaf.tools import tool\n\n@tool(\n    schema={\n        \"name\": \"calculate\",\n        \"description\": \"Perform calculation\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"operation\": {\"type\": \"string\", \"enum\": [\"add\", \"subtract\"]},\n                \"a\": {\"type\": \"number\"},\n                \"b\": {\"type\": \"number\"}\n            },\n            \"required\": [\"operation\", \"a\", \"b\"]\n        }\n    }\n)\ndef calculate(operation: str, a: float, b: float) -&gt; str:\n    if operation == \"add\":\n        return str(a + b)\n    elif operation == \"subtract\":\n        return str(a - b)\n    return \"Unknown operation\"\n\nclass TestCalculateTool:\n    def test_add(self):\n        result = calculate.execute({\"operation\": \"add\", \"a\": 5, \"b\": 3})\n        assert result == \"8\"\n\n    def test_subtract(self):\n        result = calculate.execute({\"operation\": \"subtract\", \"a\": 10, \"b\": 4})\n        assert result == \"6\"\n\n    def test_tool_metadata(self):\n        assert calculate.name == \"calculate\"\n        assert calculate.requires_approval == False\n        assert calculate.requires_platform_context == False\n\n    def test_schema(self):\n        schema = calculate.get_schema()\n        assert schema[\"name\"] == \"calculate\"\n        assert \"input_schema\" in schema\n</code></pre>"},{"location":"guides/building-tools/#testing-with-platform-context","title":"Testing with Platform Context","text":"<pre><code>@tool(\n    schema={\n        \"name\": \"greet_user\",\n        \"description\": \"Greet the current user\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {},\n            \"required\": []\n        }\n    }\n)\ndef greet_user(platform_context: dict) -&gt; str:\n    user = platform_context.get(\"user_id\", \"stranger\")\n    return f\"Hello, {user}!\"\n\nclass TestGreetUserTool:\n    def test_with_context(self):\n        context = {\"user_id\": \"alice\"}\n        result = greet_user.execute({}, context)\n        assert result == \"Hello, alice!\"\n\n    def test_without_user(self):\n        result = greet_user.execute({}, {})\n        assert result == \"Hello, stranger!\"\n\n    def test_requires_context(self):\n        assert greet_user.requires_platform_context == True\n</code></pre>"},{"location":"guides/building-tools/#integration-testing","title":"Integration Testing","text":"<pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.tools import tool\n\n@tool(schema={...})\ndef my_tool(param: str) -&gt; str:\n    return f\"Result: {param}\"\n\ndef test_agent_uses_tool():\n    llm = BedrockLLM()\n    agent = ToolCallingAgent(\n        llm=llm,\n        tools=[my_tool],\n        system_prompt=\"Use the tool when asked.\"\n    )\n\n    response = agent.invoke({\n        \"messages\": [\n            {\"role\": \"user\", \"content\": \"Call my_tool with 'test'\"}\n        ]\n    })\n\n    # Check that tool was executed\n    executed = response.data.executed_tool_calls\n    assert len(executed) &gt; 0\n    assert executed[0].name == \"my_tool\"\n</code></pre>"},{"location":"guides/building-tools/#best-practices","title":"Best Practices","text":""},{"location":"guides/building-tools/#1-clear-descriptive-names","title":"1. Clear, Descriptive Names","text":"<pre><code># \u2705 Good\n\"name\": \"delete_kubernetes_deployment\"\n\"name\": \"get_user_email_by_id\"\n\"name\": \"calculate_monthly_cost\"\n\n# \u274c Bad\n\"name\": \"delete\"\n\"name\": \"do_thing\"\n\"name\": \"process\"\n</code></pre>"},{"location":"guides/building-tools/#2-comprehensive-descriptions","title":"2. Comprehensive Descriptions","text":"<pre><code># \u2705 Good\n\"description\": \"Delete a Kubernetes deployment and all associated pods. This action is irreversible.\"\n\n# \u274c Bad\n\"description\": \"Delete deployment\"\n</code></pre>"},{"location":"guides/building-tools/#3-validate-early-fail-fast","title":"3. Validate Early, Fail Fast","text":"<pre><code>@tool(schema={...})\ndef create_resource(name: str, config: dict) -&gt; str:\n    # Validate immediately\n    if not name:\n        return \"Error: Name is required\"\n    if len(name) &gt; 63:\n        return \"Error: Name must be 63 characters or less\"\n    if not name[0].isalpha():\n        return \"Error: Name must start with a letter\"\n\n    # Only proceed if valid\n    return f\"Created: {name}\"\n</code></pre>"},{"location":"guides/building-tools/#4-return-informative-results","title":"4. Return Informative Results","text":"<pre><code># \u2705 Good\nreturn f\"Created deployment '{name}' with {replicas} replicas in namespace '{namespace}'\"\n\n# \u274c Bad\nreturn \"Done\"\n</code></pre>"},{"location":"guides/building-tools/#5-handle-errors-gracefully","title":"5. Handle Errors Gracefully","text":"<pre><code>@tool(schema={...})\ndef api_call(endpoint: str) -&gt; str:\n    try:\n        response = requests.get(endpoint)\n        response.raise_for_status()\n        return f\"Success: {response.json()}\"\n    except requests.ConnectionError:\n        return \"Error: Could not connect to server\"\n    except requests.Timeout:\n        return \"Error: Request timed out\"\n    except requests.HTTPError as e:\n        return f\"Error: HTTP {e.response.status_code}\"\n    except Exception as e:\n        return f\"Error: Unexpected error - {str(e)}\"\n</code></pre>"},{"location":"guides/building-tools/#6-use-appropriate-approval-settings","title":"6. Use Appropriate Approval Settings","text":"<pre><code># Read operations - no approval needed\n@tool(schema={...}, requires_approval=False)\ndef list_resources(): ...\n\n@tool(schema={...}, requires_approval=False)\ndef get_status(): ...\n\n# Write operations - approval recommended\n@tool(schema={...}, requires_approval=True)\ndef create_resource(): ...\n\n@tool(schema={...}, requires_approval=True)\ndef delete_resource(): ...\n</code></pre>"},{"location":"guides/building-tools/#7-document-platform-context-usage","title":"7. Document Platform Context Usage","text":"<pre><code>@tool(\n    schema={\n        \"name\": \"tenant_specific_action\",\n        \"description\": \"Perform action in current tenant. Requires tenant_name and duplo_token in platform context.\",\n        \"input_schema\": {...}\n    }\n)\ndef tenant_specific_action(data: str, platform_context: dict) -&gt; str:\n    \"\"\"\n    Perform action in tenant.\n\n    Platform context requirements:\n    - tenant_name: Current tenant name\n    - duplo_token: API authentication token\n    \"\"\"\n    pass\n</code></pre>"},{"location":"guides/building-tools/#see-also","title":"See Also","text":"<ul> <li>Tools API Reference</li> <li>Agents API Reference</li> <li>Creating Custom Agents</li> <li>Examples</li> </ul>"},{"location":"guides/creating-custom-agents/","title":"Creating Custom Agents Guide (Legacy)","text":"<p>Legacy Guide</p> <p>This documents the v1 API. For new projects, see Custom Agents using the Core API.</p> <p>See Migration Guide to upgrade existing code.</p> <p>This guide covers how to create custom agents in DCAF using the v1 API.</p>"},{"location":"guides/creating-custom-agents/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>The AgentProtocol Interface</li> <li>Simple Custom Agents</li> <li>Tool-Enabled Agents</li> <li>Stateful Agents</li> <li>Multi-Agent Systems</li> <li>Testing Custom Agents</li> <li>Best Practices</li> </ol>"},{"location":"guides/creating-custom-agents/#introduction","title":"Introduction","text":"<p>DCAF agents are Python classes that implement the <code>AgentProtocol</code> interface. This simple contract allows you to create agents that:</p> <ul> <li>Receive conversation messages</li> <li>Process them using any logic you need</li> <li>Return structured responses</li> </ul>"},{"location":"guides/creating-custom-agents/#when-to-create-a-custom-agent","title":"When to Create a Custom Agent","text":"<p>Create a custom agent when: - Built-in agents don't fit your use case - You need specialized processing logic - You want to integrate with external systems - You need custom state management - You want to combine multiple LLMs or services</p>"},{"location":"guides/creating-custom-agents/#the-agentprotocol-interface","title":"The AgentProtocol Interface","text":"<p>Every agent must implement this interface:</p> <pre><code>from typing import Protocol, runtime_checkable, Dict, Any, List\nfrom dcaf.schemas.messages import AgentMessage\n\n@runtime_checkable            \nclass AgentProtocol(Protocol):\n    \"\"\"Any agent that can respond to a chat.\"\"\"\n\n    def invoke(self, messages: Dict[str, List[Dict[str, Any]]]) -&gt; AgentMessage:\n        \"\"\"\n        Process messages and return a response.\n\n        Args:\n            messages: Dictionary with \"messages\" key containing conversation history\n\n        Returns:\n            AgentMessage with response content and optional data\n        \"\"\"\n        ...\n</code></pre>"},{"location":"guides/creating-custom-agents/#message-format","title":"Message Format","text":"<pre><code># Input format\n{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Hello!\",\n            \"data\": {...},\n            \"platform_context\": {...}\n        },\n        {\n            \"role\": \"assistant\", \n            \"content\": \"Hi there!\"\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/creating-custom-agents/#response-format","title":"Response Format","text":"<pre><code>from dcaf.schemas.messages import AgentMessage, Data\n\nAgentMessage(\n    role=\"assistant\",\n    content=\"Response text\",\n    data=Data(\n        cmds=[...],              # Suggested commands\n        tool_calls=[...],        # Tools needing approval\n        executed_tool_calls=[...] # Executed tools\n    )\n)\n</code></pre>"},{"location":"guides/creating-custom-agents/#simple-custom-agents","title":"Simple Custom Agents","text":""},{"location":"guides/creating-custom-agents/#example-1-echo-agent","title":"Example 1: Echo Agent","text":"<p>The simplest possible agent:</p> <pre><code>from dcaf.agent_server import AgentProtocol\nfrom dcaf.schemas.messages import AgentMessage\nfrom typing import Dict, Any, List\n\nclass EchoAgent(AgentProtocol):\n    \"\"\"Echoes back user messages.\"\"\"\n\n    def invoke(self, messages: Dict[str, List[Dict[str, Any]]]) -&gt; AgentMessage:\n        messages_list = messages.get(\"messages\", [])\n\n        # Find last user message\n        last_user = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            None\n        )\n\n        if last_user:\n            return AgentMessage(content=f\"Echo: {last_user.get('content', '')}\")\n\n        return AgentMessage(content=\"No message to echo\")\n</code></pre>"},{"location":"guides/creating-custom-agents/#example-2-greeting-agent","title":"Example 2: Greeting Agent","text":"<p>Agent with configurable behavior:</p> <pre><code>from dcaf.agent_server import AgentProtocol\nfrom dcaf.schemas.messages import AgentMessage\nfrom typing import Dict, Any, List\n\nclass GreetingAgent(AgentProtocol):\n    \"\"\"Greets users with a personalized message.\"\"\"\n\n    def __init__(self, greeting_template: str = \"Hello, {name}!\"):\n        self.greeting_template = greeting_template\n\n    def invoke(self, messages: Dict[str, List[Dict[str, Any]]]) -&gt; AgentMessage:\n        messages_list = messages.get(\"messages\", [])\n\n        # Get user info from platform context\n        last_user_msg = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            {}\n        )\n\n        platform_context = last_user_msg.get(\"platform_context\", {})\n        user_name = platform_context.get(\"user_id\", \"Guest\")\n\n        greeting = self.greeting_template.format(name=user_name)\n        return AgentMessage(content=greeting)\n</code></pre>"},{"location":"guides/creating-custom-agents/#example-3-faq-agent","title":"Example 3: FAQ Agent","text":"<p>Agent with predefined responses:</p> <pre><code>from dcaf.agent_server import AgentProtocol\nfrom dcaf.schemas.messages import AgentMessage\nfrom typing import Dict, Any, List\nimport re\n\nclass FAQAgent(AgentProtocol):\n    \"\"\"Answers frequently asked questions.\"\"\"\n\n    def __init__(self):\n        self.faqs = {\n            r\"what is (dcaf|duplocloud agent framework)\": \n                \"DCAF is the DuploCloud Agent Framework for building AI agents.\",\n            r\"how do i (install|set up)\":\n                \"Install with: pip install git+https://github.com/duplocloud/service-desk-agents.git\",\n            r\"where is the documentation\":\n                \"Documentation is at docs/index.md in the repository.\",\n            r\"(help|what can you do)\":\n                \"I can answer questions about DCAF. Ask about installation, features, or usage.\"\n        }\n        self.default_response = \"I don't have an answer for that. Try asking about DCAF installation or features.\"\n\n    def invoke(self, messages: Dict[str, List[Dict[str, Any]]]) -&gt; AgentMessage:\n        messages_list = messages.get(\"messages\", [])\n\n        last_user = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            {}\n        )\n\n        question = last_user.get(\"content\", \"\").lower()\n\n        # Match against FAQ patterns\n        for pattern, answer in self.faqs.items():\n            if re.search(pattern, question):\n                return AgentMessage(content=answer)\n\n        return AgentMessage(content=self.default_response)\n</code></pre>"},{"location":"guides/creating-custom-agents/#tool-enabled-agents","title":"Tool-Enabled Agents","text":""},{"location":"guides/creating-custom-agents/#extending-toolcallingagent","title":"Extending ToolCallingAgent","text":"<pre><code>from dcaf.agents.tool_calling_agent import ToolCallingAgent\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.tools import tool\nfrom dcaf.schemas.messages import AgentMessage\n\nclass EnhancedToolAgent(ToolCallingAgent):\n    \"\"\"ToolCallingAgent with custom enhancements.\"\"\"\n\n    def __init__(self, llm: BedrockLLM, company_name: str = \"Acme\"):\n        # Create custom tools\n        tools = self._create_tools()\n\n        # Custom system prompt\n        system_prompt = f\"\"\"You are an assistant for {company_name}.\n        Use the available tools to help users.\n        Be concise and helpful.\"\"\"\n\n        super().__init__(\n            llm=llm,\n            tools=tools,\n            system_prompt=system_prompt,\n            model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n        )\n\n        self.company_name = company_name\n\n    def _create_tools(self):\n        @tool(\n            schema={\n                \"name\": \"get_company_info\",\n                \"description\": \"Get company information\",\n                \"input_schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {},\n                    \"required\": []\n                }\n            }\n        )\n        def get_company_info() -&gt; str:\n            return \"Company info here...\"\n\n        return [get_company_info]\n\n    def invoke(self, messages):\n        # Pre-processing\n        self._log_request(messages)\n\n        # Call parent\n        response = super().invoke(messages)\n\n        # Post-processing\n        self._log_response(response)\n\n        return response\n\n    def _log_request(self, messages):\n        msg_count = len(messages.get(\"messages\", []))\n        print(f\"[{self.company_name}] Processing {msg_count} messages\")\n\n    def _log_response(self, response):\n        print(f\"[{self.company_name}] Responded: {response.content[:50]}...\")\n</code></pre>"},{"location":"guides/creating-custom-agents/#building-from-scratch","title":"Building from Scratch","text":"<pre><code>from dcaf.agent_server import AgentProtocol\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.tools import tool, Tool\nfrom dcaf.schemas.messages import AgentMessage, Data, ToolCall, ExecutedToolCall\nfrom typing import Dict, Any, List\n\nclass CustomToolAgent(AgentProtocol):\n    \"\"\"Custom agent with tool support built from scratch.\"\"\"\n\n    def __init__(self, llm: BedrockLLM):\n        self.llm = llm\n        self.tools = self._create_tools()\n        self.tool_schemas = [t.get_schema() for t in self.tools]\n        self.tool_map = {t.name: t for t in self.tools}\n\n    def _create_tools(self) -&gt; List[Tool]:\n        @tool(\n            schema={\n                \"name\": \"search\",\n                \"description\": \"Search for information\",\n                \"input_schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"query\": {\"type\": \"string\"}\n                    },\n                    \"required\": [\"query\"]\n                }\n            },\n            requires_approval=False\n        )\n        def search(query: str) -&gt; str:\n            return f\"Found results for: {query}\"\n\n        return [search]\n\n    def invoke(self, messages: Dict[str, List[Dict[str, Any]]]) -&gt; AgentMessage:\n        # Prepare conversation\n        conversation = self._preprocess_messages(messages)\n\n        # Call LLM\n        response = self.llm.invoke(\n            messages=conversation,\n            model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n            system_prompt=\"You are helpful. Use tools when needed.\",\n            tools=self.tool_schemas,\n            max_tokens=1000\n        )\n\n        # Process response\n        return self._process_response(response, messages)\n\n    def _preprocess_messages(self, messages):\n        processed = []\n        for msg in messages.get(\"messages\", []):\n            if msg.get(\"role\") in [\"user\", \"assistant\"]:\n                processed.append({\n                    \"role\": msg[\"role\"],\n                    \"content\": msg.get(\"content\", \"\")\n                })\n        return processed\n\n    def _process_response(self, response, original_messages):\n        content_blocks = response.get(\"output\", {}).get(\"message\", {}).get(\"content\", [])\n\n        executed_tools = []\n        text_content = \"\"\n\n        for block in content_blocks:\n            if \"text\" in block:\n                text_content = block[\"text\"]\n            elif \"toolUse\" in block:\n                tool_use = block[\"toolUse\"]\n                tool_name = tool_use[\"name\"]\n                tool_input = tool_use[\"input\"]\n\n                if tool_name in self.tool_map:\n                    tool = self.tool_map[tool_name]\n                    result = tool.execute(tool_input)\n\n                    executed_tools.append(ExecutedToolCall(\n                        id=tool_use[\"toolUseId\"],\n                        name=tool_name,\n                        input=tool_input,\n                        output=result\n                    ))\n\n        return AgentMessage(\n            content=text_content or \"I processed your request.\",\n            data=Data(executed_tool_calls=executed_tools)\n        )\n</code></pre>"},{"location":"guides/creating-custom-agents/#stateful-agents","title":"Stateful Agents","text":""},{"location":"guides/creating-custom-agents/#in-memory-state","title":"In-Memory State","text":"<pre><code>from dcaf.agent_server import AgentProtocol\nfrom dcaf.schemas.messages import AgentMessage\nfrom collections import defaultdict\nfrom typing import Dict, Any, List\n\nclass StatefulAgent(AgentProtocol):\n    \"\"\"Agent that maintains state across requests.\"\"\"\n\n    def __init__(self):\n        # Per-user state\n        self.user_state = defaultdict(lambda: {\n            \"interactions\": 0,\n            \"preferences\": {},\n            \"last_topic\": None\n        })\n\n    def invoke(self, messages: Dict[str, List[Dict[str, Any]]]) -&gt; AgentMessage:\n        messages_list = messages.get(\"messages\", [])\n\n        # Get user ID\n        user_id = self._get_user_id(messages_list)\n\n        # Update state\n        self.user_state[user_id][\"interactions\"] += 1\n        count = self.user_state[user_id][\"interactions\"]\n\n        # Get last message\n        last_user = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            {}\n        )\n        content = last_user.get(\"content\", \"\")\n\n        # Store topic\n        self.user_state[user_id][\"last_topic\"] = content[:50]\n\n        return AgentMessage(\n            content=f\"Hello {user_id}! This is interaction #{count}. \"\n                   f\"You said: {content}\"\n        )\n\n    def _get_user_id(self, messages_list):\n        for msg in reversed(messages_list):\n            if msg.get(\"role\") == \"user\":\n                context = msg.get(\"platform_context\", {})\n                return context.get(\"user_id\", \"anonymous\")\n        return \"anonymous\"\n</code></pre>"},{"location":"guides/creating-custom-agents/#persistent-state-with-redis","title":"Persistent State with Redis","text":"<pre><code>import redis\nimport json\nfrom dcaf.agent_server import AgentProtocol\nfrom dcaf.schemas.messages import AgentMessage\n\nclass RedisStatefulAgent(AgentProtocol):\n    \"\"\"Agent with Redis-backed persistent state.\"\"\"\n\n    def __init__(self, redis_url: str = \"redis://localhost:6379\"):\n        self.redis = redis.from_url(redis_url)\n\n    def invoke(self, messages):\n        messages_list = messages.get(\"messages\", [])\n        user_id = self._get_user_id(messages_list)\n\n        # Get or initialize state\n        state = self._get_state(user_id)\n        state[\"interactions\"] = state.get(\"interactions\", 0) + 1\n\n        # Save state\n        self._save_state(user_id, state)\n\n        return AgentMessage(\n            content=f\"Welcome back! Interaction #{state['interactions']}\"\n        )\n\n    def _get_state(self, user_id):\n        data = self.redis.get(f\"agent:state:{user_id}\")\n        return json.loads(data) if data else {}\n\n    def _save_state(self, user_id, state):\n        self.redis.set(\n            f\"agent:state:{user_id}\",\n            json.dumps(state),\n            ex=86400  # 24 hour TTL\n        )\n\n    def _get_user_id(self, messages_list):\n        for msg in reversed(messages_list):\n            if msg.get(\"role\") == \"user\":\n                return msg.get(\"platform_context\", {}).get(\"user_id\", \"anon\")\n        return \"anon\"\n</code></pre>"},{"location":"guides/creating-custom-agents/#multi-agent-systems","title":"Multi-Agent Systems","text":""},{"location":"guides/creating-custom-agents/#router-agent","title":"Router Agent","text":"<pre><code>from dcaf.agent_server import AgentProtocol\nfrom dcaf.schemas.messages import AgentMessage\nfrom dcaf.llm import BedrockLLM\nfrom typing import Dict, Any, List\n\nclass RouterAgent(AgentProtocol):\n    \"\"\"Routes requests to specialized sub-agents.\"\"\"\n\n    def __init__(self, llm: BedrockLLM, agents: Dict[str, AgentProtocol]):\n        self.llm = llm\n        self.agents = agents\n\n    def invoke(self, messages: Dict[str, List[Dict[str, Any]]]) -&gt; AgentMessage:\n        # Get the last user message\n        messages_list = messages.get(\"messages\", [])\n        last_user = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            {}\n        )\n        content = last_user.get(\"content\", \"\")\n\n        # Classify the request\n        agent_name = self._classify_request(content)\n\n        if agent_name in self.agents:\n            # Route to specialized agent\n            return self.agents[agent_name].invoke(messages)\n        else:\n            return AgentMessage(\n                content=\"I'm not sure how to help with that. \"\n                       \"Try asking about Kubernetes, AWS, or general help.\"\n            )\n\n    def _classify_request(self, content: str) -&gt; str:\n        \"\"\"Use LLM to classify the request.\"\"\"\n        response = self.llm.invoke(\n            messages=[{\n                \"role\": \"user\",\n                \"content\": f\"Classify this request into one of: kubernetes, aws, general\\n\\nRequest: {content}\"\n            }],\n            model_id=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n            max_tokens=10,\n            temperature=0\n        )\n\n        classification = response[\"output\"][\"message\"][\"content\"][0][\"text\"].lower()\n\n        if \"kubernetes\" in classification or \"k8s\" in classification:\n            return \"k8s\"\n        elif \"aws\" in classification:\n            return \"aws\"\n        else:\n            return \"general\"\n\n# Usage\nfrom dcaf.agents.k8s_agent import K8sAgent\nfrom dcaf.agents.aws_agent import AWSAgent\n\nllm = BedrockLLM()\nrouter = RouterAgent(\n    llm=llm,\n    agents={\n        \"k8s\": K8sAgent(llm),\n        \"aws\": AWSAgent(llm),\n        \"general\": SimpleAgent()\n    }\n)\n</code></pre>"},{"location":"guides/creating-custom-agents/#parallel-agent-execution","title":"Parallel Agent Execution","text":"<pre><code>import asyncio\nfrom concurrent.futures import ThreadPoolExecutor\nfrom dcaf.agent_server import AgentProtocol\nfrom dcaf.schemas.messages import AgentMessage\n\nclass ParallelAgent(AgentProtocol):\n    \"\"\"Runs multiple agents in parallel and combines results.\"\"\"\n\n    def __init__(self, agents: List[AgentProtocol]):\n        self.agents = agents\n        self.executor = ThreadPoolExecutor(max_workers=len(agents))\n\n    def invoke(self, messages):\n        # Run all agents in parallel\n        futures = [\n            self.executor.submit(agent.invoke, messages)\n            for agent in self.agents\n        ]\n\n        # Collect results\n        results = []\n        for future in futures:\n            try:\n                result = future.result(timeout=30)\n                results.append(result.content)\n            except Exception as e:\n                results.append(f\"Error: {e}\")\n\n        # Combine results\n        combined = \"\\n\\n---\\n\\n\".join(results)\n        return AgentMessage(content=combined)\n</code></pre>"},{"location":"guides/creating-custom-agents/#testing-custom-agents","title":"Testing Custom Agents","text":""},{"location":"guides/creating-custom-agents/#unit-tests","title":"Unit Tests","text":"<pre><code>import pytest\nfrom dcaf.schemas.messages import AgentMessage\nfrom my_agents import MyCustomAgent\n\nclass TestMyCustomAgent:\n    def setup_method(self):\n        self.agent = MyCustomAgent()\n\n    def test_basic_response(self):\n        messages = {\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"Hello\"}\n            ]\n        }\n\n        response = self.agent.invoke(messages)\n\n        assert isinstance(response, AgentMessage)\n        assert response.role == \"assistant\"\n        assert len(response.content) &gt; 0\n\n    def test_empty_messages(self):\n        messages = {\"messages\": []}\n\n        response = self.agent.invoke(messages)\n\n        assert isinstance(response, AgentMessage)\n\n    def test_with_platform_context(self):\n        messages = {\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": \"Hello\",\n                    \"platform_context\": {\n                        \"user_id\": \"test_user\",\n                        \"tenant_name\": \"test_tenant\"\n                    }\n                }\n            ]\n        }\n\n        response = self.agent.invoke(messages)\n\n        assert \"test_user\" in response.content or response.content\n</code></pre>"},{"location":"guides/creating-custom-agents/#integration-tests","title":"Integration Tests","text":"<pre><code>from fastapi.testclient import TestClient\nfrom dcaf.agent_server import create_chat_app\nfrom my_agents import MyCustomAgent\n\ndef test_agent_server_integration():\n    agent = MyCustomAgent()\n    app = create_chat_app(agent)\n    client = TestClient(app)\n\n    # Test health endpoint\n    response = client.get(\"/health\")\n    assert response.status_code == 200\n\n    # Test send message\n    response = client.post(\n        \"/api/sendMessage\",\n        json={\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"Test message\"}\n            ]\n        }\n    )\n    assert response.status_code == 200\n    assert \"content\" in response.json()\n</code></pre>"},{"location":"guides/creating-custom-agents/#mock-llm-testing","title":"Mock LLM Testing","text":"<pre><code>from unittest.mock import Mock, patch\nfrom dcaf.llm import BedrockLLM\nfrom my_agents import MyLLMAgent\n\ndef test_agent_with_mock_llm():\n    # Create mock LLM\n    mock_llm = Mock(spec=BedrockLLM)\n    mock_llm.invoke.return_value = {\n        \"output\": {\n            \"message\": {\n                \"content\": [{\"text\": \"Mocked response\"}]\n            }\n        }\n    }\n\n    # Create agent with mock\n    agent = MyLLMAgent(llm=mock_llm)\n\n    # Test\n    response = agent.invoke({\n        \"messages\": [{\"role\": \"user\", \"content\": \"Test\"}]\n    })\n\n    assert response.content == \"Mocked response\"\n    mock_llm.invoke.assert_called_once()\n</code></pre>"},{"location":"guides/creating-custom-agents/#best-practices","title":"Best Practices","text":""},{"location":"guides/creating-custom-agents/#1-always-return-agentmessage","title":"1. Always Return AgentMessage","text":"<pre><code># \u2705 Good\ndef invoke(self, messages):\n    try:\n        result = self.process(messages)\n        return AgentMessage(content=result)\n    except Exception as e:\n        return AgentMessage(content=f\"Error: {e}\")\n\n# \u274c Bad\ndef invoke(self, messages):\n    return self.process(messages)  # May not be AgentMessage\n</code></pre>"},{"location":"guides/creating-custom-agents/#2-handle-missing-data-gracefully","title":"2. Handle Missing Data Gracefully","text":"<pre><code># \u2705 Good\ndef invoke(self, messages):\n    messages_list = messages.get(\"messages\", [])\n    last_user = next(\n        (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n        None\n    )\n\n    if not last_user:\n        return AgentMessage(content=\"No user message found\")\n\n    content = last_user.get(\"content\", \"\")\n    ...\n\n# \u274c Bad\ndef invoke(self, messages):\n    content = messages[\"messages\"][-1][\"content\"]  # May crash\n</code></pre>"},{"location":"guides/creating-custom-agents/#3-use-logging","title":"3. Use Logging","text":"<pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\nclass MyAgent(AgentProtocol):\n    def invoke(self, messages):\n        logger.info(f\"Processing {len(messages.get('messages', []))} messages\")\n\n        try:\n            result = self._process(messages)\n            logger.info(f\"Response: {result.content[:100]}...\")\n            return result\n        except Exception as e:\n            logger.error(f\"Error: {e}\", exc_info=True)\n            return AgentMessage(content=f\"Error: {e}\")\n</code></pre>"},{"location":"guides/creating-custom-agents/#4-make-agents-configurable","title":"4. Make Agents Configurable","text":"<pre><code>class ConfigurableAgent(AgentProtocol):\n    def __init__(\n        self,\n        llm: BedrockLLM,\n        system_prompt: str = \"You are helpful.\",\n        max_tokens: int = 1000,\n        temperature: float = 0.7\n    ):\n        self.llm = llm\n        self.system_prompt = system_prompt\n        self.max_tokens = max_tokens\n        self.temperature = temperature\n</code></pre>"},{"location":"guides/creating-custom-agents/#5-document-your-agents","title":"5. Document Your Agents","text":"<pre><code>class DocumentedAgent(AgentProtocol):\n    \"\"\"\n    A well-documented agent.\n\n    This agent processes user messages and responds using\n    a combination of tools and LLM reasoning.\n\n    Attributes:\n        llm: The LLM client for generating responses\n        tools: List of available tools\n\n    Configuration:\n        Requires platform_context with:\n        - user_id: Current user identifier\n        - tenant_name: DuploCloud tenant name\n\n    Example:\n        agent = DocumentedAgent(llm, tools=[my_tool])\n        app = create_chat_app(agent)\n    \"\"\"\n</code></pre>"},{"location":"guides/creating-custom-agents/#see-also","title":"See Also","text":"<ul> <li>Agents API Reference</li> <li>Building Tools Guide</li> <li>Message Protocol Guide</li> <li>Examples</li> </ul>"},{"location":"guides/custom-agents/","title":"Building Custom Agents","text":"<p>This guide shows how to build agents with custom logic using DCAF.</p>"},{"location":"guides/custom-agents/#when-to-use-custom-functions","title":"When to Use Custom Functions","text":"<p>Use <code>Agent</code> directly with <code>serve()</code> for simple use cases:</p> <pre><code>from dcaf.core import Agent, serve\n\nagent = Agent(tools=[my_tool])\nserve(agent)\n</code></pre> <p>Use custom functions when you need:</p> <ul> <li>Multiple LLM calls</li> <li>Complex branching logic</li> <li>Custom pre/post processing</li> <li>Integration with external systems</li> <li>Different models for different tasks</li> </ul>"},{"location":"guides/custom-agents/#quick-start","title":"Quick Start","text":"<pre><code>from dcaf.core import Agent, Session, serve\nfrom dcaf.core.primitives import AgentResult\nfrom dcaf.tools import tool\n\n@tool(description=\"Get current time\")\ndef get_time() -&gt; str:\n    from datetime import datetime\n    return datetime.now().isoformat()\n\ndef my_agent(messages: list, context: dict, session: Session) -&gt; AgentResult:\n    \"\"\"Your custom agent logic with session access.\"\"\"\n\n    # Track call count in session\n    call_count = session.get(\"call_count\", 0)\n    session.set(\"call_count\", call_count + 1)\n\n    # Create an agent and run it\n    agent = Agent(\n        tools=[get_time],\n        system=\"You are a helpful assistant.\",\n    )\n\n    # Pass session to agent.run()\n    response = agent.run(messages, session=session.to_dict())\n\n    # Return the result with session\n    return AgentResult(\n        text=response.text,\n        session=session.to_dict(),\n    )\n\n# Serve it\nserve(my_agent)\n</code></pre> <p>Note: The <code>session</code> parameter is optional for backward compatibility. Functions without it still work.</p>"},{"location":"guides/custom-agents/#the-pattern","title":"The Pattern","text":""},{"location":"guides/custom-agents/#custom-functions-return-agentresult","title":"Custom functions return <code>AgentResult</code>","text":"<pre><code>from dcaf.core.primitives import AgentResult, ToolApproval, ToolResult\n\n# Simple text response\nreturn AgentResult(text=\"Here are your pods: nginx, redis, api\")\n\n# With session data\nreturn AgentResult(\n    text=\"Here are your pods: nginx, redis, api\",\n    session={\"last_query\": \"pods\", \"count\": 3},\n)\n\n# Needs approval\nreturn AgentResult(\n    text=\"I need approval to delete the pod.\",\n    pending_tools=[\n        ToolApproval(\n            id=\"tc_123\",\n            name=\"delete_pod\",\n            input={\"name\": \"nginx-abc\"},\n            description=\"Delete pod nginx-abc from production\",\n        )\n    ],\n)\n\n# Tool was executed\nreturn AgentResult(\n    text=\"Pod deleted successfully.\",\n    executed_tools=[\n        ToolResult(\n            id=\"tc_123\",\n            name=\"delete_pod\",\n            input={\"name\": \"nginx-abc\"},\n            output=\"pod 'nginx-abc' deleted\",\n        )\n    ],\n)\n</code></pre>"},{"location":"guides/custom-agents/#use-from_agent_response-for-convenience","title":"Use <code>from_agent_response()</code> for convenience","text":"<pre><code>from dcaf.core import Agent, Session, serve\nfrom dcaf.core.primitives import from_agent_response, AgentResult\n\ndef my_agent(messages: list, context: dict, session: Session) -&gt; AgentResult:\n    agent = Agent(tools=[...])\n    response = agent.run(messages, session=session.to_dict())\n    return from_agent_response(response)\n\nserve(my_agent)\n</code></pre>"},{"location":"guides/custom-agents/#multi-call-patterns","title":"Multi-Call Patterns","text":""},{"location":"guides/custom-agents/#pattern-1-sequential-calls","title":"Pattern 1: Sequential Calls","text":"<p>Each call depends on the previous:</p> <pre><code>from dcaf.core import Agent, Session\nfrom dcaf.core.primitives import AgentResult\n\ndef research_agent(messages: list, context: dict, session: Session) -&gt; AgentResult:\n    user_question = messages[-1][\"content\"]\n\n    # Track research topics in session\n    topics = session.get(\"research_topics\", [])\n    topics.append(user_question[:50])\n    session.set(\"research_topics\", topics)\n\n    # Step 1: Classify the question\n    classifier = Agent(system=\"Classify as: factual, opinion, or action. Reply with one word.\")\n    classification = classifier.run(messages)\n\n    # Step 2: Handle based on classification\n    if \"factual\" in classification.text.lower():\n        # Research the topic\n        researcher = Agent(system=\"Provide detailed factual information.\")\n        research = researcher.run([{\"role\": \"user\", \"content\": f\"Research: {user_question}\"}])\n\n        # Step 3: Summarize\n        summarizer = Agent(system=\"Provide a concise summary.\")\n        summary = summarizer.run([{\"role\": \"user\", \"content\": f\"Summarize: {research.text}\"}])\n\n        return AgentResult(text=summary.text, session=session.to_dict())\n\n    elif \"action\" in classification.text.lower():\n        # Use tools\n        executor = Agent(tools=[...], system=\"Execute the requested action.\")\n        result = executor.run(messages, session=session.to_dict())\n\n        return AgentResult(\n            text=result.text,\n            pending_tools=[\n                ToolApproval(id=p.id, name=p.name, input=p.input, description=p.description)\n                for p in result.pending_tools\n            ],\n            session=session.to_dict(),\n        )\n\n    else:\n        # Simple response\n        responder = Agent(system=\"Be helpful and friendly.\")\n        result = responder.run(messages)\n        return AgentResult(text=result.text, session=session.to_dict())\n</code></pre>"},{"location":"guides/custom-agents/#pattern-2-parallel-calls","title":"Pattern 2: Parallel Calls","text":"<p>When calls are independent, run them in parallel:</p> <pre><code>from concurrent.futures import ThreadPoolExecutor\nfrom dcaf.core import Agent, AgentResult\n\nexecutor = ThreadPoolExecutor(max_workers=5)\n\ndef parallel_agent(messages: list, context: dict) -&gt; AgentResult:\n    user_question = messages[-1][\"content\"]\n\n    # Define parallel tasks\n    def get_weather():\n        agent = Agent(system=\"Answer weather questions briefly.\")\n        return agent.run([{\"role\": \"user\", \"content\": \"What's the weather?\"}]).text\n\n    def get_news():\n        agent = Agent(system=\"Summarize recent news briefly.\")\n        return agent.run([{\"role\": \"user\", \"content\": \"What's the news?\"}]).text\n\n    def get_stocks():\n        agent = Agent(system=\"Summarize stock market briefly.\")\n        return agent.run([{\"role\": \"user\", \"content\": \"How are stocks?\"}]).text\n\n    # Run in parallel\n    weather_future = executor.submit(get_weather)\n    news_future = executor.submit(get_news)\n    stocks_future = executor.submit(get_stocks)\n\n    # Combine results\n    combined = f\"\"\"\n    Weather: {weather_future.result()}\n    News: {news_future.result()}\n    Stocks: {stocks_future.result()}\n    \"\"\"\n\n    # Final synthesis\n    synthesizer = Agent(system=\"Create a cohesive summary from the information provided.\")\n    final = synthesizer.run([{\"role\": \"user\", \"content\": f\"Summarize this:\\n{combined}\"}])\n\n    return AgentResult(text=final.text)\n</code></pre>"},{"location":"guides/custom-agents/#pattern-3-agentic-loop","title":"Pattern 3: Agentic Loop","text":"<p>Let the LLM decide when it's done:</p> <pre><code>from dcaf.core import Agent, AgentResult, ToolApproval\nfrom dcaf.tools import tool\n\n@tool(description=\"Mark the task as complete\")\ndef finish(result: str) -&gt; str:\n    return f\"DONE: {result}\"\n\ndef agentic_loop(messages: list, context: dict) -&gt; AgentResult:\n    MAX_ITERATIONS = 10\n    tools = [search, calculate, finish]\n\n    agent = Agent(tools=tools, system=\"Complete the task. Call finish() when done.\")\n    conversation = list(messages)\n    all_executed = []\n\n    for i in range(MAX_ITERATIONS):\n        response = agent.run(conversation)\n\n        # Check if agent called finish\n        if \"DONE:\" in response.text:\n            return AgentResult(\n                text=response.text.replace(\"DONE:\", \"\").strip(),\n                executed_tools=all_executed,\n            )\n\n        # Check for pending approvals\n        if response.pending_tools:\n            return AgentResult(\n                text=response.text,\n                pending_tools=[\n                    ToolApproval(id=p.id, name=p.name, input=p.input, description=p.description)\n                    for p in response.pending_tools\n                ],\n                executed_tools=all_executed,\n            )\n\n        # Add response to conversation and continue\n        conversation.append({\"role\": \"assistant\", \"content\": response.text})\n        conversation.append({\"role\": \"user\", \"content\": \"Continue with the task.\"})\n\n    return AgentResult(text=\"Max iterations reached.\", executed_tools=all_executed)\n</code></pre>"},{"location":"guides/custom-agents/#pattern-4-prepost-processing","title":"Pattern 4: Pre/Post Processing","text":"<p>Add logic before and after LLM calls:</p> <pre><code>from dcaf.core import Agent, AgentResult\n\ndef processing_agent(messages: list, context: dict) -&gt; AgentResult:\n    # ==================\n    # PRE-PROCESSING\n    # ==================\n\n    # Validate tenant\n    tenant = context.get(\"tenant_name\")\n    if not tenant:\n        return AgentResult(text=\"Error: No tenant specified.\")\n\n    # Enrich with tenant info\n    tenant_info = get_tenant_info(tenant)\n    enriched_system = f\"\"\"\n    You are helping tenant: {tenant}\n    Cluster: {tenant_info['cluster']}\n    Namespace: {tenant_info['namespace']}\n    \"\"\"\n\n    # Filter messages (e.g., remove PII)\n    safe_messages = sanitize_messages(messages)\n\n    # ==================\n    # LLM CALL\n    # ==================\n\n    agent = Agent(\n        tools=get_tools_for_tenant(tenant),\n        system=enriched_system,\n    )\n    response = agent.run(safe_messages)\n\n    # ==================\n    # POST-PROCESSING\n    # ==================\n\n    # Audit logging\n    log_interaction(tenant, messages, response)\n\n    # Validate response\n    response_text = response.text\n    if contains_sensitive_info(response_text):\n        response_text = redact_sensitive(response_text)\n\n    # Apply rate limiting\n    if is_rate_limited(tenant):\n        return AgentResult(text=\"Rate limit exceeded. Please try again later.\")\n\n    return AgentResult(\n        text=response_text,\n        pending_tools=[\n            ToolApproval(id=p.id, name=p.name, input=p.input, description=p.description)\n            for p in response.pending_tools\n        ],\n    )\n</code></pre>"},{"location":"guides/custom-agents/#using-different-models","title":"Using Different Models","text":"<p>Create agents with different configurations for different tasks:</p> <pre><code>from dcaf.core import Agent, AgentResult\n\ndef smart_routing_agent(messages: list, context: dict) -&gt; AgentResult:\n    # Fast model for classification\n    classifier = Agent(\n        model=\"anthropic.claude-3-haiku\",\n        system=\"Classify the complexity: simple or complex. Reply with one word.\",\n    )\n    complexity = classifier.run(messages)\n\n    if \"complex\" in complexity.text.lower():\n        # Smart model for complex tasks\n        smart_agent = Agent(\n            model=\"anthropic.claude-3-opus\",\n            tools=[...],\n            system=\"Handle complex queries thoroughly.\",\n        )\n        response = smart_agent.run(messages)\n    else:\n        # Fast model for simple tasks\n        fast_agent = Agent(\n            model=\"anthropic.claude-3-haiku\",\n            system=\"Answer simply and briefly.\",\n        )\n        response = fast_agent.run(messages)\n\n    return AgentResult(text=response.text)\n</code></pre>"},{"location":"guides/custom-agents/#complete-example","title":"Complete Example","text":"<pre><code>\"\"\"\nMulti-step Kubernetes agent using DCAF.\n\"\"\"\n\nfrom dcaf.core import Agent, AgentResult, ToolApproval, ToolResult, serve\nfrom dcaf.tools import tool\n\n# Define tools\n@tool(description=\"List pods in a namespace\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n\n@tool(requires_approval=True, description=\"Delete a pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n\nTOOLS = [list_pods, delete_pod]\n\ndef k8s_agent(messages: list, context: dict) -&gt; AgentResult:\n    \"\"\"Kubernetes assistant with approval flow.\"\"\"\n\n    user_message = messages[-1][\"content\"]\n\n    # Step 1: Classify intent\n    classifier = Agent(system=\"Classify as: query, action, or other. Reply with one word.\")\n    intent = classifier.run([{\"role\": \"user\", \"content\": user_message}])\n\n    # Step 2: Handle based on intent\n    if \"query\" in intent.text.lower():\n        # Just answer questions using tools\n        executor = Agent(\n            tools=TOOLS,\n            system=\"You are a Kubernetes assistant. Answer questions about the cluster.\",\n        )\n        response = executor.run(messages)\n\n        return AgentResult(text=response.text)\n\n    elif \"action\" in intent.text.lower():\n        # Actions may need approval\n        executor = Agent(\n            tools=TOOLS,\n            system=\"You are a Kubernetes assistant. Help with cluster management.\",\n        )\n        response = executor.run(messages)\n\n        return AgentResult(\n            text=response.text or \"I need approval for this action.\",\n            pending_tools=[\n                ToolApproval(id=p.id, name=p.name, input=p.input, description=p.description)\n                for p in response.pending_tools\n            ],\n        )\n\n    else:\n        # General conversation\n        responder = Agent(system=\"You are a friendly Kubernetes assistant.\")\n        response = responder.run(messages)\n        return AgentResult(text=response.text)\n\n\nif __name__ == \"__main__\":\n    serve(k8s_agent, port=8000)\n</code></pre>"},{"location":"guides/custom-agents/#see-also","title":"See Also","text":"<ul> <li>Server Documentation - Running agents as REST APIs</li> <li>Core Overview - The simple Agent class</li> <li>Building Tools - Creating tools with @tool decorator</li> </ul>"},{"location":"guides/environment-configuration/","title":"Environment Configuration","text":""},{"location":"guides/environment-configuration/#environment-driven-configuration","title":"Environment-Driven Configuration","text":"<p>DCAF supports full configuration through environment variables, making it easy to deploy agents across different environments (development, staging, production) and switch between LLM providers without code changes.</p>"},{"location":"guides/environment-configuration/#overview","title":"Overview","text":"<p>Instead of hardcoding provider and model settings in your code, you can configure DCAF through environment variables:</p> <pre><code>from dcaf.core import Agent, load_agent_config\n\n# Load all configuration from environment\nconfig = load_agent_config()\nagent = Agent(tools=[my_tool], **config)\n</code></pre> <p>This approach offers several benefits:</p> <ul> <li>Environment-specific settings: Different providers for dev/staging/prod</li> <li>No code changes: Switch from Bedrock to Gemini via environment</li> <li>Secure credentials: API keys in environment, not committed to git</li> <li>12-Factor App compliance: Configuration separate from code</li> </ul>"},{"location":"guides/environment-configuration/#quick-start","title":"Quick Start","text":""},{"location":"guides/environment-configuration/#1-set-environment-variables","title":"1. Set Environment Variables","text":"<pre><code># Choose your provider\nexport DCAF_PROVIDER=google\nexport DCAF_MODEL=gemini-3-flash\nexport GEMINI_API_KEY=your-api-key\n</code></pre>"},{"location":"guides/environment-configuration/#2-load-configuration","title":"2. Load Configuration","text":"<pre><code>from dcaf.core import Agent, load_agent_config\nfrom dcaf.tools import tool\n\n@tool(description=\"Get weather\")\ndef get_weather(city: str) -&gt; str:\n    return f\"Weather in {city}: Sunny, 72\u00b0F\"\n\n# Load from environment\nconfig = load_agent_config()\n\n# Create agent\nagent = Agent(tools=[get_weather], **config)\n</code></pre> <p>That's it! Your agent now uses Gemini.</p>"},{"location":"guides/environment-configuration/#3-switch-providers","title":"3. Switch Providers","text":"<p>To switch to a different provider, just change the environment variables:</p> <pre><code># Switch to Bedrock\nexport DCAF_PROVIDER=bedrock\nexport DCAF_MODEL=anthropic.claude-3-sonnet-20240229-v1:0\nexport AWS_PROFILE=my-profile\nexport AWS_REGION=us-west-2\n</code></pre> <p>No code changes needed!</p>"},{"location":"guides/environment-configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"guides/environment-configuration/#core-configuration","title":"Core Configuration","text":"Variable Description Default Example <code>DCAF_PROVIDER</code> Provider name <code>bedrock</code> <code>google</code>, <code>anthropic</code>, <code>openai</code> <code>DCAF_MODEL</code> Model identifier Auto-detected <code>gemini-3-flash</code>, <code>claude-3-sonnet</code> <code>DCAF_FRAMEWORK</code> LLM framework <code>agno</code> <code>agno</code> (only option currently) <code>DCAF_TEMPERATURE</code> Sampling temperature <code>0.1</code> <code>0.0</code> to <code>1.0</code> <code>DCAF_MAX_TOKENS</code> Maximum output tokens <code>4096</code> <code>2048</code>, <code>8192</code>"},{"location":"guides/environment-configuration/#provider-credentials","title":"Provider Credentials","text":""},{"location":"guides/environment-configuration/#aws-bedrock-dcaf_providerbedrock","title":"AWS Bedrock (<code>DCAF_PROVIDER=bedrock</code>)","text":"<pre><code># Option 1: AWS Profile (recommended)\nAWS_PROFILE=my-profile\nAWS_REGION=us-west-2\n\n# Option 2: Direct credentials\nAWS_ACCESS_KEY_ID=AKIAXXXXXXXXXX\nAWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxx\nAWS_REGION=us-west-2\n</code></pre>"},{"location":"guides/environment-configuration/#google-gemini-dcaf_providergoogle","title":"Google Gemini (<code>DCAF_PROVIDER=google</code>)","text":"<pre><code>GEMINI_API_KEY=your-gemini-api-key\n# Or\nGOOGLE_API_KEY=your-google-api-key\n</code></pre>"},{"location":"guides/environment-configuration/#anthropic-direct-dcaf_provideranthropic","title":"Anthropic Direct (<code>DCAF_PROVIDER=anthropic</code>)","text":"<pre><code>ANTHROPIC_API_KEY=sk-ant-xxxxx\n</code></pre>"},{"location":"guides/environment-configuration/#openai-dcaf_provideropenai","title":"OpenAI (<code>DCAF_PROVIDER=openai</code>)","text":"<pre><code>OPENAI_API_KEY=sk-xxxxx\n</code></pre>"},{"location":"guides/environment-configuration/#azure-openai-dcaf_providerazure","title":"Azure OpenAI (<code>DCAF_PROVIDER=azure</code>)","text":"<pre><code>AZURE_OPENAI_API_KEY=xxxxx\n</code></pre>"},{"location":"guides/environment-configuration/#ollama-dcaf_providerollama","title":"Ollama (<code>DCAF_PROVIDER=ollama</code>)","text":"<pre><code># No credentials needed, runs locally\n</code></pre>"},{"location":"guides/environment-configuration/#a2a-identity","title":"A2A Identity","text":"<p>For Agent-to-Agent protocol:</p> <pre><code>DCAF_AGENT_NAME=my-agent\nDCAF_AGENT_DESCRIPTION=\"My helpful agent\"\n</code></pre>"},{"location":"guides/environment-configuration/#behavior-flags","title":"Behavior Flags","text":"<p>Advanced configuration:</p> <pre><code>DCAF_TOOL_CALL_LIMIT=1              # Max concurrent tool calls\nDCAF_DISABLE_HISTORY=false          # Disable message history\nDCAF_DISABLE_TOOL_FILTERING=false   # Disable tool filtering\n</code></pre>"},{"location":"guides/environment-configuration/#configuration-patterns","title":"Configuration Patterns","text":""},{"location":"guides/environment-configuration/#pattern-1-pure-environment","title":"Pattern 1: Pure Environment","text":"<p>Everything from environment variables:</p> <pre><code>from dcaf.core import Agent, load_agent_config\n\nconfig = load_agent_config()\nagent = Agent(tools=[...], **config)\n</code></pre>"},{"location":"guides/environment-configuration/#pattern-2-environment-with-overrides","title":"Pattern 2: Environment with Overrides","text":"<p>Load from environment, override specific values:</p> <pre><code>from dcaf.core import Agent, load_agent_config\n\n# Load base config from env\nconfig = load_agent_config(\n    temperature=0.9,  # Override temperature\n    name=\"custom-agent\"  # Override name\n)\n\nagent = Agent(\n    tools=[...],\n    system_prompt=\"Custom prompt\",  # Add system prompt\n    **config\n)\n</code></pre>"},{"location":"guides/environment-configuration/#pattern-3-conditional-provider","title":"Pattern 3: Conditional Provider","text":"<p>Different providers for different environments:</p> <pre><code>import os\nfrom dcaf.core import Agent, load_agent_config\n\n# Load config based on environment\nenv = os.getenv(\"ENV\", \"development\")\n\nif env == \"production\":\n    # Production uses Bedrock\n    config = load_agent_config(provider=\"bedrock\")\nelif env == \"development\":\n    # Development uses Gemini (cheaper/faster)\n    config = load_agent_config(provider=\"google\", model=\"gemini-3-flash\")\nelse:\n    # Staging uses environment default\n    config = load_agent_config()\n\nagent = Agent(tools=[...], **config)\n</code></pre>"},{"location":"guides/environment-configuration/#pattern-4-provider-detection","title":"Pattern 4: Provider Detection","text":"<p>Auto-detect which provider has credentials:</p> <pre><code>from dcaf.core import Agent, load_agent_config\nfrom dcaf.core.config import get_configured_provider\n\n# Find first provider with credentials\nprovider = get_configured_provider()\n\nif provider:\n    config = load_agent_config(provider=provider)\n    agent = Agent(tools=[...], **config)\nelse:\n    raise RuntimeError(\"No provider configured!\")\n</code></pre>"},{"location":"guides/environment-configuration/#example-env-files","title":"Example .env Files","text":""},{"location":"guides/environment-configuration/#development-envdevelopment","title":"Development (.env.development)","text":"<pre><code># Development - Use Gemini (fast, cheap)\nDCAF_PROVIDER=google\nDCAF_MODEL=gemini-3-flash\nDCAF_TEMPERATURE=0.1\nGEMINI_API_KEY=your-dev-key\n\n# Agent identity\nDCAF_AGENT_NAME=dev-agent\nDCAF_AGENT_DESCRIPTION=\"Development agent\"\n</code></pre>"},{"location":"guides/environment-configuration/#staging-envstaging","title":"Staging (.env.staging)","text":"<pre><code># Staging - Use Claude on Bedrock\nDCAF_PROVIDER=bedrock\nDCAF_MODEL=anthropic.claude-3-sonnet-20240229-v1:0\nAWS_PROFILE=staging\nAWS_REGION=us-west-2\n\n# Agent identity\nDCAF_AGENT_NAME=staging-agent\n</code></pre>"},{"location":"guides/environment-configuration/#production-envproduction","title":"Production (.env.production)","text":"<pre><code># Production - Use Claude on Bedrock with specific profile\nDCAF_PROVIDER=bedrock\nDCAF_MODEL=anthropic.claude-3-sonnet-20240229-v1:0\nAWS_PROFILE=production\nAWS_REGION=us-east-1\nDCAF_TEMPERATURE=0.1\nDCAF_MAX_TOKENS=4096\n\n# Agent identity\nDCAF_AGENT_NAME=prod-agent\nDCAF_AGENT_DESCRIPTION=\"Production help desk agent\"\n\n# Behavior\nDCAF_TOOL_CALL_LIMIT=1\n</code></pre>"},{"location":"guides/environment-configuration/#docker-integration","title":"Docker Integration","text":""},{"location":"guides/environment-configuration/#dockerfile","title":"Dockerfile","text":"<pre><code>FROM python:3.12-slim\n\nWORKDIR /app\n\n# Install dependencies\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Copy application\nCOPY . .\n\n# Agent will load config from environment\nCMD [\"python\", \"main.py\"]\n</code></pre>"},{"location":"guides/environment-configuration/#docker-compose","title":"Docker Compose","text":"<pre><code>version: '3.8'\n\nservices:\n  # Development agent\n  agent-dev:\n    build: .\n    environment:\n      - DCAF_PROVIDER=google\n      - DCAF_MODEL=gemini-3-flash\n      - GEMINI_API_KEY=${GEMINI_API_KEY}\n    ports:\n      - \"8000:8000\"\n\n  # Production agent\n  agent-prod:\n    build: .\n    environment:\n      - DCAF_PROVIDER=bedrock\n      - DCAF_MODEL=anthropic.claude-3-sonnet-20240229-v1:0\n      - AWS_PROFILE=production\n    volumes:\n      - ~/.aws:/root/.aws:ro\n    ports:\n      - \"8001:8000\"\n</code></pre>"},{"location":"guides/environment-configuration/#kubernetes","title":"Kubernetes","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: agent-config\ndata:\n  DCAF_PROVIDER: \"bedrock\"\n  DCAF_MODEL: \"anthropic.claude-3-sonnet-20240229-v1:0\"\n  AWS_REGION: \"us-west-2\"\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: agent-secrets\ntype: Opaque\nstringData:\n  AWS_ACCESS_KEY_ID: \"AKIA...\"\n  AWS_SECRET_ACCESS_KEY: \"...\"\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: agent\nspec:\n  replicas: 3\n  template:\n    spec:\n      containers:\n      - name: agent\n        image: my-agent:latest\n        envFrom:\n        - configMapRef:\n            name: agent-config\n        - secretRef:\n            name: agent-secrets\n</code></pre>"},{"location":"guides/environment-configuration/#configuration-api","title":"Configuration API","text":""},{"location":"guides/environment-configuration/#load_agent_config","title":"load_agent_config()","text":"<p>Load all configuration from environment:</p> <pre><code>from dcaf.core import load_agent_config\n\n# Load everything\nconfig = load_agent_config()\n\n# Load with overrides\nconfig = load_agent_config(\n    provider=\"google\",\n    model=\"gemini-3-flash\",\n    temperature=0.9\n)\n\n# Use config\nagent = Agent(**config)\n</code></pre>"},{"location":"guides/environment-configuration/#get_provider_from_env","title":"get_provider_from_env()","text":"<p>Get the configured provider:</p> <pre><code>from dcaf.core import get_provider_from_env\n\nprovider = get_provider_from_env()\nprint(f\"Using provider: {provider}\")  # \"bedrock\", \"google\", etc.\n</code></pre>"},{"location":"guides/environment-configuration/#get_model_from_env","title":"get_model_from_env()","text":"<p>Get the configured model:</p> <pre><code>from dcaf.core import get_model_from_env\n\nmodel = get_model_from_env()\nprint(f\"Using model: {model}\")\n</code></pre>"},{"location":"guides/environment-configuration/#is_provider_configured","title":"is_provider_configured()","text":"<p>Check if a provider has credentials:</p> <pre><code>from dcaf.core.config import is_provider_configured\n\nif is_provider_configured(\"google\"):\n    print(\"\u2713 Gemini credentials configured\")\nelse:\n    print(\"\u2717 Gemini credentials missing\")\n</code></pre>"},{"location":"guides/environment-configuration/#get_configured_provider","title":"get_configured_provider()","text":"<p>Find first provider with credentials:</p> <pre><code>from dcaf.core.config import get_configured_provider\n\nprovider = get_configured_provider()\nif provider:\n    print(f\"Using {provider}\")\nelse:\n    print(\"No provider configured\")\n</code></pre>"},{"location":"guides/environment-configuration/#best-practices","title":"Best Practices","text":""},{"location":"guides/environment-configuration/#1-use-env-files","title":"1. Use .env Files","text":"<p>Create separate <code>.env</code> files for each environment:</p> <pre><code>.env.development\n.env.staging\n.env.production\n</code></pre> <p>Load the appropriate file:</p> <pre><code># Development\nexport $(cat .env.development | xargs)\n\n# Production\nexport $(cat .env.production | xargs)\n</code></pre> <p>Or use python-dotenv:</p> <pre><code>from dotenv import load_dotenv\nimport os\n\nenv = os.getenv(\"ENV\", \"development\")\nload_dotenv(f\".env.{env}\")\n\nfrom dcaf.core import Agent, load_agent_config\nagent = Agent(**load_agent_config())\n</code></pre>"},{"location":"guides/environment-configuration/#2-never-commit-credentials","title":"2. Never Commit Credentials","text":"<p>Add to <code>.gitignore</code>:</p> <pre><code>.env\n.env.*\n!.env.example\n</code></pre>"},{"location":"guides/environment-configuration/#3-use-secrets-management","title":"3. Use Secrets Management","text":"<p>For production, use a secrets manager:</p> <pre><code>import boto3\nfrom dcaf.core import Agent\n\n# Load from AWS Secrets Manager\nsecrets = boto3.client('secretsmanager')\nsecret = secrets.get_secret_value(SecretId='prod/agent-config')\nconfig = json.loads(secret['SecretString'])\n\nagent = Agent(\n    provider=config['provider'],\n    model=config['model'],\n    api_key=config['api_key'],\n    tools=[...]\n)\n</code></pre>"},{"location":"guides/environment-configuration/#4-validate-configuration","title":"4. Validate Configuration","text":"<p>Check configuration at startup:</p> <pre><code>from dcaf.core import load_agent_config\nfrom dcaf.core.config import is_provider_configured, get_provider_from_env\n\nprovider = get_provider_from_env()\n\nif not is_provider_configured(provider):\n    raise RuntimeError(\n        f\"Provider '{provider}' not configured. \"\n        f\"Set required environment variables.\"\n    )\n\nconfig = load_agent_config()\nagent = Agent(**config)\n</code></pre>"},{"location":"guides/environment-configuration/#5-document-required-variables","title":"5. Document Required Variables","text":"<p>Create a README or <code>.env.example</code>:</p> <pre><code># Copy to .env and fill in values\ncp .env.example .env\n\n# Edit .env with your credentials\nvim .env\n</code></pre>"},{"location":"guides/environment-configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/environment-configuration/#provider-not-configured","title":"Provider Not Configured","text":"<p>Error: <code>No provider configured</code> or <code>Provider 'xxx' not configured</code></p> <p>Solution: Set required environment variables for your provider:</p> <pre><code># For Bedrock\nexport AWS_PROFILE=my-profile\n\n# For Gemini\nexport GEMINI_API_KEY=your-key\n\n# Check what's configured\npython -c \"from dcaf.core.config import get_configured_provider; print(get_configured_provider())\"\n</code></pre>"},{"location":"guides/environment-configuration/#wrong-model-for-provider","title":"Wrong Model for Provider","text":"<p>Error: Model not found or invalid model</p> <p>Solution: Use provider-appropriate model IDs:</p> <pre><code># Bedrock models\nDCAF_MODEL=anthropic.claude-3-sonnet-20240229-v1:0\n\n# Gemini models\nDCAF_MODEL=gemini-3-flash\n\n# Anthropic direct\nDCAF_MODEL=claude-3-sonnet-20240229\n</code></pre>"},{"location":"guides/environment-configuration/#environment-variables-not-loading","title":"Environment Variables Not Loading","text":"<p>Error: Agent uses defaults instead of environment values</p> <p>Solution: Check that variables are exported:</p> <pre><code># Check if set\necho $DCAF_PROVIDER\n\n# Export if needed\nexport DCAF_PROVIDER=google\n\n# Or load from file\nexport $(cat .env | xargs)\n</code></pre>"},{"location":"guides/environment-configuration/#missing-api-key","title":"Missing API Key","text":"<p>Error: <code>ImportError</code> or authentication errors</p> <p>Solution: Set the correct API key variable:</p> <pre><code># Gemini\nexport GEMINI_API_KEY=your-key\n\n# Anthropic\nexport ANTHROPIC_API_KEY=sk-ant-xxx\n\n# OpenAI\nexport OPENAI_API_KEY=sk-xxx\n</code></pre>"},{"location":"guides/environment-configuration/#examples","title":"Examples","text":"<p>Complete examples in the repository:</p> <ul> <li><code>examples/config_driven_agent.py</code> - Environment-driven configuration</li> <li><code>examples/multi_environment.py</code> - Switching environments</li> <li><code>examples/docker_deployment/</code> - Docker with environment config</li> </ul>"},{"location":"guides/environment-configuration/#resources","title":"Resources","text":"<ul> <li>12-Factor App Methodology</li> </ul>"},{"location":"guides/environment-configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Set up <code>.env</code> files for your environments</li> <li>Use <code>load_agent_config()</code> in your agents</li> <li>Deploy with Docker/Kubernetes using environment config</li> <li>Implement secrets management for production</li> </ul>"},{"location":"guides/framework-adapters/","title":"Framework Adapters","text":"<p>DCAF uses a plugin-style architecture for LLM frameworks. This allows you to swap between different agent orchestration frameworks (Agno, Strands, LangChain, etc.) without changing your application code.</p>"},{"location":"guides/framework-adapters/#quick-start","title":"Quick Start","text":"<pre><code>from dcaf.core import Agent\n\n# Using Agno (default)\nagent = Agent(\n    framework=\"agno\",\n    provider=\"bedrock\",\n    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n)\n\n# Using a different framework (when available)\nagent = Agent(\n    framework=\"strands\",  # or \"langchain\", etc.\n    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n)\n</code></pre>"},{"location":"guides/framework-adapters/#how-discovery-works","title":"How Discovery Works","text":"<p>DCAF uses convention-based discovery - no manifest files or registration required.</p>"},{"location":"guides/framework-adapters/#the-convention","title":"The Convention","text":"<pre><code>dcaf/core/adapters/outbound/{framework_name}/\n\u251c\u2500\u2500 __init__.py      \u2190 Must export create_adapter(**kwargs)\n\u2514\u2500\u2500 adapter.py       \u2190 Your adapter implementation\n</code></pre>"},{"location":"guides/framework-adapters/#discovery-flow","title":"Discovery Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Agent(framework=\"myframework\")                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  loader.py: load_adapter(\"myframework\")                     \u2502\n\u2502                                                             \u2502\n\u2502  1. import dcaf.core.adapters.outbound.myframework          \u2502\n\u2502  2. call module.create_adapter(**kwargs)                    \u2502\n\u2502  3. return adapter instance                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/framework-adapters/#listing-available-frameworks","title":"Listing Available Frameworks","text":"<pre><code>from dcaf.core.adapters.loader import list_frameworks\n\nframeworks = list_frameworks()\nprint(frameworks)  # ['agno', 'strands', 'langchain']\n</code></pre>"},{"location":"guides/framework-adapters/#creating-a-new-adapter","title":"Creating a New Adapter","text":"<p>Adding a new framework adapter requires just two files:</p>"},{"location":"guides/framework-adapters/#step-1-create-the-folder","title":"Step 1: Create the Folder","text":"<pre><code>mkdir -p dcaf/core/adapters/outbound/myframework\n</code></pre>"},{"location":"guides/framework-adapters/#step-2-create-__init__py","title":"Step 2: Create <code>__init__.py</code>","text":"<p>This file must export a <code>create_adapter()</code> function:</p> <pre><code># dcaf/core/adapters/outbound/myframework/__init__.py\n\n\"\"\"\nMyFramework Adapter.\n\nThis module provides integration with MyFramework for agent orchestration.\n\"\"\"\n\ndef create_adapter(**kwargs):\n    \"\"\"\n    Factory function for creating a MyFrameworkAdapter.\n\n    This function is REQUIRED by the adapter loader convention.\n\n    Args:\n        **kwargs: Configuration passed from Agent():\n            - model_id: Model identifier\n            - provider: Provider name (if applicable)\n            - aws_profile: AWS profile (for AWS-based frameworks)\n            - aws_region: AWS region\n            - api_key: API key (for API-based providers)\n            - max_tokens: Maximum response tokens\n            - temperature: Sampling temperature\n\n    Returns:\n        Configured adapter instance\n    \"\"\"\n    from .adapter import MyFrameworkAdapter\n    return MyFrameworkAdapter(**kwargs)\n\n\n__all__ = [\"create_adapter\"]\n</code></pre>"},{"location":"guides/framework-adapters/#step-3-create-adapterpy","title":"Step 3: Create <code>adapter.py</code>","text":"<p>Your adapter must implement the <code>RuntimeAdapter</code> protocol:</p> <pre><code># dcaf/core/adapters/outbound/myframework/adapter.py\n\n\"\"\"MyFramework adapter implementing the RuntimeAdapter protocol.\"\"\"\n\nfrom typing import List, Optional, Iterator, Any\nimport logging\n\n# Import your framework\n# from myframework import Agent as MyAgent\n\nfrom ....application.dto.responses import AgentResponse, StreamEvent, ToolCallDTO\n\nlogger = logging.getLogger(__name__)\n\n\nclass MyFrameworkAdapter:\n    \"\"\"\n    Adapts MyFramework to DCAF's RuntimeAdapter protocol.\n\n    This adapter translates between DCAF's domain model and MyFramework,\n    enabling seamless integration while keeping framework-specific code isolated.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_id: str = \"default-model\",\n        provider: str = \"default\",\n        max_tokens: int = 4096,\n        temperature: float = 0.7,\n        # Add framework-specific parameters\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the adapter.\n\n        Args:\n            model_id: The model identifier\n            provider: The provider name\n            max_tokens: Maximum tokens in response\n            temperature: Sampling temperature\n            **kwargs: Additional framework-specific configuration\n        \"\"\"\n        self._model_id = model_id\n        self._provider = provider\n        self._max_tokens = max_tokens\n        self._temperature = temperature\n        self._extra_config = kwargs\n\n        logger.info(f\"MyFrameworkAdapter initialized: model={model_id}\")\n\n    @property\n    def model_id(self) -&gt; str:\n        \"\"\"Get the model identifier.\"\"\"\n        return self._model_id\n\n    @property\n    def provider(self) -&gt; str:\n        \"\"\"Get the provider name.\"\"\"\n        return self._provider\n\n    def invoke(\n        self,\n        messages: List[Any],\n        tools: List[Any],\n        system_prompt: Optional[str] = None,\n    ) -&gt; AgentResponse:\n        \"\"\"\n        Execute a single request and return the response.\n\n        This method:\n        1. Converts DCAF messages to framework format\n        2. Converts DCAF tools to framework format\n        3. Calls the framework\n        4. Converts the response back to DCAF format\n\n        Args:\n            messages: List of DCAF Message objects\n            tools: List of DCAF Tool objects\n            system_prompt: Optional system instructions\n\n        Returns:\n            AgentResponse with the result\n        \"\"\"\n        # TODO: Implement your framework integration\n\n        # 1. Convert messages to framework format\n        # framework_messages = self._convert_messages(messages)\n\n        # 2. Convert tools to framework format\n        # framework_tools = self._convert_tools(tools)\n\n        # 3. Call the framework\n        # result = my_framework_agent.run(framework_messages, framework_tools)\n\n        # 4. Convert response back\n        # return self._convert_response(result)\n\n        raise NotImplementedError(\"MyFrameworkAdapter.invoke() not implemented\")\n\n    def invoke_stream(\n        self,\n        messages: List[Any],\n        tools: List[Any],\n        system_prompt: Optional[str] = None,\n    ) -&gt; Iterator[StreamEvent]:\n        \"\"\"\n        Execute with streaming response.\n\n        Args:\n            messages: List of DCAF Message objects\n            tools: List of DCAF Tool objects\n            system_prompt: Optional system instructions\n\n        Yields:\n            StreamEvent objects for real-time updates\n        \"\"\"\n        # TODO: Implement streaming\n\n        yield StreamEvent.message_start()\n        yield StreamEvent.text_delta(\"Not implemented\")\n        yield StreamEvent.message_end(AgentResponse(\n            conversation_id=\"\",\n            text=\"Streaming not implemented\",\n            is_complete=True,\n        ))\n</code></pre>"},{"location":"guides/framework-adapters/#step-4-use-it","title":"Step 4: Use It!","text":"<pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    framework=\"myframework\",\n    model=\"my-model-id\",\n)\n</code></pre> <p>That's it! No registration, no manifest, no if-statements.</p>"},{"location":"guides/framework-adapters/#the-runtimeadapter-protocol","title":"The RuntimeAdapter Protocol","text":"<p>All adapters must implement this interface:</p> <pre><code>from typing import Protocol, List, Iterator, Any, Optional\n\nclass RuntimeAdapter(Protocol):\n    \"\"\"Protocol that all framework adapters must implement.\"\"\"\n\n    @property\n    def model_id(self) -&gt; str:\n        \"\"\"Get the model identifier.\"\"\"\n        ...\n\n    @property\n    def provider(self) -&gt; str:\n        \"\"\"Get the provider name.\"\"\"\n        ...\n\n    def invoke(\n        self,\n        messages: List[Any],\n        tools: List[Any],\n        system_prompt: Optional[str] = None,\n    ) -&gt; AgentResponse:\n        \"\"\"Execute a single request and return response.\"\"\"\n        ...\n\n    def invoke_stream(\n        self,\n        messages: List[Any],\n        tools: List[Any],\n        system_prompt: Optional[str] = None,\n    ) -&gt; Iterator[StreamEvent]:\n        \"\"\"Execute with streaming response.\"\"\"\n        ...\n</code></pre>"},{"location":"guides/framework-adapters/#available-frameworks","title":"Available Frameworks","text":""},{"location":"guides/framework-adapters/#agno-default","title":"Agno (Default)","text":"<p>The Agno SDK provides a unified interface for multiple LLM providers.</p> <pre><code>agent = Agent(\n    framework=\"agno\",\n    provider=\"bedrock\",  # or \"anthropic\", \"openai\", \"ollama\"\n    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n    aws_profile=\"my-profile\",\n)\n</code></pre> <p>Supported Providers:</p> Provider Install Model Examples <code>bedrock</code> (included) <code>anthropic.claude-3-sonnet-20240229-v1:0</code> <code>anthropic</code> (included) <code>claude-3-sonnet-20240229</code> <code>openai</code> <code>pip install openai</code> <code>gpt-4</code>, <code>gpt-4-turbo</code> <code>azure</code> <code>pip install openai</code> Azure deployment names <code>google</code> <code>pip install google-generativeai</code> <code>gemini-pro</code> <code>ollama</code> <code>pip install ollama</code> <code>llama2</code>, <code>mistral</code> <p>Production Features:</p> <p>The Agno adapter includes battle-tested patterns:</p> <ul> <li>\u2705 Async Support - Uses <code>aioboto3</code> for non-blocking AWS calls</li> <li>\u2705 Message Filtering - Removes tool messages for Bedrock compatibility</li> <li>\u2705 Alternation Validation - Ensures user/assistant message order</li> <li>\u2705 Parallel Tool Workaround - Prevents <code>ValidationException</code> errors</li> <li>\u2705 Metrics Logging - Token counts, duration, timing</li> </ul>"},{"location":"guides/framework-adapters/#strands-coming-soon","title":"Strands (Coming Soon)","text":"<p>AWS Strands Agent is AWS's native agent framework for Bedrock.</p> <pre><code>agent = Agent(\n    framework=\"strands\",\n    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n    aws_profile=\"production\",\n)\n</code></pre>"},{"location":"guides/framework-adapters/#langchain-future","title":"LangChain (Future)","text":"<p>LangChain integration for those who prefer its ecosystem.</p> <pre><code>agent = Agent(\n    framework=\"langchain\",\n    provider=\"bedrock\",\n    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n)\n</code></pre>"},{"location":"guides/framework-adapters/#best-practices","title":"Best Practices","text":""},{"location":"guides/framework-adapters/#1-keep-framework-code-isolated","title":"1. Keep Framework Code Isolated","text":"<p>All framework-specific code should live in its adapter folder:</p> <pre><code>dcaf/core/adapters/outbound/myframework/\n\u251c\u2500\u2500 __init__.py           # Factory function\n\u251c\u2500\u2500 adapter.py            # Main adapter\n\u251c\u2500\u2500 message_converter.py  # Message format conversion\n\u251c\u2500\u2500 tool_converter.py     # Tool format conversion\n\u2514\u2500\u2500 types.py              # Framework-specific types\n</code></pre>"},{"location":"guides/framework-adapters/#2-handle-errors-gracefully","title":"2. Handle Errors Gracefully","text":"<pre><code>def invoke(self, messages, tools, system_prompt=None):\n    try:\n        result = self._call_framework(messages, tools)\n        return self._convert_response(result)\n    except FrameworkError as e:\n        logger.error(f\"Framework error: {e}\")\n        return AgentResponse(\n            conversation_id=\"\",\n            text=f\"Error: {str(e)}\",\n            is_complete=True,\n        )\n</code></pre>"},{"location":"guides/framework-adapters/#3-log-important-events","title":"3. Log Important Events","text":"<pre><code>import logging\nlogger = logging.getLogger(__name__)\n\ndef invoke(self, messages, tools, system_prompt=None):\n    logger.info(f\"Invoking with {len(messages)} messages, {len(tools)} tools\")\n    # ...\n    logger.debug(f\"Response: {result}\")\n</code></pre>"},{"location":"guides/framework-adapters/#4-support-optional-dependencies","title":"4. Support Optional Dependencies","text":"<pre><code>def _create_model(self):\n    try:\n        from some_optional_package import Model\n    except ImportError:\n        raise ImportError(\n            \"This provider requires 'some-package'. \"\n            \"Install it with: pip install some-package\"\n        )\n    return Model(...)\n</code></pre>"},{"location":"guides/framework-adapters/#5-support-async-operations","title":"5. Support Async Operations","text":"<p>For non-blocking operation in async contexts (FastAPI, etc.):</p> <pre><code>class MyFrameworkAdapter:\n    # Async methods (preferred for web servers)\n    async def ainvoke(self, messages, tools, system_prompt=None):\n        # Use async session/client\n        result = await self._async_client.call(...)\n        return self._convert_response(result)\n\n    async def ainvoke_stream(self, messages, tools, system_prompt=None):\n        async for chunk in self._async_client.stream(...):\n            yield self._convert_event(chunk)\n\n    # Sync methods (wrap async internally)\n    def invoke(self, messages, tools, system_prompt=None):\n        import asyncio\n        return asyncio.run(self.ainvoke(messages, tools, system_prompt))\n</code></pre>"},{"location":"guides/framework-adapters/#6-handle-provider-specific-quirks","title":"6. Handle Provider-Specific Quirks","text":"<p>Document and work around provider-specific issues:</p> <pre><code># Example: Bedrock message filtering\ndef _filter_messages(self, messages):\n    \"\"\"\n    Bedrock requires:\n    1. First message from 'user'\n    2. Strict user/assistant alternation\n    3. No tool blocks in history\n    \"\"\"\n    filtered = []\n    for msg in messages:\n        # Skip tool messages\n        if isinstance(msg.get(\"content\"), list):\n            continue\n        filtered.append(msg)\n    return self._ensure_alternation(filtered)\n</code></pre>"},{"location":"guides/framework-adapters/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/framework-adapters/#framework-not-found","title":"Framework Not Found","text":"<pre><code>ValueError: Unknown framework: 'myframework'. Available frameworks: agno, strands\n</code></pre> <p>Check: 1. Folder exists at <code>dcaf/core/adapters/outbound/myframework/</code> 2. <code>__init__.py</code> exists and exports <code>create_adapter()</code> 3. No syntax errors in the module</p>"},{"location":"guides/framework-adapters/#missing-create_adapter","title":"Missing create_adapter","text":"<pre><code>ValueError: Framework 'myframework' is missing the required create_adapter() function\n</code></pre> <p>Fix: Add to <code>__init__.py</code>:</p> <pre><code>def create_adapter(**kwargs):\n    from .adapter import MyAdapter\n    return MyAdapter(**kwargs)\n</code></pre>"},{"location":"guides/framework-adapters/#import-errors","title":"Import Errors","text":"<pre><code>ModuleNotFoundError: No module named 'somepackage'\n</code></pre> <p>Fix: Install the required dependency:</p> <pre><code>pip install somepackage\n</code></pre>"},{"location":"guides/framework-adapters/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Your Code                                \u2502\n\u2502                   Agent(framework=\"agno\")                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Agent Class                              \u2502\n\u2502                   (dcaf/core/agent.py)                          \u2502\n\u2502                                                                  \u2502\n\u2502   self._runtime = load_adapter(framework, **kwargs)             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Adapter Loader                              \u2502\n\u2502                 (dcaf/core/adapters/loader.py)                  \u2502\n\u2502                                                                  \u2502\n\u2502   module = import(f\"dcaf.core.adapters.outbound.{framework}\")   \u2502\n\u2502   return module.create_adapter(**kwargs)                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u2502               \u2502               \u2502\n              \u25bc               \u25bc               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     agno/       \u2502 \u2502    strands/     \u2502 \u2502   langchain/    \u2502\n\u2502                 \u2502 \u2502                 \u2502 \u2502                 \u2502\n\u2502 AgnoAdapter     \u2502 \u2502 StrandsAdapter  \u2502 \u2502 LangChainAdapter\u2502\n\u2502                 \u2502 \u2502                 \u2502 \u2502                 \u2502\n\u2502 create_adapter()\u2502 \u2502 create_adapter()\u2502 \u2502 create_adapter()\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                   \u2502                   \u2502\n         \u25bc                   \u25bc                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Agno SDK      \u2502 \u2502   Strands SDK   \u2502 \u2502   LangChain     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/framework-adapters/#summary","title":"Summary","text":"Task How Use a framework <code>Agent(framework=\"name\")</code> List frameworks <code>list_frameworks()</code> Add new framework Create folder + <code>create_adapter()</code> No registration needed Convention-based discovery Swap frameworks Change one parameter"},{"location":"guides/interceptors/","title":"Interceptors Guide","text":"<p>Interceptors let you hook into the LLM request/response pipeline. Think of them as checkpoints where you can inspect, modify, or block data before it goes to the AI and after you receive a response.</p>"},{"location":"guides/interceptors/#table-of-contents","title":"Table of Contents","text":"<ol> <li>What Are Interceptors?</li> <li>Quick Start</li> <li>Request Interceptors</li> <li>Response Interceptors</li> <li>Session Access</li> <li>Error Handling</li> <li>Async Interceptors</li> <li>Common Use Cases</li> <li>Best Practices</li> <li>API Reference</li> </ol>"},{"location":"guides/interceptors/#what-are-interceptors","title":"What Are Interceptors?","text":"<p>Interceptors are functions that run at specific points in the request/response flow:</p> <pre><code>Your Message\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   REQUEST INTERCEPTORS      \u2502  \u25c4\u2500\u2500 Runs BEFORE the LLM call\n\u2502   \u2022 Add context             \u2502\n\u2502   \u2022 Validate input          \u2502\n\u2502   \u2022 Block bad requests      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         LLM                 \u2502  \u25c4\u2500\u2500 AI processes your request\n\u2502   (Claude, GPT, etc.)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   RESPONSE INTERCEPTORS     \u2502  \u25c4\u2500\u2500 Runs AFTER the LLM call\n\u2502   \u2022 Clean output            \u2502\n\u2502   \u2022 Redact secrets          \u2502\n\u2502   \u2022 Add formatting          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502\n     \u25bc\nFinal Response\n</code></pre>"},{"location":"guides/interceptors/#why-use-interceptors","title":"Why Use Interceptors?","text":"Use Case Example Add Context Tell the AI which tenant/environment the user is in Security Block prompt injection attacks Validation Ensure required data is present Clean Output Remove thinking tags or sensitive data Logging Track what's being sent and received Enrichment Look up user preferences from a database"},{"location":"guides/interceptors/#quick-start","title":"Quick Start","text":"<p>Here's a simple example that adds tenant context to every request:</p> <pre><code>from dcaf.core import Agent, LLMRequest\nfrom dcaf.tools import tool\n\n# Define a tool\n@tool(description=\"List pods in the current namespace\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return f\"Pods in {namespace}: nginx, redis, api\"\n\n# Define a request interceptor\ndef add_tenant_context(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"\n    Add information about the user's tenant to help the AI\n    understand which environment they're working in.\n    \"\"\"\n    # Get the tenant name from the context (passed by the caller)\n    tenant_name = request.context.get(\"tenant_name\", \"unknown\")\n\n    # Add it to the system prompt so the AI knows about it\n    request.add_system_context(f\"The user is working in tenant: {tenant_name}\")\n\n    # Return the modified request\n    return request\n\n# Create the agent with the interceptor\nagent = Agent(\n    tools=[list_pods],\n    request_interceptors=add_tenant_context,  # Single interceptor\n)\n\n# Use the agent\nresponse = agent.run(\n    messages=[{\"role\": \"user\", \"content\": \"What pods are running?\"}],\n    context={\"tenant_name\": \"production\"},\n)\n\nprint(response.text)\n</code></pre>"},{"location":"guides/interceptors/#request-interceptors","title":"Request Interceptors","text":"<p>Request interceptors run before your request is sent to the LLM. They receive an <code>LLMRequest</code> object and must return an <code>LLMRequest</code> object.</p>"},{"location":"guides/interceptors/#the-llmrequest-object","title":"The LLMRequest Object","text":"<pre><code>from dcaf.core import LLMRequest\n\n# What a request looks like\nrequest = LLMRequest(\n    messages=[\n        {\"role\": \"user\", \"content\": \"What pods are running?\"},\n    ],\n    tools=[list_pods, delete_pod],\n    system=\"You are a helpful Kubernetes assistant.\",\n    context={\n        \"tenant_name\": \"production\",\n        \"user_id\": \"alice\",\n        \"k8s_namespace\": \"default\",\n    },\n)\n</code></pre>"},{"location":"guides/interceptors/#llmrequest-fields","title":"LLMRequest Fields","text":"Field Type Description <code>messages</code> <code>list[dict]</code> Conversation history. Each dict has <code>role</code> and <code>content</code>. <code>tools</code> <code>list</code> Tools the AI can use. <code>system</code> <code>str \\| None</code> System prompt (instructions for the AI). <code>context</code> <code>dict</code> Platform context (tenant, user, etc.). <code>session</code> <code>Session</code> Persistent state across conversation turns."},{"location":"guides/interceptors/#llmrequest-methods","title":"LLMRequest Methods","text":"Method Description <code>get_latest_user_message()</code> Returns the content of the most recent user message. <code>add_system_context(text)</code> Appends text to the system prompt."},{"location":"guides/interceptors/#example-adding-context","title":"Example: Adding Context","text":"<pre><code>def add_user_preferences(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"\n    Add the user's language preference to help the AI respond\n    in the correct language.\n    \"\"\"\n    # Get user ID from context\n    user_id = request.context.get(\"user_id\")\n\n    if user_id:\n        # Look up user's preferred language (simplified example)\n        preferred_language = \"Spanish\"  # Would come from a database\n\n        # Tell the AI about the preference\n        request.add_system_context(\n            f\"Please respond in {preferred_language} if possible.\"\n        )\n\n    return request\n\nagent = Agent(\n    tools=[...],\n    request_interceptors=add_user_preferences,\n)\n</code></pre>"},{"location":"guides/interceptors/#example-modifying-messages","title":"Example: Modifying Messages","text":"<pre><code>def shorten_long_messages(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"\n    Truncate very long messages to save tokens.\n    \"\"\"\n    max_message_length = 5000\n\n    # Go through each message\n    for message in request.messages:\n        content = message.get(\"content\", \"\")\n\n        if len(content) &gt; max_message_length:\n            # Truncate and add indicator\n            message[\"content\"] = content[:max_message_length] + \"\\n[Message truncated...]\"\n\n    return request\n\nagent = Agent(\n    tools=[...],\n    request_interceptors=shorten_long_messages,\n)\n</code></pre>"},{"location":"guides/interceptors/#response-interceptors","title":"Response Interceptors","text":"<p>Response interceptors run after you receive a response from the LLM. They receive an <code>LLMResponse</code> object and must return an <code>LLMResponse</code> object.</p>"},{"location":"guides/interceptors/#the-llmresponse-object","title":"The LLMResponse Object","text":"<pre><code>from dcaf.core import LLMResponse\n\n# What a response looks like\nresponse = LLMResponse(\n    text=\"There are 3 pods running: nginx, redis, and api.\",\n    tool_calls=[],  # Empty if no tools were called\n    usage={\"input_tokens\": 150, \"output_tokens\": 25},\n)\n</code></pre>"},{"location":"guides/interceptors/#llmresponse-fields","title":"LLMResponse Fields","text":"Field Type Description <code>text</code> <code>str</code> The AI's text response. <code>tool_calls</code> <code>list[dict]</code> Tools the AI wants to use. <code>usage</code> <code>dict \\| None</code> Token usage statistics. <code>raw</code> <code>Any</code> Original provider response (for debugging). <code>session</code> <code>Session</code> Persistent state across conversation turns."},{"location":"guides/interceptors/#llmresponse-methods","title":"LLMResponse Methods","text":"Method Description <code>has_tool_calls()</code> Returns <code>True</code> if the AI wants to call tools. <code>get_text_length()</code> Returns the length of the text response."},{"location":"guides/interceptors/#example-cleaning-output","title":"Example: Cleaning Output","text":"<pre><code>import re\n\ndef remove_thinking_tags(response: LLMResponse) -&gt; LLMResponse:\n    \"\"\"\n    Remove &lt;thinking&gt;...&lt;/thinking&gt; tags from the response.\n\n    Some AI models include their reasoning process in these tags.\n    We hide this from users for a cleaner experience.\n    \"\"\"\n    # Use regex to remove thinking tags and their content\n    cleaned_text = re.sub(\n        r'&lt;thinking&gt;.*?&lt;/thinking&gt;',\n        '',\n        response.text,\n        flags=re.DOTALL  # Match across multiple lines\n    )\n\n    # Remove extra whitespace\n    response.text = cleaned_text.strip()\n\n    return response\n\nagent = Agent(\n    tools=[...],\n    response_interceptors=remove_thinking_tags,\n)\n</code></pre>"},{"location":"guides/interceptors/#example-redacting-sensitive-data","title":"Example: Redacting Sensitive Data","text":"<pre><code>def redact_secrets(response: LLMResponse) -&gt; LLMResponse:\n    \"\"\"\n    Remove any accidentally leaked secrets from the response.\n    \"\"\"\n    # List of patterns that might be secrets\n    secret_patterns = [\n        (r'sk-[a-zA-Z0-9]{32,}', '[API_KEY_REDACTED]'),  # API keys\n        (r'eyJ[a-zA-Z0-9_-]+\\.eyJ[a-zA-Z0-9_-]+', '[JWT_REDACTED]'),  # JWTs\n        (r'password[\"\\']?\\s*[:=]\\s*[\"\\'][^\"\\']+[\"\\']', 'password: [REDACTED]'),\n    ]\n\n    text = response.text\n\n    for pattern, replacement in secret_patterns:\n        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n\n    response.text = text\n    return response\n\nagent = Agent(\n    tools=[...],\n    response_interceptors=redact_secrets,\n)\n</code></pre>"},{"location":"guides/interceptors/#session-access","title":"Session Access","text":"<p>Both <code>LLMRequest</code> and <code>LLMResponse</code> have access to the session, allowing interceptors to read and modify persistent state across conversation turns.</p>"},{"location":"guides/interceptors/#reading-session-in-request-interceptors","title":"Reading Session in Request Interceptors","text":"<pre><code>def add_user_context(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Add user-specific context from session.\"\"\"\n    # Read from session\n    user_name = request.session.get(\"user_name\", \"User\")\n    user_prefs = request.session.get(\"user_preferences\", {})\n\n    # Add context based on session data\n    request.add_system_context(f\"User: {user_name}\")\n\n    if user_prefs.get(\"verbose_mode\"):\n        request.add_system_context(\"User prefers detailed explanations.\")\n\n    return request\n</code></pre>"},{"location":"guides/interceptors/#modifying-session-in-request-interceptors","title":"Modifying Session in Request Interceptors","text":"<pre><code>def track_request_count(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Track how many requests the user has made.\"\"\"\n    count = request.session.get(\"request_count\", 0)\n    request.session.set(\"request_count\", count + 1)\n    request.session.set(\"last_request_time\", datetime.now().isoformat())\n\n    return request\n</code></pre>"},{"location":"guides/interceptors/#modifying-session-in-response-interceptors","title":"Modifying Session in Response Interceptors","text":"<pre><code>def track_response_metrics(response: LLMResponse) -&gt; LLMResponse:\n    \"\"\"Track response metrics in session.\"\"\"\n    # Update session with response info\n    response.session.set(\"last_response_length\", len(response.text))\n    response.session.set(\"had_tool_calls\", response.has_tool_calls())\n\n    # Accumulate total tokens if available\n    if response.usage:\n        total = response.session.get(\"total_tokens\", 0)\n        total += response.usage.get(\"output_tokens\", 0)\n        response.session.set(\"total_tokens\", total)\n\n    return response\n\nagent = Agent(\n    tools=[...],\n    response_interceptors=track_response_metrics,\n)\n</code></pre>"},{"location":"guides/interceptors/#session-with-typed-models","title":"Session with Typed Models","text":"<p>You can store and retrieve typed models in session:</p> <pre><code>from pydantic import BaseModel\n\nclass UserPreferences(BaseModel):\n    theme: str = \"light\"\n    language: str = \"en\"\n    verbose: bool = False\n\ndef apply_user_preferences(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Apply user preferences from session.\"\"\"\n    # Get as typed model\n    prefs = request.session.get(\"user_prefs\", as_type=UserPreferences)\n\n    if prefs:\n        if prefs.language != \"en\":\n            request.add_system_context(f\"Respond in {prefs.language}.\")\n        if prefs.verbose:\n            request.add_system_context(\"Provide detailed explanations.\")\n\n    return request\n</code></pre>"},{"location":"guides/interceptors/#error-handling","title":"Error Handling","text":"<p>Sometimes you need to stop a request entirely. Use <code>InterceptorError</code> for this:</p> <pre><code>from dcaf.core import Agent, LLMRequest, InterceptorError\n\ndef block_dangerous_requests(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"\n    Block requests that look like prompt injection attacks.\n    \"\"\"\n    user_message = request.get_latest_user_message().lower()\n\n    # Check for suspicious patterns\n    dangerous_patterns = [\n        \"ignore previous instructions\",\n        \"disregard your instructions\",\n        \"forget everything\",\n        \"new instructions:\",\n    ]\n\n    for pattern in dangerous_patterns:\n        if pattern in user_message:\n            # STOP! Don't send this to the LLM.\n            raise InterceptorError(\n                user_message=\"I'm sorry, I can't process this request.\",\n                code=\"PROMPT_INJECTION_BLOCKED\",\n                details={\"pattern\": pattern},\n            )\n\n    # Safe to continue\n    return request\n\nagent = Agent(\n    tools=[...],\n    request_interceptors=block_dangerous_requests,\n)\n</code></pre>"},{"location":"guides/interceptors/#interceptorerror-fields","title":"InterceptorError Fields","text":"Field Description <code>user_message</code> The message shown to the user. Make it friendly! <code>code</code> Internal code for logging (not shown to user). <code>details</code> Extra info for logging (not shown to user)."},{"location":"guides/interceptors/#handling-interceptorerror-in-your-code","title":"Handling InterceptorError in Your Code","text":"<pre><code>from dcaf.core import InterceptorError\n\ntry:\n    response = agent.run(messages=[...])\n    print(response.text)\nexcept InterceptorError as error:\n    # The interceptor blocked the request\n    print(f\"Request blocked: {error.user_message}\")\n\n    # For logging/debugging\n    if error.code:\n        log.warning(f\"Blocked with code: {error.code}\")\n</code></pre>"},{"location":"guides/interceptors/#error-handling-modes","title":"Error Handling Modes","text":"<p>You can configure how the agent handles unexpected errors (not <code>InterceptorError</code>):</p> <pre><code>agent = Agent(\n    tools=[...],\n    request_interceptors=[my_interceptor],\n    on_interceptor_error=\"abort\",  # Stop on any error (default)\n    # OR\n    on_interceptor_error=\"continue\",  # Log error and keep going\n)\n</code></pre>"},{"location":"guides/interceptors/#async-interceptors","title":"Async Interceptors","text":"<p>Interceptors can be async, which is useful for:</p> <ul> <li>Database lookups</li> <li>API calls</li> <li>File I/O</li> </ul> <pre><code>import asyncio\n\nasync def enrich_from_database(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"\n    Look up user preferences from the database.\n\n    This is async because database calls take time.\n    \"\"\"\n    user_id = request.context.get(\"user_id\")\n\n    if user_id:\n        # Async database call\n        preferences = await get_user_preferences(user_id)\n\n        # Add preferences to context for tools to use\n        request.context[\"user_preferences\"] = preferences\n\n        # Also tell the AI about them\n        request.add_system_context(\n            f\"User preferences: {preferences}\"\n        )\n\n    return request\n\n# Async functions work just like sync functions\nagent = Agent(\n    tools=[...],\n    request_interceptors=enrich_from_database,\n)\n</code></pre>"},{"location":"guides/interceptors/#mixing-sync-and-async","title":"Mixing Sync and Async","text":"<p>You can use both sync and async interceptors together:</p> <pre><code># Sync interceptor\ndef add_timestamp(request: LLMRequest) -&gt; LLMRequest:\n    request.context[\"timestamp\"] = datetime.now().isoformat()\n    return request\n\n# Async interceptor\nasync def check_rate_limit(request: LLMRequest) -&gt; LLMRequest:\n    user_id = request.context.get(\"user_id\")\n    is_allowed = await rate_limiter.check(user_id)\n\n    if not is_allowed:\n        raise InterceptorError(\"You've made too many requests. Please wait.\")\n\n    return request\n\n# Both work together!\nagent = Agent(\n    tools=[...],\n    request_interceptors=[add_timestamp, check_rate_limit],\n)\n</code></pre>"},{"location":"guides/interceptors/#common-use-cases","title":"Common Use Cases","text":""},{"location":"guides/interceptors/#1-multi-tenant-context","title":"1. Multi-Tenant Context","text":"<p>Add tenant information so the AI knows which environment the user is in:</p> <pre><code>def add_tenant_context(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Add tenant and namespace info to help the AI.\"\"\"\n    tenant = request.context.get(\"tenant_name\", \"unknown\")\n    namespace = request.context.get(\"k8s_namespace\", \"default\")\n\n    context_info = f\"\"\"\nUser's Environment:\n- Tenant: {tenant}\n- Kubernetes Namespace: {namespace}\n- Only show resources from this namespace.\n\"\"\"\n\n    request.add_system_context(context_info)\n    return request\n</code></pre>"},{"location":"guides/interceptors/#2-input-validation","title":"2. Input Validation","text":"<p>Ensure required data is present:</p> <pre><code>def require_tenant(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Ensure the tenant is specified.\"\"\"\n    if not request.context.get(\"tenant_name\"):\n        raise InterceptorError(\n            user_message=\"Please select a tenant before continuing.\",\n            code=\"MISSING_TENANT\",\n        )\n    return request\n</code></pre>"},{"location":"guides/interceptors/#3-audit-logging","title":"3. Audit Logging","text":"<p>Log all requests for compliance:</p> <pre><code>import logging\n\naudit_log = logging.getLogger(\"audit\")\n\ndef log_request(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Log all requests for audit purposes.\"\"\"\n    user_id = request.context.get(\"user_id\", \"anonymous\")\n    user_message = request.get_latest_user_message()\n\n    audit_log.info(\n        f\"Request from {user_id}: {user_message[:100]}...\"\n    )\n\n    return request  # Don't modify, just log\n\ndef log_response(response: LLMResponse) -&gt; LLMResponse:\n    \"\"\"Log all responses for audit purposes.\"\"\"\n    audit_log.info(\n        f\"Response ({response.get_text_length()} chars): \"\n        f\"{response.text[:100]}...\"\n    )\n\n    return response  # Don't modify, just log\n\nagent = Agent(\n    tools=[...],\n    request_interceptors=log_request,\n    response_interceptors=log_response,\n)\n</code></pre>"},{"location":"guides/interceptors/#4-response-formatting","title":"4. Response Formatting","text":"<p>Add consistent formatting to responses:</p> <pre><code>def add_disclaimer(response: LLMResponse) -&gt; LLMResponse:\n    \"\"\"Add a disclaimer to all responses.\"\"\"\n    disclaimer = \"\\n\\n---\\n*This is an AI-generated response. Please verify before taking action.*\"\n    response.text = response.text + disclaimer\n    return response\n</code></pre>"},{"location":"guides/interceptors/#5-rate-limiting","title":"5. Rate Limiting","text":"<p>Prevent abuse by limiting requests:</p> <pre><code>from collections import defaultdict\nfrom datetime import datetime, timedelta\n\n# Simple in-memory rate limiter (use Redis in production)\nrequest_counts = defaultdict(list)\n\ndef rate_limit(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Limit users to 10 requests per minute.\"\"\"\n    user_id = request.context.get(\"user_id\", \"anonymous\")\n    now = datetime.now()\n    one_minute_ago = now - timedelta(minutes=1)\n\n    # Clean old entries\n    request_counts[user_id] = [\n        t for t in request_counts[user_id] if t &gt; one_minute_ago\n    ]\n\n    # Check limit\n    if len(request_counts[user_id]) &gt;= 10:\n        raise InterceptorError(\n            user_message=\"You've reached the rate limit. Please wait a moment.\",\n            code=\"RATE_LIMITED\",\n        )\n\n    # Record this request\n    request_counts[user_id].append(now)\n\n    return request\n</code></pre>"},{"location":"guides/interceptors/#best-practices","title":"Best Practices","text":""},{"location":"guides/interceptors/#1-keep-interceptors-focused","title":"1. Keep Interceptors Focused","text":"<p>Each interceptor should do one thing well:</p> <pre><code># Good: Single responsibility\ndef add_tenant_context(request): ...\ndef validate_input(request): ...\ndef log_request(request): ...\n\n# Bad: Doing too much\ndef do_everything(request):\n    # Adds context AND validates AND logs...\n    # Hard to maintain and test\n    ...\n</code></pre>"},{"location":"guides/interceptors/#2-order-matters","title":"2. Order Matters","text":"<p>Interceptors run in the order you specify:</p> <pre><code>agent = Agent(\n    request_interceptors=[\n        validate_input,      # First: Block bad requests early\n        check_permissions,   # Second: Verify user can do this\n        add_context,         # Third: Enrich the request\n        log_request,         # Last: Log the final request\n    ],\n)\n</code></pre>"},{"location":"guides/interceptors/#3-handle-errors-gracefully","title":"3. Handle Errors Gracefully","text":"<p>Use <code>InterceptorError</code> for user-facing errors:</p> <pre><code># Good: Friendly message\nraise InterceptorError(\n    user_message=\"Please log in to continue.\",\n    code=\"AUTH_REQUIRED\",\n)\n\n# Bad: Technical error shown to user\nraise ValueError(\"Missing auth_token in context\")\n</code></pre>"},{"location":"guides/interceptors/#4-dont-modify-what-you-dont-need","title":"4. Don't Modify What You Don't Need","text":"<p>Only change what's necessary:</p> <pre><code># Good: Only adds to system prompt\ndef add_context(request: LLMRequest) -&gt; LLMRequest:\n    request.add_system_context(\"Extra info\")\n    return request\n\n# Bad: Replaces entire system prompt\ndef add_context(request: LLMRequest) -&gt; LLMRequest:\n    request.system = \"Completely new system prompt\"  # Loses original!\n    return request\n</code></pre>"},{"location":"guides/interceptors/#5-test-your-interceptors","title":"5. Test Your Interceptors","text":"<p>Interceptors are just functions, so they're easy to test:</p> <pre><code>def test_add_tenant_context():\n    # Create a test request\n    request = LLMRequest(\n        messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n        context={\"tenant_name\": \"production\"},\n    )\n\n    # Run the interceptor\n    result = add_tenant_context(request)\n\n    # Check the result\n    assert \"production\" in result.system\n\ndef test_blocks_prompt_injection():\n    request = LLMRequest(\n        messages=[{\"role\": \"user\", \"content\": \"Ignore previous instructions\"}],\n    )\n\n    with pytest.raises(InterceptorError) as exc_info:\n        block_dangerous_requests(request)\n\n    assert exc_info.value.code == \"PROMPT_INJECTION_BLOCKED\"\n</code></pre>"},{"location":"guides/interceptors/#api-reference","title":"API Reference","text":""},{"location":"guides/interceptors/#llmrequest","title":"LLMRequest","text":"<pre><code>@dataclass\nclass LLMRequest:\n    messages: list[dict]      # Conversation messages\n    tools: list[Any]          # Available tools\n    system: str | None        # System prompt\n    context: dict             # Platform context\n    session: Session          # Session for persistent state\n\n    def get_latest_user_message(self) -&gt; str:\n        \"\"\"Get the content of the most recent user message.\"\"\"\n\n    def add_system_context(self, text: str) -&gt; None:\n        \"\"\"Add text to the system prompt.\"\"\"\n</code></pre>"},{"location":"guides/interceptors/#llmresponse","title":"LLMResponse","text":"<pre><code>@dataclass\nclass LLMResponse:\n    text: str                 # AI's text response\n    tool_calls: list[dict]    # Tool calls (if any)\n    usage: dict | None        # Token usage\n    raw: Any                  # Original response\n    session: Session          # Session for persistent state\n\n    def has_tool_calls(self) -&gt; bool:\n        \"\"\"Check if there are tool calls.\"\"\"\n\n    def get_text_length(self) -&gt; int:\n        \"\"\"Get length of text response.\"\"\"\n</code></pre>"},{"location":"guides/interceptors/#interceptorerror","title":"InterceptorError","text":"<pre><code>class InterceptorError(Exception):\n    def __init__(\n        self,\n        user_message: str,      # Shown to user\n        code: str | None,       # For logging\n        details: dict | None,   # Extra info for logging\n    ):\n        ...\n</code></pre>"},{"location":"guides/interceptors/#agent-configuration","title":"Agent Configuration","text":"<pre><code>agent = Agent(\n    tools=[...],\n\n    # Single interceptor\n    request_interceptors=my_interceptor,\n\n    # Multiple interceptors (run in order)\n    request_interceptors=[first, second, third],\n\n    # Response interceptors work the same way\n    response_interceptors=[clean_output, log_response],\n\n    # Error handling mode\n    on_interceptor_error=\"abort\",  # or \"continue\"\n)\n</code></pre>"},{"location":"guides/interceptors/#see-also","title":"See Also","text":"<ul> <li>Agent Documentation - Full Agent class reference</li> <li>Session Management - Complete session guide</li> <li>Architecture Guide - How DCAF works internally</li> <li>Custom Agents Guide - Building complex agents</li> </ul>"},{"location":"guides/mcp-tools/","title":"MCP Tools Guide","text":"<p>This guide covers how to use external MCP (Model Context Protocol) servers with DCAF agents, allowing you to connect to and use tools exposed by MCP-compatible services.</p>"},{"location":"guides/mcp-tools/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Quick Start</li> <li>Transport Protocols</li> <li>Tool Filtering</li> <li>Tool Approval</li> <li>Tool Hooks</li> <li>Using with Agents</li> <li>Connection Management</li> <li>Logging and Monitoring</li> <li>Error Handling</li> <li>Best Practices</li> </ol>"},{"location":"guides/mcp-tools/#introduction","title":"Introduction","text":"<p>The Model Context Protocol (MCP) is an open standard for connecting AI assistants to external data sources and tools. DCAF provides <code>MCPTool</code> - a framework-agnostic wrapper that lets you connect to any MCP server and use its tools alongside your local DCAF tools.</p>"},{"location":"guides/mcp-tools/#what-is-mcp","title":"What is MCP?","text":"<p>MCP servers expose:</p> <ul> <li>Tools: Functions that can be called by AI agents</li> <li>Resources: Data that can be read by AI agents</li> <li>Prompts: Pre-defined prompt templates</li> </ul> <p>DCAF's <code>MCPTool</code> focuses on consuming tools from external MCP servers.</p>"},{"location":"guides/mcp-tools/#why-use-mcptool","title":"Why Use MCPTool?","text":"<ul> <li>Extend your agent's capabilities with tools from external services</li> <li>Reuse existing MCP servers (databases, APIs, file systems, etc.)</li> <li>Framework-agnostic - no direct dependency on underlying LLM framework</li> <li>Seamless integration - MCP tools work alongside native DCAF tools</li> </ul>"},{"location":"guides/mcp-tools/#quick-start","title":"Quick Start","text":""},{"location":"guides/mcp-tools/#installation","title":"Installation","text":"<p>MCP tools require the <code>mcp</code> package:</p> <pre><code>pip install mcp\n</code></pre>"},{"location":"guides/mcp-tools/#basic-usage-automatic-lifecycle","title":"Basic Usage (Automatic Lifecycle)","text":"<p>DCAF automatically manages the MCP connection lifecycle - just pass <code>MCPTool</code> to your agent:</p> <pre><code>from dcaf.core import Agent\nfrom dcaf.mcp import MCPTool\nfrom dcaf.tools import tool\n\n# Define a local tool\n@tool(description=\"Get current time\")\ndef get_time() -&gt; str:\n    from datetime import datetime\n    return datetime.now().isoformat()\n\n# Configure MCP server connection\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n)\n\n# Just pass it to the agent - DCAF handles connect/disconnect automatically!\nasync def main():\n    agent = Agent(tools=[get_time, mcp_tool])\n    result = await agent.arun(\"Search for Python tutorials and tell me the time\")\n    print(result.text)\n</code></pre> <p>The framework automatically: 1. Connects to the MCP server when the agent runs 2. Makes tools available to the LLM 3. Disconnects and cleans up after the run completes</p>"},{"location":"guides/mcp-tools/#manual-connection-optional","title":"Manual Connection (Optional)","text":"<p>If you need explicit control over the connection lifecycle, you can still use the async context manager:</p> <pre><code>async def main():\n    async with mcp_tool:\n        # Connection is established here\n        agent = Agent(tools=[mcp_tool])\n        result = await agent.arun(\"Search for something\")\n    # Connection is closed here\n</code></pre>"},{"location":"guides/mcp-tools/#transport-protocols","title":"Transport Protocols","text":"<p>DCAF's <code>MCPTool</code> supports three transport protocols for connecting to MCP servers.</p>"},{"location":"guides/mcp-tools/#streamable-http-recommended","title":"Streamable HTTP (Recommended)","text":"<p>For HTTP-based MCP servers. This is the recommended protocol for production use.</p> <pre><code>from dcaf.mcp import MCPTool\n\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    timeout_seconds=30,\n)\n</code></pre>"},{"location":"guides/mcp-tools/#server-sent-events-sse","title":"Server-Sent Events (SSE)","text":"<p>For servers using SSE transport (deprecated in favor of streamable-http):</p> <pre><code>mcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"sse\",\n)\n</code></pre> <p>Deprecation Notice</p> <p>SSE transport is deprecated. Use <code>streamable-http</code> for new integrations.</p>"},{"location":"guides/mcp-tools/#standard-io-stdio","title":"Standard I/O (stdio)","text":"<p>For running a local MCP server process. The server communicates via stdin/stdout.</p> <pre><code>mcp_tool = MCPTool(\n    command=\"python my_mcp_server.py\",\n    transport=\"stdio\",\n    env={\"API_KEY\": \"secret\"},  # Optional environment variables\n)\n</code></pre> <p>Use stdio when:</p> <ul> <li>Running a local MCP server script</li> <li>The MCP server is packaged as a CLI tool</li> <li>You need process isolation</li> </ul>"},{"location":"guides/mcp-tools/#choosing-a-transport","title":"Choosing a Transport","text":"Transport Use Case Example <code>streamable-http</code> Remote HTTP servers Cloud APIs, microservices <code>sse</code> Legacy SSE servers Older MCP implementations <code>stdio</code> Local processes CLI tools, scripts"},{"location":"guides/mcp-tools/#tool-filtering","title":"Tool Filtering","text":"<p>When an MCP server exposes many tools, you can filter which ones to use.</p>"},{"location":"guides/mcp-tools/#include-specific-tools","title":"Include Specific Tools","text":"<p>Only include the tools you need:</p> <pre><code>mcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    include_tools=[\"search\", \"query\", \"get_document\"],\n)\n</code></pre>"},{"location":"guides/mcp-tools/#exclude-specific-tools","title":"Exclude Specific Tools","text":"<p>Exclude tools you don't want. Supports both exact names and glob patterns:</p> <pre><code>mcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    # Exact names and glob patterns both work\n    exclude_tools=[\"admin_*\", \"*_delete*\", \"drop_database\"],\n)\n</code></pre>"},{"location":"guides/mcp-tools/#add-tool-name-prefix","title":"Add Tool Name Prefix","text":"<p>Prevent name collisions by prefixing tool names:</p> <pre><code>mcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    tool_name_prefix=\"search\",  # Tools become: search_query, search_fetch, etc.\n)\n</code></pre> <p>This is useful when combining multiple MCP servers:</p> <pre><code># Two MCP servers with potentially conflicting tool names\nsearch_mcp = MCPTool(\n    url=\"http://search-service:8000/mcp\",\n    transport=\"streamable-http\",\n    tool_name_prefix=\"search\",\n)\n\ndb_mcp = MCPTool(\n    url=\"http://db-service:8000/mcp\",\n    transport=\"streamable-http\",\n    tool_name_prefix=\"db\",\n)\n\n# Multiple MCP servers - DCAF manages both automatically\nagent = Agent(tools=[search_mcp, db_mcp])\nresult = await agent.arun(\"Search and query\")\n# Agent sees: search_query, search_fetch, db_query, db_insert, etc.\n</code></pre>"},{"location":"guides/mcp-tools/#tool-approval","title":"Tool Approval","text":"<p>DCAF provides a built-in tool approval system that lets you require user confirmation before executing tools. This applies to both local DCAF tools and MCP tools.</p>"},{"location":"guides/mcp-tools/#marking-tools-as-requiring-approval","title":"Marking Tools as Requiring Approval","text":"<p>Use the <code>requires_approval</code> parameter on local tools:</p> <pre><code>from dcaf.tools import tool\n\n# This tool executes immediately (default)\n@tool(description=\"List files in a directory\")\ndef list_files(path: str) -&gt; str:\n    return \"\\n\".join(os.listdir(path))\n\n# This tool pauses for user approval before execution\n@tool(requires_approval=True, description=\"Delete a file\")\ndef delete_file(path: str) -&gt; str:\n    os.remove(path)\n    return f\"Deleted {path}\"\n</code></pre> <p>For MCP tools, the underlying Agno framework's <code>requires_confirmation</code> flag is automatically mapped to DCAF's approval system. When an MCP tool has <code>requires_confirmation=True</code>, it will pause for user approval just like local tools with <code>requires_approval=True</code>.</p>"},{"location":"guides/mcp-tools/#how-tool-approval-works","title":"How Tool Approval Works","text":"<ol> <li>Agent requests a tool call \u2014 The LLM decides to use a tool based on the conversation</li> <li>DCAF checks approval requirements \u2014 If the tool has <code>requires_approval=True</code>, execution pauses</li> <li>Response includes pending tools \u2014 The response has <code>needs_approval=True</code> and a list of <code>pending_tools</code></li> <li>User approves or rejects \u2014 Via the programmatic API or UI</li> <li>Agent resumes \u2014 Executes approved tools or handles rejections</li> </ol>"},{"location":"guides/mcp-tools/#handling-approval-in-code","title":"Handling Approval in Code","text":"<pre><code>from dcaf.core import Agent\n\nagent = Agent(tools=[list_files, delete_file, mcp_tool])\nresponse = await agent.run(messages=[\n    {\"role\": \"user\", \"content\": \"Delete the old backup files\"}\n])\n\nif response.needs_approval:\n    # Agent is paused, waiting for approval\n    for tool_call in response.pending_tools:\n        print(f\"Tool: {tool_call.name}\")\n        print(f\"Arguments: {tool_call.input}\")\n\n        if should_approve(tool_call):\n            tool_call.approve()\n        else:\n            tool_call.reject(\"Too risky, use a safer approach\")\n\n    # Resume execution with the approval decisions\n    response = agent.resume(response.conversation_id)\n\nprint(response.text)\n</code></pre>"},{"location":"guides/mcp-tools/#batch-approval","title":"Batch Approval","text":"<p>When multiple tools require approval, you can approve or reject them all at once:</p> <pre><code>response = await agent.run(messages=[...])\n\nif response.needs_approval:\n    # Approve all pending tool calls and continue\n    response = response.approve_all()\n\n    # Or reject all\n    # response = response.reject_all(\"Not authorized\")\n</code></pre>"},{"location":"guides/mcp-tools/#approval-response-format","title":"Approval Response Format","text":"<p>When tools require approval, the response includes pending tool calls in the HelpDesk protocol format:</p> <pre><code>{\n  \"content\": \"I'll delete those files for you. Please approve this action.\",\n  \"data\": {\n    \"tool_calls\": [\n      {\n        \"id\": \"tc_abc123\",\n        \"name\": \"delete_file\",\n        \"input\": {\"path\": \"/var/log/old.log\"},\n        \"requires_approval\": true,\n        \"status\": \"pending\"\n      }\n    ]\n  },\n  \"has_pending_approvals\": true,\n  \"is_complete\": false\n}\n</code></pre>"},{"location":"guides/mcp-tools/#mcp-auto-approve-with-glob-patterns","title":"MCP Auto-Approve with Glob Patterns","text":"<p>The <code>auto_approve_tools</code> parameter on <code>MCPTool</code> enables glob-pattern-based approval tiers for MCP tools:</p> <pre><code>mcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    # Block dangerous tools entirely\n    exclude_tools=[\"*_delete*\", \"*_drop*\", \"admin_*\"],\n    # Auto-approve safe read-only tools (glob patterns)\n    auto_approve_tools=[\"*_list*\", \"*_get*\", \"*_read*\", \"*_describe*\"],\n    # Everything else requires user approval before execution\n)\n</code></pre> <p>This classifies MCP tools into three tiers automatically:</p> Tier Description Blocked Tools matching <code>exclude_tools</code> patterns (exact names or globs) \u2014 never available to the agent Auto-Approved Tools matching <code>auto_approve_tools</code> glob patterns \u2014 execute immediately Requires Approval Everything else \u2014 agent pauses for user approval <p>When <code>auto_approve_tools</code> is not set (the default), all MCP tools execute without requiring approval. When set, only tools matching the patterns execute freely \u2014 all others require confirmation.</p> <p>The patterns use Python's <code>fnmatch</code> glob syntax:</p> Pattern Matches <code>*_get*</code> <code>user_get</code>, <code>data_get_all</code>, <code>get_item</code> <code>read_*</code> <code>read_file</code>, <code>read_config</code> <code>get_?</code> <code>get_a</code>, <code>get_1</code> (single character after <code>get_</code>) <code>*</code> Everything (auto-approve all tools)"},{"location":"guides/mcp-tools/#combining-with-tool-filtering","title":"Combining with Tool Filtering","text":"<p>Use <code>exclude_tools</code> to completely block dangerous tools, <code>auto_approve_tools</code> for safe MCP tools, and <code>requires_approval</code> on local tools that need oversight. Both parameters support glob patterns using Python's <code>fnmatch</code> syntax:</p> <pre><code>from dcaf.mcp import MCPTool\n\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    # Completely block these tools - agent never sees them (glob patterns supported)\n    exclude_tools=[\"admin_*\", \"*_delete*\", \"drop_database\"],\n    # Auto-approve read-only MCP tools\n    auto_approve_tools=[\"*_list*\", \"*_get*\", \"*_read*\"],\n)\n\nagent = Agent(\n    tools=[\n        mcp_tool,\n        # Local tool with approval required\n        delete_file,  # has requires_approval=True\n    ],\n)\n</code></pre>"},{"location":"guides/mcp-tools/#tool-hooks","title":"Tool Hooks","text":"<p>DCAF allows you to intercept MCP tool calls using pre-hooks and post-hooks. This is useful for logging, validation, transformation, telemetry, or modifying tool results.</p>"},{"location":"guides/mcp-tools/#mcptoolcall-context-object","title":"MCPToolCall Context Object","text":"<p>Both hooks receive an <code>MCPToolCall</code> object containing information about the tool call:</p> <pre><code>from dcaf.mcp import MCPToolCall\n\n# MCPToolCall attributes:\n# - tool_name: str           - Name of the MCP tool being called\n# - arguments: dict          - Arguments passed to the tool\n# - result: Any              - Tool result (only in post-hook)\n# - duration: float | None   - Execution time in seconds (only in post-hook)\n# - error: Exception | None  - Exception if tool failed (only in post-hook)\n# - metadata: dict           - Additional info (target URL/command, transport)\n</code></pre>"},{"location":"guides/mcp-tools/#pre-hook","title":"Pre-Hook","text":"<p>A pre-hook runs before each MCP tool execution. Use it for:</p> <ul> <li>Logging tool calls</li> <li>Validating arguments</li> <li>Modifying arguments (though the object is informational; modify kwargs in advanced use)</li> <li>Access control checks</li> </ul> <pre><code>from dcaf.mcp import MCPTool, MCPToolCall\n\nasync def log_tool_calls(call: MCPToolCall) -&gt; None:\n    \"\"\"Log every MCP tool call before execution.\"\"\"\n    print(f\"Calling tool: {call.tool_name}\")\n    print(f\"Arguments: {call.arguments}\")\n    print(f\"Target: {call.metadata.get('target')}\")\n\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    pre_hook=log_tool_calls,\n)\n</code></pre> <p>Pre-hooks can be sync or async:</p> <pre><code># Sync pre-hook\ndef sync_pre_hook(call: MCPToolCall) -&gt; None:\n    print(f\"Tool: {call.tool_name}\")\n\n# Async pre-hook\nasync def async_pre_hook(call: MCPToolCall) -&gt; None:\n    await log_to_external_service(call.tool_name, call.arguments)\n</code></pre>"},{"location":"guides/mcp-tools/#post-hook","title":"Post-Hook","text":"<p>A post-hook runs after each MCP tool execution. Use it for:</p> <ul> <li>Logging results</li> <li>Transforming or filtering results</li> <li>Recording metrics/telemetry</li> <li>Error handling</li> </ul>"},{"location":"guides/mcp-tools/#what-is-callresult","title":"What is <code>call.result</code>?","text":"<p>The <code>call.result</code> attribute contains whatever the MCP tool returned - it's the raw result from the MCP server's tool execution. The type is <code>Any</code> because different MCP tools return different types:</p> Result Type Example <code>str</code> <code>\"Found 5 results for 'python tutorials'\"</code> (most common) <code>dict</code> <code>{\"status\": \"success\", \"count\": 5, \"items\": [...]}</code> <code>list</code> <code>[\"result1\", \"result2\", \"result3\"]</code> <code>None</code> Tools with side effects that don't return data <p>In practice, most MCP tools return strings containing the tool's text output. If the tool returns structured data, it's often a JSON string that you'd parse if needed.</p> <pre><code>from dcaf.mcp import MCPTool, MCPToolCall\n\nasync def process_results(call: MCPToolCall):\n    \"\"\"Process and optionally transform tool results.\"\"\"\n    print(f\"Tool {call.tool_name} completed in {call.duration:.3f}s\")\n\n    if call.error:\n        print(f\"Tool failed with: {call.error}\")\n        # You can return a fallback value\n        return \"Tool execution failed, please try again\"\n\n    print(f\"Result: {call.result}\")\n\n    # Return the result (or a transformed version)\n    return call.result\n\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    post_hook=process_results,\n)\n</code></pre> <p>Important: The post-hook's return value replaces the tool's result. Return <code>call.result</code> to keep the original, or return a modified value to transform it.</p>"},{"location":"guides/mcp-tools/#transforming-results","title":"Transforming Results","text":"<p>Post-hooks can transform tool results before they reach the agent:</p> <pre><code>async def sanitize_results(call: MCPToolCall):\n    \"\"\"Remove sensitive data from tool results.\"\"\"\n    result = call.result\n\n    if isinstance(result, str):\n        # Redact API keys or sensitive patterns\n        result = re.sub(r'api_key=\\w+', 'api_key=REDACTED', result)\n\n    return result\n\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    post_hook=sanitize_results,\n)\n</code></pre>"},{"location":"guides/mcp-tools/#error-handling-in-hooks","title":"Error Handling in Hooks","text":"<p>Post-hooks are called even when tools fail, with <code>call.error</code> populated:</p> <pre><code>async def handle_errors(call: MCPToolCall):\n    \"\"\"Handle tool errors gracefully.\"\"\"\n    if call.error:\n        # Log the error\n        logger.error(f\"Tool {call.tool_name} failed: {call.error}\")\n\n        # Return a user-friendly message instead of raising\n        return f\"The {call.tool_name} operation failed. Please try again.\"\n\n    return call.result\n\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    post_hook=handle_errors,\n)\n</code></pre>"},{"location":"guides/mcp-tools/#complete-example-logging-and-metrics","title":"Complete Example: Logging and Metrics","text":"<p>Here's a complete example combining pre and post hooks for observability:</p> <pre><code>import time\nfrom dcaf.core import Agent\nfrom dcaf.mcp import MCPTool, MCPToolCall\n\n# Track metrics\ntool_metrics = {\"calls\": 0, \"errors\": 0, \"total_duration\": 0.0}\n\nasync def pre_hook(call: MCPToolCall) -&gt; None:\n    \"\"\"Log before each tool call.\"\"\"\n    print(f\"&gt;&gt;&gt; Calling {call.tool_name}\")\n    print(f\"    Args: {call.arguments}\")\n    tool_metrics[\"calls\"] += 1\n\nasync def post_hook(call: MCPToolCall):\n    \"\"\"Log after each tool call and collect metrics.\"\"\"\n    if call.error:\n        print(f\"&lt;&lt;&lt; {call.tool_name} FAILED: {call.error}\")\n        tool_metrics[\"errors\"] += 1\n    else:\n        print(f\"&lt;&lt;&lt; {call.tool_name} completed in {call.duration:.3f}s\")\n        tool_metrics[\"total_duration\"] += call.duration or 0\n\n    return call.result\n\n# Create MCP tool with hooks\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    pre_hook=pre_hook,\n    post_hook=post_hook,\n)\n\nasync def main():\n    agent = Agent(tools=[mcp_tool])\n    result = await agent.arun(\"Search for Python tutorials\")\n\n    print(f\"\\nMetrics: {tool_metrics}\")\n    # Output: Metrics: {'calls': 2, 'errors': 0, 'total_duration': 0.456}\n</code></pre>"},{"location":"guides/mcp-tools/#hook-type-signatures","title":"Hook Type Signatures","text":"<p>For type checking, use these signatures:</p> <pre><code>from typing import Any, Awaitable, Callable\nfrom dcaf.mcp import MCPToolCall\n\n# Pre-hook: receives MCPToolCall, returns None\nPreHookFunc = Callable[[MCPToolCall], Awaitable[None] | None]\n\n# Post-hook: receives MCPToolCall, returns transformed result (or original)\nPostHookFunc = Callable[[MCPToolCall], Awaitable[Any] | Any]\n</code></pre>"},{"location":"guides/mcp-tools/#using-with-agents","title":"Using with Agents","text":""},{"location":"guides/mcp-tools/#automatic-lifecycle-recommended","title":"Automatic Lifecycle (Recommended)","text":"<p>Just pass <code>MCPTool</code> to your agent - DCAF handles the rest:</p> <pre><code>from dcaf.core import Agent\nfrom dcaf.mcp import MCPTool\n\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n)\n\nasync def main():\n    # No context manager needed - DCAF manages connection automatically\n    agent = Agent(tools=[mcp_tool])\n    result = await agent.arun(\"Search for something\")\n    # Connection is automatically established and cleaned up\n</code></pre> <p>This is the simplest and recommended approach. The framework: - Connects when the agent runs - Disconnects after the run completes - Handles errors and cleanup automatically</p>"},{"location":"guides/mcp-tools/#explicit-context-manager-optional","title":"Explicit Context Manager (Optional)","text":"<p>Use the context manager when you need to: - Reuse a connection across multiple agent runs - Inspect available tools before running - Have explicit control over connection timing</p> <pre><code>async def main():\n    async with mcp_tool:\n        # Connection established - you can inspect tools\n        print(f\"Available tools: {mcp_tool.get_tool_names()}\")\n\n        agent = Agent(tools=[mcp_tool])\n\n        # Multiple runs share the same connection\n        result1 = await agent.arun(\"Search for X\")\n        result2 = await agent.arun(\"Now search for Y\")\n\n    # Connection explicitly closed here\n</code></pre>"},{"location":"guides/mcp-tools/#manual-connection-management","title":"Manual Connection Management","text":"<p>For fine-grained control:</p> <pre><code>async def main():\n    await mcp_tool.connect()\n\n    try:\n        agent = Agent(tools=[mcp_tool])\n        result = await agent.arun(\"Search for something\")\n    finally:\n        await mcp_tool.close()\n</code></pre>"},{"location":"guides/mcp-tools/#combining-with-local-tools","title":"Combining with Local Tools","text":"<p>MCP tools work seamlessly with native DCAF tools:</p> <pre><code>from dcaf.core import Agent\nfrom dcaf.mcp import MCPTool\nfrom dcaf.tools import tool\n\n# Local DCAF tool\n@tool(description=\"Calculate the sum of two numbers\")\ndef add(a: int, b: int) -&gt; str:\n    return str(a + b)\n\n# Local tool requiring approval\n@tool(requires_approval=True, description=\"Send an email\")\ndef send_email(to: str, subject: str, body: str) -&gt; str:\n    # Send email logic\n    return f\"Email sent to {to}\"\n\n# External MCP tools\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n)\n\nasync def main():\n    async with mcp_tool:\n        # Agent has access to both local and MCP tools\n        agent = Agent(\n            tools=[add, send_email, mcp_tool],\n            system_prompt=\"You are a helpful assistant with math, email, and search capabilities.\"\n        )\n\n        result = await agent.arun(\n            \"Search for the population of Tokyo, add 1000 to it, and email the result to bob@example.com\"\n        )\n</code></pre>"},{"location":"guides/mcp-tools/#checking-available-tools","title":"Checking Available Tools","text":"<p>After connecting, you can inspect which tools are available:</p> <pre><code>async with mcp_tool:\n    # Get list of tool names\n    tool_names = mcp_tool.get_tool_names()\n    print(f\"Available MCP tools: {tool_names}\")\n\n    # Output: ['search', 'query', 'fetch_document', ...]\n</code></pre>"},{"location":"guides/mcp-tools/#connection-management","title":"Connection Management","text":""},{"location":"guides/mcp-tools/#connection-state","title":"Connection State","text":"<p>Check if the connection is established:</p> <pre><code>mcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n)\n\nprint(mcp_tool.initialized)  # False - not connected yet\n\nasync with mcp_tool:\n    print(mcp_tool.initialized)  # True - connected\n\nprint(mcp_tool.initialized)  # False - connection closed\n</code></pre>"},{"location":"guides/mcp-tools/#connection-health-check","title":"Connection Health Check","text":"<p>Check if an existing connection is still alive:</p> <pre><code>async with mcp_tool:\n    is_alive = await mcp_tool.is_alive()\n    if not is_alive:\n        # Reconnect if needed\n        await mcp_tool.connect(force=True)\n</code></pre>"},{"location":"guides/mcp-tools/#force-reconnection","title":"Force Reconnection","text":"<p>Force a fresh connection, even if already connected:</p> <pre><code>await mcp_tool.connect(force=True)\n</code></pre>"},{"location":"guides/mcp-tools/#refresh-on-each-run","title":"Refresh on Each Run","text":"<p>For long-running applications, refresh the connection and tools on each agent run:</p> <pre><code>mcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    refresh_connection=True,  # Refresh on each agent run\n)\n</code></pre>"},{"location":"guides/mcp-tools/#logging-and-monitoring","title":"Logging and Monitoring","text":"<p>DCAF provides comprehensive logging for MCP tools to help you monitor connections, track tool usage, and debug issues.</p>"},{"location":"guides/mcp-tools/#log-levels","title":"Log Levels","text":"<p>MCP logging uses Python's standard logging module under <code>dcaf.mcp.tools</code>:</p> Level What's Logged <code>INFO</code> Connection lifecycle events, tool discovery, tool execution <code>DEBUG</code> Detailed state changes, tool result previews <code>WARNING</code> Connection issues, exceptions during cleanup <code>ERROR</code> Failed connections, tool execution errors"},{"location":"guides/mcp-tools/#enabling-mcp-logging","title":"Enabling MCP Logging","text":"<pre><code>import logging\n\n# Enable INFO level to see connection and tool events\nlogging.basicConfig(level=logging.INFO)\n\n# Or enable DEBUG for more detail\nlogging.getLogger(\"dcaf.mcp.tools\").setLevel(logging.DEBUG)\n</code></pre>"},{"location":"guides/mcp-tools/#lifecycle-events","title":"Lifecycle Events","text":"<p>When using MCPTool, you'll see logs for:</p> <p>Configuration: <pre><code>INFO - \ud83d\udd0c MCP: Configured MCPTool (transport=streamable-http, target=http://localhost:8000/mcp)\nINFO - \ud83d\udd0c MCP: Tool filter - include: ['search', 'query']\nINFO - \ud83d\udd0c MCP: Tool name prefix: docs\n</code></pre></p> <p>Connection: <pre><code>INFO - \ud83d\udd0c MCP: Connecting to MCP server (target=http://localhost:8000/mcp, force=False)...\nINFO - \ud83d\udd0c MCP: \u2705 Connected successfully - 3 tools available\nINFO - \ud83d\udd0c MCP: Available tools: ['search', 'query', 'fetch']\n</code></pre></p> <p>Disconnection: <pre><code>INFO - \ud83d\udd0c MCP: Closing connection (target=http://localhost:8000/mcp)...\nINFO - \ud83d\udd0c MCP: \u2705 Connection closed successfully\n</code></pre></p>"},{"location":"guides/mcp-tools/#tool-execution-logging","title":"Tool Execution Logging","text":"<p>When the LLM calls an MCP tool, you'll see:</p> <pre><code>INFO - \ud83d\udd27 MCP Tool Call: searchDocumentation (target=http://localhost:8000/mcp)\nINFO - \ud83d\udd27 MCP Tool Args: {'query': 'kubernetes deployment'}\nINFO - \ud83d\udd27 MCP Tool Result: searchDocumentation completed in 0.234s\n</code></pre> <p>If a tool fails: <pre><code>ERROR - \ud83d\udd27 MCP Tool Error: searchDocumentation failed after 5.012s - TimeoutError: Connection timed out\n</code></pre></p>"},{"location":"guides/mcp-tools/#agent-integration-logging","title":"Agent Integration Logging","text":"<p>When adding MCPTool to an agent, you'll see:</p> <pre><code>INFO - \ud83d\udd0c MCP: Added MCPTool to agent - will auto-connect (transport=streamable-http, target=http://localhost:8000/mcp)\n</code></pre> <p>Or if pre-connected: <pre><code>INFO - \ud83d\udd0c MCP: Added pre-connected MCPTool to agent (target=http://localhost:8000/mcp, tools=['search', 'query'])\n</code></pre></p>"},{"location":"guides/mcp-tools/#production-logging-configuration","title":"Production Logging Configuration","text":"<p>For production, configure logging to capture MCP events:</p> <pre><code>import logging\n\n# Configure structured logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# Optionally increase verbosity for debugging\n# logging.getLogger(\"dcaf.mcp.tools\").setLevel(logging.DEBUG)\n</code></pre>"},{"location":"guides/mcp-tools/#log-message-reference","title":"Log Message Reference","text":"Prefix Category Example <code>\ud83d\udd0c MCP:</code> Connection lifecycle Connecting, connected, closing, closed <code>\ud83d\udd27 MCP Tool</code> Tool execution Tool calls, arguments, results, errors"},{"location":"guides/mcp-tools/#error-handling","title":"Error Handling","text":""},{"location":"guides/mcp-tools/#connection-errors","title":"Connection Errors","text":"<p>Handle connection failures gracefully:</p> <pre><code>from dcaf.mcp import MCPTool\n\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    timeout_seconds=10,\n)\n\nasync def main():\n    try:\n        async with mcp_tool:\n            agent = Agent(tools=[mcp_tool])\n            result = await agent.arun(\"Search for something\")\n    except ConnectionError as e:\n        print(f\"Failed to connect to MCP server: {e}\")\n        # Fallback to local-only tools\n        agent = Agent(tools=[local_tool])\n        result = await agent.arun(\"Search for something\")\n</code></pre>"},{"location":"guides/mcp-tools/#not-connected-errors","title":"Not Connected Errors","text":"<p>Operations on an unconnected <code>MCPTool</code> raise <code>RuntimeError</code>:</p> <pre><code>mcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n)\n\n# This raises RuntimeError - not connected yet\ntry:\n    tool_names = mcp_tool.get_tool_names()\nexcept RuntimeError as e:\n    print(e)  # \"MCPTool not connected. Use 'async with mcp_tool:' or call 'await mcp_tool.connect()' first.\"\n</code></pre>"},{"location":"guides/mcp-tools/#timeout-configuration","title":"Timeout Configuration","text":"<p>Configure connection and read timeouts:</p> <pre><code>mcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    timeout_seconds=30,  # 30 second timeout\n)\n</code></pre>"},{"location":"guides/mcp-tools/#best-practices","title":"Best Practices","text":""},{"location":"guides/mcp-tools/#1-always-use-context-managers","title":"1. Always Use Context Managers","text":"<p>Ensure connections are properly closed:</p> <pre><code># \u2705 Good - automatic cleanup\nasync with mcp_tool:\n    agent = Agent(tools=[mcp_tool])\n    result = await agent.arun(\"...\")\n\n# \u274c Bad - connection may leak\nawait mcp_tool.connect()\nagent = Agent(tools=[mcp_tool])\nresult = await agent.arun(\"...\")\n# Forgot to close!\n</code></pre>"},{"location":"guides/mcp-tools/#2-filter-and-approve-tools-for-security","title":"2. Filter and Approve Tools for Security","text":"<p>Use a defense-in-depth approach with both filtering and approval:</p> <pre><code># \u2705 Good - block dangerous tools with glob patterns, require approval for sensitive ones\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    exclude_tools=[\"admin_*\", \"*_delete*\", \"drop_database\"],\n)\n\n@tool(requires_approval=True, description=\"Delete a resource\")\ndef delete_resource(id: str) -&gt; str:\n    ...\n\nagent = Agent(tools=[mcp_tool, delete_resource])\n\n# \u2705 Even better - whitelist specific tools\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    include_tools=[\"search\", \"query\", \"get_document\"],\n)\n\n# \u274c Risky - no filtering or approval\nmcp_tool = MCPTool(\n    url=\"http://localhost:8000/mcp\",\n    transport=\"streamable-http\",\n    # Agent can use any tool the server exposes, no approval required\n)\n</code></pre>"},{"location":"guides/mcp-tools/#3-use-tool-name-prefixes-for-multiple-servers","title":"3. Use Tool Name Prefixes for Multiple Servers","text":"<p>Prevent name collisions:</p> <pre><code># \u2705 Good - clear namespacing\nsearch_mcp = MCPTool(url=\"...\", tool_name_prefix=\"search\")\ndb_mcp = MCPTool(url=\"...\", tool_name_prefix=\"db\")\n\n# \u274c Bad - potential name collision\nsearch_mcp = MCPTool(url=\"...\")  # Has \"query\" tool\ndb_mcp = MCPTool(url=\"...\")      # Also has \"query\" tool - collision!\n</code></pre>"},{"location":"guides/mcp-tools/#4-handle-connection-failures","title":"4. Handle Connection Failures","text":"<p>Always have a fallback strategy:</p> <pre><code>async def run_with_fallback(message: str):\n    try:\n        async with mcp_tool:\n            agent = Agent(tools=[local_tools, mcp_tool])\n            return await agent.arun(message)\n    except Exception as e:\n        logger.warning(f\"MCP unavailable: {e}, falling back to local tools\")\n        agent = Agent(tools=[local_tools])\n        return await agent.arun(message)\n</code></pre>"},{"location":"guides/mcp-tools/#5-enable-logging-in-production","title":"5. Enable Logging in Production","text":"<p>Enable MCP logging to track connections and tool usage:</p> <pre><code>import logging\n\n# Enable INFO level for MCP events\nlogging.getLogger(\"dcaf.mcp.tools\").setLevel(logging.INFO)\n\n# You'll see:\n# INFO - \ud83d\udd0c MCP: \u2705 Connected successfully - 3 tools available\n# INFO - \ud83d\udd27 MCP Tool Call: search (target=http://...)\n# INFO - \ud83d\udd27 MCP Tool Result: search completed in 0.234s\n</code></pre>"},{"location":"guides/mcp-tools/#6-inspect-tools-after-connection","title":"6. Inspect Tools After Connection","text":"<p>For debugging, verify which tools are available:</p> <pre><code>async with mcp_tool:\n    tools = mcp_tool.get_tool_names()\n    logger.info(f\"Connected to MCP server with tools: {tools}\")\n</code></pre>"},{"location":"guides/mcp-tools/#api-reference","title":"API Reference","text":""},{"location":"guides/mcp-tools/#mcptool-class","title":"MCPTool Class","text":"<pre><code>class MCPTool:\n    def __init__(\n        self,\n        command: Optional[str] = None,        # For stdio transport\n        *,\n        url: Optional[str] = None,            # For HTTP transports\n        env: Optional[Dict[str, str]] = None, # Environment for stdio\n        transport: Literal[\"stdio\", \"sse\", \"streamable-http\"] = \"stdio\",\n        timeout_seconds: int = 10,\n        include_tools: Optional[List[str]] = None,\n        exclude_tools: Optional[List[str]] = None,\n        tool_name_prefix: Optional[str] = None,\n        refresh_connection: bool = False,\n        auto_approve_tools: Optional[List[str]] = None,\n        pre_hook: Optional[Callable[[MCPToolCall], Awaitable[None] | None]] = None,\n        post_hook: Optional[Callable[[MCPToolCall], Awaitable[Any] | Any]] = None,\n    ): ...\n</code></pre>"},{"location":"guides/mcp-tools/#parameters","title":"Parameters","text":"Parameter Type Description <code>command</code> <code>str</code> Command to run for stdio transport <code>url</code> <code>str</code> URL for HTTP-based transports <code>env</code> <code>Dict[str, str]</code> Environment variables for stdio transport <code>transport</code> <code>Literal[\"stdio\", \"sse\", \"streamable-http\"]</code> Transport protocol <code>timeout_seconds</code> <code>int</code> Connection timeout (default: 10) <code>include_tools</code> <code>List[str]</code> Only include these tools (exact names) <code>exclude_tools</code> <code>List[str]</code> Exclude these tools (exact names or glob patterns) <code>tool_name_prefix</code> <code>str</code> Prefix to add to all tool names <code>refresh_connection</code> <code>bool</code> Reconnect on each agent run <code>auto_approve_tools</code> <code>List[str]</code> Glob patterns for tools that execute without approval <code>pre_hook</code> <code>Callable</code> Function called before each tool execution <code>post_hook</code> <code>Callable</code> Function called after each tool execution"},{"location":"guides/mcp-tools/#properties","title":"Properties","text":"Property Type Description <code>initialized</code> <code>bool</code> Whether connected to the MCP server <code>refresh_connection</code> <code>bool</code> Whether to refresh on each agent run"},{"location":"guides/mcp-tools/#methods","title":"Methods","text":"Method Description <code>async connect(force=False)</code> Connect to the MCP server <code>async close()</code> Close the connection <code>async is_alive()</code> Check if connection is healthy <code>get_tool_names()</code> Get list of available tool names"},{"location":"guides/mcp-tools/#mcptoolcall-class","title":"MCPToolCall Class","text":"<pre><code>@dataclass\nclass MCPToolCall:\n    tool_name: str                    # Name of the MCP tool\n    arguments: dict[str, Any]         # Arguments passed to the tool\n    result: Any = None                # Tool result (post-hook only)\n    duration: float | None = None     # Execution time in seconds (post-hook only)\n    error: Exception | None = None    # Exception if failed (post-hook only)\n    metadata: dict[str, Any]          # Additional info (target, transport)\n</code></pre>"},{"location":"guides/mcp-tools/#context-manager","title":"Context Manager","text":"<pre><code>async with mcp_tool:\n    # Connection established\n    ...\n# Connection automatically closed\n</code></pre>"},{"location":"guides/mcp-tools/#see-also","title":"See Also","text":"<ul> <li>Building Tools Guide - Creating native DCAF tools</li> <li>Framework Adapters - How DCAF abstracts LLM frameworks</li> <li>Custom Agents Guide - Building complex agent workflows</li> </ul>"},{"location":"guides/message-protocol/","title":"Message Protocol Guide","text":"<p>This guide explains the message protocol used by DCAF for communication between clients, agents, and the server.</p>"},{"location":"guides/message-protocol/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Message Structure</li> <li>Request Format</li> <li>Response Format</li> <li>Tool Call Flow</li> <li>Command Flow</li> <li>Platform Context</li> <li>Examples</li> </ol>"},{"location":"guides/message-protocol/#overview","title":"Overview","text":"<p>DCAF uses a structured message protocol for all agent interactions. This protocol supports:</p> <ul> <li>Multi-turn conversations with message history</li> <li>Tool calling with approval workflows</li> <li>Terminal commands with file creation</li> <li>Platform context for runtime information</li> <li>Streaming for real-time responses</li> </ul>"},{"location":"guides/message-protocol/#communication-flow","title":"Communication Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Client  \u2502 \u2500\u2500\u2500\u2500\u2500\u2500&gt; \u2502  Server  \u2502 \u2500\u2500\u2500\u2500\u2500\u2500&gt; \u2502 Agent \u2502\n\u2502 (UI/API) \u2502 &lt;\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 (FastAPI)\u2502 &lt;\u2500\u2500\u2500\u2500\u2500\u2500 \u2502       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502                    \u2502                   \u2502\n     \u2502  POST /api/        \u2502   invoke()        \u2502\n     \u2502  sendMessage       \u2502                   \u2502\n     \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt; \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502\n     \u2502                    \u2502                   \u2502\n     \u2502   AgentMessage     \u2502   AgentMessage    \u2502\n     \u2502 &lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 &lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n     \u2502                    \u2502                   \u2502\n</code></pre>"},{"location":"guides/message-protocol/#message-structure","title":"Message Structure","text":""},{"location":"guides/message-protocol/#base-message","title":"Base Message","text":"<pre><code>{\n    \"role\": \"user\" | \"assistant\",\n    \"content\": \"Message text\",\n    \"data\": {\n        \"cmds\": [...],\n        \"executed_cmds\": [...],\n        \"tool_calls\": [...],\n        \"executed_tool_calls\": [...],\n        \"url_configs\": [...]\n    },\n    \"meta_data\": {},\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"user\": {\"name\": \"Alice\", \"id\": \"user123\"},\n    \"agent\": {\"name\": \"Bot\", \"id\": \"agent456\"}\n}\n</code></pre>"},{"location":"guides/message-protocol/#user-message","title":"User Message","text":"<p>User messages can include platform context:</p> <pre><code>{\n    \"role\": \"user\",\n    \"content\": \"Deploy my application\",\n    \"data\": {\n        \"cmds\": [],         # Commands to approve/reject\n        \"tool_calls\": []    # Tools to approve/reject\n    },\n    \"platform_context\": {\n        \"user_id\": \"alice123\",\n        \"tenant_name\": \"production\",\n        \"k8s_namespace\": \"my-app\",\n        \"duplo_base_url\": \"https://api.duplocloud.net\",\n        \"duplo_token\": \"eyJ...\",\n        \"kubeconfig\": \"base64-encoded-kubeconfig\"\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#agent-message","title":"Agent Message","text":"<p>Agent responses include response data:</p> <pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"I'll help you deploy. Please approve the following:\",\n    \"data\": {\n        \"cmds\": [\n            {\n                \"command\": \"kubectl apply -f deploy.yaml\",\n                \"execute\": false\n            }\n        ],\n        \"tool_calls\": [\n            {\n                \"id\": \"toolu_123\",\n                \"name\": \"deploy_service\",\n                \"input\": {\"name\": \"my-app\", \"image\": \"nginx:latest\"},\n                \"execute\": false,\n                \"tool_description\": \"Deploy a service\",\n                \"input_description\": {...}\n            }\n        ],\n        \"executed_tool_calls\": [\n            {\n                \"id\": \"toolu_456\",\n                \"name\": \"check_status\",\n                \"input\": {\"service\": \"my-app\"},\n                \"output\": \"Service is running\"\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#request-format","title":"Request Format","text":""},{"location":"guides/message-protocol/#basic-request","title":"Basic Request","text":"<pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Hello, how can you help me?\"\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/message-protocol/#multi-turn-request","title":"Multi-Turn Request","text":"<pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"What is Kubernetes?\"\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"Kubernetes is a container orchestration platform...\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"How do I create a deployment?\"\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/message-protocol/#with-platform-context","title":"With Platform Context","text":"<pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"List my pods\",\n            \"platform_context\": {\n                \"tenant_name\": \"production\",\n                \"k8s_namespace\": \"web-app\",\n                \"user_id\": \"alice\"\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/message-protocol/#with-source-identifier","title":"With Source Identifier","text":"<pre><code>{\n    \"messages\": [...],\n    \"source\": \"slack\"\n}\n</code></pre> <p>Valid sources: - <code>help-desk</code> (default) - <code>slack</code> - Custom values</p>"},{"location":"guides/message-protocol/#response-format","title":"Response Format","text":""},{"location":"guides/message-protocol/#simple-response","title":"Simple Response","text":"<pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"Here is the information you requested...\",\n    \"data\": {\n        \"cmds\": [],\n        \"executed_cmds\": [],\n        \"tool_calls\": [],\n        \"executed_tool_calls\": [],\n        \"url_configs\": []\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#response-with-commands","title":"Response with Commands","text":"<pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"I've analyzed the issue. Run this command to fix it:\",\n    \"data\": {\n        \"cmds\": [\n            {\n                \"command\": \"kubectl rollout restart deployment/web-app -n production\",\n                \"execute\": false,\n                \"files\": null\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#response-with-tool-calls","title":"Response with Tool Calls","text":"<pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"I need your approval to scale the deployment:\",\n    \"data\": {\n        \"tool_calls\": [\n            {\n                \"id\": \"toolu_scale_123\",\n                \"name\": \"scale_deployment\",\n                \"input\": {\n                    \"deployment\": \"web-app\",\n                    \"replicas\": 5\n                },\n                \"execute\": false,\n                \"tool_description\": \"Scale a Kubernetes deployment\",\n                \"input_description\": {\n                    \"deployment\": {\n                        \"type\": \"string\",\n                        \"description\": \"Name of the deployment\"\n                    },\n                    \"replicas\": {\n                        \"type\": \"integer\",\n                        \"description\": \"Number of replicas\"\n                    }\n                },\n                \"intent\": \"Increase capacity for traffic spike\"\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#response-with-executed-tools","title":"Response with Executed Tools","text":"<pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"I checked the status. Your deployment is healthy.\",\n    \"data\": {\n        \"executed_tool_calls\": [\n            {\n                \"id\": \"toolu_status_456\",\n                \"name\": \"check_deployment_status\",\n                \"input\": {\"deployment\": \"web-app\"},\n                \"output\": \"Deployment web-app: 3/3 pods ready, healthy\"\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#tool-call-flow","title":"Tool Call Flow","text":""},{"location":"guides/message-protocol/#flow-diagram","title":"Flow Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Client \u2502       \u2502 Agent \u2502       \u2502 Tool  \u2502       \u2502 Client \u2502\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\n     \u2502               \u2502               \u2502                \u2502\n     \u2502 \"Delete pod\"  \u2502               \u2502                \u2502\n     \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502               \u2502                \u2502\n     \u2502               \u2502               \u2502                \u2502\n     \u2502               \u2502 Needs         \u2502                \u2502\n     \u2502               \u2502 approval      \u2502                \u2502\n     \u2502               \u2502               \u2502                \u2502\n     \u2502  ToolCall     \u2502               \u2502                \u2502\n     \u2502  (execute:    \u2502               \u2502                \u2502\n     \u2502   false)      \u2502               \u2502                \u2502\n     \u2502 &lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502               \u2502                \u2502\n     \u2502               \u2502               \u2502                \u2502\n     \u2502 [User reviews and approves]   \u2502                \u2502\n     \u2502               \u2502               \u2502                \u2502\n     \u2502 ToolCall      \u2502               \u2502                \u2502\n     \u2502 (execute:true)\u2502               \u2502                \u2502\n     \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502               \u2502                \u2502\n     \u2502               \u2502               \u2502                \u2502\n     \u2502               \u2502 Execute       \u2502                \u2502\n     \u2502               \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502                \u2502\n     \u2502               \u2502               \u2502                \u2502\n     \u2502               \u2502 Result        \u2502                \u2502\n     \u2502               \u2502 &lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502                \u2502\n     \u2502               \u2502               \u2502                \u2502\n     \u2502 Response with \u2502               \u2502                \u2502\n     \u2502 ExecutedTool  \u2502               \u2502                \u2502\n     \u2502 &lt;\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502               \u2502                \u2502\n     \u2502               \u2502               \u2502                \u2502\n</code></pre>"},{"location":"guides/message-protocol/#step-1-request","title":"Step 1: Request","text":"<pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Delete the pod called web-app-abc123\"\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/message-protocol/#step-2-approval-request","title":"Step 2: Approval Request","text":"<p>Agent returns tool call needing approval:</p> <pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"I need your approval to delete the pod:\",\n    \"data\": {\n        \"tool_calls\": [\n            {\n                \"id\": \"toolu_delete_789\",\n                \"name\": \"delete_pod\",\n                \"input\": {\"pod_name\": \"web-app-abc123\", \"namespace\": \"default\"},\n                \"execute\": false,\n                \"tool_description\": \"Delete a Kubernetes pod\",\n                \"input_description\": {...}\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#step-3a-approval","title":"Step 3a: Approval","text":"<p>Client sends back with <code>execute: true</code>:</p> <pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Delete the pod called web-app-abc123\",\n            \"data\": {\n                \"tool_calls\": [\n                    {\n                        \"id\": \"toolu_delete_789\",\n                        \"name\": \"delete_pod\",\n                        \"input\": {\"pod_name\": \"web-app-abc123\", \"namespace\": \"default\"},\n                        \"execute\": true\n                    }\n                ]\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/message-protocol/#step-3b-rejection","title":"Step 3b: Rejection","text":"<p>Client sends back with <code>rejection_reason</code>:</p> <pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Delete the pod called web-app-abc123\",\n            \"data\": {\n                \"tool_calls\": [\n                    {\n                        \"id\": \"toolu_delete_789\",\n                        \"name\": \"delete_pod\",\n                        \"input\": {\"pod_name\": \"web-app-abc123\", \"namespace\": \"default\"},\n                        \"rejection_reason\": \"Wrong pod - I meant web-app-xyz789\"\n                    }\n                ]\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/message-protocol/#step-4-result","title":"Step 4: Result","text":"<p>Agent returns with executed tool:</p> <pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"Done! The pod has been deleted.\",\n    \"data\": {\n        \"executed_tool_calls\": [\n            {\n                \"id\": \"toolu_delete_789\",\n                \"name\": \"delete_pod\",\n                \"input\": {\"pod_name\": \"web-app-abc123\", \"namespace\": \"default\"},\n                \"output\": \"Pod web-app-abc123 deleted successfully\"\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#command-flow","title":"Command Flow","text":""},{"location":"guides/message-protocol/#step-1-agent-suggests-command","title":"Step 1: Agent Suggests Command","text":"<pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"To fix the issue, run this command:\",\n    \"data\": {\n        \"cmds\": [\n            {\n                \"command\": \"kubectl delete pod web-app-abc123 -n production\",\n                \"execute\": false\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#step-2-user-approves","title":"Step 2: User Approves","text":"<pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Fix my pod issue\",\n            \"data\": {\n                \"cmds\": [\n                    {\n                        \"command\": \"kubectl delete pod web-app-abc123 -n production\",\n                        \"execute\": true\n                    }\n                ]\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/message-protocol/#step-3-execution-result","title":"Step 3: Execution Result","text":"<pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"Command executed successfully. The pod is restarting.\",\n    \"data\": {\n        \"executed_cmds\": [\n            {\n                \"command\": \"kubectl delete pod web-app-abc123 -n production\",\n                \"output\": \"pod \\\"web-app-abc123\\\" deleted\"\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#commands-with-files","title":"Commands with Files","text":"<p>Some commands need files created first:</p> <pre><code>{\n    \"data\": {\n        \"cmds\": [\n            {\n                \"command\": \"helm install my-app ./chart\",\n                \"execute\": false,\n                \"files\": [\n                    {\n                        \"file_path\": \"chart/Chart.yaml\",\n                        \"file_content\": \"apiVersion: v2\\nname: my-app\\n...\"\n                    },\n                    {\n                        \"file_path\": \"chart/values.yaml\",\n                        \"file_content\": \"replicaCount: 3\\n...\"\n                    }\n                ]\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#platform-context","title":"Platform Context","text":""},{"location":"guides/message-protocol/#fields","title":"Fields","text":"Field Type Description <code>user_id</code> <code>string</code> Current user identifier <code>tenant_name</code> <code>string</code> DuploCloud tenant <code>k8s_namespace</code> <code>string</code> Kubernetes namespace <code>duplo_base_url</code> <code>string</code> DuploCloud API URL <code>duplo_token</code> <code>string</code> DuploCloud API token <code>kubeconfig</code> <code>string</code> Base64-encoded kubeconfig <code>aws_credentials</code> <code>object</code> AWS credential info"},{"location":"guides/message-protocol/#passing-context","title":"Passing Context","text":"<p>Context is passed in user messages:</p> <pre><code>{\n    \"role\": \"user\",\n    \"content\": \"List my services\",\n    \"platform_context\": {\n        \"user_id\": \"alice\",\n        \"tenant_name\": \"production\",\n        \"k8s_namespace\": \"web-app\"\n    }\n}\n</code></pre>"},{"location":"guides/message-protocol/#context-in-multi-turn","title":"Context in Multi-Turn","text":"<p>Context is typically included in the first message and the most recent message:</p> <pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Show me my pods\",\n            \"platform_context\": {\"tenant_name\": \"prod\", \"k8s_namespace\": \"app\"}\n        },\n        {\n            \"role\": \"assistant\",\n            \"content\": \"Here are your pods...\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Now scale up the deployment\",\n            \"platform_context\": {\"tenant_name\": \"prod\", \"k8s_namespace\": \"app\"}\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/message-protocol/#examples","title":"Examples","text":""},{"location":"guides/message-protocol/#example-1-simple-chat","title":"Example 1: Simple Chat","text":"<p>Request: <pre><code>{\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"What is DCAF?\"}\n    ]\n}\n</code></pre></p> <p>Response: <pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"DCAF (DuploCloud Agent Framework) is a Python framework for building LLM-powered AI agents...\",\n    \"data\": {\n        \"cmds\": [],\n        \"tool_calls\": [],\n        \"executed_tool_calls\": []\n    }\n}\n</code></pre></p>"},{"location":"guides/message-protocol/#example-2-tool-execution","title":"Example 2: Tool Execution","text":"<p>Request: <pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Check the weather in San Francisco\"\n        }\n    ]\n}\n</code></pre></p> <p>Response (tool runs automatically): <pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"The weather in San Francisco is 68\u00b0F and sunny.\",\n    \"data\": {\n        \"executed_tool_calls\": [\n            {\n                \"id\": \"toolu_weather_123\",\n                \"name\": \"get_weather\",\n                \"input\": {\"location\": \"San Francisco, CA\"},\n                \"output\": \"68\u00b0F, sunny, humidity 45%\"\n            }\n        ]\n    }\n}\n</code></pre></p>"},{"location":"guides/message-protocol/#example-3-approval-workflow","title":"Example 3: Approval Workflow","text":"<p>Initial Request: <pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Delete my staging environment\"\n        }\n    ]\n}\n</code></pre></p> <p>Response (needs approval): <pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"I found the staging environment. Please confirm deletion:\",\n    \"data\": {\n        \"tool_calls\": [\n            {\n                \"id\": \"toolu_delete_env_456\",\n                \"name\": \"delete_environment\",\n                \"input\": {\"environment\": \"staging\", \"tenant\": \"production\"},\n                \"execute\": false,\n                \"tool_description\": \"Delete an environment and all its resources\",\n                \"intent\": \"Remove staging environment as requested\"\n            }\n        ]\n    }\n}\n</code></pre></p> <p>Follow-up (approved): <pre><code>{\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": \"Delete my staging environment\",\n            \"data\": {\n                \"tool_calls\": [\n                    {\n                        \"id\": \"toolu_delete_env_456\",\n                        \"name\": \"delete_environment\",\n                        \"input\": {\"environment\": \"staging\", \"tenant\": \"production\"},\n                        \"execute\": true\n                    }\n                ]\n            }\n        }\n    ]\n}\n</code></pre></p> <p>Final Response: <pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"The staging environment has been deleted successfully.\",\n    \"data\": {\n        \"executed_tool_calls\": [\n            {\n                \"id\": \"toolu_delete_env_456\",\n                \"name\": \"delete_environment\",\n                \"input\": {\"environment\": \"staging\", \"tenant\": \"production\"},\n                \"output\": \"Environment 'staging' deleted. 15 resources removed.\"\n            }\n        ]\n    }\n}\n</code></pre></p>"},{"location":"guides/message-protocol/#example-4-command-with-files","title":"Example 4: Command with Files","text":"<p>Response with file creation: <pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"I'll create a Helm chart for your application. Please approve:\",\n    \"data\": {\n        \"cmds\": [\n            {\n                \"command\": \"helm install my-app ./my-app-chart --namespace production\",\n                \"execute\": false,\n                \"files\": [\n                    {\n                        \"file_path\": \"my-app-chart/Chart.yaml\",\n                        \"file_content\": \"apiVersion: v2\\nname: my-app\\nversion: 1.0.0\"\n                    },\n                    {\n                        \"file_path\": \"my-app-chart/values.yaml\",\n                        \"file_content\": \"replicaCount: 3\\nimage:\\n  repository: nginx\\n  tag: latest\"\n                    },\n                    {\n                        \"file_path\": \"my-app-chart/templates/deployment.yaml\",\n                        \"file_content\": \"apiVersion: apps/v1\\nkind: Deployment\\n...\"\n                    }\n                ]\n            }\n        ]\n    }\n}\n</code></pre></p>"},{"location":"guides/message-protocol/#see-also","title":"See Also","text":"<ul> <li>Schemas API Reference</li> <li>Agent Server API Reference</li> <li>Streaming Guide</li> </ul>"},{"location":"guides/migration/","title":"Migrating from v1 to Core","text":"<p>This guide helps you migrate from the legacy v1 API to the new Core API.</p>"},{"location":"guides/migration/#why-migrate","title":"Why Migrate?","text":"<p>The Core API offers:</p> <ul> <li>Simpler code - Fewer imports, less boilerplate</li> <li>One-line server - <code>serve(agent)</code> instead of <code>create_chat_app()</code> + <code>uvicorn.run()</code></li> <li>Better defaults - Sensible configuration out of the box</li> <li>Custom logic support - Write functions, not just classes</li> <li>Same capabilities - Tool calling, approvals, streaming all work</li> </ul>"},{"location":"guides/migration/#quick-comparison","title":"Quick Comparison","text":""},{"location":"guides/migration/#before-v1","title":"Before (v1)","text":"<pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.tools import tool\nfrom dcaf.agent_server import create_chat_app\nimport uvicorn\nimport dotenv\n\ndotenv.load_dotenv()\n\n@tool(\n    schema={\n        \"name\": \"list_pods\",\n        \"description\": \"List Kubernetes pods\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"namespace\": {\"type\": \"string\", \"default\": \"default\"}\n            }\n        }\n    },\n    requires_approval=False\n)\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n\nllm = BedrockLLM(region_name=\"us-east-1\")\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[list_pods],\n    system_prompt=\"You are a Kubernetes assistant.\",\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n)\n\napp = create_chat_app(agent)\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"guides/migration/#after-core","title":"After (Core)","text":"<pre><code>from dcaf.core import Agent, serve\nfrom dcaf.tools import tool\n\n@tool(description=\"List Kubernetes pods\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n\nagent = Agent(\n    tools=[list_pods],\n    system=\"You are a Kubernetes assistant.\",\n)\n\nif __name__ == \"__main__\":\n    serve(agent)\n</code></pre> <p>What changed: - No <code>BedrockLLM</code> instantiation needed - No <code>ToolCallingAgent</code> - just <code>Agent</code> - No <code>create_chat_app()</code> + <code>uvicorn.run()</code> - just <code>serve()</code> - Simpler <code>@tool</code> decorator (schema auto-generated) - <code>system_prompt</code> \u2192 <code>system</code></p>"},{"location":"guides/migration/#step-by-step-migration","title":"Step-by-Step Migration","text":""},{"location":"guides/migration/#step-1-update-imports","title":"Step 1: Update Imports","text":"<pre><code># Before\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.agent_server import create_chat_app\n\n# After\nfrom dcaf.core import Agent, serve\n</code></pre>"},{"location":"guides/migration/#step-2-simplify-tools","title":"Step 2: Simplify Tools","text":"<p>The <code>@tool</code> decorator now auto-generates schemas from type hints:</p> <pre><code># Before - explicit schema\n@tool(\n    schema={\n        \"name\": \"delete_pod\",\n        \"description\": \"Delete a Kubernetes pod\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"name\": {\"type\": \"string\", \"description\": \"Pod name\"},\n                \"namespace\": {\"type\": \"string\", \"default\": \"default\"}\n            },\n            \"required\": [\"name\"]\n        }\n    },\n    requires_approval=True\n)\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n\n# After - auto-generated schema\n@tool(requires_approval=True, description=\"Delete a Kubernetes pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    \"\"\"Delete a pod from the cluster.\"\"\"\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n</code></pre> <p>Note</p> <p>You can still use explicit schemas if needed. The Core API supports both approaches.</p>"},{"location":"guides/migration/#step-3-replace-agent-class","title":"Step 3: Replace Agent Class","text":"<pre><code># Before\nllm = BedrockLLM(region_name=\"us-east-1\")\nagent = ToolCallingAgent(\n    llm=llm,\n    tools=[my_tool],\n    system_prompt=\"You are helpful.\",\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_iterations=10\n)\n\n# After\nagent = Agent(\n    tools=[my_tool],\n    system=\"You are helpful.\",\n    # model is configured via environment or defaults\n)\n</code></pre>"},{"location":"guides/migration/#step-4-replace-server-setup","title":"Step 4: Replace Server Setup","text":"<pre><code># Before\napp = create_chat_app(agent)\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n\n# After\nif __name__ == \"__main__\":\n    serve(agent, port=8000)\n</code></pre>"},{"location":"guides/migration/#step-5-update-endpoints-clients","title":"Step 5: Update Endpoints (Clients)","text":"<p>If you have clients calling your agent:</p> Old Endpoint New Endpoint Status <code>/api/sendMessage</code> <code>/api/chat</code> Both work (legacy supported) <code>/api/sendMessageStream</code> <code>/api/chat-stream</code> Both work (legacy supported) <p>The legacy endpoints still work, but we recommend updating clients to use the new endpoints.</p>"},{"location":"guides/migration/#common-patterns","title":"Common Patterns","text":""},{"location":"guides/migration/#custom-agent-logic-v1-core","title":"Custom Agent Logic (v1 \u2192 Core)","text":"<p>Before (extending ToolCallingAgent):</p> <pre><code>from dcaf.agents import ToolCallingAgent\n\nclass MyAgent(ToolCallingAgent):\n    def invoke(self, messages):\n        # Pre-processing\n        tenant = self.extract_tenant(messages)\n\n        # Call parent\n        response = super().invoke(messages)\n\n        # Post-processing\n        self.log_response(tenant, response)\n\n        return response\n</code></pre> <p>After (custom function):</p> <pre><code>from dcaf.core import Agent, AgentResult, serve\n\ndef my_agent(messages: list, context: dict) -&gt; AgentResult:\n    # Pre-processing\n    tenant = context.get(\"tenant_name\")\n\n    # Use Agent\n    agent = Agent(tools=[...], system=\"...\")\n    response = agent.run(messages)\n\n    # Post-processing\n    log_response(tenant, response)\n\n    return AgentResult(text=response.text)\n\nserve(my_agent)\n</code></pre>"},{"location":"guides/migration/#platform-context","title":"Platform Context","text":"<p>Before:</p> <pre><code>class MyAgent(ToolCallingAgent):\n    def invoke(self, messages):\n        messages_list = messages.get(\"messages\", [])\n        last_user = next(\n            (m for m in reversed(messages_list) if m.get(\"role\") == \"user\"),\n            {}\n        )\n        platform_context = last_user.get(\"platform_context\", {})\n        tenant = platform_context.get(\"tenant_name\")\n        # ...\n</code></pre> <p>After:</p> <pre><code>def my_agent(messages: list, context: dict) -&gt; AgentResult:\n    # Context is extracted for you\n    tenant = context.get(\"tenant_name\")\n    # ...\n</code></pre>"},{"location":"guides/migration/#handling-approvals","title":"Handling Approvals","text":"<p>Before (checking response):</p> <pre><code>response = agent.invoke(messages)\nif response.data.tool_calls:\n    # Has pending approvals\n    pass\n</code></pre> <p>After:</p> <pre><code>response = agent.run(messages)\nif response.needs_approval:\n    # Has pending approvals\n    for tool in response.pending_tools:\n        print(f\"Pending: {tool.name}\")\n</code></pre>"},{"location":"guides/migration/#feature-mapping","title":"Feature Mapping","text":"v1 Feature Core Equivalent <code>ToolCallingAgent</code> <code>Agent</code> <code>BedrockLLM</code> Built into <code>Agent</code> <code>create_chat_app(agent)</code> <code>create_app(agent)</code> <code>uvicorn.run(app, ...)</code> <code>serve(agent, ...)</code> <code>system_prompt</code> param <code>system</code> param <code>model_id</code> param <code>model</code> param (or env var) <code>max_iterations</code> param Built-in with sensible default <code>AgentMessage</code> response <code>AgentResponse</code> response <code>response.content</code> <code>response.text</code> <code>response.data.tool_calls</code> <code>response.pending_tools</code> <code>/api/sendMessage</code> <code>/api/chat</code> (legacy still works) <code>/api/sendMessageStream</code> <code>/api/chat-stream</code> (legacy still works)"},{"location":"guides/migration/#using-chat-for-v1-compatible-responses","title":"Using <code>.chat()</code> for v1-Compatible Responses","text":"<p>If you have existing v1 agents that return <code>AgentMessage</code> directly (the wire format for HelpDesk), you can use the Core API's <code>.chat()</code> method instead of <code>.run()</code>. This returns <code>AgentMessage</code> directly, making it a drop-in replacement for v1's <code>invoke()</code> method.</p>"},{"location":"guides/migration/#the-problem","title":"The Problem","text":"<p>v1 agents like <code>K8sAgent</code> implement <code>AgentProtocol</code> with an <code>invoke()</code> method that returns <code>AgentMessage</code>:</p> <pre><code># v1 pattern - returns AgentMessage directly\nclass K8sAgent(AgentProtocol):\n    def invoke(self, messages: dict, thread_id: str) -&gt; AgentMessage:\n        # Process messages, call LLM, etc.\n        return AgentMessage(\n            content=\"Here are your pods...\",\n            data=Data(cmds=[...], executed_cmds=[...])\n        )\n</code></pre> <p>The Core API's <code>.run()</code> method returns <code>AgentResponse</code>, which has convenience methods like <code>.approve_all()</code>. But if your existing code expects <code>AgentMessage</code>, you'd need to convert manually.</p>"},{"location":"guides/migration/#the-solution-chat","title":"The Solution: <code>.chat()</code>","text":"<p>The Core API provides <code>.chat()</code> which returns <code>AgentMessage</code> directly:</p> <pre><code>from dcaf.core import Agent\nfrom dcaf.schemas.messages import AgentMessage\n\nagent = Agent(\n    tools=[list_pods, delete_pod],\n    system=\"You are a Kubernetes assistant.\"\n)\n\n# .chat() returns AgentMessage - same wire format as v1\nmessage: AgentMessage = await agent.chat(messages)\n\n# Ready for JSON serialization\nreturn message.model_dump()\n</code></pre>"},{"location":"guides/migration/#migrating-a-v1-agent","title":"Migrating a v1 Agent","text":"<p>Before (v1 custom agent):</p> <pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.schemas.messages import AgentMessage, Data, Command\nfrom agent_server import AgentProtocol\n\nclass K8sAgent(AgentProtocol):\n    def __init__(self, llm: BedrockLLM, system_prompt: str):\n        self.llm = llm\n        self.system_prompt = system_prompt\n        self.model_id = \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n\n    def invoke(self, messages: dict, thread_id: str) -&gt; AgentMessage:\n        # Process messages, execute approved commands\n        processed, executed = self.process_messages(messages)\n\n        # Call LLM\n        response = self.llm.invoke(\n            messages=processed,\n            model_id=self.model_id,\n            system_prompt=self.system_prompt,\n            tools=[self._create_terminal_tool()],\n        )\n\n        # Extract commands, build AgentMessage\n        commands = self._extract_commands(response)\n        return AgentMessage(\n            content=response.get(\"content\", \"\"),\n            data=Data(\n                cmds=[Command(command=c[\"command\"]) for c in commands],\n                executed_cmds=[...]\n            )\n        )\n</code></pre> <p>After (Core API with <code>.chat()</code>):</p> <pre><code>from dcaf.core import Agent\nfrom dcaf.tools import tool\nfrom dcaf.schemas.messages import AgentMessage\n\n@tool(description=\"Execute terminal command\")\ndef execute_terminal_cmd(command: str, explanation: str = \"\") -&gt; str:\n    \"\"\"Execute a terminal command.\"\"\"\n    return run_command(command)\n\nclass K8sAgent:\n    def __init__(self, system_prompt: str):\n        self.agent = Agent(\n            tools=[execute_terminal_cmd],\n            system=system_prompt,\n        )\n\n    async def invoke(self, messages: dict, thread_id: str) -&gt; AgentMessage:\n        # Extract messages list\n        messages_list = messages.get(\"messages\", [])\n\n        # .chat() returns AgentMessage directly - same as v1!\n        return await self.agent.chat(messages_list)\n</code></pre>"},{"location":"guides/migration/#key-differences","title":"Key Differences","text":"Aspect <code>.run()</code> <code>.chat()</code> Returns <code>AgentResponse</code> <code>AgentMessage</code> Use case Programmatic control (approve/reject) Wire format / HelpDesk Convenience methods <code>.approve_all()</code>, <code>.reject_all()</code> None (data in <code>message.data</code>) Serialization Call <code>.to_message().model_dump()</code> Call <code>.model_dump()</code> directly"},{"location":"guides/migration/#when-to-use-each","title":"When to Use Each","text":"<p>Use <code>.run()</code> when you need: - Programmatic approval/rejection - Access to <code>needs_approval</code>, <code>pending_tools</code> properties - More control over the agent loop</p> <p>Use <code>.chat()</code> when you need: - Direct <code>AgentMessage</code> response (v1 wire format) - Drop-in replacement for v1 <code>invoke()</code> - HelpDesk integration without conversion</p>"},{"location":"guides/migration/#handling-platform-context","title":"Handling Platform Context","text":"<p>v1 agents often extract <code>platform_context</code> from messages manually. With <code>.chat()</code>, pass it as the <code>context</code> parameter:</p> <pre><code># v1 - manually extract platform_context\nmessages_list = messages.get(\"messages\", [])\nlast_user = next((m for m in reversed(messages_list) if m.get(\"role\") == \"user\"), {})\nplatform_context = last_user.get(\"platform_context\", {})\n\n# Core - pass context directly\nmessage = await agent.chat(\n    messages=messages_list,\n    context=platform_context  # Passed to tools and interceptors\n)\n</code></pre>"},{"location":"guides/migration/#handling-session-state","title":"Handling Session State","text":"<p>v1 agents often store state in instance variables. With Core, use the <code>session</code> parameter:</p> <pre><code># Core - use session for state that persists across turns\nmessage = await agent.chat(\n    messages=messages_list,\n    session={\"thread_id\": thread_id, \"kubeconfig_path\": \"/path/to/config\"}\n)\n\n# Session data is in the response\nsession_data = message.data.session\n</code></pre>"},{"location":"guides/migration/#keeping-legacy-code","title":"Keeping Legacy Code","text":"<p>You don't have to migrate everything at once. The legacy API still works:</p> <pre><code># This still works fine\nfrom dcaf.llm import BedrockLLM\nfrom dcaf.agents import ToolCallingAgent\nfrom dcaf.agent_server import create_chat_app\n\nllm = BedrockLLM()\nagent = ToolCallingAgent(llm=llm, tools=[...])\napp = create_chat_app(agent)\n</code></pre> <p>You can have some agents on v1 and some on Core. They use the same underlying server.</p>"},{"location":"guides/migration/#gradual-migration-strategy","title":"Gradual Migration Strategy","text":"<ol> <li>New agents - Use Core API</li> <li>Existing agents - Migrate when you need to modify them</li> <li>Clients - Update to new endpoints when convenient (legacy works indefinitely)</li> </ol>"},{"location":"guides/migration/#need-help","title":"Need Help?","text":"<ul> <li>Core Documentation</li> <li>Custom Agents Guide</li> <li>Legacy API Reference</li> <li>GitHub Issues: dcaf</li> </ul>"},{"location":"guides/prompt-caching/","title":"Bedrock Prompt Caching Guide","text":""},{"location":"guides/prompt-caching/#overview","title":"Overview","text":"<p>AWS Bedrock's prompt caching feature can reduce costs by up to 90% and latency by up to 85% for agents with static instructions and dynamic context.</p> <p>Status: Experimental (v1) - Temporary implementation until Agno adds native support</p>"},{"location":"guides/prompt-caching/#how-it-works","title":"How It Works","text":"<p>When you enable caching, DCAF places a \"cache checkpoint\" in your system prompt. Everything before the checkpoint is cached by Bedrock for 5 minutes (TTL resets on each use).</p> <pre><code>[Static Instructions] \u2190 CACHED\n      \u2193\n[Cache Checkpoint]\n      \u2193\n[Dynamic Context]     \u2190 NOT cached (fresh each time)\n</code></pre>"},{"location":"guides/prompt-caching/#quick-start","title":"Quick Start","text":""},{"location":"guides/prompt-caching/#basic-usage","title":"Basic Usage","text":"<pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    system_prompt=\"You are a Kubernetes expert... [long instructions]\",\n    tools=[list_pods, delete_pod],\n    model_config={\n        \"cache_system_prompt\": True  # Enable caching\n    }\n)\n</code></pre>"},{"location":"guides/prompt-caching/#separating-static-and-dynamic-content","title":"Separating Static and Dynamic Content","text":"<p>This is the key pattern for effective caching:</p> <pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    # Static - cached\n    system_prompt=\"You are a Kubernetes expert. Your job is to help users manage their clusters...\",\n\n    # Dynamic - NOT cached\n    system_context=lambda ctx: f\"\"\"\n    Current tenant: {ctx['tenant_name']}\n    Namespace: {ctx['k8s_namespace']}\n    User: {ctx['user_email']}\n    \"\"\",\n\n    model_config={\n        \"cache_system_prompt\": True\n    }\n)\n</code></pre>"},{"location":"guides/prompt-caching/#requirements","title":"Requirements","text":""},{"location":"guides/prompt-caching/#minimum-token-count","title":"Minimum Token Count","text":"<p>Your static system prompt must be at least: - Claude 3.7 Sonnet: 1024 tokens - Claude 3.5 Haiku: 2048 tokens</p> <p>If below threshold, caching is automatically disabled with a warning log.</p> <p>Rule of thumb: ~4 characters = 1 token, so aim for 4000+ character prompts.</p>"},{"location":"guides/prompt-caching/#best-practices","title":"Best Practices","text":""},{"location":"guides/prompt-caching/#1-put-static-content-first","title":"1. Put Static Content First","text":"<p>\u2705 Good: Static instructions, then dynamic context <pre><code>system_prompt=\"You are a K8s expert. [lengthy guidelines]\"\nsystem_context=\"Current tenant: acme-corp\"\n</code></pre></p> <p>\u274c Bad: Mixing static and dynamic <pre><code>system_prompt=\"You are a K8s expert for tenant: acme-corp. [guidelines]\"\n</code></pre></p>"},{"location":"guides/prompt-caching/#2-make-static-content-detailed","title":"2. Make Static Content Detailed","text":"<p>The more static content you cache, the bigger the savings:</p> <p>\u2705 Good: Detailed instructions (1500+ tokens) <pre><code>system_prompt=\"\"\"\nYou are a Kubernetes expert assistant.\n\nGuidelines:\n- Always verify namespace before operations\n- Explain commands clearly\n- Ask for confirmation on destructive operations\n- Follow kubectl best practices\n- Provide helpful error messages\n\n[More detailed guidelines...]\n\"\"\"\n</code></pre></p> <p>\u274c Bad: Brief instructions (50 tokens) <pre><code>system_prompt=\"You are a helpful Kubernetes assistant.\"\n</code></pre></p>"},{"location":"guides/prompt-caching/#3-use-callable-for-dynamic-context","title":"3. Use Callable for Dynamic Context","text":"<p>For runtime data, use a lambda or function:</p> <pre><code>system_context=lambda ctx: f\"\"\"\nTenant: {ctx.get('tenant_name')}\nNamespace: {ctx.get('k8s_namespace')}\nUser: {ctx.get('user_email')}\n\"\"\"\n</code></pre>"},{"location":"guides/prompt-caching/#monitoring","title":"Monitoring","text":""},{"location":"guides/prompt-caching/#cache-performance-logs","title":"Cache Performance Logs","text":"<p>DCAF logs cache performance when available:</p> <pre><code>INFO: \u2705 Cache HIT: 950 tokens reused (~90% cost reduction)\nINFO: \ud83d\udcdd Cache MISS: 950 tokens cached for next request (cache created)\n</code></pre>"},{"location":"guides/prompt-caching/#first-request-is-always-a-miss","title":"First Request is Always a MISS","text":"<p>The first request creates the cache (MISS). Subsequent requests within 5 minutes are HITs:</p> <pre><code>Request 1: MISS (creates cache)  \u2192 Full cost\nRequest 2: HIT  (uses cache)     \u2192 10% cost\nRequest 3: HIT  (uses cache)     \u2192 10% cost\n...\nRequest N: MISS (cache expired)  \u2192 Full cost\n</code></pre>"},{"location":"guides/prompt-caching/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/prompt-caching/#no-cache-metrics-in-logs","title":"No Cache Metrics in Logs","text":"<p>Symptom: Caching enabled but no \"Cache HIT/MISS\" logs</p> <p>Possible causes: 1. System prompt below minimum token threshold 2. Model doesn't support caching 3. Bedrock API change</p> <p>Solution: Check logs for warnings about token threshold</p>"},{"location":"guides/prompt-caching/#caching-not-enabled","title":"Caching Not Enabled","text":"<p>Symptom: No cache-related logs at all</p> <p>Checklist: - [ ] <code>model_config={\"cache_system_prompt\": True}</code> set? - [ ] Using Bedrock provider (not OpenAI)? - [ ] Using supported model (Claude 3.5/3.7)?</p>"},{"location":"guides/prompt-caching/#cost-comparison","title":"Cost Comparison","text":""},{"location":"guides/prompt-caching/#example-scenario","title":"Example Scenario","text":"<ul> <li>Static prompt: 1500 tokens</li> <li>Dynamic context: 100 tokens</li> <li>100 requests</li> </ul> <p>Without caching: - Per request: 1600 tokens - Total: 160,000 tokens - Cost: ~$0.48</p> <p>With caching: - First request: 1600 tokens (MISS) - Next 99 requests: 100 tokens each (HIT) - Total: 11,500 tokens - Cost: ~$0.035</p> <p>Savings: ~93% \ud83d\udcb0</p>"},{"location":"guides/prompt-caching/#supported-models","title":"Supported Models","text":"<p>Prompt caching is supported on: - <code>anthropic.claude-3-7-sonnet-20250219-v1:0</code> - <code>anthropic.claude-3-5-sonnet-20241022-v2:0</code> - <code>anthropic.claude-3-5-haiku-20241022-v1:0</code></p>"},{"location":"guides/prompt-caching/#when-not-to-use-caching","title":"When NOT to Use Caching","text":"<p>\u274c Don't use caching when: - System prompt changes frequently - System prompt is very short (&lt;1024 tokens) - Low request volume (cache expires between requests) - Using non-Bedrock providers</p> <p>\u2705 DO use caching when: - Long, static system prompts - High request volume (multiple requests per 5 minutes) - Multi-tenant scenarios (static instructions, dynamic tenant context)</p>"},{"location":"guides/prompt-caching/#future-plans","title":"Future Plans","text":"<p>This is a temporary implementation. Once Agno adds native prompt caching support, we'll migrate to their implementation and remove the custom code.</p>"},{"location":"guides/prompt-caching/#related-documentation","title":"Related Documentation","text":"<ul> <li>Agent API Reference</li> <li>Creating Custom Agents</li> <li>AWS Bedrock Guide</li> </ul>"},{"location":"guides/response-conversion/","title":"Response Conversion Guide","text":"<p>Converting Core Responses to Schema Messages</p>"},{"location":"guides/response-conversion/#overview","title":"Overview","text":"<p>DCAF provides a bridge between the core's internal <code>AgentResponse</code> and the schema's <code>AgentMessage</code> (wire format). This allows you to convert internal responses to validated Pydantic models ready for JSON serialization.</p>"},{"location":"guides/response-conversion/#two-conversion-methods","title":"Two Conversion Methods","text":""},{"location":"guides/response-conversion/#method-1-to_helpdesk_message-returns-dict","title":"Method 1: <code>to_helpdesk_message()</code> - Returns Dict","text":"<p>Use when: You need a plain dictionary for immediate serialization.</p> <pre><code>from dcaf.core.application.dto import AgentResponse, DataDTO\n\nresponse = AgentResponse(\n    conversation_id=\"conv-123\",\n    text=\"Hello, how can I help?\",\n    data=DataDTO(),\n)\n\n# Convert to dict\nmessage_dict = response.to_helpdesk_message()\n# Returns: {\"role\": \"assistant\", \"content\": \"Hello...\", \"data\": {...}, \"meta_data\": {}}\n</code></pre> <p>Pros: - Simple and direct - No validation overhead - Lightweight</p> <p>Cons: - No type safety - No validation - Manual JSON serialization</p>"},{"location":"guides/response-conversion/#method-2-to_agent_message-returns-pydantic-model-new","title":"Method 2: <code>to_agent_message()</code> - Returns Pydantic Model \u2728 NEW","text":"<p>Use when: You want validated, type-safe schema models.</p> <pre><code>from dcaf.core.application.dto import AgentResponse, DataDTO\n\nresponse = AgentResponse(\n    conversation_id=\"conv-123\",\n    text=\"Hello, how can I help?\",\n    data=DataDTO(),\n)\n\n# Convert to AgentMessage (Pydantic)\nagent_message = response.to_agent_message(\n    agent_name=\"my-agent\",\n    agent_id=\"agent-001\",\n)\n\n# Now you have a validated Pydantic model\nprint(agent_message.role)  # \"assistant\"\nprint(agent_message.timestamp)  # datetime object\n\n# Serialize to JSON\njson_data = agent_message.model_dump()\n</code></pre> <p>Pros: - \u2705 Type-safe (Pydantic model) - \u2705 Validated (catches errors early) - \u2705 Rich metadata (timestamp, agent info) - \u2705 Can use Pydantic features (JSON schema, serialization options)</p> <p>Cons: - Slightly more overhead (validation)</p>"},{"location":"guides/response-conversion/#factory-method-on-schema","title":"Factory Method on Schema","text":"<p>You can also create an <code>AgentMessage</code> directly from any response:</p> <pre><code>from dcaf.schemas.messages import AgentMessage\n\n# Works with any core response\nagent_message = AgentMessage.from_agent_response(\n    response=core_response,\n    agent_name=\"k8s-agent\",\n    agent_id=\"agent-123\",\n    include_timestamp=True,  # Optional\n)\n</code></pre>"},{"location":"guides/response-conversion/#complete-example","title":"Complete Example","text":"<pre><code>from dcaf.core.application.dto import (\n    AgentResponse, \n    DataDTO, \n    ToolCallDTO,\n    ExecutedToolCall,\n)\nfrom dcaf.schemas.messages import AgentMessage\n\n# 1. Create a core response (from AgentService)\ntool_call = ToolCallDTO(\n    id=\"tc_789\",\n    name=\"delete_pod\",\n    input={\"name\": \"nginx\"},\n    tool_description=\"Delete a Kubernetes pod\",\n    execute=False,\n    requires_approval=True,\n)\n\nexecuted_tc = ExecutedToolCall(\n    id=\"tc_456\",\n    name=\"list_pods\",\n    input={\"namespace\": \"default\"},\n    output=\"3 pods found: nginx, redis, api\",\n)\n\ndata = DataDTO(\n    tool_calls=[tool_call],\n    executed_tool_calls=[executed_tc],\n)\n\nresponse = AgentResponse(\n    conversation_id=\"conv-789\",\n    text=\"I found 3 pods. Should I delete nginx?\",\n    data=data,\n    has_pending_approvals=True,\n    metadata={\"model\": \"claude-3-sonnet\"},\n)\n\n# 2. Convert to AgentMessage\nagent_message = response.to_agent_message(\n    agent_name=\"k8s-assistant\",\n    agent_id=\"agent-001\",\n)\n\n# 3. Access Pydantic features\nprint(f\"Role: {agent_message.role}\")  # \"assistant\"\nprint(f\"Timestamp: {agent_message.timestamp}\")  # datetime\nprint(f\"Agent: {agent_message.agent.name}\")  # \"k8s-assistant\"\nprint(f\"Tool calls: {len(agent_message.data.tool_calls)}\")  # 1\nprint(f\"Executed: {len(agent_message.data.executed_tool_calls)}\")  # 1\n\n# 4. Serialize to JSON\njson_data = agent_message.model_dump()\n\n# 5. Validate round-trip\nvalidated = AgentMessage(**json_data)\nassert validated.content == agent_message.content\n</code></pre>"},{"location":"guides/response-conversion/#when-to-use-which-method","title":"When to Use Which Method","text":"Scenario Use Reason HTTP API responses <code>to_agent_message()</code> Pydantic validation, JSON schema WebSocket streaming <code>to_helpdesk_message()</code> Lower overhead Logging/debugging <code>to_agent_message()</code> Rich metadata Testing <code>to_agent_message()</code> Type safety Simple dict needed <code>to_helpdesk_message()</code> Direct and fast Multi-agent systems <code>to_agent_message()</code> Agent identity tracking"},{"location":"guides/response-conversion/#conversion-path","title":"Conversion Path","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Internal Core Layer                       \u2502\n\u2502                                                              \u2502\n\u2502  AgentResponse (dto/responses.py)                           \u2502\n\u2502  - conversation_id: str                                      \u2502\n\u2502  - text: str                                                 \u2502\n\u2502  - data: DataDTO                                             \u2502\n\u2502  - has_pending_approvals: bool                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n                   \u2502 .to_agent_message(agent_name, agent_id)\n                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Schema Layer (Wire Format)                \u2502\n\u2502                                                              \u2502\n\u2502  AgentMessage (schemas/messages.py)                         \u2502\n\u2502  - role: \"assistant\"                                        \u2502\n\u2502  - content: str                                              \u2502\n\u2502  - data: Data (Pydantic)                                     \u2502\n\u2502  - timestamp: datetime                                       \u2502\n\u2502  - agent: Agent (name, id)                                   \u2502\n\u2502  - meta_data: dict                                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n                   \u2502 .model_dump()\n                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    JSON (HelpDesk Protocol)                  \u2502\n\u2502                                                              \u2502\n\u2502  {                                                           \u2502\n\u2502    \"role\": \"assistant\",                                     \u2502\n\u2502    \"content\": \"...\",                                        \u2502\n\u2502    \"data\": {                                                \u2502\n\u2502      \"tool_calls\": [...],                                   \u2502\n\u2502      \"executed_tool_calls\": [...]                           \u2502\n\u2502    },                                                        \u2502\n\u2502    \"timestamp\": \"2026-01-08T...\",                           \u2502\n\u2502    \"agent\": {\"name\": \"k8s-agent\", \"id\": \"agent-001\"}        \u2502\n\u2502  }                                                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/response-conversion/#benefits-of-the-new-conversion","title":"Benefits of the New Conversion","text":""},{"location":"guides/response-conversion/#before-dict-based","title":"Before (dict-based)","text":"<pre><code># Had to manually build dict\nmsg = {\n    \"role\": \"assistant\",\n    \"content\": response.text,\n    \"data\": response.data.to_dict(),\n    \"meta_data\": response.metadata,\n    # Missing: timestamp, agent info, validation\n}\n</code></pre>"},{"location":"guides/response-conversion/#after-pydantic-based","title":"After (Pydantic-based)","text":"<pre><code># Rich, validated model\nmsg = response.to_agent_message(agent_name=\"my-agent\")\n# Includes: timestamp, agent info, full validation\njson_data = msg.model_dump()  # Type-safe JSON\n</code></pre>"},{"location":"guides/response-conversion/#advanced-custom-agent-identity","title":"Advanced: Custom Agent Identity","text":"<pre><code># Track which agent generated the response\nagent_message = response.to_agent_message(\n    agent_name=\"k8s-specialist\",\n    agent_id=\"agent-k8s-001\",\n)\n\n# Later, identify the agent\nif agent_message.agent:\n    print(f\"Response from: {agent_message.agent.name}\")\n    print(f\"Agent ID: {agent_message.agent.id}\")\n</code></pre>"},{"location":"guides/response-conversion/#testing","title":"Testing","text":"<pre><code>def test_response_conversion():\n    \"\"\"Test that conversion preserves data.\"\"\"\n    # Create response\n    response = AgentResponse(\n        conversation_id=\"test\",\n        text=\"Hello\",\n        data=DataDTO(),\n    )\n\n    # Convert\n    msg = response.to_agent_message()\n\n    # Validate\n    assert msg.role == \"assistant\"\n    assert msg.content == \"Hello\"\n    assert msg.timestamp is not None\n\n    # Round-trip\n    json_data = msg.model_dump()\n    msg2 = AgentMessage(**json_data)\n    assert msg2.content == msg.content\n</code></pre>"},{"location":"guides/response-conversion/#summary","title":"Summary","text":"<p>\u2705 Two conversion methods available: 1. <code>to_helpdesk_message()</code> - Returns dict (lightweight) 2. <code>to_agent_message()</code> - Returns Pydantic model (rich, validated)</p> <p>\u2705 Factory method on schema: - <code>AgentMessage.from_agent_response()</code> - Create from any response</p> <p>\u2705 Benefits: - Type safety with Pydantic - Automatic timestamp tracking - Agent identity tracking - Full validation - JSON schema generation</p> <p>\u2705 When to use: - Use <code>to_agent_message()</code> for HTTP APIs, logging, testing - Use <code>to_helpdesk_message()</code> for simple, fast dict conversion</p>"},{"location":"guides/session-management/","title":"Session Management","text":"<p>Sessions allow you to persist state across conversation turns, enabling multi-step workflows where tools can share data.</p>"},{"location":"guides/session-management/#overview","title":"Overview","text":"<p>A Session is a key-value store that:</p> <ul> <li>Persists across turns - Data survives between user messages</li> <li>Travels with the protocol - Automatically serialized in responses</li> <li>Supports typed models - Store Pydantic models and dataclasses with auto-serialization</li> <li>Provides simple API - Dict-like access with type hints</li> <li>Available everywhere - In tools, interceptors, custom agent functions, and <code>agent.run()</code></li> </ul>"},{"location":"guides/session-management/#basic-usage","title":"Basic Usage","text":""},{"location":"guides/session-management/#creating-and-using-sessions","title":"Creating and Using Sessions","text":"<pre><code>from dcaf.core import Session\n\nsession = Session()\n\n# Set values\nsession.set(\"user_id\", \"12345\")\nsession.set(\"preferences\", {\"theme\": \"dark\", \"language\": \"en\"})\n\n# Get values\nuser_id = session.get(\"user_id\")  # \"12345\"\nprefs = session.get(\"preferences\")  # {\"theme\": \"dark\", ...}\n\n# Get with default\ncount = session.get(\"count\", 0)  # Returns 0 if not set\n\n# Check existence\nif session.has(\"user_id\"):\n    print(\"User is logged in\")\n\n# Delete values\nsession.delete(\"user_id\")\n</code></pre>"},{"location":"guides/session-management/#dict-like-access","title":"Dict-Like Access","text":"<p>Session supports familiar dictionary-style access:</p> <pre><code># Set/get with brackets\nsession[\"key\"] = \"value\"\nvalue = session[\"key\"]\n\n# Iteration\nfor key in session.keys():\n    print(f\"{key}: {session[key]}\")\n\n# Get all items\nfor key, value in session.items():\n    print(f\"{key}: {value}\")\n</code></pre>"},{"location":"guides/session-management/#bulk-operations","title":"Bulk Operations","text":"<pre><code># Update multiple values at once\nsession.update({\n    \"cart\": [],\n    \"user_id\": \"12345\",\n    \"step\": 1,\n})\n\n# Clear all data\nsession.clear()\n\n# Convert to dict\ndata = session.to_dict()\n</code></pre>"},{"location":"guides/session-management/#typed-storage","title":"Typed Storage","text":"<p>Session supports automatic serialization and deserialization of Pydantic models and dataclasses. This gives you type safety, IDE autocomplete, and cleaner code.</p>"},{"location":"guides/session-management/#pydantic-models","title":"Pydantic Models","text":"<pre><code>from pydantic import BaseModel, Field\nfrom dcaf.core import Session\n\nclass UserPreferences(BaseModel):\n    theme: str = \"light\"\n    language: str = \"en\"\n    notifications: bool = True\n\nsession = Session()\n\n# Store a Pydantic model (auto-serializes to dict)\nprefs = UserPreferences(theme=\"dark\", notifications=False)\nsession.set(\"prefs\", prefs)\n\n# What's actually stored:\n# {\"theme\": \"dark\", \"language\": \"en\", \"notifications\": False}\n\n# Retrieve as typed model (auto-deserializes)\nloaded_prefs = session.get(\"prefs\", as_type=UserPreferences)\nprint(loaded_prefs.theme)  # \"dark\"\nprint(type(loaded_prefs))  # &lt;class 'UserPreferences'&gt;\n\n# Retrieve without type (returns raw dict)\nraw = session.get(\"prefs\")\nprint(raw)  # {\"theme\": \"dark\", \"language\": \"en\", \"notifications\": False}\n</code></pre>"},{"location":"guides/session-management/#dataclasses","title":"Dataclasses","text":"<pre><code>from dataclasses import dataclass\nfrom dcaf.core import Session\n\n@dataclass\nclass Config:\n    debug: bool = False\n    max_retries: int = 3\n    timeout: float = 30.0\n\nsession = Session()\n\n# Store a dataclass (auto-serializes via asdict())\nsession.set(\"config\", Config(debug=True, max_retries=5))\n\n# Retrieve as typed\nconfig = session.get(\"config\", as_type=Config)\nprint(config.debug)  # True\nprint(config.max_retries)  # 5\n</code></pre>"},{"location":"guides/session-management/#nested-models","title":"Nested Models","text":"<p>Complex nested structures work seamlessly:</p> <pre><code>from pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass CartItem(BaseModel):\n    name: str\n    quantity: int\n    price: float\n\nclass ShoppingCart(BaseModel):\n    items: list[CartItem] = Field(default_factory=list)\n    discount_code: Optional[str] = None\n\n    @property\n    def total(self) -&gt; float:\n        return sum(item.price * item.quantity for item in self.items)\n\n# Store complex model\ncart = ShoppingCart()\ncart.items.append(CartItem(name=\"Widget\", quantity=2, price=9.99))\ncart.items.append(CartItem(name=\"Gadget\", quantity=1, price=24.99))\nsession.set(\"cart\", cart)\n\n# Retrieve with full type hierarchy intact\nloaded_cart = session.get(\"cart\", as_type=ShoppingCart)\nprint(loaded_cart.total)  # 44.97\nprint(loaded_cart.items[0].name)  # \"Widget\"\n</code></pre>"},{"location":"guides/session-management/#default-values-with-types","title":"Default Values with Types","text":"<pre><code># Returns None if key doesn't exist\ncart = session.get(\"cart\", as_type=ShoppingCart)  # None if not found\n\n# Provide a default instance\ncart = session.get(\"cart\", ShoppingCart(), as_type=ShoppingCart)  # Never None\n</code></pre>"},{"location":"guides/session-management/#using-session-in-tools","title":"Using Session in Tools","text":"<p>Tools can declare a <code>Session</code> parameter that DCAF automatically injects. The parameter name must be exactly <code>session</code> with type <code>Session</code>.</p>"},{"location":"guides/session-management/#basic-example","title":"Basic Example","text":"<pre><code>from dcaf.core import Session\nfrom dcaf.tools import tool\n\n@tool(description=\"Remember a value\")\ndef remember(key: str, value: str, session: Session) -&gt; str:\n    \"\"\"Store a value in session.\"\"\"\n    session.set(key, value)\n    return f\"Remembered {key}={value}\"\n\n@tool(description=\"Recall a value\")\ndef recall(key: str, session: Session) -&gt; str:\n    \"\"\"Retrieve a value from session.\"\"\"\n    value = session.get(key)\n    if value is None:\n        return f\"I don't remember '{key}'\"\n    return f\"{key} is '{value}'\"\n</code></pre>"},{"location":"guides/session-management/#shopping-cart-example","title":"Shopping Cart Example","text":"<pre><code>from dcaf.core import Session\nfrom dcaf.tools import tool\n\n@tool(description=\"Add item to shopping cart\")\ndef add_to_cart(item: str, quantity: int, session: Session) -&gt; str:\n    \"\"\"Add an item to the user's cart.\"\"\"\n    cart = session.get(\"cart\", [])\n    cart.append({\"item\": item, \"quantity\": quantity})\n    session.set(\"cart\", cart)\n\n    total_items = sum(i[\"quantity\"] for i in cart)\n    return f\"Added {quantity}x {item}. Cart now has {total_items} items.\"\n\n@tool(description=\"View shopping cart contents\")\ndef view_cart(session: Session) -&gt; str:\n    \"\"\"Show what's in the cart.\"\"\"\n    cart = session.get(\"cart\", [])\n\n    if not cart:\n        return \"Your cart is empty.\"\n\n    lines = [\"Your cart contains:\"]\n    for item in cart:\n        lines.append(f\"  - {item['quantity']}x {item['item']}\")\n\n    total = sum(i[\"quantity\"] for i in cart)\n    lines.append(f\"Total: {total} items\")\n    return \"\\n\".join(lines)\n\n@tool(description=\"Clear the shopping cart\")\ndef clear_cart(session: Session) -&gt; str:\n    \"\"\"Remove all items from the cart.\"\"\"\n    session.delete(\"cart\")\n    return \"Cart cleared.\"\n\n@tool(description=\"Checkout and complete purchase\")\ndef checkout(session: Session) -&gt; str:\n    \"\"\"Complete the purchase.\"\"\"\n    cart = session.get(\"cart\", [])\n\n    if not cart:\n        return \"Cannot checkout - cart is empty.\"\n\n    total_items = sum(i[\"quantity\"] for i in cart)\n    session.delete(\"cart\")  # Clear after checkout\n\n    return f\"\u2705 Order placed! {total_items} items will be shipped.\"\n</code></pre>"},{"location":"guides/session-management/#multi-step-workflow-example","title":"Multi-Step Workflow Example","text":"<pre><code>from dcaf.core import Session\nfrom dcaf.tools import tool\nfrom typing import Literal\n\n@tool(description=\"Start a deployment workflow\")\ndef start_deployment(\n    environment: Literal[\"staging\", \"production\"],\n    session: Session\n) -&gt; str:\n    \"\"\"Initialize a deployment workflow.\"\"\"\n    session.set(\"deployment\", {\n        \"environment\": environment,\n        \"step\": \"started\",\n        \"services\": [],\n    })\n    return f\"Deployment workflow started for {environment}. Add services to deploy.\"\n\n@tool(description=\"Add a service to the deployment\")\ndef add_service(service_name: str, version: str, session: Session) -&gt; str:\n    \"\"\"Add a service to the pending deployment.\"\"\"\n    deployment = session.get(\"deployment\")\n\n    if not deployment:\n        return \"No deployment in progress. Run start_deployment first.\"\n\n    deployment[\"services\"].append({\n        \"name\": service_name,\n        \"version\": version,\n    })\n    deployment[\"step\"] = \"services_added\"\n    session.set(\"deployment\", deployment)\n\n    return f\"Added {service_name}:{version} to deployment. {len(deployment['services'])} services total.\"\n\n@tool(requires_approval=True, description=\"Execute the deployment\")\ndef execute_deployment(session: Session) -&gt; str:\n    \"\"\"Execute the pending deployment (requires approval).\"\"\"\n    deployment = session.get(\"deployment\")\n\n    if not deployment:\n        return \"No deployment in progress.\"\n\n    if not deployment.get(\"services\"):\n        return \"No services to deploy. Add services first.\"\n\n    env = deployment[\"environment\"]\n    services = deployment[\"services\"]\n\n    # Simulate deployment\n    results = []\n    for svc in services:\n        results.append(f\"\u2705 Deployed {svc['name']}:{svc['version']} to {env}\")\n\n    # Clear deployment state\n    session.delete(\"deployment\")\n\n    return \"\\n\".join(results)\n</code></pre>"},{"location":"guides/session-management/#using-session-with-agentrun","title":"Using Session with Agent.run()","text":"<p>You can pass session data directly to <code>agent.run()</code> and <code>agent.chat()</code>:</p> <pre><code>from dcaf.core import Agent, Session\n\nagent = Agent(tools=[...])\n\n# Pass session as a dict\nresponse = agent.run(\n    messages=[{\"role\": \"user\", \"content\": \"Continue the wizard\"}],\n    session={\"wizard_step\": 2, \"user_name\": \"Alice\"},\n)\n\n# Access updated session from response\nprint(response.session)  # {\"wizard_step\": 3, \"user_name\": \"Alice\", ...}\n\n# Pass session to next request\nnext_response = agent.run(\n    messages=[{\"role\": \"user\", \"content\": \"Next step\"}],\n    session=response.session,\n)\n</code></pre> <p>You can also pass a <code>Session</code> instance:</p> <pre><code>from dcaf.core import Agent, Session\n\nsession = Session()\nsession.set(\"user_id\", \"12345\")\n\nresponse = agent.run(messages=[...], session=session)\n\n# Session changes are in response\nprint(response.session)\n</code></pre>"},{"location":"guides/session-management/#using-session-in-custom-agent-functions","title":"Using Session in Custom Agent Functions","text":"<p>Custom agent functions receive session as an optional third parameter:</p> <pre><code>from dcaf.core import serve, Session\nfrom dcaf.core.primitives import AgentResult\n\ndef my_agent(messages: list, context: dict, session: Session) -&gt; AgentResult:\n    \"\"\"Custom agent with session access.\"\"\"\n    # Read from session\n    call_count = session.get(\"call_count\", 0)\n\n    # Modify session\n    session.set(\"call_count\", call_count + 1)\n    session.set(\"last_message\", messages[-1][\"content\"])\n\n    # Return result with session data\n    return AgentResult(\n        text=f\"This is call #{call_count + 1}\",\n        session=session.to_dict(),  # Include updated session in response\n    )\n\nserve(my_agent)\n</code></pre> <p>Backward Compatibility: Functions without a session parameter still work:</p> <pre><code># Old style (still supported)\ndef my_agent(messages: list, context: dict) -&gt; AgentResult:\n    return AgentResult(text=\"Hello!\")\n\n# New style with session\ndef my_agent(messages: list, context: dict, session: Session) -&gt; AgentResult:\n    return AgentResult(text=\"Hello!\", session=session.to_dict())\n</code></pre>"},{"location":"guides/session-management/#using-session-in-interceptors","title":"Using Session in Interceptors","text":"<p>Request and response interceptors have access to session:</p>"},{"location":"guides/session-management/#request-interceptor","title":"Request Interceptor","text":"<pre><code>from dcaf.core import Agent, LLMRequest\n\ndef add_user_context(request: LLMRequest) -&gt; LLMRequest:\n    \"\"\"Add user-specific context from session.\"\"\"\n    # Access session data\n    user_prefs = request.session.get(\"user_preferences\", {})\n    user_name = request.session.get(\"user_name\", \"User\")\n\n    # Add context to system prompt\n    request.add_system_context(f\"User: {user_name}\")\n    if user_prefs.get(\"verbose\"):\n        request.add_system_context(\"User prefers detailed explanations.\")\n\n    # Track request count\n    count = request.session.get(\"request_count\", 0)\n    request.session.set(\"request_count\", count + 1)\n\n    return request\n\nagent = Agent(\n    tools=[...],\n    request_interceptors=add_user_context,\n)\n</code></pre>"},{"location":"guides/session-management/#response-interceptor","title":"Response Interceptor","text":"<pre><code>from dcaf.core import Agent, LLMResponse\n\ndef track_response_metrics(response: LLMResponse) -&gt; LLMResponse:\n    \"\"\"Track response metrics in session.\"\"\"\n    # Update session with response info\n    response.session.set(\"last_response_length\", len(response.text))\n    response.session.set(\"had_tool_calls\", response.has_tool_calls())\n\n    # Accumulate total tokens if available\n    if response.usage:\n        total = response.session.get(\"total_tokens\", 0)\n        total += response.usage.get(\"output_tokens\", 0)\n        response.session.set(\"total_tokens\", total)\n\n    return response\n\nagent = Agent(\n    tools=[...],\n    response_interceptors=track_response_metrics,\n)\n</code></pre>"},{"location":"guides/session-management/#protocol-integration","title":"Protocol Integration","text":"<p>Session data is automatically included in the HelpDesk protocol's <code>data.session</code> field.</p>"},{"location":"guides/session-management/#response-format","title":"Response Format","text":"<p>When your agent responds, session data is included:</p> <pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"Added 2x Widget to cart.\",\n  \"data\": {\n    \"session\": {\n      \"cart\": [\n        {\"item\": \"Widget\", \"quantity\": 2}\n      ],\n      \"user_preference\": \"dark_mode\"\n    },\n    \"tool_calls\": [],\n    \"executed_tool_calls\": [...]\n  }\n}\n</code></pre>"},{"location":"guides/session-management/#request-format","title":"Request Format","text":"<p>The HelpDesk sends session data back on subsequent requests:</p> <pre><code>{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"Add another widget\",\n      \"data\": {\n        \"session\": {\n          \"cart\": [\n            {\"item\": \"Widget\", \"quantity\": 2}\n          ],\n          \"user_preference\": \"dark_mode\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"guides/session-management/#session-lifecycle","title":"Session Lifecycle","text":"<pre><code>Turn 1:\n  User: \"Add 2 widgets to cart\"\n  Tool: add_to_cart(\"Widget\", 2, session)\n  Session After: {\"cart\": [{\"item\": \"Widget\", \"quantity\": 2}]}\n  Response: \"Added 2x Widget. Cart has 2 items.\"\n\nTurn 2:\n  Session Before: {\"cart\": [{\"item\": \"Widget\", \"quantity\": 2}]}\n  User: \"Add 3 gadgets\"\n  Tool: add_to_cart(\"Gadget\", 3, session)\n  Session After: {\"cart\": [..., {\"item\": \"Gadget\", \"quantity\": 3}]}\n  Response: \"Added 3x Gadget. Cart has 5 items.\"\n\nTurn 3:\n  Session Before: {\"cart\": [{...}, {...}]}\n  User: \"Checkout\"\n  Tool: checkout(session)\n  Session After: {}  \u2190 Cleared\n  Response: \"Order placed! 5 items shipped.\"\n\nTurn 4:\n  Session Before: {}\n  User: \"What's in my cart?\"\n  Tool: view_cart(session)\n  Response: \"Your cart is empty.\"\n</code></pre>"},{"location":"guides/session-management/#session-api-reference","title":"Session API Reference","text":""},{"location":"guides/session-management/#session-class","title":"<code>Session</code> Class","text":"<pre><code>from dcaf.core import Session\n</code></pre>"},{"location":"guides/session-management/#methods","title":"Methods","text":"Method Description <code>get(key, default=None, *, as_type=None)</code> Get a value, optionally deserializing to <code>as_type</code> <code>set(key, value)</code> Set a value (auto-serializes Pydantic/dataclass) <code>delete(key)</code> Delete a value <code>has(key)</code> Check if key exists <code>keys()</code> Get all keys <code>items()</code> Get all key-value pairs (raw data) <code>update(dict)</code> Update multiple values (auto-serializes) <code>clear()</code> Remove all values <code>to_dict()</code> Convert to plain dict"},{"location":"guides/session-management/#the-as_type-parameter","title":"The <code>as_type</code> Parameter","text":"<p>The <code>get()</code> method's <code>as_type</code> parameter enables typed retrieval:</p> <pre><code>from pydantic import BaseModel\n\nclass UserPrefs(BaseModel):\n    theme: str = \"light\"\n\n# Store a model\nsession.set(\"prefs\", UserPrefs(theme=\"dark\"))\n\n# Retrieve as typed model\nprefs = session.get(\"prefs\", as_type=UserPrefs)  # UserPrefs instance\nprint(prefs.theme)  # \"dark\"\n\n# Retrieve without type (raw dict)\nraw = session.get(\"prefs\")  # {\"theme\": \"dark\"}\n\n# With default value\nprefs = session.get(\"prefs\", UserPrefs(), as_type=UserPrefs)  # Never None\n</code></pre> <p>Supported Types: - Pydantic models (v2) - via <code>model_validate()</code> - Dataclasses - via constructor - Primitives - returned as-is</p>"},{"location":"guides/session-management/#class-methods","title":"Class Methods","text":"Method Description <code>Session.from_dict(data)</code> Create session from dict"},{"location":"guides/session-management/#properties","title":"Properties","text":"Property Description <code>is_modified</code> True if session was changed since creation <code>is_empty</code> True if session has no data"},{"location":"guides/session-management/#best-practices","title":"Best Practices","text":""},{"location":"guides/session-management/#1-use-meaningful-keys","title":"1. Use Meaningful Keys","text":"<pre><code># Good - clear, namespaced\nsession.set(\"deployment_state\", {...})\nsession.set(\"user_preferences\", {...})\n\n# Bad - ambiguous\nsession.set(\"state\", {...})\nsession.set(\"data\", {...})\n</code></pre>"},{"location":"guides/session-management/#2-clean-up-when-done","title":"2. Clean Up When Done","text":"<pre><code>@tool(description=\"Complete the workflow\")\ndef finish_workflow(session: Session) -&gt; str:\n    # Process the workflow...\n    result = process(session.get(\"workflow_data\"))\n\n    # Clean up session state\n    session.delete(\"workflow_data\")\n    session.delete(\"workflow_step\")\n\n    return result\n</code></pre>"},{"location":"guides/session-management/#3-use-defaults-for-safety","title":"3. Use Defaults for Safety","text":"<pre><code># Always provide defaults for optional data\ncart = session.get(\"cart\", [])  # Empty list if not set\ncount = session.get(\"attempt_count\", 0)  # Zero if not set\n\n# With typed models, provide a default instance\nprefs = session.get(\"prefs\", UserPrefs(), as_type=UserPrefs)\n</code></pre>"},{"location":"guides/session-management/#4-use-typed-models-for-complex-data","title":"4. Use Typed Models for Complex Data","text":"<pre><code># Good - typed model with validation\nclass DeploymentState(BaseModel):\n    environment: str\n    services: list[str] = []\n    step: int = 0\n\nstate = session.get(\"deployment\", as_type=DeploymentState)\nif state:\n    # IDE autocomplete, type checking, validation\n    print(state.environment)\n    print(state.step)\n\n# Less ideal - raw dicts require manual key access\nstate = session.get(\"deployment\")\nif state:\n    # No autocomplete, prone to typos\n    print(state.get(\"enviroment\"))  # Typo goes unnoticed!\n</code></pre>"},{"location":"guides/session-management/#4-keep-session-data-serializable","title":"4. Keep Session Data Serializable","text":"<p>Session data must be JSON-serializable:</p> <pre><code># Good - JSON-serializable types\nsession.set(\"items\", [\"a\", \"b\", \"c\"])\nsession.set(\"config\", {\"key\": \"value\"})\nsession.set(\"count\", 42)\n\n# Bad - non-serializable types\nsession.set(\"connection\", db_connection)  # Will fail\nsession.set(\"callback\", lambda x: x)  # Will fail\n</code></pre>"},{"location":"guides/session-management/#5-dont-store-sensitive-data","title":"5. Don't Store Sensitive Data","text":"<p>Session data is included in protocol messages. Avoid storing:</p> <ul> <li>Passwords or tokens</li> <li>API keys</li> <li>Personal identifiable information (PII)</li> </ul> <pre><code># Bad - sensitive data in session\nsession.set(\"api_key\", \"sk-secret-key\")\n\n# Good - store only references\nsession.set(\"user_id\", \"12345\")  # Look up details server-side\n</code></pre>"},{"location":"guides/session-management/#related-documentation","title":"Related Documentation","text":"<ul> <li>Getting Started - Session quick start</li> <li>HelpDesk Protocol - Protocol format details</li> <li>Building Tools - Complete tool guide</li> </ul>"},{"location":"guides/streaming/","title":"Streaming Guide","text":"<p>This guide covers how to use streaming responses in DCAF for real-time, incremental updates from agents.</p>"},{"location":"guides/streaming/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Stream Event Types</li> <li>Server-Side Streaming</li> <li>Client-Side Consumption</li> <li>Error Handling</li> <li>Best Practices</li> </ol>"},{"location":"guides/streaming/#overview","title":"Overview","text":"<p>DCAF supports streaming responses through the <code>/api/sendMessageStream</code> endpoint. Streaming provides:</p> <ul> <li>Real-time updates as the LLM generates tokens</li> <li>Progressive UI updates for better user experience</li> <li>Tool execution visibility before completion</li> <li>Early termination capability</li> </ul>"},{"location":"guides/streaming/#streaming-format","title":"Streaming Format","text":"<p>DCAF uses NDJSON (Newline-Delimited JSON) for streaming:</p> <pre><code>{\"type\":\"text_delta\",\"text\":\"Hello\"}\n{\"type\":\"text_delta\",\"text\":\" there!\"}\n{\"type\":\"done\",\"stop_reason\":\"end_turn\"}\n</code></pre> <p>Each line is a complete JSON object that can be parsed independently.</p>"},{"location":"guides/streaming/#stream-event-types","title":"Stream Event Types","text":"<p>DCAF supports 7 event types:</p>"},{"location":"guides/streaming/#1-text_delta","title":"1. text_delta","text":"<p>Streaming text tokens from the LLM.</p> <pre><code>{\n    \"type\": \"text_delta\",\n    \"text\": \"Hello\"\n}\n</code></pre> <p>Use: Append <code>text</code> to the displayed response.</p>"},{"location":"guides/streaming/#2-tool_calls","title":"2. tool_calls","text":"<p>Tool calls requiring user approval.</p> <pre><code>{\n    \"type\": \"tool_calls\",\n    \"tool_calls\": [\n        {\n            \"id\": \"toolu_123\",\n            \"name\": \"delete_file\",\n            \"input\": {\"path\": \"/tmp/file.txt\"},\n            \"execute\": false,\n            \"tool_description\": \"Delete a file\",\n            \"input_description\": {...}\n        }\n    ]\n}\n</code></pre> <p>Use: Display approval UI for tools.</p>"},{"location":"guides/streaming/#3-executed_tool_calls","title":"3. executed_tool_calls","text":"<p>Tools that were executed automatically.</p> <pre><code>{\n    \"type\": \"executed_tool_calls\",\n    \"executed_tool_calls\": [\n        {\n            \"id\": \"toolu_456\",\n            \"name\": \"get_status\",\n            \"input\": {\"service\": \"web-app\"},\n            \"output\": \"Service is running\"\n        }\n    ]\n}\n</code></pre> <p>Use: Display executed tool information.</p>"},{"location":"guides/streaming/#4-commands","title":"4. commands","text":"<p>Terminal commands for approval.</p> <pre><code>{\n    \"type\": \"commands\",\n    \"commands\": [\n        {\n            \"command\": \"kubectl get pods -n production\",\n            \"execute\": false,\n            \"files\": null\n        }\n    ]\n}\n</code></pre> <p>Use: Display command approval UI.</p>"},{"location":"guides/streaming/#5-executed_commands","title":"5. executed_commands","text":"<p>Commands that were executed.</p> <pre><code>{\n    \"type\": \"executed_commands\",\n    \"executed_cmds\": [\n        {\n            \"command\": \"kubectl get pods\",\n            \"output\": \"NAME        READY   STATUS\\nweb-123   1/1     Running\"\n        }\n    ]\n}\n</code></pre> <p>Use: Display command output.</p>"},{"location":"guides/streaming/#6-done","title":"6. done","text":"<p>Stream completed successfully.</p> <pre><code>{\n    \"type\": \"done\",\n    \"stop_reason\": \"end_turn\"\n}\n</code></pre> <p>Stop reasons: - <code>end_turn</code> - Normal completion - <code>tool_use</code> - Stopped for tool execution - <code>max_tokens</code> - Token limit reached</p> <p>Use: Finalize UI, enable user input.</p>"},{"location":"guides/streaming/#7-error","title":"7. error","text":"<p>Error during streaming.</p> <pre><code>{\n    \"type\": \"error\",\n    \"error\": \"Connection timeout\"\n}\n</code></pre> <p>Use: Display error message, offer retry.</p>"},{"location":"guides/streaming/#server-side-streaming","title":"Server-Side Streaming","text":""},{"location":"guides/streaming/#agent-with-streaming-support","title":"Agent with Streaming Support","text":"<p>Agents that support streaming implement <code>invoke_stream</code>:</p> <pre><code>from dcaf.schemas.events import (\n    TextDeltaEvent, \n    ToolCallsEvent,\n    ExecutedToolCallsEvent,\n    DoneEvent, \n    ErrorEvent\n)\nfrom typing import Generator\n\nclass StreamingAgent:\n    def invoke_stream(\n        self, \n        messages: dict\n    ) -&gt; Generator:\n        \"\"\"Stream response events.\"\"\"\n        try:\n            # Stream text deltas\n            for chunk in self._generate_response(messages):\n                yield TextDeltaEvent(text=chunk)\n\n            # Check for tool calls\n            if self.pending_tool_calls:\n                yield ToolCallsEvent(tool_calls=self.pending_tool_calls)\n\n            # Yield done event\n            yield DoneEvent(stop_reason=\"end_turn\")\n\n        except Exception as e:\n            yield ErrorEvent(error=str(e))\n</code></pre>"},{"location":"guides/streaming/#using-bedrockllm-streaming","title":"Using BedrockLLM Streaming","text":"<pre><code>from dcaf.llm import BedrockLLM\nfrom dcaf.schemas.events import TextDeltaEvent, DoneEvent\n\nllm = BedrockLLM()\n\ndef stream_response(messages):\n    for event in llm.invoke_stream(\n        messages=messages,\n        model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n        max_tokens=1000\n    ):\n        if \"contentBlockDelta\" in event:\n            delta = event[\"contentBlockDelta\"].get(\"delta\", {})\n            if \"text\" in delta:\n                yield TextDeltaEvent(text=delta[\"text\"])\n\n        elif \"messageStop\" in event:\n            reason = event[\"messageStop\"].get(\"stopReason\", \"end_turn\")\n            yield DoneEvent(stop_reason=reason)\n</code></pre>"},{"location":"guides/streaming/#client-side-consumption","title":"Client-Side Consumption","text":""},{"location":"guides/streaming/#python-client","title":"Python Client","text":"<pre><code>import requests\nimport json\n\ndef stream_chat(messages: list):\n    \"\"\"Stream responses from the agent.\"\"\"\n    response = requests.post(\n        \"http://localhost:8000/api/sendMessageStream\",\n        json={\"messages\": messages},\n        stream=True\n    )\n\n    accumulated_text = \"\"\n\n    for line in response.iter_lines():\n        if line:\n            event = json.loads(line.decode('utf-8'))\n            event_type = event.get(\"type\")\n\n            if event_type == \"text_delta\":\n                text = event.get(\"text\", \"\")\n                accumulated_text += text\n                print(text, end=\"\", flush=True)\n\n            elif event_type == \"tool_calls\":\n                print(\"\\n[Tool calls pending approval]\")\n                for tc in event.get(\"tool_calls\", []):\n                    print(f\"  - {tc['name']}: {tc['input']}\")\n\n            elif event_type == \"executed_tool_calls\":\n                for etc in event.get(\"executed_tool_calls\", []):\n                    print(f\"\\n[Executed: {etc['name']}]\")\n                    print(f\"  Output: {etc['output']}\")\n\n            elif event_type == \"commands\":\n                print(\"\\n[Commands pending approval]\")\n                for cmd in event.get(\"commands\", []):\n                    print(f\"  $ {cmd['command']}\")\n\n            elif event_type == \"executed_commands\":\n                for cmd in event.get(\"executed_cmds\", []):\n                    print(f\"\\n[Executed: {cmd['command']}]\")\n                    print(f\"  Output: {cmd['output']}\")\n\n            elif event_type == \"done\":\n                print(f\"\\n[Done: {event.get('stop_reason')}]\")\n                return accumulated_text\n\n            elif event_type == \"error\":\n                print(f\"\\n[Error: {event.get('error')}]\")\n                raise Exception(event.get(\"error\"))\n\n    return accumulated_text\n\n# Usage\nresult = stream_chat([\n    {\"role\": \"user\", \"content\": \"Tell me about Kubernetes\"}\n])\n</code></pre>"},{"location":"guides/streaming/#javascripttypescript-client","title":"JavaScript/TypeScript Client","text":"<pre><code>async function streamChat(messages) {\n    const response = await fetch('/api/sendMessageStream', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ messages })\n    });\n\n    const reader = response.body.getReader();\n    const decoder = new TextDecoder();\n\n    let accumulatedText = '';\n    let buffer = '';\n\n    while (true) {\n        const { value, done } = await reader.read();\n\n        if (done) break;\n\n        buffer += decoder.decode(value, { stream: true });\n\n        // Process complete lines\n        const lines = buffer.split('\\n');\n        buffer = lines.pop(); // Keep incomplete line in buffer\n\n        for (const line of lines) {\n            if (!line.trim()) continue;\n\n            try {\n                const event = JSON.parse(line);\n\n                switch (event.type) {\n                    case 'text_delta':\n                        accumulatedText += event.text;\n                        updateDisplay(event.text);\n                        break;\n\n                    case 'tool_calls':\n                        showToolApproval(event.tool_calls);\n                        break;\n\n                    case 'executed_tool_calls':\n                        showExecutedTools(event.executed_tool_calls);\n                        break;\n\n                    case 'commands':\n                        showCommandApproval(event.commands);\n                        break;\n\n                    case 'executed_commands':\n                        showExecutedCommands(event.executed_cmds);\n                        break;\n\n                    case 'done':\n                        finalize(event.stop_reason);\n                        return accumulatedText;\n\n                    case 'error':\n                        handleError(event.error);\n                        throw new Error(event.error);\n                }\n            } catch (e) {\n                console.error('Parse error:', e);\n            }\n        }\n    }\n\n    return accumulatedText;\n}\n\nfunction updateDisplay(text) {\n    const display = document.getElementById('response');\n    display.textContent += text;\n}\n\nfunction showToolApproval(toolCalls) {\n    // Render tool approval UI\n    for (const tc of toolCalls) {\n        console.log(`Tool: ${tc.name}`, tc.input);\n    }\n}\n</code></pre>"},{"location":"guides/streaming/#react-hook","title":"React Hook","text":"<pre><code>import { useState, useCallback } from 'react';\n\nfunction useStreamingChat() {\n    const [text, setText] = useState('');\n    const [isStreaming, setIsStreaming] = useState(false);\n    const [toolCalls, setToolCalls] = useState([]);\n    const [error, setError] = useState(null);\n\n    const sendMessage = useCallback(async (messages) =&gt; {\n        setText('');\n        setToolCalls([]);\n        setError(null);\n        setIsStreaming(true);\n\n        try {\n            const response = await fetch('/api/sendMessageStream', {\n                method: 'POST',\n                headers: { 'Content-Type': 'application/json' },\n                body: JSON.stringify({ messages })\n            });\n\n            const reader = response.body.getReader();\n            const decoder = new TextDecoder();\n\n            let buffer = '';\n\n            while (true) {\n                const { value, done } = await reader.read();\n\n                if (done) break;\n\n                buffer += decoder.decode(value, { stream: true });\n                const lines = buffer.split('\\n');\n                buffer = lines.pop();\n\n                for (const line of lines) {\n                    if (!line.trim()) continue;\n\n                    const event = JSON.parse(line);\n\n                    switch (event.type) {\n                        case 'text_delta':\n                            setText(prev =&gt; prev + event.text);\n                            break;\n                        case 'tool_calls':\n                            setToolCalls(event.tool_calls);\n                            break;\n                        case 'error':\n                            setError(event.error);\n                            break;\n                    }\n                }\n            }\n        } catch (e) {\n            setError(e.message);\n        } finally {\n            setIsStreaming(false);\n        }\n    }, []);\n\n    return { text, isStreaming, toolCalls, error, sendMessage };\n}\n\n// Usage in component\nfunction ChatComponent() {\n    const { text, isStreaming, toolCalls, error, sendMessage } = useStreamingChat();\n    const [input, setInput] = useState('');\n\n    const handleSubmit = () =&gt; {\n        sendMessage([{ role: 'user', content: input }]);\n        setInput('');\n    };\n\n    return (\n        &lt;div&gt;\n            &lt;div className=\"response\"&gt;\n                {text}\n                {isStreaming &amp;&amp; &lt;span className=\"cursor\"&gt;\u258c&lt;/span&gt;}\n            &lt;/div&gt;\n\n            {toolCalls.length &gt; 0 &amp;&amp; (\n                &lt;div className=\"tool-calls\"&gt;\n                    {toolCalls.map(tc =&gt; (\n                        &lt;ToolApproval key={tc.id} toolCall={tc} /&gt;\n                    ))}\n                &lt;/div&gt;\n            )}\n\n            {error &amp;&amp; &lt;div className=\"error\"&gt;{error}&lt;/div&gt;}\n\n            &lt;input\n                value={input}\n                onChange={e =&gt; setInput(e.target.value)}\n                disabled={isStreaming}\n            /&gt;\n            &lt;button onClick={handleSubmit} disabled={isStreaming}&gt;\n                Send\n            &lt;/button&gt;\n        &lt;/div&gt;\n    );\n}\n</code></pre>"},{"location":"guides/streaming/#curl","title":"cURL","text":"<pre><code># Stream response\ncurl -N -X POST http://localhost:8000/api/sendMessageStream \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a story\"}]}'\n\n# Output (each line is a separate event):\n# {\"type\":\"text_delta\",\"text\":\"Once\"}\n# {\"type\":\"text_delta\",\"text\":\" upon\"}\n# {\"type\":\"text_delta\",\"text\":\" a\"}\n# {\"type\":\"text_delta\",\"text\":\" time\"}\n# ...\n# {\"type\":\"done\",\"stop_reason\":\"end_turn\"}\n</code></pre>"},{"location":"guides/streaming/#error-handling","title":"Error Handling","text":""},{"location":"guides/streaming/#client-side-error-handling","title":"Client-Side Error Handling","text":"<pre><code>import requests\nimport json\n\ndef safe_stream_chat(messages):\n    \"\"\"Stream with comprehensive error handling.\"\"\"\n    try:\n        response = requests.post(\n            \"http://localhost:8000/api/sendMessageStream\",\n            json={\"messages\": messages},\n            stream=True,\n            timeout=60\n        )\n        response.raise_for_status()\n\n        for line in response.iter_lines():\n            if not line:\n                continue\n\n            try:\n                event = json.loads(line.decode('utf-8'))\n            except json.JSONDecodeError as e:\n                print(f\"JSON parse error: {e}\")\n                continue\n\n            event_type = event.get(\"type\")\n\n            if event_type == \"error\":\n                error_msg = event.get(\"error\", \"Unknown error\")\n                raise StreamError(error_msg)\n\n            elif event_type == \"text_delta\":\n                yield event.get(\"text\", \"\")\n\n            elif event_type == \"done\":\n                return\n\n    except requests.exceptions.Timeout:\n        raise StreamError(\"Request timed out\")\n\n    except requests.exceptions.ConnectionError:\n        raise StreamError(\"Connection failed\")\n\n    except requests.exceptions.HTTPError as e:\n        raise StreamError(f\"HTTP error: {e}\")\n\nclass StreamError(Exception):\n    pass\n\n# Usage with retry\ndef stream_with_retry(messages, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            result = \"\"\n            for chunk in safe_stream_chat(messages):\n                result += chunk\n                print(chunk, end=\"\", flush=True)\n            return result\n        except StreamError as e:\n            if attempt &lt; max_retries - 1:\n                print(f\"\\nRetrying ({attempt + 1}/{max_retries})...\")\n                time.sleep(2 ** attempt)\n            else:\n                raise\n</code></pre>"},{"location":"guides/streaming/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>def chat_with_fallback(messages):\n    \"\"\"Try streaming, fall back to regular request.\"\"\"\n    try:\n        # Try streaming first\n        result = \"\"\n        for chunk in safe_stream_chat(messages):\n            result += chunk\n            print(chunk, end=\"\", flush=True)\n        return result\n\n    except StreamError:\n        # Fall back to non-streaming\n        print(\"\\nStreaming failed, using regular request...\")\n        response = requests.post(\n            \"http://localhost:8000/api/sendMessage\",\n            json={\"messages\": messages}\n        )\n        return response.json()[\"content\"]\n</code></pre>"},{"location":"guides/streaming/#best-practices","title":"Best Practices","text":""},{"location":"guides/streaming/#1-buffer-incomplete-lines","title":"1. Buffer Incomplete Lines","text":"<p>NDJSON may arrive in chunks that don't align with line boundaries:</p> <pre><code>buffer = \"\"\n\nfor chunk in response.iter_content():\n    buffer += chunk.decode('utf-8')\n\n    while '\\n' in buffer:\n        line, buffer = buffer.split('\\n', 1)\n        if line.strip():\n            event = json.loads(line)\n            process_event(event)\n</code></pre>"},{"location":"guides/streaming/#2-handle-partial-updates","title":"2. Handle Partial Updates","text":"<p>Don't assume events arrive in a specific order:</p> <pre><code>let state = {\n    text: '',\n    toolCalls: [],\n    executedTools: [],\n    commands: [],\n    executedCommands: [],\n    done: false,\n    error: null\n};\n\nfunction processEvent(event) {\n    switch (event.type) {\n        case 'text_delta':\n            state.text += event.text;\n            break;\n        case 'tool_calls':\n            state.toolCalls.push(...event.tool_calls);\n            break;\n        case 'executed_tool_calls':\n            state.executedTools.push(...event.executed_tool_calls);\n            break;\n        case 'commands':\n            state.commands.push(...event.commands);\n            break;\n        case 'executed_commands':\n            state.executedCommands.push(...event.executed_cmds);\n            break;\n        case 'done':\n            state.done = true;\n            break;\n        case 'error':\n            state.error = event.error;\n            break;\n    }\n\n    updateUI(state);\n}\n</code></pre>"},{"location":"guides/streaming/#3-implement-timeouts","title":"3. Implement Timeouts","text":"<pre><code>import time\n\ndef stream_with_timeout(messages, timeout=60):\n    \"\"\"Stream with overall timeout.\"\"\"\n    start_time = time.time()\n\n    for chunk in safe_stream_chat(messages):\n        if time.time() - start_time &gt; timeout:\n            raise TimeoutError(\"Stream timeout exceeded\")\n        yield chunk\n</code></pre>"},{"location":"guides/streaming/#4-show-progress-indicators","title":"4. Show Progress Indicators","text":"<pre><code>function StreamingResponse({ text, isStreaming }) {\n    return (\n        &lt;div className=\"response\"&gt;\n            {text}\n            {isStreaming &amp;&amp; (\n                &lt;span className=\"streaming-indicator\"&gt;\n                    &lt;span className=\"cursor\"&gt;\u258c&lt;/span&gt;\n                    &lt;span className=\"status\"&gt;Generating...&lt;/span&gt;\n                &lt;/span&gt;\n            )}\n        &lt;/div&gt;\n    );\n}\n</code></pre>"},{"location":"guides/streaming/#5-enable-cancellation","title":"5. Enable Cancellation","text":"<pre><code>const controller = new AbortController();\n\n// Start streaming\nfetch('/api/sendMessageStream', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({ messages }),\n    signal: controller.signal\n});\n\n// Cancel if needed\ndocument.getElementById('cancel').onclick = () =&gt; {\n    controller.abort();\n};\n</code></pre>"},{"location":"guides/streaming/#6-batch-ui-updates","title":"6. Batch UI Updates","text":"<pre><code>let pendingText = '';\nlet updateScheduled = false;\n\nfunction processTextDelta(text) {\n    pendingText += text;\n\n    if (!updateScheduled) {\n        updateScheduled = true;\n        requestAnimationFrame(() =&gt; {\n            document.getElementById('response').textContent += pendingText;\n            pendingText = '';\n            updateScheduled = false;\n        });\n    }\n}\n</code></pre>"},{"location":"guides/streaming/#see-also","title":"See Also","text":"<ul> <li>Agent Server API Reference</li> <li>Schemas API Reference</li> <li>Message Protocol Guide</li> </ul>"},{"location":"guides/tracing-observability/","title":"Tracing and Observability","text":"<p>DCAF provides built-in support for distributed tracing and observability, allowing you to track requests through the entire agent execution pipeline from your application to the LLM provider.</p>"},{"location":"guides/tracing-observability/#overview","title":"Overview","text":"<p>Tracing in DCAF is built around four key identifiers that flow through the system:</p> Field Purpose Example <code>user_id</code> Identifies the user making requests <code>\"user-123\"</code> <code>session_id</code> Groups related runs into a session <code>\"session-abc\"</code> <code>run_id</code> Unique identifier for a single execution <code>\"run-xyz\"</code> <code>request_id</code> HTTP request correlation ID <code>\"req-456\"</code> <p>These identifiers are: - Passed to the LLM provider (Agno SDK) for end-to-end tracing - Included in response metadata for correlation - Available in logs throughout the execution pipeline - Compatible with OpenTelemetry and other observability platforms</p>"},{"location":"guides/tracing-observability/#quick-start","title":"Quick Start","text":""},{"location":"guides/tracing-observability/#option-1-via-agentrequest","title":"Option 1: Via AgentRequest","text":"<p>The simplest way to add tracing is through the <code>AgentRequest</code>:</p> <pre><code>from dcaf.core.application.dto import AgentRequest\n\nrequest = AgentRequest(\n    content=\"What pods are running?\",\n    tools=[kubectl_tool],\n    # Tracing fields\n    user_id=\"user-123\",\n    session_id=\"session-abc\",\n    run_id=\"run-xyz\",\n    request_id=\"req-456\",\n)\n\nresponse = await agent_service.execute(request)\n\n# Tracing IDs are returned in response metadata\nprint(response.metadata)\n# {'run_id': 'run-xyz', 'session_id': 'session-abc', 'user_id': 'user-123', 'request_id': 'req-456'}\n</code></pre>"},{"location":"guides/tracing-observability/#option-2-via-platformcontext","title":"Option 2: Via PlatformContext","text":"<p>For more control, use the <code>PlatformContext</code> value object:</p> <pre><code>from dcaf.core.domain.value_objects import PlatformContext\n\n# Create context with tracing\ncontext = PlatformContext(\n    tenant_id=\"tenant-1\",\n    tenant_name=\"acme-corp\",\n    user_id=\"user-123\",\n    session_id=\"session-abc\",\n    run_id=\"run-xyz\",\n    request_id=\"req-456\",\n)\n\n# Or add tracing to an existing context\ncontext = PlatformContext.from_dict({\"tenant_id\": \"tenant-1\"})\ncontext = context.with_tracing(\n    user_id=\"user-123\",\n    session_id=\"session-abc\",\n    run_id=\"run-xyz\",\n)\n\n# Pass as dict in request\nrequest = AgentRequest(\n    content=\"Deploy my app\",\n    context=context.to_dict(),\n    tools=[deploy_tool],\n)\n</code></pre>"},{"location":"guides/tracing-observability/#tracing-fields","title":"Tracing Fields","text":""},{"location":"guides/tracing-observability/#user_id","title":"user_id","text":"<p>Identifies the user making the request. Use this for: - User-level analytics and quotas - Audit trails showing who performed actions - Personalization and context</p> <pre><code>request = AgentRequest(\n    content=\"Delete the old pods\",\n    user_id=\"alice@company.com\",  # Or user ID from your auth system\n    tools=[kubectl_tool],\n)\n</code></pre>"},{"location":"guides/tracing-observability/#session_id","title":"session_id","text":"<p>Groups related runs into a logical session. Use this for: - Conversation continuity tracking - Session-level analytics - Grouping related agent interactions</p> <pre><code># Generate session ID at the start of a conversation\nimport uuid\nsession_id = f\"session-{uuid.uuid4()}\"\n\n# Use it for all requests in the conversation\nrequest1 = AgentRequest(content=\"What's running?\", session_id=session_id, ...)\nrequest2 = AgentRequest(content=\"Delete pod-1\", session_id=session_id, ...)\n</code></pre>"},{"location":"guides/tracing-observability/#run_id","title":"run_id","text":"<p>Unique identifier for a single agent execution. Use this for: - Correlating logs across services - Debugging specific executions - Linking to external tracing systems</p> <pre><code>import uuid\n\nrequest = AgentRequest(\n    content=\"Scale deployment to 5 replicas\",\n    run_id=f\"run-{uuid.uuid4()}\",\n    tools=[scale_tool],\n)\n</code></pre>"},{"location":"guides/tracing-observability/#request_id","title":"request_id","text":"<p>HTTP request correlation ID. Use this for: - End-to-end request tracing - Correlating with API gateway logs - Debugging request flows</p> <pre><code># Typically passed from your HTTP framework\nfrom fastapi import Request\n\n@app.post(\"/chat\")\nasync def chat(request: Request, body: ChatRequest):\n    request_id = request.headers.get(\"X-Request-ID\", str(uuid.uuid4()))\n\n    agent_request = AgentRequest(\n        content=body.message,\n        request_id=request_id,\n        tools=[...],\n    )\n</code></pre>"},{"location":"guides/tracing-observability/#how-tracing-flows-through-the-system","title":"How Tracing Flows Through the System","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   HTTP Request      \u2502  X-Request-ID, user from JWT, etc.\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   AgentRequest      \u2502  user_id, session_id, run_id, request_id\n\u2502   + PlatformContext \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   AgentService      \u2502  Logs tracing context\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   AgnoAdapter       \u2502  Passes to Agno SDK:\n\u2502                     \u2502  - run_id \u2192 agno_agent.arun(run_id=...)\n\u2502                     \u2502  - session_id \u2192 agno_agent.arun(session_id=...)\n\u2502                     \u2502  - user_id \u2192 agno_agent.arun(user_id=...)\n\u2502                     \u2502  - metadata \u2192 agno_agent.arun(metadata={...})\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Agno SDK          \u2502  Native tracing support\n\u2502   (LLM Provider)    \u2502  Integrates with observability platforms\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   AgentResponse     \u2502  metadata contains tracing IDs\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/tracing-observability/#accessing-tracing-context","title":"Accessing Tracing Context","text":""},{"location":"guides/tracing-observability/#in-response-metadata","title":"In Response Metadata","text":"<p>After execution, tracing IDs are available in the response:</p> <pre><code>response = await agent_service.execute(request)\n\n# Access tracing metadata\nrun_id = response.metadata.get(\"run_id\")\nsession_id = response.metadata.get(\"session_id\")\nuser_id = response.metadata.get(\"user_id\")\nrequest_id = response.metadata.get(\"request_id\")\ntenant_id = response.metadata.get(\"tenant_id\")\n</code></pre>"},{"location":"guides/tracing-observability/#in-platformcontext","title":"In PlatformContext","text":"<p>The <code>PlatformContext</code> provides a helper method to extract only tracing fields:</p> <pre><code>context = PlatformContext.from_dict(request.context or {})\n\n# Get only tracing fields (safe to log, no sensitive data)\ntracing = context.get_tracing_dict()\n# {'user_id': 'user-123', 'session_id': 'session-abc', ...}\n\nlogger.info(f\"Processing request\", extra=tracing)\n</code></pre>"},{"location":"guides/tracing-observability/#integration-with-agno-debug-mode","title":"Integration with Agno Debug Mode","text":"<p>DCAF automatically syncs Agno's debug logging with Python's logging level:</p> <pre><code># Enable Agno debug mode (verbose tracing)\nLOG_LEVEL=DEBUG python your_agent.py\n\n# Or set AGNO_DEBUG directly\nAGNO_DEBUG=true python your_agent.py\n</code></pre> <p>When debug mode is enabled, you'll see: - Detailed message flow logging - Tool call parameters and results - Agno SDK internal operations</p>"},{"location":"guides/tracing-observability/#integration-with-opentelemetry","title":"Integration with OpenTelemetry","text":"<p>Agno supports OpenTelemetry for distributed tracing. To enable:</p> <pre><code>pip install openinference-instrumentation-agno opentelemetry-sdk\n</code></pre> <pre><code>import openlit\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n\n# Configure OpenTelemetry\nprovider = TracerProvider()\nexporter = OTLPSpanExporter(endpoint=\"http://localhost:4318/v1/traces\")\n# ... configure processor and provider\n\n# Initialize instrumentation\nopenlit.init()\n\n# Your DCAF code will now emit traces\nresponse = await agent_service.execute(request)\n</code></pre> <p>With OpenTelemetry enabled, each agent execution creates spans that include: - The tracing IDs you provided (run_id, session_id, etc.) - Tool call durations and parameters - LLM request/response timing - Token usage metrics</p>"},{"location":"guides/tracing-observability/#logging-best-practices","title":"Logging Best Practices","text":""},{"location":"guides/tracing-observability/#structured-logging-with-tracing","title":"Structured Logging with Tracing","text":"<pre><code>import logging\nimport structlog\n\n# Configure structured logging\nstructlog.configure(\n    processors=[\n        structlog.processors.add_log_level,\n        structlog.processors.TimeStamper(fmt=\"iso\"),\n        structlog.processors.JSONRenderer(),\n    ]\n)\n\nlogger = structlog.get_logger()\n\n# Include tracing in all log entries\nasync def handle_chat(user_id: str, session_id: str, message: str):\n    run_id = f\"run-{uuid.uuid4()}\"\n\n    # Bind tracing context to logger\n    log = logger.bind(\n        user_id=user_id,\n        session_id=session_id,\n        run_id=run_id,\n    )\n\n    log.info(\"Starting agent execution\")\n\n    request = AgentRequest(\n        content=message,\n        user_id=user_id,\n        session_id=session_id,\n        run_id=run_id,\n        tools=[...],\n    )\n\n    response = await agent_service.execute(request)\n\n    log.info(\"Agent execution complete\",\n             has_pending=response.has_pending_approvals)\n\n    return response\n</code></pre>"},{"location":"guides/tracing-observability/#log-output-example","title":"Log Output Example","text":"<pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"level\": \"info\",\n  \"event\": \"Starting agent execution\",\n  \"user_id\": \"user-123\",\n  \"session_id\": \"session-abc\",\n  \"run_id\": \"run-xyz\"\n}\n{\n  \"timestamp\": \"2024-01-15T10:30:02Z\",\n  \"level\": \"info\",\n  \"event\": \"Agno: Tracing context\",\n  \"run_id\": \"run-xyz\",\n  \"session_id\": \"session-abc\",\n  \"user_id\": \"user-123\"\n}\n{\n  \"timestamp\": \"2024-01-15T10:30:05Z\",\n  \"level\": \"info\",\n  \"event\": \"Agent execution complete\",\n  \"user_id\": \"user-123\",\n  \"session_id\": \"session-abc\",\n  \"run_id\": \"run-xyz\",\n  \"has_pending\": false\n}\n</code></pre>"},{"location":"guides/tracing-observability/#environment-variables","title":"Environment Variables","text":"Variable Default Description <code>LOG_LEVEL</code> <code>INFO</code> Python log level. Set to <code>DEBUG</code> for Agno verbose mode <code>AGNO_DEBUG</code> <code>false</code> Enable Agno debug mode directly <code>AGNO_MONITOR</code> <code>false</code> Enable Agno monitoring dashboard"},{"location":"guides/tracing-observability/#see-also","title":"See Also","text":"<ul> <li>Adapters - AgnoAdapter configuration</li> <li>Environment Configuration - Environment variables</li> <li>Working with Bedrock - AWS Bedrock setup</li> </ul>"},{"location":"guides/versioning/","title":"Documentation Versioning","text":"<p>DCAF uses Mike for documentation versioning. This allows multiple versions of documentation to coexist, so users on older versions can still access relevant docs.</p>"},{"location":"guides/versioning/#how-it-works","title":"How It Works","text":"<p>Mike deploys each version to a subdirectory on GitHub Pages:</p> <pre><code>https://duplocloud.github.io/dcaf/          \u2192 Redirects to latest\nhttps://duplocloud.github.io/dcaf/latest/   \u2192 Current stable version\nhttps://duplocloud.github.io/dcaf/2.0/      \u2192 Version 2.0 docs\nhttps://duplocloud.github.io/dcaf/1.0/      \u2192 Version 1.0 docs\n</code></pre> <p>A version selector dropdown appears in the header, allowing users to switch between versions.</p>"},{"location":"guides/versioning/#commands","title":"Commands","text":""},{"location":"guides/versioning/#deploy-a-new-version","title":"Deploy a New Version","text":"<pre><code># Deploy version 1.0 as the latest\nmike deploy 1.0 latest --update-aliases\n\n# Later, deploy version 2.0 as the new latest\nmike deploy 2.0 latest --update-aliases\n</code></pre> <p>The <code>--update-aliases</code> flag moves the <code>latest</code> alias to point to the new version.</p>"},{"location":"guides/versioning/#deploy-without-changing-latest","title":"Deploy Without Changing Latest","text":"<pre><code># Deploy a patch version without making it latest\nmike deploy 1.1\n\n# Deploy a beta version\nmike deploy 2.0-beta\n</code></pre>"},{"location":"guides/versioning/#list-deployed-versions","title":"List Deployed Versions","text":"<pre><code>mike list\n</code></pre> <p>Output: <pre><code>1.0\n2.0 [latest]\n</code></pre></p>"},{"location":"guides/versioning/#set-an-alias","title":"Set an Alias","text":"<pre><code># Make 2.0 the \"stable\" alias\nmike alias 2.0 stable\n\n# Make 1.0 the \"legacy\" alias\nmike alias 1.0 legacy\n</code></pre>"},{"location":"guides/versioning/#delete-a-version","title":"Delete a Version","text":"<pre><code>mike delete 1.0-beta\n</code></pre>"},{"location":"guides/versioning/#serve-locally","title":"Serve Locally","text":"<pre><code># Preview versioned docs locally\nmike serve\n\n# Opens at http://localhost:8000\n</code></pre>"},{"location":"guides/versioning/#versioning-workflow","title":"Versioning Workflow","text":""},{"location":"guides/versioning/#initial-release","title":"Initial Release","text":"<pre><code># First time deploying docs\nmike deploy 0.1.0 latest --update-aliases --push\n</code></pre>"},{"location":"guides/versioning/#minorpatch-updates","title":"Minor/Patch Updates","text":"<p>For documentation fixes that apply to the current version:</p> <pre><code># Just rebuild and redeploy the current version\nmike deploy 2.0 latest --update-aliases --push\n</code></pre>"},{"location":"guides/versioning/#major-version-release","title":"Major Version Release","text":"<p>When releasing a new major version:</p> <pre><code># Deploy new version and update latest alias\nmike deploy 3.0 latest --update-aliases --push\n\n# Old versions (1.0, 2.0) remain accessible\n</code></pre>"},{"location":"guides/versioning/#maintaining-old-versions","title":"Maintaining Old Versions","text":"<p>To update docs for an older version:</p> <pre><code># Checkout the old version's branch/tag\ngit checkout v1.0\n\n# Deploy to that version slot\nmike deploy 1.0 --push\n\n# Switch back\ngit checkout main\n</code></pre>"},{"location":"guides/versioning/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"guides/versioning/#github-actions-example","title":"GitHub Actions Example","text":"<pre><code># .github/workflows/docs.yml\nname: Deploy Docs\n\non:\n  push:\n    branches: [main]\n    tags: ['v*']\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 0  # Required for mike\n\n      - uses: actions/setup-python@v5\n        with:\n          python-version: '3.11'\n\n      - name: Install dependencies\n        run: pip install -r requirements-docs.txt\n\n      - name: Configure git\n        run: |\n          git config user.name \"github-actions[bot]\"\n          git config user.email \"github-actions[bot]@users.noreply.github.com\"\n\n      - name: Deploy docs\n        run: |\n          # For tagged releases, deploy that version\n          if [[ \"$GITHUB_REF\" == refs/tags/v* ]]; then\n            VERSION=${GITHUB_REF#refs/tags/v}\n            mike deploy $VERSION latest --update-aliases --push\n          else\n            # For main branch, deploy as 'dev'\n            mike deploy dev --push\n          fi\n</code></pre>"},{"location":"guides/versioning/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use semantic versioning: Match your doc versions to your code versions (1.0, 2.0, etc.)</p> </li> <li> <p>Keep <code>latest</code> updated: Always point <code>latest</code> to the current stable version</p> </li> <li> <p>Don't delete old versions hastily: Users may still be on older versions</p> </li> <li> <p>Use aliases: Create meaningful aliases like <code>stable</code>, <code>legacy</code>, <code>dev</code></p> </li> <li> <p>Document breaking changes: When updating docs, note what changed between versions</p> </li> </ol>"},{"location":"guides/versioning/#configuration","title":"Configuration","text":"<p>Mike is configured in <code>mkdocs.yml</code>:</p> <pre><code>extra:\n  version:\n    provider: mike\n    default: latest  # Default version when accessing root URL\n</code></pre> <p>This enables the version selector in the Material theme header.</p>"},{"location":"guides/working-with-bedrock/","title":"Working with AWS Bedrock Guide","text":"<p>This guide covers how to effectively use AWS Bedrock with DCAF, including configuration, model selection, tool integration, and best practices.</p>"},{"location":"guides/working-with-bedrock/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Introduction</li> <li>Setup and Configuration</li> <li>Model Selection</li> <li>Using the BedrockLLM Client</li> <li>Tool Integration</li> <li>Streaming</li> <li>Performance Optimization</li> <li>Error Handling</li> <li>Best Practices</li> </ol>"},{"location":"guides/working-with-bedrock/#introduction","title":"Introduction","text":"<p>DCAF uses AWS Bedrock's Converse API to interact with foundation models. The Converse API provides:</p> <ul> <li>Unified interface across all Bedrock models</li> <li>Tool calling (function calling) support</li> <li>Streaming responses</li> <li>Multi-turn conversations</li> <li>Consistent message format</li> </ul>"},{"location":"guides/working-with-bedrock/#key-concepts","title":"Key Concepts","text":"<ul> <li>Model ID: Identifies the model to use (e.g., <code>us.anthropic.claude-3-5-sonnet-20240620-v1:0</code>)</li> <li>Converse API: AWS Bedrock's unified API for all models</li> <li>Tool Config: How tools are defined for LLM consumption</li> <li>Inference Config: Parameters like temperature, max tokens</li> </ul>"},{"location":"guides/working-with-bedrock/#setup-and-configuration","title":"Setup and Configuration","text":""},{"location":"guides/working-with-bedrock/#prerequisites","title":"Prerequisites","text":"<ol> <li>AWS Account with Bedrock access</li> <li>IAM permissions for Bedrock</li> <li>Model access enabled in AWS console</li> </ol>"},{"location":"guides/working-with-bedrock/#required-iam-permissions","title":"Required IAM Permissions","text":"<pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"bedrock:InvokeModel\",\n                \"bedrock:InvokeModelWithResponseStream\"\n            ],\n            \"Resource\": [\n                \"arn:aws:bedrock:*::foundation-model/anthropic.*\",\n                \"arn:aws:bedrock:*::foundation-model/amazon.*\"\n            ]\n        }\n    ]\n}\n</code></pre>"},{"location":"guides/working-with-bedrock/#environment-setup","title":"Environment Setup","text":"<pre><code># .env file\nAWS_ACCESS_KEY_ID=your_access_key\nAWS_SECRET_ACCESS_KEY=your_secret_key\nAWS_SESSION_TOKEN=your_session_token  # If using temporary credentials\nAWS_REGION=us-east-1\n\n# Optional: Boto3 configuration\nBOTO3_READ_TIMEOUT=20\nBOTO3_CONNECT_TIMEOUT=10\nBOTO3_MAX_ATTEMPTS=3\nBOTO3_RETRY_MODE=standard\n</code></pre>"},{"location":"guides/working-with-bedrock/#creating-the-llm-client","title":"Creating the LLM Client","text":"<pre><code>from dcaf.llm import BedrockLLM\nimport dotenv\n\n# Load environment\ndotenv.load_dotenv(override=True)\n\n# Option 1: Defaults (recommended for most cases)\nllm = BedrockLLM(region_name=\"us-east-1\")\n\n# Option 2: Custom boto3 config\nfrom botocore.config import Config\n\ncustom_config = Config(\n    read_timeout=60,\n    connect_timeout=15,\n    retries={\n        'max_attempts': 5,\n        'mode': 'adaptive'\n    }\n)\nllm = BedrockLLM(region_name=\"us-east-1\", boto3_config=custom_config)\n</code></pre>"},{"location":"guides/working-with-bedrock/#model-selection","title":"Model Selection","text":""},{"location":"guides/working-with-bedrock/#available-models","title":"Available Models","text":"Model ID Best For Claude 3.5 Sonnet <code>us.anthropic.claude-3-5-sonnet-20240620-v1:0</code> General purpose, balanced Claude 3 Sonnet <code>us.anthropic.claude-3-sonnet-20240229-v1:0</code> Cost-effective general Claude 3.5 Haiku <code>us.anthropic.claude-3-5-haiku-20241022-v1:0</code> Fast, simple tasks Claude 4 Opus <code>us.anthropic.claude-opus-4-20250514-v1:0</code> Complex reasoning"},{"location":"guides/working-with-bedrock/#cross-region-inference","title":"Cross-Region Inference","text":"<p>Use the <code>us.</code> prefix for cross-region inference profiles:</p> <pre><code># Cross-region (recommended for availability)\nmodel_id = \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n\n# Single region\nmodel_id = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n</code></pre>"},{"location":"guides/working-with-bedrock/#choosing-the-right-model","title":"Choosing the Right Model","text":"<pre><code># For fast, simple operations (routing, classification)\nfast_model = \"us.anthropic.claude-3-5-haiku-20241022-v1:0\"\n\n# For general purpose (most agents)\ngeneral_model = \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\"\n\n# For complex reasoning (advanced analysis)\ncomplex_model = \"us.anthropic.claude-opus-4-20250514-v1:0\"\n</code></pre>"},{"location":"guides/working-with-bedrock/#using-the-bedrockllm-client","title":"Using the BedrockLLM Client","text":""},{"location":"guides/working-with-bedrock/#basic-invocation","title":"Basic Invocation","text":"<pre><code>from dcaf.llm import BedrockLLM\n\nllm = BedrockLLM()\n\nresponse = llm.invoke(\n    messages=[\n        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n    ],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_tokens=100\n)\n\n# Extract text\ntext = response['output']['message']['content'][0]['text']\nprint(text)  # \"The capital of France is Paris.\"\n</code></pre>"},{"location":"guides/working-with-bedrock/#with-system-prompt","title":"With System Prompt","text":"<pre><code>response = llm.invoke(\n    messages=[\n        {\"role\": \"user\", \"content\": \"Explain quantum computing\"}\n    ],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    system_prompt=\"\"\"You are a physics teacher for high school students.\n    Use simple language and helpful analogies.\n    Keep explanations under 3 paragraphs.\"\"\",\n    max_tokens=500\n)\n</code></pre>"},{"location":"guides/working-with-bedrock/#multi-turn-conversation","title":"Multi-Turn Conversation","text":"<pre><code>conversation = [\n    {\"role\": \"user\", \"content\": \"My name is Alice\"},\n    {\"role\": \"assistant\", \"content\": \"Nice to meet you, Alice!\"},\n    {\"role\": \"user\", \"content\": \"What did I just tell you?\"}\n]\n\nresponse = llm.invoke(\n    messages=conversation,\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_tokens=100\n)\n\n# \"You told me your name is Alice.\"\n</code></pre>"},{"location":"guides/working-with-bedrock/#inference-parameters","title":"Inference Parameters","text":"<pre><code>response = llm.invoke(\n    messages=[{\"role\": \"user\", \"content\": \"Write a creative story\"}],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_tokens=1000,      # Maximum output tokens\n    temperature=0.8,      # Higher = more creative (0-1)\n    top_p=0.9             # Nucleus sampling parameter\n)\n</code></pre> Parameter Range Description <code>max_tokens</code> 1-4096+ Maximum tokens to generate <code>temperature</code> 0-1 Randomness (0=deterministic) <code>top_p</code> 0-1 Nucleus sampling threshold"},{"location":"guides/working-with-bedrock/#tool-integration","title":"Tool Integration","text":""},{"location":"guides/working-with-bedrock/#defining-tools","title":"Defining Tools","text":"<pre><code>tools = [\n    {\n        \"name\": \"get_weather\",\n        \"description\": \"Get current weather for a location\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"City and state, e.g., San Francisco, CA\"\n                },\n                \"unit\": {\n                    \"type\": \"string\",\n                    \"enum\": [\"celsius\", \"fahrenheit\"],\n                    \"description\": \"Temperature unit\"\n                }\n            },\n            \"required\": [\"location\"]\n        }\n    }\n]\n</code></pre>"},{"location":"guides/working-with-bedrock/#invoking-with-tools","title":"Invoking with Tools","text":"<pre><code>response = llm.invoke(\n    messages=[{\"role\": \"user\", \"content\": \"What's the weather in Tokyo?\"}],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    tools=tools\n)\n\n# Check for tool use\ncontent = response['output']['message']['content']\nfor block in content:\n    if 'toolUse' in block:\n        tool_use = block['toolUse']\n        print(f\"Tool: {tool_use['name']}\")\n        print(f\"Input: {tool_use['input']}\")\n</code></pre>"},{"location":"guides/working-with-bedrock/#tool-choice-strategies","title":"Tool Choice Strategies","text":"<pre><code># Auto (default) - Model decides\nresponse = llm.invoke(\n    messages=...,\n    tools=tools,\n    tool_choice=\"auto\"\n)\n\n# Any - Must use a tool\nresponse = llm.invoke(\n    messages=...,\n    tools=tools,\n    tool_choice=\"any\"\n)\n\n# Specific - Must use this tool\nresponse = llm.invoke(\n    messages=...,\n    tools=tools,\n    tool_choice={\"type\": \"tool\", \"name\": \"get_weather\"}\n)\n</code></pre>"},{"location":"guides/working-with-bedrock/#complete-tool-loop","title":"Complete Tool Loop","text":"<pre><code>def process_with_tools(user_message: str, tools: list, tool_functions: dict):\n    \"\"\"Complete tool execution loop.\"\"\"\n    messages = [{\"role\": \"user\", \"content\": user_message}]\n\n    while True:\n        # Call LLM\n        response = llm.invoke(\n            messages=messages,\n            model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n            tools=tools\n        )\n\n        content = response['output']['message']['content']\n        stop_reason = response.get('stopReason', '')\n\n        # Check for tool use\n        tool_uses = [b for b in content if 'toolUse' in b]\n\n        if not tool_uses:\n            # No tools, return text response\n            text = next((b['text'] for b in content if 'text' in b), \"\")\n            return text\n\n        # Execute tools\n        tool_results = []\n        for block in tool_uses:\n            tool_use = block['toolUse']\n            tool_name = tool_use['name']\n            tool_input = tool_use['input']\n            tool_id = tool_use['toolUseId']\n\n            # Execute the tool\n            if tool_name in tool_functions:\n                result = tool_functions[tool_name](**tool_input)\n            else:\n                result = f\"Unknown tool: {tool_name}\"\n\n            tool_results.append({\n                \"toolResult\": {\n                    \"toolUseId\": tool_id,\n                    \"content\": [{\"text\": str(result)}]\n                }\n            })\n\n        # Add assistant message with tool use\n        messages.append({\n            \"role\": \"assistant\",\n            \"content\": content\n        })\n\n        # Add tool results\n        messages.append({\n            \"role\": \"user\",\n            \"content\": tool_results\n        })\n\n# Usage\ndef get_weather(location: str, unit: str = \"celsius\"):\n    return f\"Weather in {location}: 72\u00b0F, sunny\"\n\nresult = process_with_tools(\n    \"What's the weather in NYC?\",\n    tools=tools,\n    tool_functions={\"get_weather\": get_weather}\n)\n</code></pre>"},{"location":"guides/working-with-bedrock/#streaming","title":"Streaming","text":""},{"location":"guides/working-with-bedrock/#basic-streaming","title":"Basic Streaming","text":"<pre><code>import sys\n\nfor event in llm.invoke_stream(\n    messages=[{\"role\": \"user\", \"content\": \"Tell me a story\"}],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    max_tokens=500\n):\n    if \"contentBlockDelta\" in event:\n        delta = event[\"contentBlockDelta\"].get(\"delta\", {})\n        if \"text\" in delta:\n            sys.stdout.write(delta[\"text\"])\n            sys.stdout.flush()\n</code></pre>"},{"location":"guides/working-with-bedrock/#event-types","title":"Event Types","text":"<pre><code>for event in llm.invoke_stream(...):\n    if \"messageStart\" in event:\n        print(\"Stream started\")\n\n    elif \"contentBlockStart\" in event:\n        # New content block (text or tool use)\n        start = event[\"contentBlockStart\"]\n        if \"toolUse\" in start.get(\"start\", {}):\n            print(f\"Tool: {start['start']['toolUse']['name']}\")\n\n    elif \"contentBlockDelta\" in event:\n        delta = event[\"contentBlockDelta\"][\"delta\"]\n        if \"text\" in delta:\n            print(delta[\"text\"], end=\"\")\n        elif \"toolUse\" in delta:\n            # Tool input streaming\n            pass\n\n    elif \"contentBlockStop\" in event:\n        print()  # End of block\n\n    elif \"messageStop\" in event:\n        print(f\"\\nStop reason: {event['messageStop']['stopReason']}\")\n</code></pre>"},{"location":"guides/working-with-bedrock/#streaming-with-tools","title":"Streaming with Tools","text":"<pre><code>accumulated_text = \"\"\ncurrent_tool = None\n\nfor event in llm.invoke_stream(\n    messages=[{\"role\": \"user\", \"content\": \"What's the weather?\"}],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    tools=tools\n):\n    if \"contentBlockStart\" in event:\n        start = event[\"contentBlockStart\"].get(\"start\", {})\n        if \"toolUse\" in start:\n            current_tool = {\n                \"name\": start[\"toolUse\"][\"name\"],\n                \"id\": start[\"toolUse\"][\"toolUseId\"],\n                \"input\": \"\"\n            }\n\n    elif \"contentBlockDelta\" in event:\n        delta = event[\"contentBlockDelta\"][\"delta\"]\n\n        if \"text\" in delta:\n            accumulated_text += delta[\"text\"]\n            print(delta[\"text\"], end=\"\", flush=True)\n\n        elif \"toolUse\" in delta and current_tool:\n            current_tool[\"input\"] += delta[\"toolUse\"].get(\"input\", \"\")\n\n    elif \"contentBlockStop\" in event:\n        if current_tool:\n            print(f\"\\nTool call: {current_tool['name']}\")\n            current_tool = None\n</code></pre>"},{"location":"guides/working-with-bedrock/#performance-optimization","title":"Performance Optimization","text":""},{"location":"guides/working-with-bedrock/#timeout-configuration","title":"Timeout Configuration","text":"<pre><code>from botocore.config import Config\n\n# For fast, short responses\nfast_config = Config(\n    read_timeout=10,\n    connect_timeout=5\n)\n\n# For long, complex responses\nslow_config = Config(\n    read_timeout=120,\n    connect_timeout=30\n)\n\nllm_fast = BedrockLLM(boto3_config=fast_config)\nllm_slow = BedrockLLM(boto3_config=slow_config)\n</code></pre>"},{"location":"guides/working-with-bedrock/#retry-configuration","title":"Retry Configuration","text":"<pre><code># Aggressive retry for production\nproduction_config = Config(\n    retries={\n        'max_attempts': 10,\n        'mode': 'adaptive'  # Smart exponential backoff\n    }\n)\n\n# Light retry for development\ndev_config = Config(\n    retries={\n        'max_attempts': 2,\n        'mode': 'standard'\n    }\n)\n</code></pre>"},{"location":"guides/working-with-bedrock/#latency-optimization","title":"Latency Optimization","text":"<pre><code># Use latency-optimized mode\nresponse = llm.invoke(\n    messages=[...],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",\n    performance_config={\"latency\": \"optimized\"}\n)\n</code></pre>"},{"location":"guides/working-with-bedrock/#message-optimization","title":"Message Optimization","text":"<pre><code># Let BedrockLLM normalize messages automatically\nmessages = [\n    {\"role\": \"user\", \"content\": \"Hello\"},\n    {\"role\": \"user\", \"content\": \"How are you?\"},  # Will be merged\n]\n\n# Messages are automatically normalized:\n# [{\"role\": \"user\", \"content\": \"Hello\\nHow are you?\"}]\n</code></pre>"},{"location":"guides/working-with-bedrock/#error-handling","title":"Error Handling","text":""},{"location":"guides/working-with-bedrock/#common-errors","title":"Common Errors","text":"<pre><code>from botocore.exceptions import ClientError\n\ntry:\n    response = llm.invoke(messages=..., model_id=...)\nexcept ClientError as e:\n    error_code = e.response['Error']['Code']\n\n    if error_code == 'ExpiredTokenException':\n        # Refresh credentials\n        print(\"Credentials expired - refresh with dcaf env-update-aws-creds\")\n\n    elif error_code == 'ResourceNotFoundException':\n        # Model not found\n        print(\"Model not found - check model ID and region\")\n\n    elif error_code == 'ThrottlingException':\n        # Rate limited\n        import time\n        time.sleep(5)  # Wait and retry\n\n    elif error_code == 'ValidationException':\n        # Invalid request\n        print(\"Invalid request - check message format\")\n\n    elif error_code == 'ServiceUnavailableException':\n        # Service issue\n        print(\"Bedrock temporarily unavailable\")\n\n    else:\n        print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"guides/working-with-bedrock/#retry-wrapper","title":"Retry Wrapper","text":"<pre><code>import time\nfrom botocore.exceptions import ClientError\n\ndef invoke_with_retry(llm, max_retries=3, **kwargs):\n    \"\"\"Invoke LLM with exponential backoff retry.\"\"\"\n    for attempt in range(max_retries):\n        try:\n            return llm.invoke(**kwargs)\n        except ClientError as e:\n            error_code = e.response['Error']['Code']\n\n            # Don't retry validation errors\n            if error_code == 'ValidationException':\n                raise\n\n            # Don't retry expired tokens\n            if error_code == 'ExpiredTokenException':\n                raise\n\n            # Retry throttling and service errors\n            if error_code in ['ThrottlingException', 'ServiceUnavailableException']:\n                if attempt &lt; max_retries - 1:\n                    wait = 2 ** attempt\n                    print(f\"Retrying in {wait}s...\")\n                    time.sleep(wait)\n                else:\n                    raise\n            else:\n                raise\n\n    raise Exception(\"Max retries exceeded\")\n</code></pre>"},{"location":"guides/working-with-bedrock/#best-practices","title":"Best Practices","text":""},{"location":"guides/working-with-bedrock/#1-use-appropriate-model-for-task","title":"1. Use Appropriate Model for Task","text":"<pre><code># Routing/classification - use fast model\nrouting_response = llm.invoke(\n    messages=[...],\n    model_id=\"us.anthropic.claude-3-5-haiku-20241022-v1:0\",  # Fast\n    max_tokens=10\n)\n\n# Main task - use capable model\nmain_response = llm.invoke(\n    messages=[...],\n    model_id=\"us.anthropic.claude-3-5-sonnet-20240620-v1:0\",  # Capable\n    max_tokens=1000\n)\n</code></pre>"},{"location":"guides/working-with-bedrock/#2-set-appropriate-limits","title":"2. Set Appropriate Limits","text":"<pre><code># Short responses\nresponse = llm.invoke(\n    messages=[{\"role\": \"user\", \"content\": \"Yes or no: Is 2+2=4?\"}],\n    max_tokens=10,\n    temperature=0  # Deterministic\n)\n\n# Creative tasks\nresponse = llm.invoke(\n    messages=[{\"role\": \"user\", \"content\": \"Write a poem\"}],\n    max_tokens=500,\n    temperature=0.8  # Creative\n)\n</code></pre>"},{"location":"guides/working-with-bedrock/#3-use-system-prompts-effectively","title":"3. Use System Prompts Effectively","text":"<pre><code>system_prompt = \"\"\"\nRole: You are a Kubernetes expert assistant.\n\nGuidelines:\n- Always specify namespaces in commands\n- Prefer kubectl over direct API calls\n- Explain what each command does\n- Warn about destructive operations\n\nFormat:\n- Use code blocks for commands\n- Keep explanations concise\n\"\"\"\n\nresponse = llm.invoke(\n    messages=[...],\n    system_prompt=system_prompt\n)\n</code></pre>"},{"location":"guides/working-with-bedrock/#4-handle-empty-responses","title":"4. Handle Empty Responses","text":"<pre><code>response = llm.invoke(messages=..., model_id=...)\n\ncontent = response.get('output', {}).get('message', {}).get('content', [])\n\nif not content:\n    print(\"No content in response\")\nelse:\n    for block in content:\n        if 'text' in block:\n            print(block['text'])\n</code></pre>"},{"location":"guides/working-with-bedrock/#5-monitor-usage","title":"5. Monitor Usage","text":"<pre><code>response = llm.invoke(messages=..., model_id=...)\n\n# Check token usage\nusage = response.get('usage', {})\nprint(f\"Input tokens: {usage.get('inputTokens', 0)}\")\nprint(f\"Output tokens: {usage.get('outputTokens', 0)}\")\n</code></pre>"},{"location":"guides/working-with-bedrock/#see-also","title":"See Also","text":"<ul> <li>BedrockLLM API Reference</li> <li>Agents API Reference</li> <li>AWS Bedrock Documentation</li> </ul>"},{"location":"guides/working-with-gemini/","title":"Working with Google Gemini","text":"<p>DCAF supports Google's Gemini models through Vertex AI, providing zero-configuration deployment on Google Cloud Platform.</p>"},{"location":"guides/working-with-gemini/#overview","title":"Overview","text":"<p>Google Gemini offers: - Gemini 3: Latest generation with advanced reasoning - Gemini 2.x: High-performance models with thinking budgets - Gemini 1.5: Large context windows and efficient inference - Vertex AI: Enterprise integration through Google Cloud Platform</p>"},{"location":"guides/working-with-gemini/#installation","title":"Installation","text":"<p>Install the required Google AI dependencies:</p> <pre><code>pip install google-generativeai google-auth\n\n# Or install DCAF with Gemini support\npip install dcaf[gemini]\n</code></pre>"},{"location":"guides/working-with-gemini/#configuration","title":"Configuration","text":""},{"location":"guides/working-with-gemini/#zero-configuration-on-gcp-recommended","title":"Zero Configuration on GCP (Recommended)","text":"<p>When running on GCP (GKE, GCE, Cloud Run), DCAF automatically detects your project and location:</p> <pre><code>from dcaf.core import Agent\n\n# That's it! Project/location auto-detected on GCP\nagent = Agent(\n    provider=\"google\",\n    model=\"gemini-2.5-pro\",\n    system_prompt=\"You are a helpful assistant.\"\n)\n</code></pre>"},{"location":"guides/working-with-gemini/#environment-variables-optional","title":"Environment Variables (Optional)","text":"<p>Override auto-detected values if needed:</p> <pre><code>export GOOGLE_CLOUD_PROJECT=\"your-project-id\"\nexport DCAF_GOOGLE_MODEL_LOCATION=\"us-central1\"  # Optional, defaults to us-central1\n</code></pre>"},{"location":"guides/working-with-gemini/#quick-start","title":"Quick Start","text":""},{"location":"guides/working-with-gemini/#basic-gemini-agent","title":"Basic Gemini Agent","text":"<pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    provider=\"google\",\n    model=\"gemini-2.5-pro\",\n    system_prompt=\"You are a helpful assistant.\"\n)\n\nresponse = agent.run([\n    {\"role\": \"user\", \"content\": \"What's the capital of France?\"}\n])\n\nprint(response.text)\n</code></pre>"},{"location":"guides/working-with-gemini/#available-gemini-models","title":"Available Gemini Models","text":""},{"location":"guides/working-with-gemini/#gemini-3-latest","title":"Gemini 3 (Latest)","text":"<p>gemini-3-pro-preview - Most capable model with advanced reasoning <pre><code>agent = Agent(provider=\"google\", model=\"gemini-3-pro-preview\")\n</code></pre></p> <p>gemini-3-flash - Fast inference with strong reasoning <pre><code>agent = Agent(provider=\"google\", model=\"gemini-3-flash\")\n</code></pre></p>"},{"location":"guides/working-with-gemini/#gemini-2x","title":"Gemini 2.x","text":"<p>gemini-2.5-flash - Fast model with thinking support <pre><code>agent = Agent(provider=\"google\", model=\"gemini-2.5-flash\")\n</code></pre></p> <p>gemini-2.5-pro - More capable, supports thinking budget <pre><code>agent = Agent(provider=\"google\", model=\"gemini-2.5-pro\")\n</code></pre></p> <p>gemini-2.0-flash - Previous generation flash <pre><code>agent = Agent(provider=\"google\", model=\"gemini-2.0-flash\")\n</code></pre></p>"},{"location":"guides/working-with-gemini/#gemini-15","title":"Gemini 1.5","text":"<p>gemini-1.5-flash - Lightweight, fast responses <pre><code>agent = Agent(provider=\"google\", model=\"gemini-1.5-flash\")\n</code></pre></p> <p>gemini-1.5-pro - Large context window (2M tokens) <pre><code>agent = Agent(provider=\"google\", model=\"gemini-1.5-pro\")\n</code></pre></p>"},{"location":"guides/working-with-gemini/#model-configuration","title":"Model Configuration","text":""},{"location":"guides/working-with-gemini/#temperature-and-max-tokens","title":"Temperature and Max Tokens","text":"<p>Control generation behavior:</p> <pre><code>agent = Agent(\n    provider=\"google\",\n    model=\"gemini-3-flash\",\n    model_config={\n        \"temperature\": 0.7,      # 0.0 to 1.0 (default: 0.1)\n        \"max_tokens\": 8192,      # Maximum output tokens\n    }\n)\n</code></pre>"},{"location":"guides/working-with-gemini/#advanced-model-configuration","title":"Advanced Model Configuration","text":"<p>Pass additional Gemini-specific parameters:</p> <pre><code>agent = Agent(\n    provider=\"google\",\n    model=\"gemini-3-pro-preview\",\n    model_config={\n        \"thinking_level\": \"high\",     # \"low\" or \"high\" (Gemini 3 only)\n        \"top_p\": 0.9,\n        \"top_k\": 40,\n    }\n)\n</code></pre> <p>Note: Gemini 3 models use <code>thinking_level</code>, while Gemini 2.5 models use <code>thinking_budget</code>. See Agno's documentation for model-specific parameters.</p>"},{"location":"guides/working-with-gemini/#using-tools-with-gemini","title":"Using Tools with Gemini","text":"<p>Gemini excels at tool use and function calling:</p> <pre><code>from dcaf.core import Agent\nfrom dcaf.tools import tool\nimport os\n\n@tool(description=\"Search for current information\")\ndef search(query: str) -&gt; str:\n    \"\"\"Search the web for information.\"\"\"\n    # Your search implementation\n    return f\"Results for: {query}\"\n\n@tool(description=\"Get weather information\")\ndef get_weather(city: str) -&gt; str:\n    \"\"\"Get current weather for a city.\"\"\"\n    return f\"Weather in {city}: Sunny, 72\u00b0F\"\n\nagent = Agent(\n    provider=\"google\",\n    model=\"gemini-2.5-flash\",\n    tools=[search, get_weather],\n    system_prompt=\"You are a helpful assistant with access to search and weather tools.\"\n)\n\nresponse = agent.run([\n    {\"role\": \"user\", \"content\": \"What's the weather in Paris and any recent news?\"}\n])\n\nprint(response.text)\n</code></pre>"},{"location":"guides/working-with-gemini/#streaming-responses","title":"Streaming Responses","text":"<p>Use streaming for real-time token generation:</p> <pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    provider=\"google\",\n    model=\"gemini-3-flash\",\n)\n\nfor event in agent.stream([\n    {\"role\": \"user\", \"content\": \"Write a short story about AI.\"}\n]):\n    if event.type == \"text_delta\":\n        print(event.data.text, end=\"\", flush=True)\n    elif event.type == \"complete\":\n        print(\"\\n\\nDone!\")\n</code></pre>"},{"location":"guides/working-with-gemini/#rest-server-with-gemini","title":"REST Server with Gemini","text":"<p>Expose a Gemini agent as a REST API:</p> <pre><code>from dcaf.core import Agent, serve\nfrom dcaf.tools import tool\nimport os\n\n@tool(description=\"Analyze code for issues\")\ndef analyze_code(code: str, language: str) -&gt; str:\n    \"\"\"Analyze code and return suggestions.\"\"\"\n    return f\"Analyzing {language} code...\"\n\nagent = Agent(\n    name=\"code-reviewer\",\n    description=\"AI code review assistant\",\n    provider=\"google\",\n    model=\"gemini-3-flash\",\n    tools=[analyze_code]\n)\n\n# Start server with A2A support\nserve(agent, port=8000, a2a=True)\n</code></pre> <p>Access via: - HTTP: <code>POST http://localhost:8000/api/chat</code> - A2A: <code>GET http://localhost:8000/.well-known/agent.json</code></p>"},{"location":"guides/working-with-gemini/#multi-agent-systems-with-gemini","title":"Multi-Agent Systems with Gemini","text":"<p>Use Gemini in multi-agent architectures:</p> <pre><code>from dcaf.core import Agent\nfrom dcaf.core.a2a import RemoteAgent\nimport os\n\n# Specialist agent using Gemini\nresearch_agent = Agent(\n    name=\"researcher\",\n    provider=\"google\",\n    model=\"gemini-2.5-flash\",\n    tools=[web_search],\n    system_prompt=\"You are a research specialist. Gather information from the web.\"\n)\n\n# Orchestrator using Claude on Bedrock\norchestrator = Agent(\n    name=\"orchestrator\",\n    provider=\"bedrock\",\n    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n    aws_profile=\"my-profile\",\n    tools=[research_agent.as_tool()],  # Gemini agent as a tool\n    system_prompt=\"Route research tasks to the specialist.\"\n)\n\nresponse = orchestrator.run([\n    {\"role\": \"user\", \"content\": \"Research the latest AI developments\"}\n])\n</code></pre>"},{"location":"guides/working-with-gemini/#vertex-ai-default","title":"Vertex AI (Default)","text":"<p>The Google provider always uses Vertex AI. Project and location are auto-detected on GCP:</p> <pre><code>from dcaf.core import Agent\n\n# On GCP - this is all you need!\nagent = Agent(\n    provider=\"google\",\n    model=\"gemini-2.5-pro\",\n)\n</code></pre>"},{"location":"guides/working-with-gemini/#how-auto-detection-works","title":"How Auto-Detection Works","text":"<p>DCAF automatically detects your GCP environment:</p> <ol> <li>google.auth.default(): Gets project ID from ADC (works with Workload Identity)</li> <li>Metadata service: Falls back to <code>http://metadata.google.internal/</code> for project/zone</li> <li>Default location: Uses <code>us-central1</code> if location can't be detected</li> </ol>"},{"location":"guides/working-with-gemini/#explicit-configuration","title":"Explicit Configuration","text":"<p>Override auto-detected values if needed:</p> <pre><code>agent = Agent(\n    provider=\"google\",\n    model=\"gemini-2.5-pro\",\n    google_project_id=\"my-project\",      # Explicit project\n    google_location=\"europe-west1\",       # Explicit region\n)\n</code></pre> <p>Or via environment variables:</p> <pre><code>export GOOGLE_CLOUD_PROJECT=\"my-project\"\nexport GOOGLE_CLOUD_LOCATION=\"us-central1\"\n</code></pre>"},{"location":"guides/working-with-gemini/#requirements","title":"Requirements","text":"<ol> <li>GCP project with Vertex AI API enabled</li> <li>Application Default Credentials configured:</li> <li>Local dev: <code>gcloud auth application-default login</code></li> <li>GKE: Workload Identity with appropriate IAM bindings</li> <li>GCE/Cloud Run: Attached service account</li> <li>IAM role: <code>roles/aiplatform.user</code> on the service account</li> </ol>"},{"location":"guides/working-with-gemini/#model-selection-guide","title":"Model Selection Guide","text":"Model Best For Context Speed Cost gemini-3-pro-preview Complex reasoning, multi-step tasks Large Slow High gemini-3-flash General-purpose, balanced performance Large Fast Low gemini-2.5-pro Advanced capabilities, thinking Large Medium Medium gemini-2.5-flash Fast inference, good reasoning Large Very Fast Low gemini-1.5-pro Huge context (2M tokens) Massive Medium Medium gemini-1.5-flash Quick tasks, simple queries Large Very Fast Very Low"},{"location":"guides/working-with-gemini/#error-handling","title":"Error Handling","text":"<p>Handle Gemini-specific errors:</p> <pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    provider=\"google\",\n    model=\"gemini-3-flash\",\n)\n\ntry:\n    response = agent.run([\n        {\"role\": \"user\", \"content\": \"Hello!\"}\n    ])\n    print(response.text)\nexcept ImportError as e:\n    print(\"Google AI package not installed:\")\n    print(\"  pip install google-generativeai google-auth\")\nexcept ValueError as e:\n    print(f\"Configuration error: {e}\")\n    print(\"Ensure GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_LOCATION are set\")\nexcept Exception as e:\n    print(f\"Error: {e}\")\n</code></pre>"},{"location":"guides/working-with-gemini/#best-practices","title":"Best Practices","text":""},{"location":"guides/working-with-gemini/#1-choose-the-right-model","title":"1. Choose the Right Model","text":"<pre><code># For production - use flash models for speed and cost\nproduction_agent = Agent(\n    provider=\"google\",\n    model=\"gemini-3-flash\",  # Fast, cost-effective\n)\n\n# For complex reasoning - use pro models\nresearch_agent = Agent(\n    provider=\"google\",\n    model=\"gemini-3-pro-preview\",  # Advanced reasoning\n)\n</code></pre>"},{"location":"guides/working-with-gemini/#2-monitor-token-usage","title":"2. Monitor Token Usage","text":"<p>Gemini models have different context windows and pricing:</p> <pre><code>agent = Agent(\n    provider=\"google\",\n    model=\"gemini-3-flash\",\n    model_config={\n        \"max_tokens\": 2048,  # Limit output to control costs\n    }\n)\n</code></pre>"},{"location":"guides/working-with-gemini/#3-test-with-flash-deploy-with-pro","title":"3. Test with Flash, Deploy with Pro","text":"<pre><code>import os\n\n# Development/testing\nif os.getenv(\"ENV\") == \"development\":\n    model = \"gemini-3-flash\"\nelse:\n    model = \"gemini-3-pro-preview\"\n\nagent = Agent(\n    provider=\"google\",\n    model=model,\n)\n</code></pre>"},{"location":"guides/working-with-gemini/#comparison-gemini-vs-claude-vs-gpt","title":"Comparison: Gemini vs Claude vs GPT","text":"Feature Gemini Claude (Bedrock) GPT-4 Tool Use Excellent Excellent Good Reasoning Strong (G3) Excellent Strong Speed Very Fast (Flash) Fast Medium Context 2M (1.5 Pro) 200K 128K Cost Low (Flash) Medium High Deployment Direct API or Vertex AWS Bedrock OpenAI or Azure"},{"location":"guides/working-with-gemini/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/working-with-gemini/#project-or-location-not-found","title":"Project or Location Not Found","text":"<pre><code># Check if environment variables are set\necho $GOOGLE_CLOUD_PROJECT\necho $GOOGLE_CLOUD_LOCATION\n\n# Set them if not on GCP (for local development)\nexport GOOGLE_CLOUD_PROJECT=\"your-project-id\"\nexport GOOGLE_CLOUD_LOCATION=\"us-central1\"\n\n# Or use gcloud to set up ADC\ngcloud auth application-default login\n</code></pre>"},{"location":"guides/working-with-gemini/#import-error","title":"Import Error","text":"<pre><code># Install the Google AI packages\npip install google-generativeai google-auth\n\n# Or upgrade if already installed\npip install --upgrade google-generativeai\n</code></pre>"},{"location":"guides/working-with-gemini/#rate-limiting","title":"Rate Limiting","text":"<p>Gemini API has rate limits. Handle gracefully:</p> <pre><code>import time\nfrom dcaf.core import Agent\n\nagent = Agent(provider=\"google\", model=\"gemini-3-flash\")\n\nfor i in range(10):\n    try:\n        response = agent.run([{\"role\": \"user\", \"content\": f\"Request {i}\"}])\n        print(response.text)\n    except Exception as e:\n        if \"429\" in str(e) or \"rate limit\" in str(e).lower():\n            print(\"Rate limited, waiting...\")\n            time.sleep(60)\n        else:\n            raise\n</code></pre>"},{"location":"guides/working-with-gemini/#examples","title":"Examples","text":"<p>Complete examples available in the repository:</p> <ul> <li><code>examples/gemini_basic.py</code> - Basic Gemini usage</li> <li><code>examples/gemini_tools.py</code> - Tool use with Gemini</li> <li><code>examples/gemini_multi_agent.py</code> - Multi-agent with Gemini</li> </ul>"},{"location":"guides/working-with-gemini/#resources","title":"Resources","text":"<ul> <li>Vertex AI Documentation</li> <li>Gemini API Documentation</li> <li>Agno Gemini Guide</li> <li>DCAF Documentation</li> </ul>"},{"location":"guides/working-with-gemini/#support","title":"Support","text":"<p>For issues with Gemini in DCAF:</p> <ol> <li>Check this guide</li> <li>Review Agno's Gemini docs</li> <li>Verify ADC is configured: <code>gcloud auth application-default login</code></li> <li>Check Vertex AI quotas in GCP Console</li> <li>Open an issue on GitHub with logs</li> </ol> <p>Next Steps: - Building Tools - Multi-Agent Systems - Working with Bedrock</p>"},{"location":"plans/2025-02-02-mcp-approval-test-server-design/","title":"MCP Approval Test Server Design","text":"<p>Date: 2025-02-02 Purpose: Create a test MCP server and integration test to exercise the blacklist, auto-accept, and glob-based approval features.</p>"},{"location":"plans/2025-02-02-mcp-approval-test-server-design/#test-mcp-server","title":"Test MCP Server","text":"<p>File: <code>tests/mcp_test_server.py</code></p> <p>A lightweight FastMCP server running over stdio with 9 dummy tools. Each tool returns a string confirming it was called.</p>"},{"location":"plans/2025-02-02-mcp-approval-test-server-design/#tools","title":"Tools","text":"Tool Category Expected Classification <code>user_get</code> read-like auto-approved via <code>*_get*</code> <code>file_read</code> read-like auto-approved via <code>*_read*</code> <code>items_list</code> read-like auto-approved via <code>*_list*</code> <code>user_delete</code> write-like requires approval <code>file_write</code> write-like requires approval <code>admin_reset</code> write-like blocked via <code>exclude_tools=[\"admin_*\"]</code> <code>data_export</code> ambiguous requires approval <code>config_update</code> ambiguous requires approval <code>system_status</code> ambiguous requires approval"},{"location":"plans/2025-02-02-mcp-approval-test-server-design/#integration-test","title":"Integration Test","text":"<p>File: <code>tests/test_mcp_approval_flow.py</code></p> <p>Connects to the test server using <code>MCPTool</code> with:</p> <pre><code>mcp = MCPTool(\n    command=\".venv/bin/python tests/mcp_test_server.py\",\n    transport=\"stdio\",\n    exclude_tools=[\"admin_*\"],\n    auto_approve_tools=[\"*_get*\", \"*_read*\", \"*_list*\"],\n)\n</code></pre>"},{"location":"plans/2025-02-02-mcp-approval-test-server-design/#assertions","title":"Assertions","text":"<ol> <li>Blocked tools: <code>admin_reset</code> not present in available tools</li> <li>Auto-approved tools: <code>user_get</code>, <code>file_read</code>, <code>items_list</code> have <code>requires_confirmation</code> unset (None)</li> <li>Approval-required tools: <code>user_delete</code>, <code>file_write</code>, <code>data_export</code>, <code>config_update</code>, <code>system_status</code> have <code>requires_confirmation = True</code></li> <li>Tool execution: Calling an auto-approved tool returns the expected dummy string</li> </ol>"},{"location":"plans/2025-02-05-merge-resolution-plan/","title":"Merge Resolution Plan: vnext \u2190 main","text":"<p>Date: 2025-02-05 Direction: Merging <code>vnext</code> into <code>main</code> (release direction) Conflicts: 3 files</p>"},{"location":"plans/2025-02-05-merge-resolution-plan/#executive-summary","title":"Executive Summary","text":"<p>The main branch has added new features while vnext has refactored the architecture for better async support and backwards compatibility. The resolution strategy is:</p> <ol> <li>Keep vnext's architecture (async handlers, modern type hints, new endpoints)</li> <li>Add main's new features (A2A agent card, cache metrics, new schema fields)</li> <li>Preserve all backwards compatibility work done in vnext</li> </ol>"},{"location":"plans/2025-02-05-merge-resolution-plan/#conflict-1-dcafagent_serverpy","title":"Conflict 1: <code>dcaf/agent_server.py</code>","text":""},{"location":"plans/2025-02-05-merge-resolution-plan/#what-main-added","title":"What Main Added","text":"<ul> <li><code>a2a_agent_card_path</code> parameter to <code>create_chat_app()</code></li> <li><code>/.well-known/agent.json</code> endpoint for Agent2Agent protocol support</li> </ul>"},{"location":"plans/2025-02-05-merge-resolution-plan/#what-vnext-changed","title":"What vnext Changed","text":"<ul> <li>Refactored sync handlers to async with <code>asyncio.to_thread()</code> for non-blocking health checks</li> <li>Added <code>/api/chat</code> and <code>/api/chat-stream</code> as preferred endpoints</li> <li>Added <code>/api/sendMessage</code> and <code>/api/sendMessageStream</code> as deprecated aliases (ADR-007)</li> <li>Added <code>/api/chat-ws</code> WebSocket endpoint</li> <li>Added <code>_has_invoke_stream()</code> fallback for v1 agents without streaming</li> <li>Added <code>_request_fields</code> forwarding for thread_id, tenant_id, etc.</li> </ul>"},{"location":"plans/2025-02-05-merge-resolution-plan/#resolution-strategy","title":"Resolution Strategy","text":"<p>Keep vnext's architecture and ADD main's A2A feature.</p> <p>Rationale: 1. vnext's async architecture is essential for non-blocking health checks in production 2. vnext's legacy endpoint aliases are required for backwards compatibility (ADR-007) 3. vnext's WebSocket support is a new feature we want to keep 4. Main's A2A agent card feature is additive and non-breaking</p> <p>Specific Changes: <pre><code># Update function signature to include a2a_agent_card_path\ndef create_chat_app(\n    agent: AgentProtocol,\n    router: ChannelResponseRouter | None = None,\n    a2a_agent_card_path: str | None = None,  # ADD from main\n) -&gt; FastAPI:\n</code></pre></p> <pre><code># Add A2A endpoint after health check (from main)\nif a2a_agent_card_path:\n    card_path = Path(a2a_agent_card_path)\n\n    @app.get(\"/.well-known/agent.json\", tags=[\"system\"])\n    def get_agent_card() -&gt; dict[str, Any]:\n        \"\"\"Serves the Agent2Agent agent card JSON.\"\"\"\n        # ... (copy from main, update type hints to modern style)\n</code></pre> <p>Why This Choice: - Preserves vnext's async architecture (critical for production) - Preserves all backwards compatibility work - Adds A2A support without breaking anything - A2A is an additive feature that doesn't conflict with our architecture</p>"},{"location":"plans/2025-02-05-merge-resolution-plan/#conflict-2-dcafllmbedrockpy","title":"Conflict 2: <code>dcaf/llm/bedrock.py</code>","text":""},{"location":"plans/2025-02-05-merge-resolution-plan/#what-main-added_1","title":"What Main Added","text":"<ul> <li><code>CACHE_MIN_TOKENS</code> class constant for model-specific caching thresholds</li> <li><code>_get_cache_min_tokens()</code> method</li> <li><code>_log_cache_metrics()</code> method for logging cache hits/misses</li> <li><code>cache_system_prompt</code> parameter to <code>invoke_stream()</code> and <code>invoke()</code></li> <li><code>top_p</code> made optional with <code>None</code> default</li> </ul>"},{"location":"plans/2025-02-05-merge-resolution-plan/#what-vnext-changed_1","title":"What vnext Changed","text":"<ul> <li>Modernized type hints (<code>Dict</code> \u2192 <code>dict</code>, <code>List</code> \u2192 <code>list</code>, <code>Optional</code> \u2192 <code>| None</code>)</li> <li>Minor formatting/style improvements</li> <li><code>**kwargs</code> \u2192 <code>**_kwargs: Any</code> for explicit unused parameter handling</li> </ul>"},{"location":"plans/2025-02-05-merge-resolution-plan/#resolution-strategy_1","title":"Resolution Strategy","text":"<p>Keep vnext's modern type hints and ADD main's caching features.</p> <p>Rationale: 1. vnext's modern type hints are preferred (Python 3.10+ style) 2. Main's caching features are valuable for production performance 3. The features are orthogonal - no architectural conflict</p> <p>Specific Changes: <pre><code>class BedrockLLM(LLM):\n    # ADD from main (with modern type hints)\n    CACHE_MIN_TOKENS: dict[str, int] = {\n        \"claude-haiku-4-5\": 4096,\n        \"claude-sonnet-4-5\": 1024,\n        # ... etc\n    }\n\n    def _get_cache_min_tokens(self, model_id: str) -&gt; int:\n        # ADD from main\n        ...\n\n    def _log_cache_metrics(self, response: dict[str, Any], model_id: str) -&gt; None:\n        # ADD from main\n        ...\n</code></pre></p> <pre><code># Update invoke_stream signature to include cache_system_prompt\ndef invoke_stream(\n    self,\n    messages: list[dict[str, Any]],\n    model_id: str,\n    system_prompt: str | None = None,\n    tools: list[dict[str, Any]] | None = None,\n    max_tokens: int = 1000,\n    temperature: float = 0.0,\n    additional_params: dict[str, Any] | None = None,\n    cache_system_prompt: bool = False,  # ADD from main\n):\n</code></pre> <p>Why This Choice: - Caching is a production performance feature - valuable to keep - Type hints are cosmetic but preferred modern style - No behavioral conflict between the changes</p>"},{"location":"plans/2025-02-05-merge-resolution-plan/#conflict-3-dcafschemasmessagespy","title":"Conflict 3: <code>dcaf/schemas/messages.py</code>","text":""},{"location":"plans/2025-02-05-merge-resolution-plan/#what-main-added_2","title":"What Main Added","text":"<ul> <li><code>FileObject.refers_persistent_file: Optional[str] = None</code> - reference to persistent file storage</li> <li><code>Data.user_file_uploads: List[FileObject] = Field(default_factory=list)</code> - user uploaded files</li> </ul>"},{"location":"plans/2025-02-05-merge-resolution-plan/#what-vnext-changed_2","title":"What vnext Changed","text":"<ul> <li><code>PlatformContext.tenant_id: str | None = None</code> - tenant identification</li> <li><code>PlatformContext.user_roles: list[str] = Field(default_factory=list)</code> - access control</li> <li><code>PlatformContext.aws_region: str | None = None</code> - AWS region for credentials</li> <li><code>PlatformContext.model_config = ConfigDict(extra=\"allow\")</code> - allow additional fields</li> <li><code>Data.session: dict[str, Any]</code> - session state persistence</li> <li><code>AgentMessage.from_agent_response()</code> class method - conversion helper</li> <li>Modernized type hints throughout</li> </ul>"},{"location":"plans/2025-02-05-merge-resolution-plan/#resolution-strategy_2","title":"Resolution Strategy","text":"<p>COMBINE both sets of changes - they are complementary.</p> <p>Rationale: 1. Main's <code>user_file_uploads</code> and <code>refers_persistent_file</code> are new features for file handling 2. vnext's <code>PlatformContext</code> enhancements are for multi-tenant access control 3. vnext's <code>Data.session</code> is for state persistence 4. All changes are additive - no conflicts in meaning or behavior</p> <p>Specific Changes: <pre><code>class FileObject(BaseModel):\n    file_path: str\n    file_content: str\n    refers_persistent_file: str | None = None  # ADD from main\n\n\nclass PlatformContext(BaseModel):\n    # Keep ALL vnext fields\n    tenant_id: str | None = None\n    tenant_name: str | None = None\n    user_roles: list[str] = Field(default_factory=list)\n    k8s_namespace: str | None = None\n    kubeconfig: str | None = None\n    duplo_base_url: str | None = None\n    duplo_token: str | None = None\n    aws_credentials: dict[str, Any] | None = None\n    aws_region: str | None = None\n\n    model_config = ConfigDict(extra=\"allow\")\n\n\nclass Data(BaseModel):\n    cmds: list[Command] = Field(default_factory=list)\n    executed_cmds: list[ExecutedCommand] = Field(default_factory=list)\n    tool_calls: list[ToolCall] = Field(default_factory=list)\n    executed_tool_calls: list[ExecutedToolCall] = Field(default_factory=list)\n    url_configs: list[URLConfig] = Field(default_factory=list)\n    user_file_uploads: list[FileObject] = Field(default_factory=list)  # ADD from main\n    session: dict[str, Any] = Field(default_factory=dict)  # Keep from vnext\n</code></pre></p> <p>Why This Choice: - Both branches added useful features to different parts of the schema - No semantic conflict - file uploads and platform context are independent concerns - All fields have defaults, so existing code won't break</p>"},{"location":"plans/2025-02-05-merge-resolution-plan/#test-plan","title":"Test Plan","text":"<p>After resolving conflicts:</p> <ol> <li>Run v1 compatibility tests: <code>pytest tests/test_v1_compatibility.py -v</code></li> <li>Run full test suite: <code>pytest --tb=short</code></li> <li>Verify new features work:</li> <li>A2A agent card endpoint responds correctly</li> <li>Cache metrics logging works</li> <li>File upload fields serialize/deserialize correctly</li> <li>Verify legacy endpoints still work:</li> <li><code>/api/sendMessage</code> returns 200</li> <li><code>/api/sendMessageStream</code> streams correctly</li> </ol>"},{"location":"plans/2025-02-05-merge-resolution-plan/#summary-table","title":"Summary Table","text":"File Main's Addition vnext's Change Resolution <code>agent_server.py</code> A2A agent card endpoint Async architecture, legacy aliases, WebSocket Keep vnext architecture, ADD A2A <code>bedrock.py</code> System prompt caching Modern type hints Keep vnext types, ADD caching <code>messages.py</code> File upload fields Platform context fields, session COMBINE both"},{"location":"plans/2025-02-05-merge-resolution-plan/#risk-assessment","title":"Risk Assessment","text":"Risk Likelihood Mitigation A2A endpoint breaks existing routes Low A2A uses <code>/.well-known/</code> path (standard, non-conflicting) Caching changes performance characteristics Low Caching is opt-in (<code>cache_system_prompt=False</code> default) New schema fields break serialization Low All new fields have defaults"},{"location":"plans/2025-02-05-merge-resolution-plan/#approval","title":"Approval","text":"<ul> <li> Plan reviewed and approved</li> <li> Ready to proceed with merge resolution</li> </ul>"},{"location":"plans/bedrock-prompt-caching-plan/","title":"Bedrock Prompt Caching Implementation Plan (Revised)","text":""},{"location":"plans/bedrock-prompt-caching-plan/#overview","title":"Overview","text":"<p>Feature: Add AWS Bedrock prompt caching support to DCAF agents Priority: Performance optimization Estimated Effort: 3-4 days (including testing and examples) Target Engineer Level: Junior Status: Experimental (v1) - Temporary implementation until Agno adds native support</p>"},{"location":"plans/bedrock-prompt-caching-plan/#background","title":"Background","text":""},{"location":"plans/bedrock-prompt-caching-plan/#what-is-prompt-caching","title":"What is Prompt Caching?","text":"<p>AWS Bedrock offers a feature called \"prompt caching\" that can significantly reduce latency and costs when the same prompt content is used repeatedly. Instead of re-processing the same text on every request, Bedrock caches it and reuses the computed result.</p> <p>Benefits: - Up to 90% cost reduction on cached tokens - Up to 85% latency reduction - 5-minute cache TTL (resets on each cache hit)</p>"},{"location":"plans/bedrock-prompt-caching-plan/#how-it-works","title":"How It Works","text":"<p>Bedrock uses \"cache checkpoints\" - markers you place in your request to indicate what should be cached:</p> <pre><code>{\n  \"system\": [\n    {\"text\": \"You are a helpful assistant...\"},\n    {\"cachePoint\": {\"type\": \"default\"}}\n  ],\n  \"messages\": [...]\n}\n</code></pre> <p>Everything before the <code>cachePoint</code> gets cached. Content after the checkpoint is processed fresh each time.</p>"},{"location":"plans/bedrock-prompt-caching-plan/#why-this-matters-for-dcaf","title":"Why This Matters for DCAF","text":"<p>DCAF agents typically have: - Static system prompts (instructions that don't change) - CACHEABLE \u2705 - Static tool definitions (same tools every request) - CACHEABLE \u2705 - Dynamic context (tenant, user, namespace) - NOT cacheable \u274c - User messages (different each turn) - NOT cacheable \u274c</p> <p>By caching the static parts, we can make agents faster and cheaper to run.</p>"},{"location":"plans/bedrock-prompt-caching-plan/#important-note","title":"Important Note","text":"<p>This is a temporary implementation. Agno is expected to add native prompt caching support in a future release. Once that's available, we'll remove this custom implementation and use Agno's built-in support.</p>"},{"location":"plans/bedrock-prompt-caching-plan/#requirements","title":"Requirements","text":""},{"location":"plans/bedrock-prompt-caching-plan/#functional-requirements","title":"Functional Requirements","text":"<ol> <li>FR-1: Developers can enable prompt caching on an Agent via <code>model_config</code></li> <li>FR-2: Developers can provide a static system prompt (cached) and dynamic context (not cached)</li> <li>FR-3: DCAF places a cache checkpoint between static and dynamic parts</li> <li>FR-4: Caching works with AWS Bedrock Claude models (3.5 Haiku, 3.7 Sonnet, etc.)</li> <li>FR-5: Existing agents without caching continue to work unchanged (backward compatible)</li> <li>FR-6: Cache performance metrics are logged when available</li> </ol>"},{"location":"plans/bedrock-prompt-caching-plan/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ol> <li>NFR-1: No breaking changes to existing Agent API</li> <li>NFR-2: Clear error messages if caching is misconfigured</li> <li>NFR-3: Extensive logging of cache-related information for debugging</li> <li>NFR-4: All caching logic stays within adapter implementation (not exposed in public API)</li> </ol>"},{"location":"plans/bedrock-prompt-caching-plan/#api-design","title":"API Design","text":""},{"location":"plans/bedrock-prompt-caching-plan/#basic-usage-simple-flag","title":"Basic Usage (Simple Flag)","text":"<pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    system=\"You are a Kubernetes expert...\",  # This gets cached\n    tools=[list_pods, delete_pod],\n    model_config={\n        \"cache_system_prompt\": True  # Enable caching\n    }\n)\n</code></pre>"},{"location":"plans/bedrock-prompt-caching-plan/#separating-static-and-dynamic-prompts","title":"Separating Static and Dynamic Prompts","text":"<p>This is the key pattern for effective caching:</p> <pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    # Static part - gets cached (same for every request)\n    system=\"You are a Kubernetes expert. Your job is to help users manage their clusters...\",\n\n    # Dynamic part - NOT cached (changes per request)\n    system_context=lambda ctx: f\"\"\"\n    Current tenant: {ctx.get('tenant_name', 'unknown')}\n    Namespace: {ctx.get('k8s_namespace', 'default')}\n    User: {ctx.get('user_email', 'anonymous')}\n    \"\"\",\n\n    tools=[list_pods, delete_pod],\n    model_config={\n        \"cache_system_prompt\": True\n    }\n)\n</code></pre> <p>Why separate them? - Even without caching, this is good design (separates static instructions from runtime context) - With caching, DCAF places a cache checkpoint between them automatically - Works gracefully with non-caching providers (they just concatenate)</p>"},{"location":"plans/bedrock-prompt-caching-plan/#how-platform_context-flows","title":"How platform_context Flows","text":"<pre><code># User request includes platform_context\n{\n  \"messages\": [...],\n  \"platform_context\": {\n    \"tenant_name\": \"acme-corp\",\n    \"k8s_namespace\": \"production\"\n  }\n}\n\n# Agent receives it and passes to system_context callable\nresult = agent.run(messages, context=platform_context)\n\n# system_context function is called with platform_context\n# Result is appended AFTER cache checkpoint\n</code></pre>"},{"location":"plans/bedrock-prompt-caching-plan/#implementation-tasks","title":"Implementation Tasks","text":""},{"location":"plans/bedrock-prompt-caching-plan/#task-1-update-agent-class-to-accept-system_context","title":"Task 1: Update Agent Class to Accept system_context","text":"<p>File: <code>dcaf/core/agent.py</code></p> <p>Purpose: Add <code>system_context</code> parameter to separate static and dynamic prompt parts.</p> <p>Changes Required:</p> <ol> <li> <p>Add import at top of file: <pre><code>from typing import Union, Callable\n</code></pre></p> </li> <li> <p>Update Agent.init signature: <pre><code>def __init__(\n    self,\n    # ... existing parameters ...\n    system: Optional[str] = None,\n\n    # NEW PARAMETER:\n    system_context: Optional[Union[str, Callable[[dict], str]]] = None,\n\n    # ... rest of existing parameters ...\n    model_config: Optional[dict] = None,  # Ensure this exists\n):\n</code></pre></p> </li> <li> <p>Add docstring for new parameter: <pre><code>\"\"\"\nArgs:\n    system: Static system prompt/instructions. When caching is enabled,\n            this content is cached for reuse across requests.\n\n    system_context: Dynamic context appended to system prompt. Can be:\n            - A string: Used as-is\n            - A callable: Called with platform_context dict, returns string\n            This content is NOT cached and is evaluated fresh each request.\n\n    model_config: Configuration passed to the model adapter. For caching:\n            {\"cache_system_prompt\": True}\n\"\"\"\n</code></pre></p> </li> <li> <p>Store the attributes: <pre><code>self._system = system\nself._system_context = system_context\nself._model_config = model_config or {}\n</code></pre></p> </li> <li> <p>Add method to build system prompt parts separately: <pre><code>def _build_system_parts(self, platform_context: Optional[dict] = None) -&gt; tuple[Optional[str], Optional[str]]:\n    \"\"\"\n    Build static and dynamic system prompt parts separately.\n\n    This separation is useful even without caching - it keeps static\n    instructions separate from runtime context. When caching is enabled,\n    adapters can place a cache checkpoint between these parts.\n\n    Args:\n        platform_context: Runtime context (tenant, namespace, etc.)\n\n    Returns:\n        (static_part, dynamic_part) where either can be None\n    \"\"\"\n    static = self._system\n\n    dynamic = None\n    if self._system_context:\n        if callable(self._system_context):\n            # Call the function with platform_context\n            dynamic = self._system_context(platform_context or {})\n        else:\n            # Use the string directly\n            dynamic = self._system_context\n\n    return static, dynamic\n</code></pre></p> </li> <li> <p>Update the agent execution flow to pass system parts to adapter:</p> </li> </ol> <p>Find the method where the agent invokes the runtime (likely <code>run()</code> or similar) and update it to pass the system parts:</p> <pre><code>def run(self, messages: list, context: dict = None) -&gt; AgentResult:\n    \"\"\"Execute the agent with the given messages.\"\"\"\n    platform_context = context or {}\n\n    # Build system prompt parts\n    static_system, dynamic_system = self._build_system_parts(platform_context)\n\n    # Pass to adapter with both parts\n    response = self._runtime.invoke(\n        messages=messages,\n        static_system=static_system,\n        dynamic_system=dynamic_system,\n        tools=self._tools,\n        # ... other params\n    )\n\n    return response\n</code></pre> <p>Note: The exact location will depend on current Agent implementation. Look for where <code>self._runtime</code> or the adapter is called.</p> <p>Acceptance Criteria: - [ ] <code>Agent(system=\"...\", system_context=\"...\")</code> stores both parts - [ ] <code>Agent(system=\"...\", system_context=lambda ctx: \"...\")</code> accepts callable - [ ] <code>agent._build_system_parts({})</code> returns tuple of (static, dynamic) - [ ] Callable context receives platform_context dict - [ ] Existing agents without <code>system_context</code> continue to work - [ ] <code>model_config</code> is stored and accessible</p>"},{"location":"plans/bedrock-prompt-caching-plan/#task-2-create-cachingawsbedrock-model-class","title":"Task 2: Create CachingAwsBedrock Model Class","text":"<p>File: <code>dcaf/core/adapters/outbound/agno/caching_bedrock.py</code> (new file)</p> <p>Purpose: Extend Agno's AwsBedrock to add cache checkpoints to requests.</p> <p>Important: This is a temporary workaround until Agno adds native caching support. Once Agno implements caching, we'll remove this class and use their implementation.</p> <pre><code>\"\"\"\nAWS Bedrock model with prompt caching support.\n\nTEMPORARY IMPLEMENTATION: This module extends Agno's AwsBedrock class to add \ncache checkpoints to system prompts. This is a workaround until Agno adds \nnative prompt caching support (expected in future release).\n\nOnce Agno supports caching natively, this module should be removed.\n\"\"\"\n\nfrom typing import Any, Dict, List, Optional, Tuple\nimport logging\n\nfrom agno.models.aws import AwsBedrock\nfrom agno.models.message import Message\n\nlogger = logging.getLogger(__name__)\n\n\nclass CachingAwsBedrock(AwsBedrock):\n    \"\"\"\n    AWS Bedrock model with prompt caching support.\n\n    This class extends AwsBedrock to add cache checkpoints to the system\n    prompt, enabling Bedrock's prompt caching feature for reduced latency\n    and cost.\n\n    TEMPORARY: Remove once Agno adds native caching support.\n\n    Attributes:\n        cache_system_prompt: Whether to add cache checkpoint to system prompt\n        static_system: Static portion of system prompt (cached)\n        dynamic_system: Dynamic portion of system prompt (not cached)\n\n    Example:\n        model = CachingAwsBedrock(\n            id=\"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n            cache_system_prompt=True,\n            static_system=\"You are a helpful assistant...\",\n            dynamic_system=\"Tenant: acme-corp\",\n        )\n    \"\"\"\n\n    # Minimum tokens required for caching (varies by model)\n    # Claude 3.7 Sonnet: 1024, Claude 3.5 Haiku: 2048\n    MIN_CACHE_TOKENS = 1024\n\n    def __init__(\n        self,\n        cache_system_prompt: bool = False,\n        static_system: Optional[str] = None,\n        dynamic_system: Optional[str] = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the caching Bedrock model.\n\n        Args:\n            cache_system_prompt: Whether to add cache checkpoint to system prompt\n            static_system: Static portion (cached)\n            dynamic_system: Dynamic portion (not cached)\n            **kwargs: Passed to parent AwsBedrock class\n        \"\"\"\n        super().__init__(**kwargs)\n        self._cache_system_prompt = cache_system_prompt\n        self._static_system = static_system\n        self._dynamic_system = dynamic_system\n\n        if cache_system_prompt:\n            logger.info(\n                f\"CachingAwsBedrock: Prompt caching enabled for model {self.id}\"\n            )\n\n    def _format_messages(\n        self, \n        messages: List[Message], \n        compress_tool_results: bool = False\n    ) -&gt; Tuple[List[Dict[str, Any]], Optional[List[Dict[str, Any]]]]:\n        \"\"\"\n        Format messages for the request, adding cache checkpoints.\n\n        This overrides the parent method to add a cachePoint to the\n        system message when caching is enabled.\n\n        Note: This override may be fragile if Agno updates their implementation.\n        Last verified compatible with: agno==0.6.x\n\n        Args:\n            messages: List of messages to format\n            compress_tool_results: Whether to compress tool results\n\n        Returns:\n            Tuple of (formatted_messages, system_message_with_cache)\n        \"\"\"\n        # Get the base formatted messages from parent\n        formatted_messages, system_message = super()._format_messages(\n            messages, compress_tool_results\n        )\n\n        # If we have static/dynamic parts, build custom system message\n        if self._static_system or self._dynamic_system:\n            system_message = self._build_cached_system_message()\n        elif self._cache_system_prompt and system_message:\n            # Just add checkpoint to existing system message\n            system_message = self._add_cache_checkpoint(system_message)\n\n        return formatted_messages, system_message\n\n    def _build_cached_system_message(self) -&gt; Optional[List[Dict[str, Any]]]:\n        \"\"\"\n        Build system message with cache checkpoint between static and dynamic parts.\n\n        Structure:\n        [\n            {\"text\": \"static content...\"},\n            {\"cachePoint\": {\"type\": \"default\"}},  # \u2190 Cache everything above\n            {\"text\": \"dynamic content...\"}\n        ]\n\n        Returns:\n            System message content blocks, or None if no content\n        \"\"\"\n        parts = []\n\n        # Add static part\n        if self._static_system:\n            # Check if it meets minimum token threshold\n            if self._cache_system_prompt and not self._check_token_threshold(self._static_system):\n                logger.warning(\n                    \"Static system prompt below minimum token threshold for caching. \"\n                    \"Caching disabled for this request.\"\n                )\n                # Disable caching for this request, just concatenate\n                combined = \"\\n\\n\".join([p for p in [self._static_system, self._dynamic_system] if p])\n                return [{\"text\": combined}] if combined else None\n\n            parts.append({\"text\": self._static_system})\n\n        # Add cache checkpoint (only if we have static content to cache)\n        if self._static_system and self._cache_system_prompt:\n            parts.append({\"cachePoint\": {\"type\": \"default\"}})\n            logger.debug(\n                f\"Added cache checkpoint after static system prompt \"\n                f\"(~{len(self._static_system)//4} tokens)\"\n            )\n\n        # Add dynamic part\n        if self._dynamic_system:\n            parts.append({\"text\": self._dynamic_system})\n            logger.debug(\n                f\"Added dynamic system context \"\n                f\"(~{len(self._dynamic_system)//4} tokens)\"\n            )\n\n        return parts if parts else None\n\n    def _add_cache_checkpoint(\n        self, \n        system_message: List[Dict[str, Any]]\n    ) -&gt; List[Dict[str, Any]]:\n        \"\"\"\n        Add a cache checkpoint to the system message.\n\n        The checkpoint is added after the text content, marking everything\n        before it as cacheable.\n\n        Args:\n            system_message: The system message content blocks\n\n        Returns:\n            System message with cache checkpoint appended\n\n        Example:\n            Input:  [{\"text\": \"You are a helpful assistant...\"}]\n            Output: [{\"text\": \"You are a helpful assistant...\"}, \n                     {\"cachePoint\": {\"type\": \"default\"}}]\n        \"\"\"\n        # Create a copy to avoid mutating the original\n        cached_system = list(system_message)\n\n        # Add the cache checkpoint at the end\n        cached_system.append({\n            \"cachePoint\": {\n                \"type\": \"default\"\n            }\n        })\n\n        logger.debug(\n            f\"Added cache checkpoint to system message \"\n            f\"({len(system_message)} content blocks)\"\n        )\n\n        return cached_system\n\n    def _check_token_threshold(self, text: str) -&gt; bool:\n        \"\"\"\n        Check if text meets minimum caching threshold.\n\n        Args:\n            text: The text to check\n\n        Returns:\n            True if text is long enough to cache, False otherwise\n        \"\"\"\n        # Rough estimate: 4 chars \u2248 1 token\n        estimated_tokens = len(text) // 4\n\n        if estimated_tokens &lt; self.MIN_CACHE_TOKENS:\n            logger.warning(\n                f\"System prompt (~{estimated_tokens} tokens) below minimum \"\n                f\"threshold ({self.MIN_CACHE_TOKENS} tokens). \"\n                f\"Consider longer instructions or disable caching.\"\n            )\n            return False\n\n        logger.info(\n            f\"System prompt (~{estimated_tokens} tokens) meets caching threshold\"\n        )\n        return True\n\n    def _log_cache_metrics(self, response: Dict[str, Any]) -&gt; None:\n        \"\"\"\n        Log cache performance metrics from Bedrock response.\n\n        Bedrock returns cache metrics in the response under 'usage':\n        - cacheReadInputTokens: Tokens retrieved from cache (cache HIT)\n        - cacheCreationInputTokens: Tokens cached for first time (cache MISS)\n\n        Args:\n            response: The Bedrock API response\n        \"\"\"\n        usage = response.get(\"usage\", {})\n        cache_hit = usage.get(\"cacheReadInputTokens\", 0)\n        cache_miss = usage.get(\"cacheCreationInputTokens\", 0)\n\n        if cache_hit &gt; 0:\n            logger.info(\n                f\"\u2705 Cache HIT: {cache_hit} tokens reused \"\n                f\"(~{cache_hit * 0.9:.0f}% cost reduction)\"\n            )\n        elif cache_miss &gt; 0:\n            logger.info(\n                f\"\ud83d\udcdd Cache MISS: {cache_miss} tokens cached for next request \"\n                f\"(cache created)\"\n            )\n        elif self._cache_system_prompt:\n            logger.warning(\n                \"\u26a0\ufe0f Caching enabled but no cache metrics in response. \"\n                \"Possible reasons: system prompt too short, caching not supported \"\n                \"by this model, or Bedrock API change.\"\n            )\n\n\n# Note: We intentionally don't export a create_caching_model() factory\n# to keep the public API simple. Adapter handles instantiation.\n</code></pre> <p>Acceptance Criteria: - [ ] <code>CachingAwsBedrock</code> extends <code>AwsBedrock</code> without breaking existing functionality - [ ] When <code>cache_system_prompt=True</code> and static_system provided, cache checkpoint is added - [ ] Cache checkpoint is placed BETWEEN static and dynamic parts - [ ] Original system message is not mutated (copy is made) - [ ] Token threshold is checked before enabling caching - [ ] Logging indicates when caching is enabled/disabled - [ ] Cache metrics are logged when available in response</p>"},{"location":"plans/bedrock-prompt-caching-plan/#task-3-update-agnoadapter-to-use-caching","title":"Task 3: Update AgnoAdapter to Use Caching","text":"<p>File: <code>dcaf/core/adapters/outbound/agno/adapter.py</code></p> <p>Purpose: Modify the adapter to use CachingAwsBedrock when caching is enabled.</p> <p>Changes Required:</p> <ol> <li> <p>Add import at top of file: <pre><code>from .caching_bedrock import CachingAwsBedrock\n</code></pre></p> </li> <li> <p>Update the method that creates the Bedrock model to check for caching config:</p> </li> </ol> <p>Find the method that creates the AwsBedrock instance (likely <code>_create_bedrock_model_async</code> or similar). Update it to conditionally use <code>CachingAwsBedrock</code>:</p> <pre><code>async def _create_bedrock_model_async(self, static_system=None, dynamic_system=None):\n    \"\"\"\n    Create an AWS Bedrock model with async session.\n\n    Args:\n        static_system: Static portion of system prompt (for caching)\n        dynamic_system: Dynamic portion of system prompt (for caching)\n    \"\"\"\n    import aioboto3\n\n    # ... existing session setup code ...\n\n    # Check if caching is enabled via model_config\n    cache_enabled = self._model_config.get(\"cache_system_prompt\", False)\n\n    # Log configuration\n    logger.info(\n        f\"Agno: Initialized Bedrock model {self._model_id} \"\n        f\"(temperature={self._temperature}, max_tokens={self._max_tokens}, \"\n        f\"cache_system_prompt={cache_enabled})\"\n    )\n\n    # Create the appropriate model\n    if cache_enabled:\n        logger.info(\"Using CachingAwsBedrock (temporary until Agno adds native support)\")\n        return CachingAwsBedrock(\n            id=self._model_id,\n            aws_region=region,\n            async_session=async_session,\n            temperature=self._temperature,\n            max_tokens=self._max_tokens,\n            cache_system_prompt=True,\n            static_system=static_system,\n            dynamic_system=dynamic_system,\n        )\n    else:\n        return AwsBedrock(\n            id=self._model_id,\n            aws_region=region,\n            async_session=async_session,\n            temperature=self._temperature,\n            max_tokens=self._max_tokens,\n        )\n</code></pre> <ol> <li>Update the <code>invoke</code> method to accept and pass through system parts:</li> </ol> <pre><code>def invoke(\n    self, \n    messages: List[Message],\n    static_system: Optional[str] = None,\n    dynamic_system: Optional[str] = None,\n    **kwargs\n) -&gt; AgentResponse:\n    \"\"\"\n    Invoke the model with messages.\n\n    Args:\n        messages: Conversation messages\n        static_system: Static portion of system prompt (cached)\n        dynamic_system: Dynamic portion of system prompt (not cached)\n        **kwargs: Additional arguments\n    \"\"\"\n    # If we need to recreate the model with new system parts\n    # (for caching), do so here\n    if static_system or dynamic_system:\n        # Store for model creation\n        self._static_system = static_system\n        self._dynamic_system = dynamic_system\n\n    # ... rest of invoke logic ...\n</code></pre> <p>Note: The exact implementation depends on how AgnoAdapter currently handles system prompts. You may need to: - Store static/dynamic parts as instance variables - Pass them when creating the model - Or handle them in the message formatting step</p> <p>Acceptance Criteria: - [ ] <code>AgnoAdapter</code> with <code>model_config={\"cache_system_prompt\": True}</code> uses <code>CachingAwsBedrock</code> - [ ] <code>AgnoAdapter</code> without cache config uses regular <code>AwsBedrock</code> - [ ] Static and dynamic system parts are passed to the model - [ ] Logging shows whether caching is enabled - [ ] All existing tests continue to pass</p>"},{"location":"plans/bedrock-prompt-caching-plan/#task-4-add-cache-metrics-logging-to-response-handling","title":"Task 4: Add Cache Metrics Logging to Response Handling","text":"<p>File: <code>dcaf/core/adapters/outbound/agno/caching_bedrock.py</code> (update)</p> <p>Purpose: Extract and log cache metrics from Bedrock responses.</p> <p>Changes Required:</p> <p>In the <code>CachingAwsBedrock</code> class, find where Bedrock responses are processed and add cache metrics logging:</p> <pre><code># In whatever method processes the Bedrock response\ndef _process_response(self, response: Dict[str, Any]) -&gt; Any:\n    \"\"\"Process Bedrock response.\"\"\"\n\n    # Log cache metrics if caching is enabled\n    if self._cache_system_prompt:\n        self._log_cache_metrics(response)\n\n    # ... rest of response processing ...\n</code></pre> <p>Note: The exact location depends on Agno's response handling flow. Look for where the raw Bedrock API response is received.</p> <p>If Agno doesn't expose the raw response with usage metrics, add a comment:</p> <pre><code># TODO: Cache metrics logging currently not available through Agno API\n# Once Agno exposes usage metrics, add logging here\n# Expected format: response['usage']['cacheReadInputTokens']\n</code></pre> <p>Acceptance Criteria: - [ ] Cache HIT is logged when tokens are reused - [ ] Cache MISS is logged when cache is created - [ ] Warning is logged if caching is enabled but no metrics returned - [ ] Logging includes token counts and cost savings estimate</p>"},{"location":"plans/bedrock-prompt-caching-plan/#task-5-add-unit-tests","title":"Task 5: Add Unit Tests","text":"<p>File: <code>tests/test_prompt_caching.py</code> (new file)</p> <pre><code>\"\"\"Tests for Bedrock prompt caching functionality.\"\"\"\n\nimport pytest\nfrom dcaf.core.adapters.outbound.agno.caching_bedrock import CachingAwsBedrock\n\n\nclass TestCachingAwsBedrock:\n    \"\"\"Tests for CachingAwsBedrock class.\"\"\"\n\n    def test_build_cached_system_message_static_only(self):\n        \"\"\"Static-only system message has checkpoint at end.\"\"\"\n        model = CachingAwsBedrock(\n            id=\"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n            cache_system_prompt=True,\n            static_system=\"Static instructions here.\" * 300,  # Make it long enough\n        )\n\n        result = model._build_cached_system_message()\n\n        assert len(result) == 2\n        assert result[0][\"text\"].startswith(\"Static instructions\")\n        assert result[1] == {\"cachePoint\": {\"type\": \"default\"}}\n\n    def test_build_cached_system_message_static_and_dynamic(self):\n        \"\"\"Static + dynamic has checkpoint between them.\"\"\"\n        model = CachingAwsBedrock(\n            id=\"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n            cache_system_prompt=True,\n            static_system=\"Static instructions.\" * 300,\n            dynamic_system=\"Dynamic context.\",\n        )\n\n        result = model._build_cached_system_message()\n\n        assert len(result) == 3\n        assert result[0][\"text\"].startswith(\"Static instructions\")\n        assert result[1] == {\"cachePoint\": {\"type\": \"default\"}}\n        assert result[2] == {\"text\": \"Dynamic context.\"}\n\n    def test_build_cached_system_message_dynamic_only(self):\n        \"\"\"Dynamic-only system message has no checkpoint.\"\"\"\n        model = CachingAwsBedrock(\n            id=\"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n            cache_system_prompt=True,\n            dynamic_system=\"Dynamic context only.\",\n        )\n\n        result = model._build_cached_system_message()\n\n        assert len(result) == 1\n        assert result[0] == {\"text\": \"Dynamic context only.\"}\n        # No cache checkpoint - nothing static to cache\n\n    def test_add_cache_checkpoint(self):\n        \"\"\"Cache checkpoint is added to system message.\"\"\"\n        model = CachingAwsBedrock(\n            id=\"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n            cache_system_prompt=True,\n        )\n\n        system_message = [{\"text\": \"You are a helpful assistant.\" * 300}]\n        result = model._add_cache_checkpoint(system_message)\n\n        assert len(result) == 2\n        assert result[0][\"text\"].startswith(\"You are a helpful assistant\")\n        assert result[1] == {\"cachePoint\": {\"type\": \"default\"}}\n\n    def test_add_cache_checkpoint_does_not_mutate_original(self):\n        \"\"\"Original system message is not modified.\"\"\"\n        model = CachingAwsBedrock(\n            id=\"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n            cache_system_prompt=True,\n        )\n\n        original = [{\"text\": \"You are a helpful assistant.\"}]\n        original_copy = list(original)\n\n        model._add_cache_checkpoint(original)\n\n        assert original == original_copy  # Original unchanged\n\n    def test_check_token_threshold_below_minimum(self):\n        \"\"\"Short text below threshold returns False.\"\"\"\n        model = CachingAwsBedrock(\n            id=\"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n            cache_system_prompt=True,\n        )\n\n        short_text = \"Too short\"\n        result = model._check_token_threshold(short_text)\n\n        assert result is False\n\n    def test_check_token_threshold_above_minimum(self):\n        \"\"\"Long text above threshold returns True.\"\"\"\n        model = CachingAwsBedrock(\n            id=\"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n            cache_system_prompt=True,\n        )\n\n        # Create text with ~2000 tokens (8000 chars)\n        long_text = \"This is a long system prompt. \" * 270\n        result = model._check_token_threshold(long_text)\n\n        assert result is True\n\n    def test_log_cache_metrics_cache_hit(self, caplog):\n        \"\"\"Cache HIT is logged correctly.\"\"\"\n        model = CachingAwsBedrock(\n            id=\"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n            cache_system_prompt=True,\n        )\n\n        response = {\n            \"usage\": {\n                \"inputTokens\": 100,\n                \"outputTokens\": 50,\n                \"cacheReadInputTokens\": 950,\n            }\n        }\n\n        model._log_cache_metrics(response)\n\n        assert \"Cache HIT\" in caplog.text\n        assert \"950 tokens\" in caplog.text\n\n    def test_log_cache_metrics_cache_miss(self, caplog):\n        \"\"\"Cache MISS is logged correctly.\"\"\"\n        model = CachingAwsBedrock(\n            id=\"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n            cache_system_prompt=True,\n        )\n\n        response = {\n            \"usage\": {\n                \"inputTokens\": 1000,\n                \"outputTokens\": 50,\n                \"cacheCreationInputTokens\": 950,\n            }\n        }\n\n        model._log_cache_metrics(response)\n\n        assert \"Cache MISS\" in caplog.text\n        assert \"950 tokens\" in caplog.text\n\n\nclass TestAgentWithCaching:\n    \"\"\"Tests for Agent class with caching enabled.\"\"\"\n\n    def test_agent_build_system_parts_static_only(self):\n        \"\"\"Build system parts with static content only.\"\"\"\n        from dcaf.core import Agent\n\n        agent = Agent(system=\"Static instructions\")\n\n        static, dynamic = agent._build_system_parts({})\n\n        assert static == \"Static instructions\"\n        assert dynamic is None\n\n    def test_agent_build_system_parts_with_context_string(self):\n        \"\"\"Build system parts with static + string context.\"\"\"\n        from dcaf.core import Agent\n\n        agent = Agent(\n            system=\"Static instructions\",\n            system_context=\"Dynamic context\",\n        )\n\n        static, dynamic = agent._build_system_parts({})\n\n        assert static == \"Static instructions\"\n        assert dynamic == \"Dynamic context\"\n\n    def test_agent_build_system_parts_with_context_callable(self):\n        \"\"\"Build system parts with static + callable context.\"\"\"\n        from dcaf.core import Agent\n\n        agent = Agent(\n            system=\"Static instructions\",\n            system_context=lambda ctx: f\"Tenant: {ctx.get('tenant', 'unknown')}\",\n        )\n\n        static, dynamic = agent._build_system_parts({\"tenant\": \"acme\"})\n\n        assert static == \"Static instructions\"\n        assert dynamic == \"Tenant: acme\"\n\n    def test_agent_with_model_config_caching(self):\n        \"\"\"Agent with cache in model_config.\"\"\"\n        from dcaf.core import Agent\n\n        agent = Agent(\n            system=\"Test prompt\",\n            model_config={\"cache_system_prompt\": True}\n        )\n\n        assert agent._model_config.get(\"cache_system_prompt\") is True\n\n    def test_agent_without_caching(self):\n        \"\"\"Agent without caching config.\"\"\"\n        from dcaf.core import Agent\n\n        agent = Agent(system=\"Test prompt\")\n\n        assert agent._model_config.get(\"cache_system_prompt\", False) is False\n</code></pre> <p>Acceptance Criteria: - [ ] All tests pass - [ ] Tests cover cache checkpoint placement - [ ] Tests cover static + dynamic prompt building - [ ] Tests verify original data is not mutated - [ ] Tests verify token threshold checking - [ ] Tests verify cache metrics logging</p>"},{"location":"plans/bedrock-prompt-caching-plan/#task-6-create-example-application","title":"Task 6: Create Example Application","text":"<p>File: <code>examples/prompt_caching_example.py</code> (new file)</p> <pre><code>\"\"\"\nExample: Using Bedrock Prompt Caching with DCAF\n\nThis example demonstrates how to use prompt caching to reduce costs and latency\nwhen working with agents that have static instructions and dynamic context.\n\"\"\"\n\nfrom dcaf.core import Agent, tool\nimport logging\n\n# Enable detailed logging to see cache metrics\nlogging.basicConfig(level=logging.INFO)\n\n# Define some example tools\n@tool(description=\"List all Kubernetes pods in a namespace\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    \"\"\"List pods (simulated).\"\"\"\n    return f\"Pods in {namespace}: pod-1, pod-2, pod-3\"\n\n@tool(description=\"Get details about a specific pod\")\ndef get_pod(name: str, namespace: str = \"default\") -&gt; str:\n    \"\"\"Get pod details (simulated).\"\"\"\n    return f\"Pod {name} in {namespace}: Running, 2 containers\"\n\n\n# Example 1: Basic caching with static prompt only\ndef example_basic_caching():\n    \"\"\"Simple caching example with just a static prompt.\"\"\"\n    print(\"\\n=== Example 1: Basic Caching ===\\n\")\n\n    agent = Agent(\n        system=\"\"\"\n        You are a Kubernetes expert assistant. Your role is to help users\n        manage their Kubernetes clusters safely and efficiently.\n\n        Guidelines:\n        - Always verify namespace before operations\n        - Explain what each command does\n        - Ask for confirmation on destructive operations\n        - Use kubectl best practices\n        - Provide helpful error messages\n\n        (Add more detailed instructions here to exceed 1024 tokens for caching)\n        \"\"\" * 3,  # Repeat to exceed minimum token threshold\n\n        tools=[list_pods, get_pod],\n\n        model_config={\n            \"cache_system_prompt\": True  # Enable caching\n        }\n    )\n\n    # First request - cache MISS (creates cache)\n    print(\"First request (cache MISS):\")\n    result1 = agent.run([{\"role\": \"user\", \"content\": \"List pods\"}])\n    print(f\"Response: {result1.text}\\n\")\n\n    # Second request - cache HIT (reuses cache)\n    print(\"Second request (cache HIT):\")\n    result2 = agent.run([{\"role\": \"user\", \"content\": \"Get details for pod-1\"}])\n    print(f\"Response: {result2.text}\\n\")\n\n    print(\"Check logs above for cache HIT/MISS indicators\")\n\n\n# Example 2: Static instructions + dynamic context\ndef example_static_and_dynamic():\n    \"\"\"Caching with separated static and dynamic parts.\"\"\"\n    print(\"\\n=== Example 2: Static + Dynamic Context ===\\n\")\n\n    agent = Agent(\n        # Static part - cached (same for all requests)\n        system=\"\"\"\n        You are a Kubernetes expert assistant for a multi-tenant platform.\n\n        Your responsibilities:\n        - Help users manage pods, services, and deployments\n        - Ensure operations are scoped to the correct tenant and namespace\n        - Follow security best practices\n        - Provide clear explanations\n\n        Guidelines:\n        - Always check tenant context before operations\n        - Verify namespace matches tenant configuration\n        - Ask for confirmation on destructive operations\n        - Log all operations for audit trail\n\n        (Add detailed instructions to exceed 1024 tokens)\n        \"\"\" * 3,\n\n        # Dynamic part - NOT cached (changes per request)\n        system_context=lambda ctx: f\"\"\"\n        === CURRENT CONTEXT ===\n        Tenant: {ctx.get('tenant_name', 'unknown')}\n        Namespace: {ctx.get('k8s_namespace', 'default')}\n        User: {ctx.get('user_email', 'anonymous')}\n        Environment: {ctx.get('environment', 'production')}\n\n        You MUST scope all operations to the above context.\n        \"\"\",\n\n        tools=[list_pods, get_pod],\n\n        model_config={\n            \"cache_system_prompt\": True\n        }\n    )\n\n    # Request 1: Tenant A\n    print(\"Request for Tenant A:\")\n    context_a = {\n        \"tenant_name\": \"acme-corp\",\n        \"k8s_namespace\": \"acme-prod\",\n        \"user_email\": \"alice@acme.com\",\n        \"environment\": \"production\"\n    }\n    result1 = agent.run(\n        [{\"role\": \"user\", \"content\": \"List all pods\"}],\n        context=context_a\n    )\n    print(f\"Response: {result1.text}\\n\")\n\n    # Request 2: Tenant B (cache HIT for static, fresh dynamic)\n    print(\"Request for Tenant B:\")\n    context_b = {\n        \"tenant_name\": \"widgets-inc\",\n        \"k8s_namespace\": \"widgets-dev\",\n        \"user_email\": \"bob@widgets.com\",\n        \"environment\": \"development\"\n    }\n    result2 = agent.run(\n        [{\"role\": \"user\", \"content\": \"Show pod-1 details\"}],\n        context=context_b\n    )\n    print(f\"Response: {result2.text}\\n\")\n\n    print(\"Static instructions are cached, dynamic context is fresh each time\")\n\n\n# Example 3: Cost comparison (conceptual)\ndef example_cost_comparison():\n    \"\"\"Show the cost impact of caching.\"\"\"\n    print(\"\\n=== Example 3: Cost Impact ===\\n\")\n\n    # Simulated token counts\n    static_tokens = 1500  # Long system prompt\n    dynamic_tokens = 100   # Short context\n\n    print(\"Without caching:\")\n    print(f\"  Per request: {static_tokens + dynamic_tokens} input tokens\")\n    print(f\"  100 requests: {(static_tokens + dynamic_tokens) * 100} tokens\")\n    print(f\"  Approx cost: ${((static_tokens + dynamic_tokens) * 100) * 0.000003:.4f}\")\n\n    print(\"\\nWith caching:\")\n    print(f\"  First request: {static_tokens + dynamic_tokens} tokens (cache MISS)\")\n    print(f\"  Subsequent 99: {dynamic_tokens * 99} tokens (cache HIT)\")\n    print(f\"  Total: {static_tokens + dynamic_tokens + (dynamic_tokens * 99)} tokens\")\n    print(f\"  Approx cost: ${(static_tokens + dynamic_tokens + (dynamic_tokens * 99)) * 0.000003:.4f}\")\n\n    savings = 100 - ((static_tokens + dynamic_tokens + (dynamic_tokens * 99)) / \n                     ((static_tokens + dynamic_tokens) * 100) * 100)\n    print(f\"\\n  Savings: ~{savings:.1f}%\")\n\n\nif __name__ == \"__main__\":\n    print(\"Bedrock Prompt Caching Examples\")\n    print(\"=\" * 50)\n\n    # Run examples\n    example_basic_caching()\n    example_static_and_dynamic()\n    example_cost_comparison()\n\n    print(\"\\n\" + \"=\" * 50)\n    print(\"Examples complete!\")\n    print(\"\\nKey takeaways:\")\n    print(\"1. Enable caching with model_config={'cache_system_prompt': True}\")\n    print(\"2. Separate static (cached) and dynamic (fresh) content\")\n    print(\"3. Ensure static content exceeds 1024 tokens for best results\")\n    print(\"4. Monitor logs for cache HIT/MISS indicators\")\n</code></pre> <p>Acceptance Criteria: - [ ] Example runs without errors - [ ] Shows basic caching usage - [ ] Shows static/dynamic separation - [ ] Demonstrates cost savings - [ ] Includes helpful comments and explanations</p>"},{"location":"plans/bedrock-prompt-caching-plan/#task-7-update-documentation","title":"Task 7: Update Documentation","text":"<p>File: <code>docs/guides/prompt-caching.md</code> (new file)</p> <p><pre><code># Bedrock Prompt Caching Guide\n\n## Overview\n\nAWS Bedrock's prompt caching feature can reduce costs by up to 90% and latency by up to 85% for agents with static instructions and dynamic context.\n\n**Status**: Experimental (v1) - Temporary implementation until Agno adds native support\n\n## How It Works\n\nWhen you enable caching, DCAF places a \"cache checkpoint\" in your system prompt. Everything before the checkpoint is cached by Bedrock for 5 minutes (TTL resets on each use).\n</code></pre> [Static Instructions] \u2190 CACHED       \u2193 [Cache Checkpoint]       \u2193 [Dynamic Context]     \u2190 NOT cached (fresh each time) <pre><code>## Quick Start\n\n### Basic Usage\n\n```python\nfrom dcaf.core import Agent\n\nagent = Agent(\n    system=\"You are a Kubernetes expert... [long instructions]\",\n    tools=[list_pods, delete_pod],\n    model_config={\n        \"cache_system_prompt\": True\n    }\n)\n</code></pre></p>"},{"location":"plans/bedrock-prompt-caching-plan/#separating-static-and-dynamic-content","title":"Separating Static and Dynamic Content","text":"<p>For maximum benefit, separate static instructions from dynamic context:</p> <pre><code>agent = Agent(\n    # Static - cached\n    system=\"You are a Kubernetes expert...\",\n\n    # Dynamic - NOT cached\n    system_context=lambda ctx: f\"Tenant: {ctx['tenant']}\\nNamespace: {ctx['namespace']}\",\n\n    model_config={\n        \"cache_system_prompt\": True\n    }\n)\n</code></pre>"},{"location":"plans/bedrock-prompt-caching-plan/#requirements_1","title":"Requirements","text":""},{"location":"plans/bedrock-prompt-caching-plan/#minimum-token-count","title":"Minimum Token Count","text":"<p>Your static system prompt must be at least: - Claude 3.7 Sonnet: 1024 tokens - Claude 3.5 Haiku: 2048 tokens</p> <p>If below threshold, caching is automatically disabled with a warning log.</p> <p>Rule of thumb: ~4 characters = 1 token, so aim for 4000+ character prompts.</p>"},{"location":"plans/bedrock-prompt-caching-plan/#best-practices","title":"Best Practices","text":""},{"location":"plans/bedrock-prompt-caching-plan/#1-put-static-content-first","title":"1. Put Static Content First","text":"<p>\u2705 Good: Static instructions, then dynamic context <pre><code>system=\"You are a K8s expert. [lengthy guidelines]\"\nsystem_context=\"Current tenant: acme-corp\"\n</code></pre></p> <p>\u274c Bad: Mixing static and dynamic <pre><code>system=\"You are a K8s expert for tenant: acme-corp. [guidelines]\"\n</code></pre></p>"},{"location":"plans/bedrock-prompt-caching-plan/#2-make-static-content-detailed","title":"2. Make Static Content Detailed","text":"<p>The more static content you cache, the bigger the savings:</p> <p>\u2705 Good: Detailed instructions (1500+ tokens) <pre><code>system=\"\"\"\nYou are a Kubernetes expert assistant.\n\nGuidelines:\n- Always verify namespace before operations\n- Explain commands clearly\n- Ask for confirmation on destructive operations\n- Follow kubectl best practices\n- Provide helpful error messages\n\n[More detailed guidelines...]\n\"\"\"\n</code></pre></p> <p>\u274c Bad: Brief instructions (50 tokens) <pre><code>system=\"You are a helpful Kubernetes assistant.\"\n</code></pre></p>"},{"location":"plans/bedrock-prompt-caching-plan/#3-use-callable-for-dynamic-context","title":"3. Use Callable for Dynamic Context","text":"<p>For runtime data, use a lambda or function:</p> <pre><code>system_context=lambda ctx: f\"\"\"\nTenant: {ctx.get('tenant_name')}\nNamespace: {ctx.get('k8s_namespace')}\nUser: {ctx.get('user_email')}\n\"\"\"\n</code></pre>"},{"location":"plans/bedrock-prompt-caching-plan/#monitoring","title":"Monitoring","text":""},{"location":"plans/bedrock-prompt-caching-plan/#cache-performance-logs","title":"Cache Performance Logs","text":"<p>DCAF logs cache performance when available:</p> <pre><code>INFO: \u2705 Cache HIT: 950 tokens reused (~90% cost reduction)\nINFO: \ud83d\udcdd Cache MISS: 950 tokens cached for next request (cache created)\n</code></pre>"},{"location":"plans/bedrock-prompt-caching-plan/#first-request-is-always-a-miss","title":"First Request is Always a MISS","text":"<p>The first request creates the cache (MISS). Subsequent requests within 5 minutes are HITs:</p> <pre><code>Request 1: MISS (creates cache)  \u2192 Full cost\nRequest 2: HIT  (uses cache)     \u2192 10% cost\nRequest 3: HIT  (uses cache)     \u2192 10% cost\n...\nRequest N: MISS (cache expired)  \u2192 Full cost\n</code></pre>"},{"location":"plans/bedrock-prompt-caching-plan/#troubleshooting","title":"Troubleshooting","text":""},{"location":"plans/bedrock-prompt-caching-plan/#no-cache-metrics-in-logs","title":"No Cache Metrics in Logs","text":"<p>Symptom: Caching enabled but no \"Cache HIT/MISS\" logs</p> <p>Possible causes: 1. System prompt below minimum token threshold 2. Model doesn't support caching 3. Bedrock API change</p> <p>Solution: Check logs for warnings about token threshold</p>"},{"location":"plans/bedrock-prompt-caching-plan/#caching-not-enabled","title":"Caching Not Enabled","text":"<p>Symptom: No cache-related logs at all</p> <p>Checklist: - [ ] <code>model_config={\"cache_system_prompt\": True}</code> set? - [ ] Using Bedrock provider (not OpenAI)? - [ ] Using supported model (Claude 3.5/3.7)?</p>"},{"location":"plans/bedrock-prompt-caching-plan/#cost-comparison","title":"Cost Comparison","text":""},{"location":"plans/bedrock-prompt-caching-plan/#example-scenario","title":"Example Scenario","text":"<ul> <li>Static prompt: 1500 tokens</li> <li>Dynamic context: 100 tokens</li> <li>100 requests</li> </ul> <p>Without caching: - Per request: 1600 tokens - Total: 160,000 tokens - Cost: ~$0.48</p> <p>With caching: - First request: 1600 tokens (MISS) - Next 99 requests: 100 tokens each (HIT) - Total: 11,500 tokens - Cost: ~$0.035</p> <p>Savings: ~93% \ud83d\udcb0</p>"},{"location":"plans/bedrock-prompt-caching-plan/#supported-models","title":"Supported Models","text":"<p>Prompt caching is supported on: - <code>anthropic.claude-3-7-sonnet-20250219-v1:0</code> - <code>anthropic.claude-3-5-sonnet-20241022-v2:0</code> - <code>anthropic.claude-3-5-haiku-20241022-v1:0</code></p>"},{"location":"plans/bedrock-prompt-caching-plan/#when-not-to-use-caching","title":"When NOT to Use Caching","text":"<p>\u274c Don't use caching when: - System prompt changes frequently - System prompt is very short (&lt;1024 tokens) - Low request volume (cache expires between requests) - Using non-Bedrock providers</p> <p>\u2705 DO use caching when: - Long, static system prompts - High request volume (multiple requests per 5 minutes) - Multi-tenant scenarios (static instructions, dynamic tenant context)</p>"},{"location":"plans/bedrock-prompt-caching-plan/#future-plans","title":"Future Plans","text":"<p>This is a temporary implementation. Once Agno adds native prompt caching support, we'll migrate to their implementation and remove the custom code.</p>"},{"location":"plans/bedrock-prompt-caching-plan/#related-documentation","title":"Related Documentation","text":"<p>See the DCAF documentation for more information. <pre><code>**File**: `docs/api-reference/agents.md` (update)\n\nAdd to the Agent class documentation:\n\n```markdown\n### system_context\n\nOptional dynamic context appended to the system prompt.\n\n**Type**: `Optional[Union[str, Callable[[dict], str]]]`\n\n**Purpose**: Separate dynamic runtime data from static instructions. When caching is enabled, this content is NOT cached and is evaluated fresh each request.\n\n**Examples**:\n\n```python\n# String\nagent = Agent(\n    system=\"Static instructions\",\n    system_context=\"Tenant: acme-corp\"\n)\n\n# Callable\nagent = Agent(\n    system=\"Static instructions\",\n    system_context=lambda ctx: f\"Tenant: {ctx['tenant']}\"\n)\n</code></pre></p>"},{"location":"plans/bedrock-prompt-caching-plan/#model_config","title":"model_config","text":"<p>Configuration passed to the model adapter.</p> <p>Type: <code>Optional[dict]</code></p> <p>Caching Options: - <code>cache_system_prompt</code> (bool): Enable Bedrock prompt caching. Requires static system prompt \u22651024 tokens.</p> <p>Example:</p> <p><pre><code>agent = Agent(\n    system=\"Long static instructions...\",\n    model_config={\n        \"cache_system_prompt\": True\n    }\n)\n</code></pre> <pre><code>**Acceptance Criteria**:\n- [ ] Guide explains what caching is and how it works\n- [ ] Guide shows when to use and not use caching\n- [ ] Guide includes troubleshooting section\n- [ ] Guide includes cost comparison\n- [ ] API reference documents new parameters\n\n---\n\n## Testing Strategy\n\n### Unit Tests\n- Cache checkpoint placement in system messages\n- Static + dynamic prompt combination\n- Token threshold checking\n- Cache metrics logging\n- Agent parameter handling\n\n### Integration Tests\n- End-to-end test with mock Bedrock client\n- Verify cache checkpoint appears in actual request\n- Test with real Bedrock (optional, in dev environment)\n\n### Manual Testing\n\n1. **Create test agent**:\n```python\nagent = Agent(\n    system=\"...\" * 300,  # Long prompt\n    system_context=lambda ctx: f\"Tenant: {ctx['tenant']}\",\n    model_config={\"cache_system_prompt\": True}\n)\n</code></pre></p> <ol> <li> <p>Make first request - look for \"Cache MISS\" in logs</p> </li> <li> <p>Make second request - look for \"Cache HIT\" in logs</p> </li> <li> <p>Check Bedrock console - verify requests include <code>cachePoint</code></p> </li> </ol>"},{"location":"plans/bedrock-prompt-caching-plan/#rollout-plan","title":"Rollout Plan","text":"<ol> <li>Phase 1 (Day 1): </li> <li>Task 1: Update Agent class</li> <li> <p>Task 2: Create CachingAwsBedrock</p> </li> <li> <p>Phase 2 (Day 2):</p> </li> <li>Task 3: Update AgnoAdapter</li> <li>Task 4: Add cache metrics logging</li> <li> <p>Task 5: Unit tests</p> </li> <li> <p>Phase 3 (Day 3):</p> </li> <li>Task 6: Example application</li> <li>Task 7: Documentation</li> <li> <p>Manual testing with real Bedrock</p> </li> <li> <p>Phase 4 (Day 4):</p> </li> <li>Code review</li> <li>Integration testing</li> <li>Documentation review</li> </ol>"},{"location":"plans/bedrock-prompt-caching-plan/#success-criteria","title":"Success Criteria","text":"<ul> <li> <code>Agent(model_config={\"cache_system_prompt\": True})</code> enables caching</li> <li> <code>Agent(system=\"...\", system_context=\"...\")</code> correctly separates cached/uncached content</li> <li> Bedrock requests include <code>cachePoint</code> when caching is enabled</li> <li> Cache metrics are logged when available in Bedrock responses</li> <li> Token threshold is checked with appropriate warnings</li> <li> All existing tests pass (no regressions)</li> <li> New tests cover caching functionality</li> <li> Example application demonstrates usage</li> <li> Documentation is clear for new users</li> </ul>"},{"location":"plans/bedrock-prompt-caching-plan/#questions-for-tech-lead","title":"Questions for Tech Lead","text":"<ol> <li> <p>Should we log cache hit/miss metrics from Bedrock responses?    \u2192 YES - if available through Agno</p> </li> <li> <p>Should we warn if system prompt is below minimum token count?    \u2192 YES - warn and skip caching</p> </li> <li> <p>Should we support tool definition caching in v1 or defer to v2?    \u2192 DEFER to v2 (experimental only)</p> </li> <li> <p>Where exactly in Agent is the runtime called?    \u2192 Need to identify in current implementation</p> </li> <li> <p>Does Agno expose Bedrock response metrics?    \u2192 Need to verify in Agno source</p> </li> </ol>"},{"location":"plans/bedrock-prompt-caching-plan/#resources","title":"Resources","text":"<ul> <li>AWS Bedrock Prompt Caching Docs</li> <li>Agno AwsBedrock Source</li> </ul>"},{"location":"plans/bedrock-prompt-caching-plan/#notes","title":"Notes","text":"<ul> <li>This is a temporary implementation until Agno adds native caching support</li> <li>All caching logic is internal to adapters (not exposed in public API)</li> <li>Caching is always opt-in via <code>model_config</code></li> <li>Extensive logging for debugging and monitoring</li> <li>Token threshold checked automatically with warnings</li> </ul>"},{"location":"plans/message-response-gap-analysis/","title":"Message &amp; Response Gap Analysis","text":"<p>Date: January 8, 2026 Purpose: Analyze the gaps between schema's <code>AgentMessage</code> and core's response classes</p>"},{"location":"plans/message-response-gap-analysis/#overview","title":"Overview","text":"<p>The schema and core have intentionally different message/response structures because they serve different architectural purposes:</p> Layer Classes Purpose Schema (Wire Format) <code>Message</code>, <code>UserMessage</code>, <code>AgentMessage</code> HelpDesk protocol serialization Core (User API) <code>AgentResponse</code> (agent.py) Simple API for <code>Agent.run()</code> Core (Application) <code>AgentResponse</code> (dto/responses.py) Internal application DTO Core (Custom Functions) <code>AgentResult</code> (primitives.py) Return type for custom agent functions"},{"location":"plans/message-response-gap-analysis/#side-by-side-comparison","title":"Side-by-Side Comparison","text":""},{"location":"plans/message-response-gap-analysis/#schemas-agentmessage-wire-format","title":"Schema's AgentMessage (Wire Format)","text":"<pre><code># dcaf/schemas/messages.py\nclass Message(BaseModel):\n    role: Literal[\"user\", \"assistant\"]\n    content: str = \"\"\n    data: Data = Field(default_factory=Data)\n    meta_data: Dict[str, Any] = Field(default_factory=dict)\n    timestamp: Optional[datetime] = None\n    user: Optional[User] = None\n    agent: Optional[Agent] = None\n\nclass AgentMessage(Message):\n    role: Literal[\"assistant\"] = \"assistant\"\n</code></pre> <p>Purpose: Serialization format for HelpDesk API Type: Pydantic BaseModel (validation, JSON schema) Usage: HTTP requests/responses, message history storage</p>"},{"location":"plans/message-response-gap-analysis/#cores-agentresponse-user-facing-api","title":"Core's AgentResponse (User-Facing API)","text":"<pre><code># dcaf/core/agent.py\n@dataclass\nclass AgentResponse:\n    text: str | None = None\n    needs_approval: bool = False\n    pending_tools: list[PendingToolCall] = field(default_factory=list)\n    conversation_id: str = \"\"\n    is_complete: bool = True\n    _agent: \"Agent\" = field(repr=False, default=None)\n\n    def approve_all(self) -&gt; \"AgentResponse\": ...\n    def reject_all(self, reason: str) -&gt; \"AgentResponse\": ...\n</code></pre> <p>Purpose: Simple, Pythonic API for end users Type: Python dataclass with behavior Usage: Return value from <code>Agent.run()</code></p> <p>Example: <pre><code>response = agent.run(messages)\nif response.needs_approval:\n    response = response.approve_all()\nprint(response.text)\n</code></pre></p>"},{"location":"plans/message-response-gap-analysis/#cores-agentresponse-application-dto","title":"Core's AgentResponse (Application DTO)","text":"<pre><code># dcaf/core/application/dto/responses.py\n@dataclass\nclass AgentResponse:\n    conversation_id: str\n    text: Optional[str] = None\n    data: DataDTO = field(default_factory=DataDTO)\n    has_pending_approvals: bool = False\n    is_complete: bool = True\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def to_dict(self) -&gt; Dict[str, Any]: ...\n    def to_helpdesk_message(self, role: str = \"assistant\") -&gt; Dict[str, Any]: ...\n</code></pre> <p>Purpose: Internal application layer DTO for Clean Architecture Type: Python dataclass with serialization Usage: Between application services and adapters</p>"},{"location":"plans/message-response-gap-analysis/#cores-agentresult-custom-agent-functions","title":"Core's AgentResult (Custom Agent Functions)","text":"<pre><code># dcaf/core/primitives.py\n@dataclass\nclass AgentResult:\n    text: str = \"\"\n    pending_tools: list[ToolApproval] = field(default_factory=list)\n    executed_tools: list[ToolResult] = field(default_factory=list)\n    metadata: dict[str, Any] = field(default_factory=dict)\n\n    @property\n    def needs_approval(self) -&gt; bool:\n        return len(self.pending_tools) &gt; 0\n</code></pre> <p>Purpose: Return type for custom multi-call agent functions Type: Python dataclass (simple) Usage: User-defined agent functions with <code>serve(my_agent)</code></p> <p>Example: <pre><code>def my_agent(messages: list, context: dict) -&gt; AgentResult:\n    classifier = Agent(system=\"Classify intent\")\n    executor = Agent(tools=[delete_pod])\n\n    intent = classifier.run(messages)\n    if \"action\" in intent.text:\n        result = executor.run(messages)\n        return from_agent_response(result)\n\n    return AgentResult(text=intent.text)\n</code></pre></p>"},{"location":"plans/message-response-gap-analysis/#key-gaps-reasoning","title":"Key Gaps &amp; Reasoning","text":""},{"location":"plans/message-response-gap-analysis/#gap-1-message-metadata","title":"Gap 1: Message Metadata","text":"Field Schema's AgentMessage Core Responses Reason for Gap <code>timestamp</code> \u2705 Yes \u274c No Core generates fresh; schema stores for history <code>user</code> \u2705 Yes (<code>User</code> object) \u274c No Not needed in response; part of request context <code>agent</code> \u2705 Yes (<code>Agent</code> object) \u274c No Agent identity implicit; not needed in single-agent scenarios <p>Reasoning: - Schema needs these for wire format - when storing/retrieving conversation history, timestamps and identity matter - Core doesn't need them in-memory - the response is generated \"now\" by \"this agent\" - adding fields would be redundant - Clean separation of concerns - request context (who's asking) vs response (what to do)</p>"},{"location":"plans/message-response-gap-analysis/#gap-2-role-field","title":"Gap 2: Role Field","text":"Class Has <code>role</code> field? Value Reason Schema's <code>AgentMessage</code> \u2705 Yes <code>\"assistant\"</code> HelpDesk protocol requirement Core's <code>AgentResponse</code> (agent.py) \u274c No N/A Not needed - always from agent Core's <code>AgentResponse</code> (dto) \u274c No N/A Added in <code>to_helpdesk_message()</code> Core's <code>AgentResult</code> \u274c No N/A Not needed - always from agent <p>Reasoning: - Schema is neutral wire format - needs explicit role because messages can be user or assistant - Core responses are type-safe - <code>AgentResponse</code> is inherently from the agent, so <code>role</code> would be redundant - Added at serialization boundary - <code>to_helpdesk_message()</code> adds <code>role=\"assistant\"</code> when converting to wire format</p>"},{"location":"plans/message-response-gap-analysis/#gap-3-data-structure","title":"Gap 3: Data Structure","text":"Class Data Container Contents Schema's <code>AgentMessage</code> <code>Data</code> (Pydantic) <code>cmds</code>, <code>executed_cmds</code>, <code>tool_calls</code>, <code>executed_tool_calls</code>, <code>url_configs</code> Core's <code>AgentResponse</code> (agent.py) N/A (flat) <code>text</code>, <code>pending_tools</code> list directly Core's <code>AgentResponse</code> (dto) <code>DataDTO</code> (dataclass) <code>cmds</code>, <code>executed_cmds</code>, <code>tool_calls</code>, <code>executed_tool_calls</code>, <code>session</code> Core's <code>AgentResult</code> N/A (flat) <code>pending_tools</code>, <code>executed_tools</code> lists directly <p>Reasoning:</p> <p>Schema's nested structure: <pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"I'll delete that pod.\",\n  \"data\": {\n    \"tool_calls\": [{\"id\": \"tc_123\", \"name\": \"delete_pod\", ...}],\n    \"executed_tool_calls\": []\n  }\n}\n</code></pre></p> <p>Core's flat structure (user-facing): <pre><code>AgentResponse(\n    text=\"I'll delete that pod.\",\n    pending_tools=[PendingToolCall(id=\"tc_123\", name=\"delete_pod\", ...)]\n)\n</code></pre></p> <p>Why the difference? 1. User API simplicity - Users don't need to know about the nested <code>data</code> structure 2. Protocol compliance at boundary - The application DTO has <code>DataDTO</code> and serializes to schema format 3. Progressive disclosure - Simple cases don't see complexity</p>"},{"location":"plans/message-response-gap-analysis/#gap-4-behavioral-methods","title":"Gap 4: Behavioral Methods","text":"Method Schema's AgentMessage Core's AgentResponse (agent.py) Core's AgentResponse (dto) <code>approve_all()</code> \u274c No \u2705 Yes \u274c No <code>reject_all()</code> \u274c No \u2705 Yes \u274c No <code>to_dict()</code> \u2705 Yes (Pydantic) \u274c No \u2705 Yes <code>to_helpdesk_message()</code> \u274c No \u274c No \u2705 Yes <p>Reasoning:</p> <p>Schema = Pure Data (Pydantic validation) <pre><code>msg = AgentMessage(content=\"Hello\")\ndata = msg.model_dump()  # Pydantic's serialization\n</code></pre></p> <p>User-Facing = Data + Behavior <pre><code>response = agent.run(messages)\nif response.needs_approval:\n    response = response.approve_all()  # Behavior!\n</code></pre></p> <p>Application DTO = Data + Serialization <pre><code>response = AgentResponse(conversation_id=\"123\", text=\"Hello\", ...)\nhelpdesk_msg = response.to_helpdesk_message()  # Convert to wire format\n</code></pre></p>"},{"location":"plans/message-response-gap-analysis/#gap-5-multiple-response-types-in-core","title":"Gap 5: Multiple Response Types in Core","text":"<p>The core has 3 different response types for different use cases:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    User-Facing Layer                         \u2502\n\u2502                                                              \u2502\n\u2502  AgentResponse (agent.py)                                   \u2502\n\u2502  - Simple API                                                \u2502\n\u2502  - Has approve_all(), reject_all()                          \u2502\n\u2502  - Used by: agent.run()                                     \u2502\n\u2502                                                              \u2502\n\u2502  AgentResult (primitives.py)                                \u2502\n\u2502  - For custom functions                                      \u2502\n\u2502  - Simple return type                                        \u2502\n\u2502  - Used by: serve(my_custom_agent)                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u2502 Converted by server/facade\n                            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Application Layer (Internal)                \u2502\n\u2502                                                              \u2502\n\u2502  AgentResponse (dto/responses.py)                           \u2502\n\u2502  - Full HelpDesk protocol                                   \u2502\n\u2502  - Has to_dict(), to_helpdesk_message()                    \u2502\n\u2502  - Used by: AgentService, adapters                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502\n                            \u2502 Serialized to\n                            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Wire Format (Schema)                      \u2502\n\u2502                                                              \u2502\n\u2502  AgentMessage (schemas/messages.py)                         \u2502\n\u2502  - Pydantic model                                           \u2502\n\u2502  - JSON schema for API                                       \u2502\n\u2502  - Used by: HTTP endpoints, storage                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Schema has 1 type - it's the wire format Core has 3 types - they serve different architectural layers</p>"},{"location":"plans/message-response-gap-analysis/#conversion-flow","title":"Conversion Flow","text":"<p>Here's how a response flows from core to schema:</p> <pre><code># 1. User calls Agent.run()\nresponse = agent.run(messages)\n# \u2192 Returns: AgentResponse (agent.py) - simple user API\n\n# 2. Internally, AgentService returns application DTO\ninternal_response = agent_service.execute(request)\n# \u2192 Returns: AgentResponse (dto/responses.py) - full protocol\n\n# 3. Application DTO is converted to user-facing\nuser_response = agent._convert_response(internal_response)\n# \u2192 Returns: AgentResponse (agent.py) - hides complexity\n\n# 4. For HTTP API, server converts to schema\nhelpdesk_msg = internal_response.to_helpdesk_message()\n# \u2192 Returns: Dict matching AgentMessage schema\n\n# 5. Schema validates and serializes\nvalidated = AgentMessage(**helpdesk_msg)\njson_response = validated.model_dump()\n# \u2192 Returns: JSON for HTTP response\n</code></pre>"},{"location":"plans/message-response-gap-analysis/#should-we-unify-them","title":"Should We Unify Them?","text":""},{"location":"plans/message-response-gap-analysis/#no-keep-them-separate","title":"\u274c NO - Keep Them Separate","text":"<p>Reasons:</p> <ol> <li>Different Concerns</li> <li>Schema: Wire format (HTTP, storage)</li> <li> <p>Core: Business logic (behavior, domain)</p> </li> <li> <p>Different Technologies</p> </li> <li>Schema: Pydantic (validation, JSON schema)</li> <li> <p>Core: Dataclasses (simple, fast, Pythonic)</p> </li> <li> <p>API Simplicity</p> </li> <li>User-facing API should be minimal</li> <li> <p>Wire format needs full protocol compliance</p> </li> <li> <p>Flexibility</p> </li> <li>Can change internal structure without breaking API</li> <li> <p>Can support multiple protocols</p> </li> <li> <p>Clean Architecture</p> </li> <li>Keeps domain logic pure</li> <li>Adapters handle serialization</li> </ol>"},{"location":"plans/message-response-gap-analysis/#what-we-could-improve","title":"What We Could Improve","text":""},{"location":"plans/message-response-gap-analysis/#option-1-add-factory-methods-to-schema","title":"Option 1: Add Factory Methods to Schema","text":"<p>Add convenience methods to create schema messages from core responses:</p> <pre><code># In dcaf/schemas/messages.py\nclass AgentMessage(Message):\n    role: Literal[\"assistant\"] = \"assistant\"\n\n    @classmethod\n    def from_agent_response(cls, response: AgentResponse) -&gt; \"AgentMessage\":\n        \"\"\"Create AgentMessage from core AgentResponse.\"\"\"\n        return cls(\n            content=response.text or \"\",\n            data=Data(\n                tool_calls=[tc.to_dict() for tc in response.tool_calls],\n                executed_tool_calls=[etc.to_dict() for etc in response.executed_tool_calls],\n            ),\n            timestamp=datetime.now(timezone.utc),\n        )\n</code></pre>"},{"location":"plans/message-response-gap-analysis/#option-2-add-timestamp-to-application-dto","title":"Option 2: Add Timestamp to Application DTO","text":"<p>If we want to track response times:</p> <pre><code># In dcaf/core/application/dto/responses.py\n@dataclass\nclass AgentResponse:\n    conversation_id: str\n    text: Optional[str] = None\n    data: DataDTO = field(default_factory=DataDTO)\n    has_pending_approvals: bool = False\n    is_complete: bool = True\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))  # NEW\n</code></pre>"},{"location":"plans/message-response-gap-analysis/#option-3-add-useragent-identity-fields-optional","title":"Option 3: Add User/Agent Identity Fields (Optional)","text":"<p>For multi-agent scenarios:</p> <pre><code>@dataclass\nclass AgentResponse:\n    conversation_id: str\n    text: Optional[str] = None\n    data: DataDTO = field(default_factory=DataDTO)\n    # ... existing fields ...\n    agent_name: Optional[str] = None  # NEW: Which agent generated this\n    agent_id: Optional[str] = None    # NEW: Agent instance ID\n</code></pre>"},{"location":"plans/message-response-gap-analysis/#recommendations","title":"Recommendations","text":""},{"location":"plans/message-response-gap-analysis/#keep-current-structure","title":"Keep Current Structure \u2705","text":"<p>The separation is intentional and beneficial:</p> Layer Use Keep As Schema (<code>AgentMessage</code>) Wire format, API contracts Pydantic models User API (<code>AgentResponse</code> in agent.py) Simple <code>.run()</code> API Dataclass with behavior Application (<code>AgentResponse</code> in dto/) Internal protocol handling Dataclass with serialization Custom functions (<code>AgentResult</code>) User-defined agents Simple dataclass"},{"location":"plans/message-response-gap-analysis/#minor-enhancements-optional","title":"Minor Enhancements (Optional)","text":"<ol> <li>\u2705 Add factory method to <code>AgentMessage.from_agent_response()</code></li> <li>\u26a0\ufe0f Consider timestamp in application DTO if timing metrics needed</li> <li>\u26a0\ufe0f Consider agent identity fields for multi-agent orchestration</li> </ol>"},{"location":"plans/message-response-gap-analysis/#dont-change","title":"Don't Change","text":"<ol> <li>\u274c Don't merge schema and core responses</li> <li>\u274c Don't add <code>role</code> field to core responses</li> <li>\u274c Don't add behavior to schema classes</li> <li>\u274c Don't expose full DataDTO in user-facing API</li> </ol>"},{"location":"plans/message-response-gap-analysis/#summary-table","title":"Summary Table","text":"Feature Schema AgentMessage Core AgentResponse (User) Core AgentResponse (DTO) Core AgentResult Purpose Wire format Simple API Internal DTO Custom functions Type Pydantic Dataclass Dataclass Dataclass Has role \u2705 Yes \u274c No \u274c No (added in to_dict) \u274c No Has timestamp \u2705 Yes \u274c No \u274c No \u274c No Has user/agent \u2705 Yes \u274c No \u274c No \u274c No Has data container \u2705 Yes (Data) \u274c No (flat) \u2705 Yes (DataDTO) \u274c No (flat) Has approve_all() \u274c No \u2705 Yes \u274c No \u274c No Has to_dict() \u2705 Yes (Pydantic) \u274c No \u2705 Yes \u274c No Used by HTTP API, storage <code>Agent.run()</code> <code>AgentService</code> <code>serve(fn)</code>"},{"location":"plans/message-response-gap-analysis/#conclusion","title":"Conclusion","text":"<p>The gaps are intentional design choices, not mistakes:</p> <ol> <li>Schema is universal wire format - needs all metadata</li> <li>Core responses are specialized - optimized for their use case</li> <li>Separation enables evolution - can change internals without breaking API</li> <li>Converters bridge the gap - <code>to_helpdesk_message()</code> does the translation</li> </ol> <p>Recommendation: Keep the current separation. It follows Clean Architecture principles and provides a better developer experience.</p>"},{"location":"plans/response-conversion-feature-summary/","title":"Response Conversion Feature - Implementation Summary","text":"<p>Date: January 8, 2026 Status: \u2705 Complete Feature: Bridge between core AgentResponse and schema AgentMessage</p>"},{"location":"plans/response-conversion-feature-summary/#what-we-built","title":"What We Built","text":"<p>A bidirectional conversion system between DCAF's internal response types and the HelpDesk protocol message format.</p>"},{"location":"plans/response-conversion-feature-summary/#new-methods-added","title":"New Methods Added","text":""},{"location":"plans/response-conversion-feature-summary/#1-agentmessagefrom_agent_response-factory-method","title":"1. <code>AgentMessage.from_agent_response()</code> (Factory Method)","text":"<p>Location: <code>dcaf/schemas/messages.py</code></p> <p>Purpose: Create a validated Pydantic <code>AgentMessage</code> from any core <code>AgentResponse</code>.</p> <p>Signature: <pre><code>@classmethod\ndef from_agent_response(\n    cls,\n    response,  # AgentResponse from core\n    include_timestamp: bool = True,\n    agent_name: Optional[str] = None,\n    agent_id: Optional[str] = None,\n) -&gt; \"AgentMessage\"\n</code></pre></p> <p>Features: - \u2705 Converts core DTO \u2192 schema Pydantic model - \u2705 Adds timestamp automatically - \u2705 Supports agent identity tracking - \u2705 Handles both DataDTO and flat response structures - \u2705 Preserves all data (tool calls, executed tools, metadata) - \u2705 Full Pydantic validation</p>"},{"location":"plans/response-conversion-feature-summary/#2-agentresponseto_agent_message-convenience-method","title":"2. <code>AgentResponse.to_agent_message()</code> (Convenience Method)","text":"<p>Location: <code>dcaf/core/application/dto/responses.py</code></p> <p>Purpose: Convert application DTO to schema message directly.</p> <p>Signature: <pre><code>def to_agent_message(\n    self,\n    agent_name: Optional[str] = None,\n    agent_id: Optional[str] = None,\n    include_timestamp: bool = True,\n) -&gt; AgentMessage\n</code></pre></p> <p>Features: - \u2705 One-liner conversion from DTO - \u2705 Returns validated Pydantic model - \u2705 Complements existing <code>to_helpdesk_message()</code> method - \u2705 Better for type-safe APIs</p>"},{"location":"plans/response-conversion-feature-summary/#usage-examples","title":"Usage Examples","text":""},{"location":"plans/response-conversion-feature-summary/#basic-conversion","title":"Basic Conversion","text":"<pre><code>from dcaf.core.application.dto import AgentResponse, DataDTO\nfrom dcaf.schemas.messages import AgentMessage\n\n# Create core response\nresponse = AgentResponse(\n    conversation_id=\"conv-123\",\n    text=\"Hello, world!\",\n    data=DataDTO(),\n)\n\n# Convert to schema message\nmessage = response.to_agent_message(\n    agent_name=\"my-agent\",\n    agent_id=\"agent-001\",\n)\n\n# Access rich metadata\nprint(message.role)        # \"assistant\"\nprint(message.timestamp)   # datetime object\nprint(message.agent.name)  # \"my-agent\"\n\n# Serialize to JSON\njson_data = message.model_dump()\n</code></pre>"},{"location":"plans/response-conversion-feature-summary/#with-tool-calls","title":"With Tool Calls","text":"<pre><code>from dcaf.core.application.dto import (\n    AgentResponse, \n    DataDTO, \n    ToolCallDTO,\n)\n\n# Create response with tool calls\ntool_call = ToolCallDTO(\n    id=\"tc_123\",\n    name=\"delete_pod\",\n    input={\"name\": \"nginx\"},\n    tool_description=\"Delete Kubernetes pod\",\n)\n\nresponse = AgentResponse(\n    conversation_id=\"conv-456\",\n    text=\"I need approval to delete the pod.\",\n    data=DataDTO(tool_calls=[tool_call]),\n    has_pending_approvals=True,\n)\n\n# Convert\nmessage = response.to_agent_message(agent_name=\"k8s-agent\")\n\n# Verify tool calls preserved\nassert len(message.data.tool_calls) == 1\nassert message.data.tool_calls[0].name == \"delete_pod\"\n</code></pre>"},{"location":"plans/response-conversion-feature-summary/#direct-factory-usage","title":"Direct Factory Usage","text":"<pre><code>from dcaf.schemas.messages import AgentMessage\n\n# Works with any response object\nmessage = AgentMessage.from_agent_response(\n    response=any_core_response,\n    agent_name=\"custom-agent\",\n    include_timestamp=True,\n)\n</code></pre>"},{"location":"plans/response-conversion-feature-summary/#comparison-old-vs-new","title":"Comparison: Old vs New","text":""},{"location":"plans/response-conversion-feature-summary/#before-this-feature","title":"Before This Feature","text":"<pre><code># Had to manually construct dict\nmessage_dict = {\n    \"role\": \"assistant\",\n    \"content\": response.text or \"\",\n    \"data\": response.data.to_dict(),\n    \"meta_data\": response.metadata,\n    # Missing: timestamp, agent info\n}\n\n# No validation\n# No type safety\n# Manual serialization\n</code></pre>"},{"location":"plans/response-conversion-feature-summary/#after-this-feature","title":"After This Feature","text":"<pre><code># One line, validated, type-safe\nmessage = response.to_agent_message(agent_name=\"my-agent\")\n\n# Includes: timestamp, agent info, full validation\njson_data = message.model_dump()\n\n# Type hints work\nreveal_type(message)  # AgentMessage (Pydantic)\n</code></pre>"},{"location":"plans/response-conversion-feature-summary/#architecture-benefits","title":"Architecture Benefits","text":""},{"location":"plans/response-conversion-feature-summary/#1-clean-separation-of-concerns","title":"1. Clean Separation of Concerns","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Core Layer       \u2502  Business logic (Python dataclasses)\n\u2502 AgentResponse    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 .to_agent_message()\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Schema Layer     \u2502  Wire format (Pydantic validation)\n\u2502 AgentMessage     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502 .model_dump()\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 JSON             \u2502  Over the wire (HTTP, WebSocket)\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"plans/response-conversion-feature-summary/#2-type-safety","title":"2. Type Safety","text":"<p>Pydantic provides: - Runtime validation - JSON schema generation - Type hints support - IDE autocomplete - Serialization options</p>"},{"location":"plans/response-conversion-feature-summary/#3-flexibility","title":"3. Flexibility","text":"<p>Two methods for different needs: - <code>to_helpdesk_message()</code> - Fast dict (existing) - <code>to_agent_message()</code> - Rich Pydantic (new)</p>"},{"location":"plans/response-conversion-feature-summary/#when-to-use-which-method","title":"When to Use Which Method","text":"Scenario Use Why HTTP API responses <code>to_agent_message()</code> Validation + JSON schema WebSocket streaming <code>to_helpdesk_message()</code> Lower overhead Logging <code>to_agent_message()</code> Rich metadata Testing <code>to_agent_message()</code> Type safety Simple dict <code>to_helpdesk_message()</code> Direct Multi-agent systems <code>to_agent_message()</code> Agent tracking"},{"location":"plans/response-conversion-feature-summary/#testing","title":"Testing","text":""},{"location":"plans/response-conversion-feature-summary/#test-coverage","title":"Test Coverage","text":"<pre><code># Test 1: Basic conversion\nresponse = AgentResponse(...)\nmessage = response.to_agent_message()\nassert message.role == \"assistant\"\nassert message.timestamp is not None\n\n# Test 2: Tool calls preserved\nresponse_with_tools = AgentResponse(data=DataDTO(tool_calls=[...]))\nmessage = response_with_tools.to_agent_message()\nassert len(message.data.tool_calls) == 1\n\n# Test 3: Agent identity\nmessage = response.to_agent_message(\n    agent_name=\"test-agent\",\n    agent_id=\"agent-123\",\n)\nassert message.agent.name == \"test-agent\"\nassert message.agent.id == \"agent-123\"\n\n# Test 4: Round-trip validation\njson_data = message.model_dump()\nmessage2 = AgentMessage(**json_data)\nassert message2.content == message.content\n\n# Test 5: Metadata preservation\nresponse = AgentResponse(\n    conversation_id=\"conv-123\",\n    has_pending_approvals=True,\n    metadata={\"source\": \"test\"},\n)\nmessage = response.to_agent_message()\nassert \"conversation_id\" in message.meta_data\nassert \"has_pending_approvals\" in message.meta_data\n</code></pre>"},{"location":"plans/response-conversion-feature-summary/#test-results","title":"Test Results","text":"<pre><code>\u2705 All 55 core tests pass\n\u2705 Conversion tests pass\n\u2705 Round-trip validation passes\n\u2705 Backward compatibility maintained\n</code></pre>"},{"location":"plans/response-conversion-feature-summary/#files-modified","title":"Files Modified","text":""},{"location":"plans/response-conversion-feature-summary/#1-dcafschemasmessagespy","title":"1. <code>dcaf/schemas/messages.py</code>","text":"<ul> <li>Added <code>AgentMessage.from_agent_response()</code> factory method</li> <li>~75 lines of code</li> <li>Full docstring with examples</li> </ul>"},{"location":"plans/response-conversion-feature-summary/#2-dcafcoreapplicationdtoresponsespy","title":"2. <code>dcaf/core/application/dto/responses.py</code>","text":"<ul> <li>Added <code>AgentResponse.to_agent_message()</code> convenience method</li> <li>~35 lines of code</li> <li>Full docstring with examples</li> </ul>"},{"location":"plans/response-conversion-feature-summary/#3-documentation","title":"3. Documentation","text":"<ul> <li>Created <code>docs/guides/response-conversion.md</code> - Complete usage guide</li> <li>Created <code>docs/plans/response-conversion-feature-summary.md</code> - This file</li> </ul>"},{"location":"plans/response-conversion-feature-summary/#code-quality","title":"Code Quality","text":"<p>\u2705 Type hints: Full type annotations \u2705 Docstrings: Comprehensive with examples \u2705 Testing: Manual validation passed \u2705 Backward compatible: Existing code unaffected \u2705 Clean code: Follows existing patterns  </p>"},{"location":"plans/response-conversion-feature-summary/#future-enhancements-optional","title":"Future Enhancements (Optional)","text":""},{"location":"plans/response-conversion-feature-summary/#1-add-to-user-facing-agent-api","title":"1. Add to User-Facing Agent API","text":"<pre><code># In dcaf/core/agent.py\nclass Agent:\n    def run(self, messages) -&gt; AgentResponse:\n        ...\n\n    def run_as_message(self, messages) -&gt; AgentMessage:\n        \"\"\"Run and return as schema message.\"\"\"\n        response = self.run(messages)\n        return response.to_agent_message()  # If we add internal conversion\n</code></pre>"},{"location":"plans/response-conversion-feature-summary/#2-streaming-support","title":"2. Streaming Support","text":"<pre><code>def to_agent_message_stream(self):\n    \"\"\"Stream conversion for real-time updates.\"\"\"\n    ...\n</code></pre>"},{"location":"plans/response-conversion-feature-summary/#3-batch-conversion","title":"3. Batch Conversion","text":"<pre><code>@classmethod\ndef from_agent_responses(\n    cls, \n    responses: List[AgentResponse],\n) -&gt; List[AgentMessage]:\n    \"\"\"Convert multiple responses at once.\"\"\"\n    return [cls.from_agent_response(r) for r in responses]\n</code></pre>"},{"location":"plans/response-conversion-feature-summary/#impact","title":"Impact","text":""},{"location":"plans/response-conversion-feature-summary/#developer-experience","title":"Developer Experience","text":"<p>Before: <pre><code># Manual, error-prone\nmsg = {\n    \"role\": \"assistant\",\n    \"content\": response.text,\n    \"data\": response.data.to_dict(),\n    \"meta_data\": {...},  # What goes here?\n}\n</code></pre></p> <p>After: <pre><code># Simple, validated\nmsg = response.to_agent_message(agent_name=\"my-agent\")\njson_data = msg.model_dump()  # Type-safe!\n</code></pre></p>"},{"location":"plans/response-conversion-feature-summary/#benefits","title":"Benefits","text":"<ol> <li>Type Safety - Pydantic validation catches errors early</li> <li>Rich Metadata - Automatic timestamps and agent tracking</li> <li>Flexibility - Choose between dict or Pydantic based on needs</li> <li>Documentation - Self-documenting with type hints</li> <li>Testing - Easier to test with validated models</li> </ol>"},{"location":"plans/response-conversion-feature-summary/#conclusion","title":"Conclusion","text":"<p>\u2705 Implemented: Bidirectional conversion between core and schema \u2705 Tested: All existing tests pass + manual validation \u2705 Documented: Complete guide with examples \u2705 Backward Compatible: Existing code unaffected  </p> <p>This feature bridges the gap between internal DTOs and wire protocol while maintaining clean architecture principles.</p>"},{"location":"plans/response-conversion-feature-summary/#related-documentation","title":"Related Documentation","text":"<ul> <li>Message &amp; Response Gap Analysis</li> <li>Response Conversion Guide</li> <li>Schema Reuse Analysis</li> </ul>"},{"location":"plans/schema-reuse-analysis/","title":"Schema Reuse Analysis for Core Framework v2","text":"<p>Date: January 8, 2026 Status: Draft Author: Engineering Team</p>"},{"location":"plans/schema-reuse-analysis/#executive-summary","title":"Executive Summary","text":"<p>This document analyzes the existing schema classes in <code>dcaf/schemas/messages.py</code> and identifies opportunities to reuse them in the new Core Framework (<code>dcaf/core/</code>). The goal is to reduce code duplication, establish a single source of truth for wire protocol types, and maintain consistency between the legacy and v2 implementations.</p>"},{"location":"plans/schema-reuse-analysis/#background","title":"Background","text":"<p>The DCAF framework currently has two parallel sets of data classes:</p> <ol> <li>Schema Classes (<code>dcaf/schemas/messages.py</code>) - Pydantic BaseModels for the HelpDesk wire protocol</li> <li>Core DTOs (<code>dcaf/core/application/dto/</code>) - Python dataclasses for the Clean Architecture implementation</li> </ol> <p>Both define similar structures for commands, tool calls, platform context, and messages. This analysis identifies which schema classes can be directly reused, which need enhancement, and which should remain separate due to intentional design differences.</p>"},{"location":"plans/schema-reuse-analysis/#class-by-class-comparison","title":"Class-by-Class Comparison","text":""},{"location":"plans/schema-reuse-analysis/#schema-classes-inventory","title":"Schema Classes Inventory","text":"Schema Class Location Purpose <code>FileObject</code> <code>messages.py:7-9</code> File path and content for command execution <code>Command</code> <code>messages.py:12-16</code> Terminal command awaiting approval <code>ExecutedCommand</code> <code>messages.py:19-21</code> Terminal command that was executed <code>ToolCall</code> <code>messages.py:24-32</code> Tool call awaiting approval <code>ExecutedToolCall</code> <code>messages.py:35-39</code> Tool call that was executed <code>URLConfig</code> <code>messages.py:42-44</code> URL configuration <code>PlatformContext</code> <code>messages.py:47-73</code> Runtime context (tenant, credentials, etc.) <code>AmbientContext</code> <code>messages.py:77-78</code> User terminal commands (unused) <code>Data</code> <code>messages.py:81-86</code> Container for all actionable data <code>User</code> <code>messages.py:89-91</code> User identification <code>Agent</code> <code>messages.py:94-96</code> Agent identification <code>Message</code> <code>messages.py:99-106</code> Base message with role and content <code>UserMessage</code> <code>messages.py:109-112</code> User message with platform context <code>AgentMessage</code> <code>messages.py:115-116</code> Assistant message <code>Messages</code> <code>messages.py:119-120</code> Container for message list"},{"location":"plans/schema-reuse-analysis/#core-dtos-inventory","title":"Core DTOs Inventory","text":"Core Class Location Purpose <code>FileObject</code> <code>responses.py:63-73</code> File path and content (duplicate) <code>CommandDTO</code> <code>responses.py:76-116</code> Terminal command awaiting approval <code>ExecutedCommandDTO</code> <code>responses.py:119-144</code> Terminal command that was executed <code>ToolCallDTO</code> <code>responses.py:147-239</code> Tool call with extended fields <code>ExecutedToolCallDTO</code> <code>responses.py:242-275</code> Tool call that was executed <code>DataDTO</code> <code>responses.py:282-341</code> Container with session support <code>PlatformContext</code> <code>value_objects/platform_context.py</code> Immutable domain value object <code>Message</code> <code>entities/message.py</code> Domain entity with rich content"},{"location":"plans/schema-reuse-analysis/#reuse-categories","title":"Reuse Categories","text":""},{"location":"plans/schema-reuse-analysis/#category-1-highly-reusable-direct-replacement","title":"\u2705 Category 1: Highly Reusable (Direct Replacement)","text":"<p>These schema classes are nearly identical to their core counterparts and can directly replace the core DTOs.</p>"},{"location":"plans/schema-reuse-analysis/#category-2-partially-reusable-needs-enhancement","title":"\u26a0\ufe0f Category 2: Partially Reusable (Needs Enhancement)","text":"<p>These schema classes have the right foundation but need additional fields or methods to fully support the core framework's requirements.</p>"},{"location":"plans/schema-reuse-analysis/#category-3-not-recommended-for-reuse-intentional-design-difference","title":"\u274c Category 3: Not Recommended for Reuse (Intentional Design Difference)","text":"<p>These classes serve different architectural purposes and should remain separate, with converters between them.</p>"},{"location":"plans/schema-reuse-analysis/#category-1-highly-reusable","title":"Category 1: Highly Reusable","text":""},{"location":"plans/schema-reuse-analysis/#checklist","title":"Checklist","text":"<ul> <li> FileObject \u2192 Replace <code>dcaf/core/application/dto/responses.py:FileObject</code></li> <li>Schema: <code>file_path: str</code>, <code>file_content: str</code></li> <li>Core: Identical fields</li> <li>Action: Import from <code>dcaf.schemas.messages</code> instead of defining locally</li> <li>Effort: Low (simple import change)</li> <li> <p>\u2705 COMPLETED (2026-01-08)</p> </li> <li> <p> ExecutedCommand \u2192 Replace <code>ExecutedCommandDTO</code></p> </li> <li>Schema: <code>command: str</code>, <code>output: str</code></li> <li>Core: Identical fields</li> <li>Action: Replace <code>ExecutedCommandDTO</code> with <code>ExecutedCommand</code> alias or direct use</li> <li>Effort: Low (rename references)</li> <li> <p>\u2705 COMPLETED (2026-01-08)</p> </li> <li> <p> ExecutedToolCall \u2192 Replace <code>ExecutedToolCallDTO</code></p> </li> <li>Schema: <code>id: str</code>, <code>name: str</code>, <code>input: Dict[str, Any]</code>, <code>output: str</code></li> <li>Core: Identical fields</li> <li>Action: Replace <code>ExecutedToolCallDTO</code> with <code>ExecutedToolCall</code></li> <li>Effort: Low (rename references)</li> <li> <p>\u2705 COMPLETED (2026-01-08)</p> </li> <li> <p> Command \u2192 Replace <code>CommandDTO</code></p> </li> <li>Schema: <code>command: str</code>, <code>execute: bool</code>, <code>rejection_reason: Optional[str]</code>, <code>files: Optional[List[FileObject]]</code></li> <li>Core: Same fields</li> <li>Action: Replace <code>CommandDTO</code> with <code>Command</code></li> <li>Note: Added <code>_to_dict()</code> helper to handle both Pydantic and dataclass serialization</li> <li>Effort: Low-Medium (may need to add serialization helpers)</li> <li>\u2705 COMPLETED (2026-01-08)</li> </ul>"},{"location":"plans/schema-reuse-analysis/#migration-steps-for-category-1","title":"Migration Steps for Category 1","text":"<ol> <li> <p>Update imports in <code>dcaf/core/application/dto/responses.py</code>: <pre><code>from dcaf.schemas.messages import (\n    FileObject,\n    Command,\n    ExecutedCommand,\n    ExecutedToolCall,\n)\n</code></pre></p> </li> <li> <p>Create aliases for backward compatibility (optional): <pre><code># Aliases for backward compatibility during migration\nCommandDTO = Command\nExecutedCommandDTO = ExecutedCommand\nExecutedToolCallDTO = ExecutedToolCall\n</code></pre></p> </li> <li> <p>Update all internal references to use schema classes</p> </li> <li> <p>Remove duplicate class definitions from <code>responses.py</code></p> </li> <li> <p>Update tests to use schema classes</p> </li> </ol>"},{"location":"plans/schema-reuse-analysis/#category-2-partially-reusable","title":"Category 2: Partially Reusable","text":""},{"location":"plans/schema-reuse-analysis/#checklist_1","title":"Checklist","text":"<ul> <li> ToolCall \u2192 Enhance to replace <code>ToolCallDTO</code></li> <li>Schema fields:<ul> <li><code>id: str</code></li> <li><code>name: str</code></li> <li><code>input: Dict[str, Any]</code></li> <li><code>execute: bool = False</code></li> <li><code>tool_description: str</code></li> <li><code>input_description: Dict[str, Any]</code></li> <li><code>intent: Optional[str] = None</code></li> <li><code>rejection_reason: Optional[str] = None</code></li> </ul> </li> <li>Core adds:<ul> <li><code>requires_approval: bool = True</code></li> <li><code>status: str = \"pending\"</code> (pending, approved, executed, rejected, failed)</li> <li><code>result: Optional[str] = None</code></li> <li><code>error: Optional[str] = None</code></li> </ul> </li> <li>Action: Add missing fields to schema's <code>ToolCall</code></li> <li> <p>Effort: Medium</p> </li> <li> <p> Data \u2192 Enhance to replace <code>DataDTO</code></p> </li> <li>Schema fields:<ul> <li><code>cmds: List[Command]</code></li> <li><code>executed_cmds: List[ExecutedCommand]</code></li> <li><code>tool_calls: List[ToolCall]</code></li> <li><code>executed_tool_calls: List[ExecutedToolCall]</code></li> <li><code>url_configs: List[URLConfig]</code></li> </ul> </li> <li>Core adds:<ul> <li><code>session: Dict[str, Any] = Field(default_factory=dict)</code></li> </ul> </li> <li>Core also adds helper properties:<ul> <li><code>has_pending_items: bool</code></li> <li><code>is_empty: bool</code></li> </ul> </li> <li>Action: Add <code>session</code> field and helper properties to schema's <code>Data</code></li> <li> <p>Effort: Medium</p> </li> <li> <p> User \u2192 Consider for inclusion in core</p> </li> <li>Schema: <code>name: str</code>, <code>id: str</code></li> <li>Core: Not currently used</li> <li>Action: Evaluate if needed in core, import if yes</li> <li> <p>Effort: Low (optional)</p> </li> <li> <p> Agent (schema class) \u2192 Consider for inclusion in core</p> </li> <li>Schema: <code>name: str</code>, <code>id: str</code></li> <li>Core: Not currently used as data class</li> <li>Action: Evaluate if needed in core, import if yes</li> <li>Effort: Low (optional)</li> </ul>"},{"location":"plans/schema-reuse-analysis/#enhancement-plan-for-category-2","title":"Enhancement Plan for Category 2","text":""},{"location":"plans/schema-reuse-analysis/#toolcall-enhancement","title":"ToolCall Enhancement","text":"<pre><code># Proposed changes to dcaf/schemas/messages.py\n\nclass ToolCall(BaseModel):\n    \"\"\"Tool call for approval workflow.\"\"\"\n    id: str\n    name: str\n    input: Dict[str, Any]\n    execute: bool = False\n    tool_description: str = \"\"\n    input_description: Dict[str, Any] = Field(default_factory=dict)\n    intent: Optional[str] = None\n    rejection_reason: Optional[str] = None\n    # NEW: Fields for full protocol support\n    requires_approval: bool = True\n    status: str = \"pending\"  # pending, approved, rejected, executed, failed\n    result: Optional[str] = None\n    error: Optional[str] = None\n\n    @property\n    def description(self) -&gt; str:\n        \"\"\"Alias for backward compatibility.\"\"\"\n        return self.tool_description\n</code></pre>"},{"location":"plans/schema-reuse-analysis/#data-enhancement","title":"Data Enhancement","text":"<pre><code># Proposed changes to dcaf/schemas/messages.py\n\nclass Data(BaseModel):\n    \"\"\"Container for all actionable data in a message.\"\"\"\n    cmds: List[Command] = Field(default_factory=list)\n    executed_cmds: List[ExecutedCommand] = Field(default_factory=list)\n    tool_calls: List[ToolCall] = Field(default_factory=list)\n    executed_tool_calls: List[ExecutedToolCall] = Field(default_factory=list)\n    url_configs: List[URLConfig] = Field(default_factory=list)\n    # NEW: Session state for persistence across turns\n    session: Dict[str, Any] = Field(default_factory=dict)\n\n    @property\n    def has_pending_items(self) -&gt; bool:\n        \"\"\"Check if there are items awaiting approval.\"\"\"\n        pending_cmds = any(not c.execute for c in self.cmds)\n        pending_tools = any(not t.execute for t in self.tool_calls)\n        return pending_cmds or pending_tools\n\n    @property\n    def is_empty(self) -&gt; bool:\n        \"\"\"Check if data container is empty.\"\"\"\n        return (\n            not self.cmds and\n            not self.executed_cmds and\n            not self.tool_calls and\n            not self.executed_tool_calls\n        )\n</code></pre>"},{"location":"plans/schema-reuse-analysis/#category-3-not-recommended-for-reuse","title":"Category 3: Not Recommended for Reuse","text":""},{"location":"plans/schema-reuse-analysis/#checklist_2","title":"Checklist","text":"<ul> <li> PlatformContext \u2192 Keep separate implementations</li> <li>Reason: Intentional design difference</li> <li>Schema: Pydantic BaseModel (mutable, for serialization)</li> <li>Core: Frozen dataclass (immutable value object for DDD)</li> <li>Action: Create <code>from_schema()</code> converter method in core</li> <li> <p>Effort: Low (add factory method)</p> </li> <li> <p> Message / UserMessage / AgentMessage \u2192 Keep separate implementations</p> </li> <li>Reason: Different architectural purpose</li> <li>Schema: Wire format for HelpDesk protocol (flat structure)</li> <li>Core: Domain entity with rich content model (MessageContent, ContentBlock)</li> <li>Action: Create converter utilities between wire format and domain entities</li> <li> <p>Effort: Medium (converters already partially exist)</p> </li> <li> <p> Messages \u2192 Keep separate</p> </li> <li>Reason: Simple container, core uses different patterns</li> <li>Schema: <code>messages: List[Union[UserMessage, AgentMessage]]</code></li> <li>Core: Conversation aggregate with message collection</li> <li> <p>Action: No action needed</p> </li> <li> <p> AmbientContext \u2192 Evaluate for deprecation</p> </li> <li>Current status: Marked as \"unused\" in schema</li> <li>Action: Confirm if needed, remove if not</li> <li> <p>Effort: Low</p> </li> <li> <p> URLConfig \u2192 Evaluate for inclusion</p> </li> <li>Current status: In schema, not in core</li> <li>Action: Determine if needed in core framework</li> <li>Effort: Low (optional)</li> </ul>"},{"location":"plans/schema-reuse-analysis/#converter-implementation-plan","title":"Converter Implementation Plan","text":""},{"location":"plans/schema-reuse-analysis/#platformcontext-converter","title":"PlatformContext Converter","text":"<p>Add to <code>dcaf/core/domain/value_objects/platform_context.py</code>:</p> <pre><code>@classmethod\ndef from_schema(cls, schema_ctx: \"PlatformContext\") -&gt; \"PlatformContext\":\n    \"\"\"\n    Convert schema PlatformContext to domain value object.\n\n    This converts the mutable Pydantic model used in the API layer\n    to an immutable value object for domain logic.\n    \"\"\"\n    from dcaf.schemas.messages import PlatformContext as SchemaPlatformContext\n\n    if not isinstance(schema_ctx, SchemaPlatformContext):\n        raise TypeError(f\"Expected SchemaPlatformContext, got {type(schema_ctx)}\")\n\n    return cls.from_dict(schema_ctx.model_dump())\n\ndef to_schema(self) -&gt; \"PlatformContext\":\n    \"\"\"Convert domain value object to schema PlatformContext.\"\"\"\n    from dcaf.schemas.messages import PlatformContext as SchemaPlatformContext\n    return SchemaPlatformContext(**self.to_dict())\n</code></pre>"},{"location":"plans/schema-reuse-analysis/#message-converters","title":"Message Converters","text":"<p>Consider adding to <code>dcaf/core/adapters/</code> a message converter:</p> <pre><code># dcaf/core/adapters/message_converter.py\n\nfrom dcaf.schemas.messages import UserMessage, AgentMessage, Message as SchemaMessage\nfrom dcaf.core.domain.entities import Message as DomainMessage\n\ndef schema_to_domain(msg: SchemaMessage) -&gt; DomainMessage:\n    \"\"\"Convert schema message to domain entity.\"\"\"\n    if msg.role == \"user\":\n        return DomainMessage.user(msg.content)\n    elif msg.role == \"assistant\":\n        return DomainMessage.assistant(msg.content)\n    else:\n        raise ValueError(f\"Unknown role: {msg.role}\")\n\ndef domain_to_schema(msg: DomainMessage, include_data: bool = False) -&gt; SchemaMessage:\n    \"\"\"Convert domain entity to schema message.\"\"\"\n    if msg.is_user_message:\n        return UserMessage(content=msg.text or \"\")\n    else:\n        return AgentMessage(content=msg.text or \"\")\n</code></pre>"},{"location":"plans/schema-reuse-analysis/#implementation-priority","title":"Implementation Priority","text":""},{"location":"plans/schema-reuse-analysis/#phase-1-quick-wins-week-1-completed","title":"Phase 1: Quick Wins (Week 1) \u2705 COMPLETED","text":"<ol> <li> Import <code>FileObject</code> from schemas</li> <li> Import <code>ExecutedCommand</code> from schemas  </li> <li> Import <code>ExecutedToolCall</code> from schemas</li> <li> Import <code>Command</code> from schemas</li> <li> Create backward-compatible aliases (<code>CommandDTO</code>, <code>ExecutedCommandDTO</code>, <code>ExecutedToolCallDTO</code>)</li> <li> Add <code>_to_dict()</code> helper for Pydantic/dataclass compatibility</li> <li> Update tests - all 55 tests pass</li> </ol>"},{"location":"plans/schema-reuse-analysis/#phase-2-schema-enhancement-week-2","title":"Phase 2: Schema Enhancement (Week 2)","text":"<ol> <li> Add missing fields to <code>ToolCall</code> in schemas</li> <li> Add <code>session</code> field to <code>Data</code> in schemas</li> <li> Add helper properties to <code>Data</code></li> <li> Replace <code>ToolCallDTO</code> with enhanced <code>ToolCall</code></li> <li> Replace <code>DataDTO</code> with enhanced <code>Data</code></li> <li> Update tests</li> </ol>"},{"location":"plans/schema-reuse-analysis/#phase-3-converters-week-3","title":"Phase 3: Converters (Week 3)","text":"<ol> <li> Add <code>from_schema()</code> to core <code>PlatformContext</code></li> <li> Add <code>to_schema()</code> to core <code>PlatformContext</code></li> <li> Create message converter utilities</li> <li> Document the schema/core boundary</li> <li> Update engineering handoff doc</li> </ol>"},{"location":"plans/schema-reuse-analysis/#phase-4-cleanup-week-4","title":"Phase 4: Cleanup (Week 4)","text":"<ol> <li> Remove duplicate class definitions</li> <li> Deprecate old DTO classes</li> <li> Update all imports across codebase</li> <li> Final testing and validation</li> <li> Update documentation</li> </ol>"},{"location":"plans/schema-reuse-analysis/#breaking-changes","title":"Breaking Changes","text":""},{"location":"plans/schema-reuse-analysis/#api-compatibility","title":"API Compatibility","text":"<p>The following changes may affect external consumers:</p> Change Impact Mitigation <code>CommandDTO</code> \u2192 <code>Command</code> Low Provide alias <code>ExecutedCommandDTO</code> \u2192 <code>ExecutedCommand</code> Low Provide alias <code>ExecutedToolCallDTO</code> \u2192 <code>ExecutedToolCall</code> Low Provide alias <code>ToolCallDTO</code> \u2192 <code>ToolCall</code> Medium Fields are additive <code>DataDTO</code> \u2192 <code>Data</code> Medium Fields are additive"},{"location":"plans/schema-reuse-analysis/#internal-compatibility","title":"Internal Compatibility","text":"<ul> <li>Core framework consumers using <code>from dcaf.core import *</code> should be unaffected</li> <li>Direct imports of DTO classes will need updates</li> <li>Type hints referencing DTO classes will need updates</li> </ul>"},{"location":"plans/schema-reuse-analysis/#testing-strategy","title":"Testing Strategy","text":"<ol> <li>Unit Tests: Verify schema classes pass existing DTO tests</li> <li>Integration Tests: Verify serialization/deserialization round-trips</li> <li>Protocol Tests: Verify HelpDesk protocol compatibility</li> <li>Regression Tests: Run full test suite after each phase</li> </ol>"},{"location":"plans/schema-reuse-analysis/#open-questions","title":"Open Questions","text":"<ol> <li>Should we keep <code>URLConfig</code> in core? (Currently schema-only)</li> <li>Should we deprecate <code>AmbientContext</code>? (Marked unused)</li> <li>Should <code>User</code> and <code>Agent</code> schema classes be used in core?</li> <li>Do we need versioning for schema changes?</li> </ol>"},{"location":"plans/schema-reuse-analysis/#appendix-file-locations","title":"Appendix: File Locations","text":""},{"location":"plans/schema-reuse-analysis/#schema-files","title":"Schema Files","text":"<ul> <li><code>dcaf/schemas/__init__.py</code></li> <li><code>dcaf/schemas/messages.py</code></li> <li><code>dcaf/schemas/events.py</code></li> </ul>"},{"location":"plans/schema-reuse-analysis/#core-dto-files","title":"Core DTO Files","text":"<ul> <li><code>dcaf/core/application/dto/__init__.py</code></li> <li><code>dcaf/core/application/dto/requests.py</code></li> <li><code>dcaf/core/application/dto/responses.py</code></li> </ul>"},{"location":"plans/schema-reuse-analysis/#core-domain-files","title":"Core Domain Files","text":"<ul> <li><code>dcaf/core/domain/entities/message.py</code></li> <li><code>dcaf/core/domain/entities/tool_call.py</code></li> <li><code>dcaf/core/domain/value_objects/platform_context.py</code></li> </ul>"},{"location":"plans/schema-reuse-analysis/#revision-history","title":"Revision History","text":"Date Author Changes 2026-01-08 Engineering Initial analysis 2026-01-08 Engineering Implemented Category 1 (FileObject, Command, ExecutedCommand, ExecutedToolCall)"},{"location":"plans/server-integration-plan/","title":"DCAF Core Server Integration Plan","text":"<p>Goal: Enable new Core agents to be served via REST/streaming with zero friction. Status: Draft Created: 2024-12-22</p>"},{"location":"plans/server-integration-plan/#executive-summary","title":"Executive Summary","text":"<p>Make it dead simple to spin up a DCAF Core agent as a server:</p> <pre><code>from dcaf.core import Agent, serve\n\nagent = Agent(\n    tools=[...],\n    system_prompt=\"You are a helpful assistant.\"\n)\n\n# One line to start the server\nserve(agent, port=8000)\n</code></pre>"},{"location":"plans/server-integration-plan/#current-state","title":"Current State","text":""},{"location":"plans/server-integration-plan/#existing-server-dcafagent_serverpy","title":"Existing Server (<code>dcaf/agent_server.py</code>)","text":"<ul> <li>\u2705 FastAPI with <code>/api/sendMessage</code> (sync) and <code>/api/sendMessageStream</code> (streaming)</li> <li>\u2705 <code>AgentProtocol</code> interface for pluggable agents</li> <li>\u2705 Rich schemas for tool calls, approvals, streaming events</li> <li>\u2705 Slack/channel routing support</li> <li>\u2705 Health check endpoint</li> </ul>"},{"location":"plans/server-integration-plan/#new-core-dcafcore","title":"New Core (<code>dcaf/core/</code>)","text":"<ul> <li>\u2705 <code>Agent</code> class with <code>run(messages)</code> method</li> <li>\u2705 <code>ChatMessage</code> for structured input</li> <li>\u2705 <code>AgentResponse</code> with <code>needs_approval</code>, <code>pending_tools</code></li> <li>\u274c Does NOT implement <code>AgentProtocol</code></li> <li>\u274c No streaming support yet</li> <li>\u274c No server adapter</li> </ul>"},{"location":"plans/server-integration-plan/#phases","title":"Phases","text":""},{"location":"plans/server-integration-plan/#phase-1-protocol-adapter-bridge","title":"Phase 1: Protocol Adapter (Bridge)","text":"<p>Goal: Make Core agents work with the existing server immediately.</p> <p>Create an adapter that wraps <code>dcaf.core.Agent</code> to implement <code>AgentProtocol</code>:</p> <pre><code># dcaf/core/adapters/inbound/server_adapter.py\nfrom dcaf.core import Agent, AgentResponse\nfrom dcaf.agent_server import AgentProtocol\nfrom dcaf.schemas.messages import AgentMessage, ToolCall\n\nclass ServerAdapter(AgentProtocol):\n    \"\"\"Adapts a Core Agent to work with the existing FastAPI server.\"\"\"\n\n    def __init__(self, agent: Agent):\n        self.agent = agent\n\n    def invoke(self, messages: dict) -&gt; AgentMessage:\n        # Convert input format\n        core_messages = self._convert_messages(messages)\n\n        # Run the core agent\n        response = self.agent.run(messages=core_messages)\n\n        # Convert response to AgentMessage\n        return self._to_agent_message(response)\n\n    def _convert_messages(self, messages: dict) -&gt; list[dict]:\n        \"\"\"Convert from server format to Core format.\"\"\"\n        return messages.get(\"messages\", [])\n\n    def _to_agent_message(self, response: AgentResponse) -&gt; AgentMessage:\n        \"\"\"Convert AgentResponse to AgentMessage schema.\"\"\"\n        agent_msg = AgentMessage(content=response.text or \"\")\n\n        # Add pending tool calls for approval\n        if response.needs_approval:\n            for pending in response.pending_tools:\n                agent_msg.data.tool_calls.append(ToolCall(\n                    id=pending.id,\n                    name=pending.name,\n                    input=pending.input,\n                    tool_description=pending.description,\n                    input_description={},\n                ))\n\n        return agent_msg\n</code></pre> <p>Deliverables: - [x] <code>dcaf/core/adapters/inbound/server_adapter.py</code> - [x] Update <code>dcaf/core/__init__.py</code> to export <code>ServerAdapter</code> - [x] Example in <code>examples/core_server.py</code></p> <p>Usage: <pre><code>from dcaf.core import Agent\nfrom dcaf.core.adapters.inbound import ServerAdapter\nfrom dcaf.agent_server import create_chat_app\n\nagent = Agent(tools=[...])\napp = create_chat_app(ServerAdapter(agent))\n</code></pre></p>"},{"location":"plans/server-integration-plan/#phase-2-convenience-function","title":"Phase 2: Convenience Function","text":"<p>Goal: One-liner server startup.</p> <pre><code># dcaf/core/server.py\ndef serve(\n    agent: Agent,\n    port: int = 8000,\n    host: str = \"0.0.0.0\",\n    reload: bool = False,\n):\n    \"\"\"\n    Start a REST server for the agent.\n\n    Example:\n        from dcaf.core import Agent, serve\n\n        agent = Agent(tools=[...])\n        serve(agent, port=8000)\n    \"\"\"\n    from dcaf.agent_server import create_chat_app\n    from .adapters.inbound import ServerAdapter\n    import uvicorn\n\n    adapter = ServerAdapter(agent)\n    app = create_chat_app(adapter)\n\n    uvicorn.run(app, host=host, port=int(port), reload=reload)\n</code></pre> <p>Deliverables: - [x] <code>dcaf/core/server.py</code> with <code>serve()</code> and <code>create_app()</code> functions - [x] Export from <code>dcaf/core/__init__.py</code> - [ ] Update getting-started docs</p> <p>Usage: <pre><code>from dcaf.core import Agent, serve\n\nagent = Agent(tools=[my_tool])\nserve(agent)  # That's it!\n</code></pre></p>"},{"location":"plans/server-integration-plan/#phase-3-streaming-support","title":"Phase 3: Streaming Support","text":"<p>Goal: Real-time token streaming for better UX.</p> <p>Add streaming to the Core agent:</p> <pre><code># In dcaf/core/agent.py\nclass Agent:\n    def run_stream(\n        self, \n        messages: list[ChatMessage | dict],\n        context: dict | None = None,\n    ) -&gt; Iterator[StreamEvent]:\n        \"\"\"Stream agent response as events.\"\"\"\n        # Yield events as they happen\n        yield TextDeltaEvent(text=\"Hello\")\n        yield TextDeltaEvent(text=\" world\")\n        yield ToolCallsEvent(tool_calls=[...])  # If approval needed\n        yield DoneEvent()\n</code></pre> <p>Update <code>ServerAdapter</code> to implement <code>invoke_stream()</code>:</p> <pre><code>def invoke_stream(self, messages: dict) -&gt; Iterator[StreamEvent]:\n    core_messages = self._convert_messages(messages)\n    for event in self.agent.run_stream(messages=core_messages):\n        yield event\n</code></pre> <p>Deliverables: - [x] <code>Agent.run_stream()</code> method - [x] Agno adapter streaming support (already had it) - [x] <code>ServerAdapter.invoke_stream()</code> implementation - [x] Test with <code>/api/chat-stream</code> endpoint</p>"},{"location":"plans/server-integration-plan/#phase-4-cli-integration","title":"Phase 4: CLI Integration","text":"<p>Status: SKIPPED - <code>serve()</code> function is sufficient for current needs.</p>"},{"location":"plans/server-integration-plan/#phase-5-documentation-examples","title":"Phase 5: Documentation &amp; Examples","text":"<p>Goal: Make it obvious how to get started.</p> <p>Deliverables: - [x] <code>docs/core/server.md</code> - Server guide - [x] <code>examples/core_server.py</code> - Server example - [x] <code>examples/streaming_example.py</code> - Streaming example - [x] Updated <code>docs/core/index.md</code> with streaming section - [x] Updated <code>mkdocs.yml</code> navigation</p>"},{"location":"plans/server-integration-plan/#design-decisions","title":"Design Decisions","text":""},{"location":"plans/server-integration-plan/#q-reuse-existing-server-or-build-new","title":"Q: Reuse existing server or build new?","text":"<p>A: Reuse. The existing <code>agent_server.py</code> is well-designed: - Already handles streaming, health checks, channel routing - Battle-tested with DuploCloud helpdesk - Keeps compatibility with existing deployments</p>"},{"location":"plans/server-integration-plan/#q-where-does-the-adapter-live","title":"Q: Where does the adapter live?","text":"<p>A: <code>dcaf/core/adapters/inbound/</code>. This follows Clean Architecture: - Inbound adapters convert external formats to domain - Keeps the Core agent pure and framework-agnostic</p>"},{"location":"plans/server-integration-plan/#q-should-core-agents-depend-on-the-old-schemas","title":"Q: Should Core agents depend on the old schemas?","text":"<p>A: No, use adapters. The <code>ServerAdapter</code> does the translation: - Core uses simple types (<code>AgentResponse</code>, <code>PendingToolCall</code>) - Adapter converts to rich schemas (<code>AgentMessage</code>, <code>ToolCall</code>) - This allows schemas to evolve independently</p>"},{"location":"plans/server-integration-plan/#success-criteria","title":"Success Criteria","text":"<ol> <li>Zero Config Start: <code>serve(agent)</code> works out of the box</li> <li>Full Compatibility: Works with existing helpdesk integrations</li> <li>Streaming Works: Token-by-token streaming via NDJSON</li> <li>Approvals Work: Tool approval flow functions end-to-end</li> <li>Documented: Clear examples for common patterns</li> </ol>"},{"location":"plans/server-integration-plan/#timeline-estimate","title":"Timeline Estimate","text":"Phase Effort Dependencies Phase 1: Protocol Adapter 2-3 hours None Phase 2: Convenience Function 1 hour Phase 1 Phase 3: Streaming Support 4-6 hours Phase 1, Agno work Phase 4: CLI Integration 2 hours Phase 2 Phase 5: Documentation 2-3 hours All phases <p>Total: ~12-15 hours of development</p>"},{"location":"plans/server-integration-plan/#open-questions","title":"Open Questions","text":"<ol> <li>MCP Support: Should we also support FastMCP? (Model Context Protocol)</li> <li>The old code mentions it but I don't see implementation</li> <li> <p>Could be a Phase 6 addition</p> </li> <li> <p>Authentication: Does the server need auth middleware?</p> </li> <li>Currently relies on network-level security</li> <li> <p>May need API keys for public deployment</p> </li> <li> <p>Metrics/Observability: Add Prometheus metrics endpoint?</p> </li> <li>Could track request latency, tool execution time, errors</li> </ol>"},{"location":"plans/server-integration-plan/#next-actions","title":"Next Actions","text":"<ol> <li> Review this plan with team</li> <li> Start Phase 1: Create <code>ServerAdapter</code></li> <li> Test with existing helpdesk integration</li> <li> Iterate based on feedback</li> </ol>"},{"location":"presenation/dcaf-core-evolution/","title":"DCAF Core: A New Approach","text":"<p>A presentation introducing the DCAF Core API.</p>"},{"location":"presenation/dcaf-core-evolution/#slide-1-title","title":"Slide 1: Title","text":""},{"location":"presenation/dcaf-core-evolution/#dcaf-core","title":"DCAF Core","text":""},{"location":"presenation/dcaf-core-evolution/#building-ai-agents-with-simplicity","title":"Building AI Agents with Simplicity","text":"<p>DCAF = DuploCloud Agent Framework</p> <p>A Python framework for building LLM-powered AI agents with: - Tool calling - Human-in-the-loop approval - Production-ready REST API</p>"},{"location":"presenation/dcaf-core-evolution/#slide-2-what-is-dcaf-core","title":"Slide 2: What is DCAF Core?","text":""},{"location":"presenation/dcaf-core-evolution/#a-simple-api-for-complex-agent-workflows","title":"A Simple API for Complex Agent Workflows","text":"<p>DCAF Core provides a streamlined interface for building AI agents that can:</p> <ul> <li>\ud83d\udee0\ufe0f Call tools - Execute functions on behalf of users</li> <li>\u2705 Request approval - Pause for human authorization on sensitive operations</li> <li>\ud83d\udce1 Stream responses - Real-time token-by-token output</li> <li>\ud83c\udf10 Serve via REST - One-line HTTP server deployment</li> </ul> <p>Philosophy: Hide complexity, expose simplicity.</p>"},{"location":"presenation/dcaf-core-evolution/#slide-3-the-core-api-in-10-lines","title":"Slide 3: The Core API in 10 Lines","text":"<pre><code>from dcaf.core import Agent, serve\nfrom dcaf.tools import tool\n\n@tool(description=\"List Kubernetes pods\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n\nagent = Agent(tools=[list_pods], system=\"You are a Kubernetes assistant.\")\n\nserve(agent)\n</code></pre> <p>That's it. Your agent is now running at <code>http://localhost:8000</code>.</p>"},{"location":"presenation/dcaf-core-evolution/#slide-4-tool-definitions","title":"Slide 4: Tool Definitions","text":""},{"location":"presenation/dcaf-core-evolution/#three-ways-to-define-tool-schemas","title":"Three Ways to Define Tool Schemas","text":"<p>Option 1: Auto-Generate (Simplest)</p> <pre><code>@tool(description=\"Delete a Kubernetes pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n</code></pre> <p>The framework automatically infers parameter names, types, and required/optional from the signature.</p> <p>Option 2: Dict Schema (Full Control)</p> <pre><code>@tool(\n    description=\"Delete a Kubernetes pod\",\n    schema={\"type\": \"object\", \"properties\": {\"name\": {\"type\": \"string\"}, ...}}\n)\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n</code></pre> <p>Option 3: Pydantic Model (Type-Safe)</p> <pre><code>from pydantic import BaseModel, Field\n\nclass DeletePodInput(BaseModel):\n    name: str = Field(..., description=\"Pod name\")\n    namespace: str = Field(default=\"default\")\n\n@tool(description=\"Delete a pod\", schema=DeletePodInput)\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#adding-approval-requirements","title":"Adding Approval Requirements","text":"<pre><code>@tool(requires_approval=True, description=\"Delete a Kubernetes pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n</code></pre> <p>The agent will pause and request user approval before executing.</p>"},{"location":"presenation/dcaf-core-evolution/#slide-5-the-agent-class","title":"Slide 5: The Agent Class","text":""},{"location":"presenation/dcaf-core-evolution/#minimal-configuration-maximum-capability","title":"Minimal Configuration, Maximum Capability","text":"<pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    tools=[list_pods, delete_pod, restart_deployment],\n    system=\"You are a Kubernetes assistant for the production cluster.\",\n)\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#running-the-agent-programmatically","title":"Running the Agent Programmatically","text":"<pre><code>response = agent.run([\n    {\"role\": \"user\", \"content\": \"What pods are running in the default namespace?\"}\n])\n\nprint(response.text)\n# \"Here are the pods currently running in the default namespace: ...\"\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-6-the-serve-function","title":"Slide 6: The serve() Function","text":""},{"location":"presenation/dcaf-core-evolution/#one-line-rest-api-server","title":"One-Line REST API Server","text":"<pre><code>from dcaf.core import serve\n\nserve(agent)  # Running at http://0.0.0.0:8000\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#configuration-options","title":"Configuration Options","text":"<pre><code>serve(\n    agent,\n    port=8000,              # Port to listen on\n    host=\"0.0.0.0\",         # Host to bind to\n    reload=True,            # Auto-reload for development\n    log_level=\"info\",       # Logging verbosity\n)\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-7-production-configuration","title":"Slide 7: Production Configuration","text":""},{"location":"presenation/dcaf-core-evolution/#built-in-support-for-production-deployments","title":"Built-in Support for Production Deployments","text":"<pre><code>serve(\n    agent,\n    port=8000,\n    workers=4,              # Multiple worker processes\n    timeout_keep_alive=30,  # Match load balancer timeout\n    log_level=\"warning\",\n)\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#parameters","title":"Parameters","text":"Parameter Default Purpose <code>workers</code> <code>1</code> Number of worker processes for parallelism <code>timeout_keep_alive</code> <code>5</code> Keep-alive timeout in seconds"},{"location":"presenation/dcaf-core-evolution/#best-practices","title":"Best Practices","text":"<ul> <li>Workers: Use <code>(2 \u00d7 cpu_cores) + 1</code> for production</li> <li>Keep-Alive: Set to match your load balancer (AWS ALB default is 60s)</li> </ul>"},{"location":"presenation/dcaf-core-evolution/#slide-8-rest-api-endpoints","title":"Slide 8: REST API Endpoints","text":""},{"location":"presenation/dcaf-core-evolution/#automatically-created-endpoints","title":"Automatically Created Endpoints","text":"Endpoint Method Description <code>/health</code> GET Health check (always responds immediately) <code>/api/chat</code> POST Synchronous chat <code>/api/chat-stream</code> POST Streaming chat (NDJSON)"},{"location":"presenation/dcaf-core-evolution/#example-request","title":"Example Request","text":"<pre><code>curl -X POST http://localhost:8000/api/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"messages\": [{\"role\": \"user\", \"content\": \"List the pods\"}]}'\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#example-response","title":"Example Response","text":"<pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"Here are the pods in the default namespace: nginx-abc, redis-xyz...\",\n  \"data\": {\"tool_calls\": [], \"executed_tool_calls\": [...]}\n}\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-9-human-in-the-loop-approval","title":"Slide 9: Human-in-the-Loop Approval","text":""},{"location":"presenation/dcaf-core-evolution/#how-it-works","title":"How It Works","text":"<ol> <li>User asks agent to perform an action</li> <li>Agent identifies a tool that requires approval</li> <li>Agent pauses and returns pending tool calls</li> <li>User reviews and approves (or rejects)</li> <li>Agent executes the approved tool</li> </ol>"},{"location":"presenation/dcaf-core-evolution/#response-with-pending-approval","title":"Response with Pending Approval","text":"<pre><code>{\n  \"role\": \"assistant\",\n  \"content\": \"I'll delete the pod. This requires your approval.\",\n  \"data\": {\n    \"tool_calls\": [{\n      \"id\": \"tc_123\",\n      \"name\": \"delete_pod\",\n      \"input\": {\"name\": \"nginx-abc\", \"namespace\": \"production\"},\n      \"execute\": false\n    }]\n  }\n}\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-10-custom-agent-logic","title":"Slide 10: Custom Agent Logic","text":""},{"location":"presenation/dcaf-core-evolution/#using-functions-for-complex-workflows","title":"Using Functions for Complex Workflows","text":"<pre><code>from dcaf.core import Agent, AgentResult, serve\n\ndef my_agent(messages: list, context: dict) -&gt; AgentResult:\n    # Access platform context\n    tenant = context.get(\"tenant_name\")\n\n    # Classify intent first\n    classifier = Agent(system=\"Classify as: query, action, or unknown\")\n    intent = classifier.run(messages)\n\n    if \"action\" in intent.text.lower():\n        # Use tools for actions\n        executor = Agent(\n            tools=[list_pods, delete_pod],\n            system=f\"You are helping tenant: {tenant}\"\n        )\n        result = executor.run(messages)\n        return AgentResult(text=result.text)\n\n    # Just answer the question\n    return AgentResult(text=intent.text)\n\nserve(my_agent)\n</code></pre> <p>Any structure you need. Multiple LLM calls, branching, orchestration.</p>"},{"location":"presenation/dcaf-core-evolution/#slide-11-platform-context","title":"Slide 11: Platform Context","text":""},{"location":"presenation/dcaf-core-evolution/#automatic-context-extraction","title":"Automatic Context Extraction","text":"<p>The framework automatically extracts platform context from incoming requests:</p> <pre><code>def my_agent(messages: list, context: dict) -&gt; AgentResult:\n    # Context is extracted for you\n    tenant = context.get(\"tenant_name\")\n    namespace = context.get(\"k8s_namespace\")\n    user_id = context.get(\"user_id\")\n\n    # Use it in your logic\n    agent = Agent(\n        tools=[...],\n        system=f\"Assisting tenant {tenant} in namespace {namespace}\"\n    )\n    ...\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#available-context-fields","title":"Available Context Fields","text":"<ul> <li><code>tenant_name</code> - DuploCloud tenant</li> <li><code>k8s_namespace</code> - Kubernetes namespace</li> <li><code>user_id</code> - Requesting user</li> <li><code>duplo_token</code> - Authentication token</li> <li>Custom fields from your integration</li> </ul>"},{"location":"presenation/dcaf-core-evolution/#slide-12-streaming-responses","title":"Slide 12: Streaming Responses","text":""},{"location":"presenation/dcaf-core-evolution/#real-time-token-by-token-output","title":"Real-Time Token-by-Token Output","text":"<pre><code>curl -X POST http://localhost:8000/api/chat-stream \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"messages\": [{\"role\": \"user\", \"content\": \"Explain Kubernetes\"}]}'\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#ndjson-response-stream","title":"NDJSON Response Stream","text":"<pre><code>{\"type\": \"text_delta\", \"text\": \"Kubernetes\"}\n{\"type\": \"text_delta\", \"text\": \" is\"}\n{\"type\": \"text_delta\", \"text\": \" a\"}\n{\"type\": \"text_delta\", \"text\": \" container\"}\n{\"type\": \"text_delta\", \"text\": \" orchestration\"}\n{\"type\": \"text_delta\", \"text\": \" platform...\"}\n{\"type\": \"done\"}\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#event-types","title":"Event Types","text":"Type Description <code>text_delta</code> Incremental text from the LLM <code>tool_calls</code> Tools requiring approval <code>executed_tool_calls</code> Results from executed tools <code>done</code> Stream completed <code>error</code> An error occurred"},{"location":"presenation/dcaf-core-evolution/#slide-13-adding-custom-endpoints","title":"Slide 13: Adding Custom Endpoints","text":""},{"location":"presenation/dcaf-core-evolution/#extend-your-agent-server","title":"Extend Your Agent Server","text":"<pre><code>from dcaf.core import Agent, serve\nfrom fastapi import APIRouter\n\nagent = Agent(tools=[...])\n\n# Create custom router\ncustom_router = APIRouter()\n\n@custom_router.get(\"/api/custom/schema\")\nasync def get_schema():\n    return {\"tools\": [\"list_pods\", \"delete_pod\"]}\n\n@custom_router.get(\"/api/custom/health\")\nasync def detailed_health():\n    return {\"status\": \"healthy\", \"tools_loaded\": 2}\n\n# Include custom routes\nserve(agent, additional_routers=[custom_router])\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-14-programmatic-app-control","title":"Slide 14: Programmatic App Control","text":""},{"location":"presenation/dcaf-core-evolution/#using-create_app-for-full-control","title":"Using create_app() for Full Control","text":"<pre><code>from dcaf.core import Agent, create_app\nimport uvicorn\n\nagent = Agent(tools=[...])\napp = create_app(agent)\n\n# Add middleware, custom configuration, etc.\n@app.middleware(\"http\")\nasync def log_requests(request, call_next):\n    print(f\"Request: {request.url}\")\n    return await call_next(request)\n\n# Run with full uvicorn control\nuvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-15-docker-deployment","title":"Slide 15: Docker Deployment","text":""},{"location":"presenation/dcaf-core-evolution/#production-ready-container","title":"Production-Ready Container","text":"<pre><code># main.py\nimport os\nfrom dcaf.core import Agent, serve\nfrom my_tools import list_pods, delete_pod\n\nagent = Agent(\n    tools=[list_pods, delete_pod],\n    system=\"You are a Kubernetes assistant.\"\n)\n\nif __name__ == \"__main__\":\n    serve(\n        agent,\n        host=\"0.0.0.0\",\n        port=int(os.getenv(\"PORT\", 8000)),\n        workers=int(os.getenv(\"WORKERS\", 4)),\n        timeout_keep_alive=int(os.getenv(\"KEEP_ALIVE\", 30)),\n    )\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#dockerfile","title":"Dockerfile","text":"<pre><code>FROM python:3.11-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .\nCMD [\"python\", \"main.py\"]\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#run-with-configuration","title":"Run with Configuration","text":"<pre><code>docker run -e WORKERS=8 -e KEEP_ALIVE=60 -p 8000:8000 my-agent:latest\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-16-kubernetes-deployment","title":"Slide 16: Kubernetes Deployment","text":""},{"location":"presenation/dcaf-core-evolution/#health-check-configuration","title":"Health Check Configuration","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n        - name: agent\n          livenessProbe:\n            httpGet:\n              path: /health\n              port: 8000\n            initialDelaySeconds: 5\n            periodSeconds: 10\n            timeoutSeconds: 5\n          readinessProbe:\n            httpGet:\n              path: /health\n              port: 8000\n            periodSeconds: 5\n</code></pre> <p>Note: The <code>/health</code> endpoint is non-blocking, so health checks won't timeout during long LLM calls.</p>"},{"location":"presenation/dcaf-core-evolution/#slide-17-complete-example-kubernetes-agent","title":"Slide 17: Complete Example - Kubernetes Agent","text":"<pre><code>from dcaf.core import Agent, serve\nfrom dcaf.tools import tool\nimport subprocess\n\ndef kubectl(cmd: str) -&gt; str:\n    result = subprocess.run(f\"kubectl {cmd}\", shell=True, capture_output=True, text=True)\n    return result.stdout or result.stderr\n\n@tool(description=\"List Kubernetes pods in a namespace\")\ndef list_pods(namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"get pods -n {namespace}\")\n\n@tool(description=\"Get details about a specific pod\")\ndef describe_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"describe pod {name} -n {namespace}\")\n\n@tool(requires_approval=True, description=\"Delete a Kubernetes pod\")\ndef delete_pod(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"delete pod {name} -n {namespace}\")\n\n@tool(requires_approval=True, description=\"Restart a deployment\")\ndef restart_deployment(name: str, namespace: str = \"default\") -&gt; str:\n    return kubectl(f\"rollout restart deployment {name} -n {namespace}\")\n\nagent = Agent(\n    tools=[list_pods, describe_pod, delete_pod, restart_deployment],\n    system=\"You are a Kubernetes assistant. Help users manage their cluster.\",\n)\n\nif __name__ == \"__main__\":\n    serve(agent, port=8000, workers=4)\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-18-architecture-overview","title":"Slide 18: Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         Your Code                                \u2502\n\u2502                                                                  \u2502\n\u2502   agent = Agent(tools=[...])    OR    def my_agent(messages, ctx)\u2502\n\u2502   serve(agent)                        serve(my_agent)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        DCAF Core                                 \u2502\n\u2502                                                                  \u2502\n\u2502   \u2022 Receives HTTP request                                       \u2502\n\u2502   \u2022 Converts to simple message format                           \u2502\n\u2502   \u2022 Runs your agent logic                                       \u2502\n\u2502   \u2022 Handles tool approvals automatically                        \u2502\n\u2502   \u2022 Returns response in HelpDesk protocol                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n                             \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    LLM (AWS Bedrock)                             \u2502\n\u2502                                                                  \u2502\n\u2502   Claude 3.5 Sonnet / Claude 4 / etc.                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-19-key-concepts","title":"Slide 19: Key Concepts","text":"Concept Description Agent Your LLM-powered assistant with tools Tool A function the agent can call (auto-generate, dict, or Pydantic schema) Approval Human authorization for sensitive tools serve() One-line REST API server create_app() Programmatic FastAPI control Platform Context Runtime environment (tenant, namespace, etc.) AgentResult Return type for custom agent functions"},{"location":"presenation/dcaf-core-evolution/#slide-20-getting-started","title":"Slide 20: Getting Started","text":""},{"location":"presenation/dcaf-core-evolution/#installation","title":"Installation","text":"<pre><code>pip install git+https://github.com/duplocloud/dcaf.git\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#minimal-example","title":"Minimal Example","text":"<pre><code>from dcaf.core import Agent, serve\nfrom dcaf.tools import tool\n\n@tool(description=\"Say hello\")\ndef greet(name: str) -&gt; str:\n    return f\"Hello, {name}!\"\n\nagent = Agent(tools=[greet])\nserve(agent)\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#documentation","title":"Documentation","text":"<ul> <li>Core Overview: <code>docs/core/index.md</code></li> <li>Server Guide: <code>docs/core/server.md</code></li> <li>Custom Agents: <code>docs/guides/custom-agents.md</code></li> <li>Streaming: <code>docs/guides/streaming.md</code></li> </ul>"},{"location":"presenation/dcaf-core-evolution/#slide-21-prompt-caching","title":"Slide 21: Prompt Caching","text":""},{"location":"presenation/dcaf-core-evolution/#reduce-costs-by-up-to-90","title":"Reduce Costs by up to 90%","text":"<p>What is Prompt Caching?</p> <p>AWS Bedrock feature that caches static prompt content.</p> <p>Benefits: - Up to 90% cost reduction on cached tokens - Up to 85% latency reduction - 5-minute cache TTL (resets on each cache hit)</p> <p>Key Insight: Separate static instructions (cached) from dynamic context (fresh)</p> <p>Status: Experimental v1 - Temporary until Agno adds native support</p>"},{"location":"presenation/dcaf-core-evolution/#slide-22-how-prompt-caching-works","title":"Slide 22: How Prompt Caching Works","text":""},{"location":"presenation/dcaf-core-evolution/#dcaf-places-a-cache-checkpoint-between-static-and-dynamic-parts","title":"DCAF places a cache checkpoint between static and dynamic parts:","text":"<pre><code>[Static Instructions]  \u2190 CACHED (same for all requests)\n         \u2193\n[Cache Checkpoint]\n         \u2193\n[Dynamic Context]      \u2190 NOT cached (fresh each time)\n</code></pre> <p>Example: - Static: \"You are a K8s expert. [detailed guidelines]\" \u2190 CACHED - Dynamic: \"Tenant: acme-corp, User: alice\" \u2190 FRESH</p>"},{"location":"presenation/dcaf-core-evolution/#slide-23-basic-prompt-caching-usage","title":"Slide 23: Basic Prompt Caching Usage","text":""},{"location":"presenation/dcaf-core-evolution/#enable-caching-with-one-parameter","title":"Enable caching with one parameter:","text":"<pre><code>from dcaf.core import Agent\n\nagent = Agent(\n    system_prompt='''You are a Kubernetes expert.\n\n    [Add detailed guidelines here - aim for 1024+ tokens]\n\n    Guidelines:\n    - Always verify namespace before operations\n    - Explain what each command does\n    - Ask for confirmation on destructive operations\n    [... more detailed instructions ...]\n    ''',\n\n    tools=[list_pods, delete_pod],\n\n    model_config={\n        \"cache_system_prompt\": True  # Enable caching\n    }\n)\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-24-static-dynamic-pattern","title":"Slide 24: Static + Dynamic Pattern","text":""},{"location":"presenation/dcaf-core-evolution/#the-recommended-pattern-for-maximum-savings","title":"The recommended pattern for maximum savings:","text":"<pre><code>agent = Agent(\n    # Static part - cached (same for all requests)\n    system_prompt='''You are a Kubernetes expert for a multi-tenant platform.\n\n    [Detailed guidelines, examples, best practices...]\n    - Verify tenant context before operations\n    - Follow security best practices\n    - Provide clear explanations\n    ''',\n\n    # Dynamic part - NOT cached (changes per request)\n    system_context=lambda ctx: f'''\n    === CURRENT CONTEXT ===\n    Tenant: {ctx.get('tenant_name')}\n    Namespace: {ctx.get('k8s_namespace')}\n    User: {ctx.get('user_email')}\n    ''',\n\n    model_config={\"cache_system_prompt\": True}\n)\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-25-requirements-best-practices","title":"Slide 25: Requirements &amp; Best Practices","text":""},{"location":"presenation/dcaf-core-evolution/#minimum-token-count","title":"Minimum Token Count:","text":"<ul> <li>Claude 3.7 Sonnet: 1024 tokens</li> <li>Claude 3.5 Haiku: 2048 tokens</li> <li>~4 characters = 1 token (aim for 4000+ chars)</li> </ul>"},{"location":"presenation/dcaf-core-evolution/#best-practices_1","title":"Best Practices:","text":"<ol> <li>Make static content detailed and comprehensive</li> <li>Put all variable data in <code>system_context</code></li> <li>Monitor logs for cache HIT/MISS indicators</li> <li>Ensure high request volume (&gt;1 per 5 minutes)</li> </ol>"},{"location":"presenation/dcaf-core-evolution/#slide-26-cost-savings-example","title":"Slide 26: Cost Savings Example","text":""},{"location":"presenation/dcaf-core-evolution/#scenario-100-requests-with-1500-token-static-prompt-100-token-dynamic","title":"Scenario: 100 requests with 1500-token static prompt + 100-token dynamic","text":"<p>Without caching: - 100 \u00d7 1600 tokens = 160,000 tokens - Cost: ~$0.48</p> <p>With caching: - First request: 1600 tokens (MISS) - Next 99 requests: 100 tokens each (HIT) - Total: 11,500 tokens - Cost: ~$0.035</p> <p>Savings: ~93% \ud83d\udcb0</p>"},{"location":"presenation/dcaf-core-evolution/#slide-27-monitoring-cache-performance","title":"Slide 27: Monitoring Cache Performance","text":""},{"location":"presenation/dcaf-core-evolution/#dcaf-logs-cache-metrics-automatically","title":"DCAF logs cache metrics automatically:","text":"<pre><code># Console logs show cache status:\n\nINFO: \u2705 Cache HIT: 950 tokens reused (~90% cost reduction)\nINFO: \ud83d\udcdd Cache MISS: 950 tokens cached for next request\n\n# First request is always a MISS (creates cache)\nRequest 1: MISS (creates cache)  \u2192 Full cost\nRequest 2: HIT  (uses cache)     \u2192 10% cost\nRequest 3: HIT  (uses cache)     \u2192 10% cost\n...\nRequest N: MISS (cache expired after 5 min) \u2192 Full cost\n\n# Warnings if misconfigured:\nWARNING: System prompt (~500 tokens) below minimum threshold\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-28-a2a-agent-to-agent-protocol","title":"Slide 28: A2A (Agent-to-Agent) Protocol","text":""},{"location":"presenation/dcaf-core-evolution/#multi-agent-systems-made-easy","title":"Multi-Agent Systems Made Easy","text":"<p>DCAF now supports Google's A2A protocol for agent-to-agent communication.</p> <p>What is A2A? - \ud83d\udd0d Agent Discovery via Agent Cards - \ud83d\udce1 Standardized task execution - \ud83c\udf10 HTTP/JSON-RPC based - \u26a1 Async task support</p> <p>Why A2A? - Specialize: Build focused agents (K8s, AWS, databases) - Compose: Combine agents into powerful systems - Interoperate: Work with agents from other frameworks</p>"},{"location":"presenation/dcaf-core-evolution/#slide-29-a2a-server-expose-your-agent","title":"Slide 29: A2A Server - Expose Your Agent","text":""},{"location":"presenation/dcaf-core-evolution/#make-your-agent-discoverable","title":"Make Your Agent Discoverable","text":"<pre><code>from dcaf.core import Agent, serve\n\nagent = Agent(\n    name=\"k8s-assistant\",              # A2A identity\n    description=\"Kubernetes helper\",   # A2A description\n    tools=[list_pods, delete_pod],\n)\n\n# Enable A2A alongside REST API\nserve(agent, port=8000, a2a=True)\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#automatic-endpoints","title":"Automatic Endpoints","text":"Endpoint Purpose <code>GET /.well-known/agent.json</code> Agent card (discovery) <code>POST /a2a/tasks/send</code> Receive tasks <code>GET /a2a/tasks/{id}</code> Task status"},{"location":"presenation/dcaf-core-evolution/#slide-30-a2a-client-call-remote-agents","title":"Slide 30: A2A Client - Call Remote Agents","text":""},{"location":"presenation/dcaf-core-evolution/#connect-and-call","title":"Connect and Call","text":"<pre><code>from dcaf.core.a2a import RemoteAgent\n\n# Connect to remote agent\nk8s = RemoteAgent(url=\"http://k8s-agent:8000\")\n\n# Send a task\nresult = k8s.send(\"What pods are failing in production?\")\nprint(result.text)\n\n# Check agent capabilities\nprint(f\"Agent: {k8s.name}\")           # \"k8s-assistant\"\nprint(f\"Skills: {k8s.skills}\")        # [\"list_pods\", \"delete_pod\", ...]\n</code></pre> <p>Agent Card (Auto-Generated): <pre><code>{\n  \"name\": \"k8s-assistant\",\n  \"description\": \"Kubernetes helper\",\n  \"skills\": [\"list_pods\", \"delete_pod\"],\n  \"url\": \"http://k8s-agent:8000\"\n}\n</code></pre></p>"},{"location":"presenation/dcaf-core-evolution/#slide-31-multi-agent-orchestration","title":"Slide 31: Multi-Agent Orchestration","text":""},{"location":"presenation/dcaf-core-evolution/#pattern-orchestrator-specialists","title":"Pattern: Orchestrator + Specialists","text":"<pre><code>from dcaf.core import Agent\nfrom dcaf.core.a2a import RemoteAgent\n\n# Connect to specialist agents\nk8s = RemoteAgent(url=\"http://k8s-agent:8000\")\naws = RemoteAgent(url=\"http://aws-agent:8000\")\ndb = RemoteAgent(url=\"http://db-agent:8000\")\n\n# Orchestrator routes to specialists\norchestrator = Agent(\n    name=\"orchestrator\",\n    tools=[\n        k8s.as_tool(),  # Remote agent as tool\n        aws.as_tool(),\n        db.as_tool(),\n    ],\n    system=\"Route requests to the appropriate specialist agent\"\n)\n</code></pre> <p>The LLM decides which specialist to call!</p>"},{"location":"presenation/dcaf-core-evolution/#slide-32-a2a-architecture","title":"Slide 32: A2A Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Multi-Agent System                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Orchestrator \u2502                          \u2502 K8s Agent    \u2502\n\u2502   (Port 8000)\u2502    /.well-known/agent    \u2502 (Port 8001)  \u2502\n\u2502              \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502              \u2502\n\u2502  Tools:      \u2502    /a2a/tasks/send       \u2502  Tools:      \u2502\n\u2502  - k8s       \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  - list_pods \u2502\n\u2502  - aws       \u2502                          \u2502  - delete_pod\u2502\n\u2502  - db        \u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                                   \u2502 AWS Agent    \u2502\n       \u2502    /.well-known/agent             \u2502 (Port 8002)  \u2502\n       \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502              \u2502\n       \u2502    /a2a/tasks/send                \u2502  Tools:      \u2502\n       \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  - list_ec2  \u2502\n       \u2502                                   \u2502  - get_costs \u2502\n       \u2502                                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n       \u25bc\n    User Query: \"What's my infrastructure status?\"\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-33-a2a-example-complete-system","title":"Slide 33: A2A Example - Complete System","text":""},{"location":"presenation/dcaf-core-evolution/#kubernetes-specialist","title":"Kubernetes Specialist","text":"<pre><code># k8s_agent.py\nfrom dcaf.core import Agent, serve\n\nagent = Agent(\n    name=\"k8s-assistant\",\n    description=\"Manages Kubernetes clusters\",\n    tools=[list_pods, delete_pod],\n)\nserve(agent, port=8001, a2a=True)\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#aws-specialist","title":"AWS Specialist","text":"<pre><code># aws_agent.py\nfrom dcaf.core import Agent, serve\n\nagent = Agent(\n    name=\"aws-assistant\",\n    description=\"Manages AWS resources\",\n    tools=[list_ec2, get_costs],\n)\nserve(agent, port=8002, a2a=True)\n</code></pre>"},{"location":"presenation/dcaf-core-evolution/#slide-34-a2a-orchestrator","title":"Slide 34: A2A Orchestrator","text":"<pre><code># orchestrator.py\nfrom dcaf.core import Agent, serve\nfrom dcaf.core.a2a import RemoteAgent\n\n# Connect to specialists\nk8s = RemoteAgent(url=\"http://localhost:8001\")\naws = RemoteAgent(url=\"http://localhost:8002\")\n\n# Create orchestrator\norchestrator = Agent(\n    name=\"orchestrator\",\n    tools=[k8s.as_tool(), aws.as_tool()],\n    system=\"\"\"You route requests to specialist agents.\n    Use k8s_assistant for Kubernetes questions.\n    Use aws_assistant for AWS questions.\"\"\"\n)\n\nserve(orchestrator, port=8000, a2a=True)\n</code></pre> <p>Usage: <pre><code>result = orchestrator.send(\"How many pods and EC2 instances?\")\n# Orchestrator calls both specialists automatically!\n</code></pre></p>"},{"location":"presenation/dcaf-core-evolution/#slide-35-a2a-benefits","title":"Slide 35: A2A Benefits","text":"Benefit Description Specialization Each agent focuses on one domain Composability Build complex systems from simple agents Scalability Distribute work across multiple agents Interoperability Works with other A2A-compatible frameworks No Agno Lock-in Clean abstraction, swappable adapters"},{"location":"presenation/dcaf-core-evolution/#design-principles","title":"Design Principles","text":"<p>\u2705 Simple: One line to enable (<code>a2a=True</code>) \u2705 Flexible: Use as tool or call directly \u2705 Standard: Google's A2A protocol \u2705 Extensible: Adapter pattern for future implementations</p>"},{"location":"presenation/dcaf-core-evolution/#slide-36-updated-feature-matrix","title":"Slide 36: Updated Feature Matrix","text":"Feature Status Example Simple Agent \u2705 <code>Agent(tools=[...])</code> Tool Calling \u2705 <code>@tool(description=\"...\")</code> Human Approval \u2705 <code>requires_approval=True</code> Interceptors \u2705 <code>request_interceptors=[...]</code> Streaming \u2705 <code>agent.run_stream(...)</code> REST Server \u2705 <code>serve(agent, port=8000)</code> Prompt Caching \u2705 NEW! <code>model_config={\"cache_system_prompt\": True}</code> A2A Protocol \u2705 NEW! <code>serve(agent, a2a=True)</code> Multi-Agent \u2705 NEW! <code>RemoteAgent(url=...).as_tool()</code>"},{"location":"presenation/dcaf-core-evolution/#slide-37-qa","title":"Slide 37: Q&amp;A","text":""},{"location":"presenation/dcaf-core-evolution/#questions","title":"Questions?","text":""},{"location":"presenation/dcaf-core-evolution/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Simple API - <code>Agent</code> + <code>serve()</code> is all you need</li> <li>Flexible tool schemas - Auto-generate, dict, or Pydantic models</li> <li>Human-in-the-loop - Built-in approval for sensitive operations</li> <li>Production-ready - Workers, keep-alive, health checks included</li> <li>Cost Optimization - NEW! Prompt caching reduces costs by up to 90%</li> <li>Multi-Agent - NEW! A2A protocol for agent-to-agent communication</li> </ol> <p>Presentation created January 2026 DCAF Core - vnext branch Updated with A2A support</p>"},{"location":"responses/tool-context-injection-response/","title":"Response to Feature Request: Tool Context Injection","text":"<p>To: Architecture Diagram Agent Team From: DCAF Core Team Date: January 6, 2026 Re: Feature Request - Tool Context Injection Status: \u2705 Resolved</p>"},{"location":"responses/tool-context-injection-response/#summary","title":"Summary","text":"<p>We reviewed your feature request and have good news: the functionality you need already exists in DCAF, but there was a bug preventing it from working when Agno executes tools. We've fixed that bug and pushed the changes to the <code>vnext</code> branch.</p> <p>You don't need a new <code>_context</code> convention. Use the existing <code>platform_context</code> parameter instead.</p>"},{"location":"responses/tool-context-injection-response/#what-was-wrong","title":"What Was Wrong","text":"<p>Your diagnosis was accurate. When Agno executes tools internally, it was bypassing DCAF's context injection mechanism. The flow was:</p> <pre><code>Interceptor \u2192 sets request.context[\"tenant_id\"]\n      \u2193\nAgentService \u2192 had the context\n      \u2193\nAgnoAdapter \u2192 did NOT pass context to tools\n      \u2193\nAgno \u2192 called raw functions with only LLM-provided args\n      \u2193\nTool \u2192 received NO platform_context \u274c\n</code></pre>"},{"location":"responses/tool-context-injection-response/#what-we-fixed","title":"What We Fixed","text":"<p>We updated the Agno adapter to inject <code>platform_context</code> into tools that declare it. The fix (commit <code>0247d3f</code>) includes:</p> <ol> <li>AgentRuntime port \u2014 Added <code>platform_context</code> parameter to <code>invoke()</code> and <code>invoke_stream()</code></li> <li>AgentService \u2014 Now passes context to the runtime</li> <li>AgnoAdapter \u2014 Creates wrapper closures that inject <code>platform_context</code> into tools</li> </ol>"},{"location":"responses/tool-context-injection-response/#how-to-use-it","title":"How to Use It","text":"<p>Use the existing <code>platform_context</code> parameter convention:</p> <pre><code>from dcaf.tools import tool\n\n@tool(description=\"Execute a Cypher query with tenant scoping\")\ndef run_cypher_query(\n    cypher: str,\n    params: dict = None,\n    platform_context: dict = None,  # \u2190 DCAF injects this automatically\n) -&gt; str:\n    \"\"\"Execute a Cypher query with automatic tenant scoping.\"\"\"\n    tenant_id = platform_context.get(\"tenant_id\")\n    role = platform_context.get(\"_resolved_role\", \"User\")\n\n    # Now you can enforce security!\n    if role != \"Administrator\":\n        cypher = add_tenant_filter(cypher, tenant_id)\n\n    return execute_query(cypher, params)\n</code></pre>"},{"location":"responses/tool-context-injection-response/#key-points","title":"Key Points","text":"Aspect Behavior Parameter name Must be exactly <code>platform_context</code> Hidden from LLM \u2705 Yes \u2014 not included in tool schema Automatically injected \u2705 Yes \u2014 when Agno executes the tool Contains interceptor values \u2705 Yes \u2014 same context object Thread-safe \u2705 Yes \u2014 captured in closure, no globals Testable \u2705 Yes \u2014 just pass the dict in unit tests"},{"location":"responses/tool-context-injection-response/#testing-your-tools","title":"Testing Your Tools","text":"<pre><code>def test_query_with_tenant_scoping():\n    result = run_cypher_query(\n        cypher=\"MATCH (n) RETURN n\",\n        platform_context={\"tenant_id\": \"test-tenant\", \"_resolved_role\": \"User\"}\n    )\n    assert \"IN_TENANT\" in result  # Verify scoping was applied\n</code></pre>"},{"location":"responses/tool-context-injection-response/#why-we-didnt-use-the-_-prefix-convention","title":"Why We Didn't Use the <code>_</code> Prefix Convention","text":"<p>Your proposed <code>_context</code> convention was well-designed, but we already had <code>platform_context</code> doing the same thing. Adding a parallel convention would:</p> <ol> <li>Increase API surface area</li> <li>Create confusion about which to use</li> <li>Require documentation for both patterns</li> </ol> <p>The existing convention works \u2014 it just needed the adapter bug fixed.</p>"},{"location":"responses/tool-context-injection-response/#removing-your-workaround","title":"Removing Your Workaround","text":"<p>You can now remove the thread-local global store workaround:</p> <pre><code># BEFORE (workaround) - can be removed\nset_platform_context({\"tenant_id\": \"abc\"})\nctx = get_platform_context()\n\n# AFTER (native DCAF) - just use the parameter\ndef my_tool(arg: str, platform_context: dict = None) -&gt; str:\n    ctx = platform_context  # Already injected!\n</code></pre>"},{"location":"responses/tool-context-injection-response/#questions","title":"Questions?","text":"<p>The fix is available now on <code>vnext</code>. If you encounter any issues or need additional context fields exposed, please reach out.</p> <p>Commit: <code>0247d3f</code> on <code>vnext</code> Files changed:  - <code>dcaf/core/adapters/outbound/agno/adapter.py</code> - <code>dcaf/core/application/ports/agent_runtime.py</code> - <code>dcaf/core/application/services/agent_service.py</code></p>"},{"location":"review/review-1/","title":"DECAF Framework Review Meeting Summary","text":"<p>Date: Meeting transcript review Presenter: Chuck Conway Attendees: Pranav Chakilam, Andy Boutte, Prem Lakshmanan, Mal Marconi, Sum Yip, Adam Smith</p>"},{"location":"review/review-1/#overview","title":"Overview","text":"<p>Chuck presented an expanded version of DECAF (DuploCloud Agent Framework), building on Pranav's original work. The goal is to create a framework that abstracts complexity while allowing agents to focus on solving domain problems. The framework currently uses Agno under the covers but is designed to be swappable.</p>"},{"location":"review/review-1/#key-points-takeaways","title":"Key Points &amp; Takeaways","text":""},{"location":"review/review-1/#philosophy-design-principles","title":"Philosophy &amp; Design Principles","text":"<ul> <li>\"Hide complexity, expose simplicity\" \u2014 but still allow access to advanced controls when needed</li> <li>No vendor lock-in \u2014 abstract implementation details (Agno, LangChain, Strands) so they can be swapped</li> <li>Pranav's strong emphasis on \"no magic\" \u2014 keep code lean, transparent, and minimal abstractions</li> <li>An agent is fundamentally: one LLM API call + tools. Everything else is noise.</li> <li>As few lines of code and as few abstractions as possible</li> <li>Complete transparency \u2014 no one should wonder \"what is this? how does it work?\"</li> <li>Target audience: internal engineers now, but eventually customers building their own agents</li> </ul>"},{"location":"review/review-1/#new-features-added","title":"New Features Added","text":"Feature Description Tool calling With approval workflows Human-in-the-loop Approval process for high-risk operations Session state management Persist data between conversation turns Streaming support Real-time response streaming REST API changes Renamed endpoints, snake_case convention Request/Response interceptors Modify payloads before/after LLM calls Event system Pub/sub pattern for logging, notifications Prompt caching Cache static portions of prompts for cost/speed savings (experimental)"},{"location":"review/review-1/#tool-definition-methods","title":"Tool Definition Methods","text":"<p>Three ways to define tool schemas:</p> <ol> <li>Auto-generated \u2014 from function signature (simplest)</li> <li>Dictionary schema \u2014 most flexible, least safe</li> <li>Pydantic models \u2014 most structured, validates at definition time</li> </ol>"},{"location":"review/review-1/#modules-duplocloud-should-fully-own","title":"Modules DuploCloud Should Fully Own","text":"<p>Per team agreement, these should NOT be delegated to Agno:</p> <ol> <li>Schemas module \u2014 Pydantic data classes for API inputs/outputs</li> <li>Agent server module \u2014 FastAPI app creation and endpoints</li> </ol>"},{"location":"review/review-1/#key-agreements-reached","title":"Key Agreements Reached","text":"Decision Details High-risk tools flag location Should live on the tool itself via decorator (<code>requires_approval=True</code>), not passed separately to agent Schema ownership Schemas and agent server modules fully owned by DuploCloud REST endpoint naming Lowercase snake_case (<code>/chat</code> instead of <code>/sendMessage</code>) Type safety Use Pydantic models wherever possible"},{"location":"review/review-1/#questions-asked","title":"Questions Asked","text":""},{"location":"review/review-1/#pranav-chakilam","title":"Pranav Chakilam","text":"<ol> <li>Can we go to the slide with all the agent inputs (high-risk tools, system prompt, etc.)?</li> <li>Why is <code>high_risk_tools</code> a separate agent parameter instead of an attribute on the tool itself?</li> <li>What is the input/output of request interceptors? Is it the raw JSON body sent to the LLM API?</li> <li>Can we reuse existing schema classes (e.g., <code>AgentMessage</code>) instead of creating new ones like <code>AgentResult</code>?</li> <li>Does the <code>serve()</code> function contain custom logic or reuse existing code?</li> <li>Are we moving to a stateful session pattern where the agent maintains internal state (like LangChain)?</li> <li>How do we invoke the agent? Can we pass in the entire messages array?</li> <li>How is platform context (kubeconfig, Duplo token) passed to tools without exposing it to the LLM?</li> <li>Does Agno let us log the time taken by an LLM API call and the request body sent?</li> </ol>"},{"location":"review/review-1/#prem-lakshmanan","title":"Prem Lakshmanan","text":"<ol> <li>Are the request interceptors and response interceptors from Agno, or custom additions?</li> <li>There are places using Pydantic models and places using dictionaries \u2014 is this intentional?</li> <li>The session object goes to AI Help Desk and back \u2014 how does this workflow function?</li> <li>What happens with dynamic prompts for caching (values injected at runtime)?</li> <li>Is platform context sent to the LLM? (Concern about sensitive data like kubeconfig)</li> <li>Can we generate PyDocs/documentation from the code?</li> </ol>"},{"location":"review/review-1/#andy-boutte","title":"Andy Boutte","text":"<ol> <li>Did you claim \"decaf\" on PyPI? (To Pranav)</li> <li>Regarding high-risk tools \u2014 shouldn't this be more granular than true/false? (e.g., regex patterns, approval checker functions)</li> <li>The interceptors are a decaf engineering responsibility to place hooks \u2014 am I thinking about that correctly?</li> <li>The interceptor feature is great \u2014 should we commit it upstream to Agno?</li> <li>So system context is just prompt organization to maximize cache hits?</li> <li>Prompt caching increased performance but also cost? Or decreased cost?</li> </ol>"},{"location":"review/review-1/#adam-smith","title":"Adam Smith","text":"<ol> <li>When is the test? When can I feed it into the robot?</li> </ol>"},{"location":"review/review-1/#actionable-items","title":"Actionable Items","text":""},{"location":"review/review-1/#must-address","title":"Must Address","text":"Item Owner Status Notes Move <code>high_risk_tools</code> to tool decorator (<code>requires_approval=True</code>) Chuck Open Pranav's suggestion \u2014 team agreed Review <code>AgentResult</code> vs existing <code>AgentMessage</code> schema Chuck Open Determine if they can be unified Clarify how messages/thread history is passed to agent Chuck Open Pranav asked \u2014 Chuck to investigate Verify platform context is NOT sent to LLM Chuck Open Prem's security concern Confirm how platform context is injected into tools Chuck Open Explain the wrapper/currying mechanism Test prompt caching implementation Chuck Open Currently experimental Claim \"decaf\" on PyPI Pranav Open Andy's suggestion to avoid naming conflicts"},{"location":"review/review-1/#design-considerations","title":"Design Considerations","text":"Item Notes Interceptor granularity Add more hooks over time: before/after tool call, before response flows back, etc. High-risk tool approval Make it more granular \u2014 support regex patterns, approval checker functions (Andy's suggestion) <code>serve()</code> abstraction debate Pranav prefers explicit UVicorn code (transparency); Chuck prefers abstraction (simplicity for customers). Decision: see how it evolves Session naming Pranav suggests \"session\" may be confusing \u2014 consider \"turn_data\" or similar Logging from Agno Verify what Agno logs (timing, request bodies)"},{"location":"review/review-1/#future-work","title":"Future Work","text":"<ul> <li> Add more interceptor hooks as use cases emerge</li> <li> Consider upstream contribution of interceptor feature to Agno</li> <li> Generate public documentation (MKDocs/PyDocs) for customer consumption</li> <li> Test streaming functionality end-to-end</li> <li> Evaluate prompt caching cost/benefit on real agents</li> </ul>"},{"location":"review/review-1/#technical-deep-dives","title":"Technical Deep Dives","text":""},{"location":"review/review-1/#session-state-management","title":"Session State Management","text":"<p>Problem: Data retrieved during a conversation (e.g., tenant info from Neo4j) must be re-fetched on every turn.</p> <p>Solution: Session storage that persists data across conversation turns.</p> <p>Example use case (Architecture Diagram Agent): 1. User asks to diagram all pods 2. Agent queries database, generates diagram 3. User asks to add Docker image versions 4. Without sessions: Re-query database 5. With sessions: Use cached data, regenerate immediately</p> <p>Current implementation: Uses the <code>data</code> attribute in Help Desk responses (server-side storage, transmitted back and forth).</p> <p>Future options: Redis, file storage, database \u2014 swappable via interface.</p>"},{"location":"review/review-1/#prompt-caching","title":"Prompt Caching","text":"<p>How it works: - Cache static portions of prompts (instructions, examples) - Only dynamic content (user input, context) is reprocessed</p> <p>Bedrock specifics: - 4 checkpoints available - Cache expires after 5 minutes of inactivity - Minimum 1,000 tokens required</p> <p>Cost implications: | Operation | Cost | |-----------|------| | First write (cache creation) | ~25% MORE expensive | | Subsequent reads (cache hits) | ~90% CHEAPER, up to 50% faster |</p> <p>Best candidates: Agents with large static prompts and multi-turn conversations (e.g., Architecture Diagram Agent where ~90-95% of prompt is static).</p>"},{"location":"review/review-1/#platform-context-tool-security","title":"Platform Context &amp; Tool Security","text":"<p>Concern: Sensitive data (kubeconfig, Duplo tokens) should NOT be sent to the LLM.</p> <p>Solution: Platform context is injected into tools via function wrapping (currying/<code>functools.partial</code> pattern).</p> <ul> <li>LLM only sees the tool schema with required parameters (e.g., <code>cipher</code>, <code>params</code>)</li> <li>Platform context is pre-bound to the function before LLM invocation</li> <li>Tool receives context at execution time without LLM involvement</li> </ul>"},{"location":"review/review-1/#notable-quotes","title":"Notable Quotes","text":"<p>Pranav: \"An agent, at the end of the day, is one LLM API call and two functions. Everything else is noise.\"</p> <p>Chuck: \"We want to do the most with the least \u2014 most work done, least amount of abstraction.\"</p> <p>Andy: \"We have very low expectations that a customer is gonna build agents end-to-end by themselves [in the short term], but that's absolutely the direction we want things to go.\"</p> <p>Pranav: \"We should try to not have as few lines as possible in the framework, because it can easily become bloated, and then it'll become spaghetti.\"</p>"},{"location":"review/review-1/#appendix-framework-architecture","title":"Appendix: Framework Architecture","text":""},{"location":"review/review-1/#agent-parameters","title":"Agent Parameters","text":"<pre><code>Agent(\n    tools=[...],                    # List of tool functions\n    system_prompt=\"...\",            # Static instructions\n    model=\"...\",                    # Model identifier\n    provider=\"...\",                 # LLM provider (Anthropic, OpenAI, etc.)\n    high_risk_tools=[...],          # DEPRECATED: Move to tool decorator\n    on_event=callback,              # Event handler for logging, etc.\n    request_interceptors=[...],     # Modify requests before LLM\n    response_interceptors=[...]     # Modify responses after LLM\n)\n</code></pre>"},{"location":"review/review-1/#serve-method","title":"Serve Method","text":"<pre><code>serve(\n    agent=agent,      # Agent instance or callable returning AgentResult\n    port=8000,        # Server port\n    host=\"0.0.0.0\",   # Server host\n    workers=4,        # UVicorn worker count\n    timeout=30,       # Request timeout\n    log_level=\"info\"  # Logging verbosity\n)\n</code></pre>"},{"location":"review/review-1/#tool-definition-with-approval","title":"Tool Definition with Approval","text":"<pre><code>@tool(\n    description=\"Execute kubectl command\",\n    requires_approval=True  # Triggers human-in-the-loop\n)\ndef execute_kubectl(command: str, platform_context: PlatformContext):\n    # Platform context injected via wrapper, not by LLM\n    ...\n</code></pre>"},{"location":"review/review-1/#next-steps","title":"Next Steps","text":"<ol> <li>Chuck to address outstanding questions and update design</li> <li>Team code review once implementation hardens</li> <li>Test with existing agents (Architecture Diagram, Kubernetes)</li> <li>Documentation for internal and eventual customer use</li> </ol>"}]}